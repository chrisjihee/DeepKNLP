{"id": "374", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Dish", "Hours", "Restaurant Name", "Cuisine", "Rating", "Amenity", "Price", "Location"], "instance": {"id": "374", "words": ["find", "me", "a", "good", "pho", "restaurant", "in", "portland", "or"], "labels": ["O", "O", "O", "B-Rating", "B-Cuisine", "O", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Hours, Restaurant Name, Cuisine, Rating, Amenity, Price, Location and O.\nSentence: find me a good pho restaurant in portland or", "prompt_labels": "find(O) me(O) a(O) good(B-Rating) pho(B-Cuisine) restaurant(O) in(O) portland(B-Location) or(I-Location)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 30192, 11, 26568, 4076, 11, 81961, 11, 19767, 11, 3383, 56685, 11, 8650, 11, 10067, 323, 507, 627, 85664, 25, 1505, 757, 264, 1695, 1343, 78, 10960, 304, 2700, 1974, 477, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "find(O) me(O) a(O) good(B-Rating) pho(B-Cuisine) restaurant(O) in(O) portland(B-Location) or(I-Location)"}
{"id": "307", "dataset": "crossner_science", "split": "dev", "label_list": ["enzyme", "chemical element", "location", "event", "academic journal", "astronomical object", "scientist", "person", "university", "organization", "chemical compound", "discipline", "theory", "award", "country", "protein"], "instance": {"id": "307", "words": ["In", "the", "2010", "Bandy", "World", "Championship", ",", "he", "scored", "the", "golden", "goal", "in", "the", "final", ",", "giving", "the", "game", "to", "Sweden", "with", "6-5", "against", "Russia", "."], "labels": ["O", "O", "B-event", "I-event", "I-event", "I-event", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-country", "O", "O", "O", "B-country", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: enzyme, chemical element, location, event, academic journal, astronomical object, scientist, person, university, organization, chemical compound, discipline, theory, award, country, protein and O.\nSentence: In the 2010 Bandy World Championship , he scored the golden goal in the final , giving the game to Sweden with 6-5 against Russia .", "prompt_labels": "In(O) the(O) 2010(B-event) Bandy(I-event) World(I-event) Championship(I-event) ,(O) he(O) scored(O) the(O) golden(O) goal(O) in(O) the(O) final(O) ,(O) giving(O) the(O) game(O) to(O) Sweden(B-country) with(O) 6-5(O) against(O) Russia(B-country) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49242, 11, 11742, 2449, 11, 3813, 11, 1567, 11, 14584, 8486, 11, 87283, 1665, 11, 28568, 11, 1732, 11, 12374, 11, 7471, 11, 11742, 24549, 11, 26434, 11, 10334, 11, 10292, 11, 3224, 11, 13128, 323, 507, 627, 85664, 25, 763, 279, 220, 679, 15, 426, 13634, 4435, 19134, 1174, 568, 16957, 279, 21411, 5915, 304, 279, 1620, 1174, 7231, 279, 1847, 311, 24067, 449, 220, 21, 12, 20, 2403, 8524, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "when(O) was(O) the(O) movie(O) sculpture(B-title) released(O)"}
{"id": "1160", "dataset": "mit-movie", "split": "dev", "label_list": ["director", "trailer", "actor", "character", "average ratings", "review", "year", "rating", "genre", "title", "plot", "song"], "instance": {"id": "1160", "words": ["did", "ron", "howard", "direct", "a", "science", "fiction", "film"], "labels": ["O", "B-director", "I-director", "O", "O", "B-genre", "I-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, trailer, actor, character, average ratings, review, year, rating, genre, title, plot, song and O.\nSentence: did ron howard direct a science fiction film", "prompt_labels": "did(O) ron(B-director) howard(I-director) direct(O) a(O) science(B-genre) fiction(I-genre) film(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 19809, 11, 12360, 11, 3752, 11, 5578, 18594, 11, 3477, 11, 1060, 11, 10959, 11, 17779, 11, 2316, 11, 7234, 11, 5609, 323, 507, 627, 85664, 25, 1550, 436, 263, 1268, 569, 2167, 264, 8198, 17422, 4632, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "looking(O) for(O) a(O) restaurant(O) with(O) the(O) highest(B-Rating) approval(I-Rating) ratings(I-Rating)"}
{"id": "114", "dataset": "crossner_literature", "split": "dev", "label_list": ["person", "event", "location", "organization", "literary genre", "award", "magazine", "writer", "poem", "country", "book"], "instance": {"id": "114", "words": ["Writing", "for", "The", "Spectator", "in", "1936", ",", "Graham", "Greene", "gave", "the", "film", "a", "good", "review", ",", "describing", "it", "as", "an", "honest", ",", "interesting", "and", "well-made", "picture", "."], "labels": ["O", "O", "B-magazine", "I-magazine", "O", "O", "O", "B-writer", "I-writer", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, event, location, organization, literary genre, award, magazine, writer, poem, country, book and O.\nSentence: Writing for The Spectator in 1936 , Graham Greene gave the film a good review , describing it as an honest , interesting and well-made picture .", "prompt_labels": "Writing(O) for(O) The(B-magazine) Spectator(I-magazine) in(O) 1936(O) ,(O) Graham(B-writer) Greene(I-writer) gave(O) the(O) film(O) a(O) good(O) review(O) ,(O) describing(O) it(O) as(O) an(O) honest(O) ,(O) interesting(O) and(O) well-made(O) picture(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 1567, 11, 3813, 11, 7471, 11, 32465, 17779, 11, 10292, 11, 14756, 11, 7061, 11, 33894, 11, 3224, 11, 2363, 323, 507, 627, 85664, 25, 24838, 369, 578, 27726, 859, 304, 220, 7285, 21, 1174, 26181, 59174, 6688, 279, 4632, 264, 1695, 3477, 1174, 23524, 433, 439, 459, 10978, 1174, 7185, 323, 1664, 27975, 6945, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "what(O) horror(B-genre) movies(O) featured(O) freddy(B-character) and(O) were(O) rated(O) r(B-rating)"}
{"id": "2269", "dataset": "mit-movie", "split": "dev", "label_list": ["genre", "average ratings", "character", "plot", "actor", "year", "title", "song", "review", "rating", "trailer", "director"], "instance": {"id": "2269", "words": ["when", "was", "the", "movie", "sculpture", "released"], "labels": ["O", "O", "O", "O", "B-title", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, average ratings, character, plot, actor, year, title, song, review, rating, trailer, director and O.\nSentence: when was the movie sculpture released", "prompt_labels": "when(O) was(O) the(O) movie(O) sculpture(B-title) released(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 5578, 18594, 11, 3752, 11, 7234, 11, 12360, 11, 1060, 11, 2316, 11, 5609, 11, 3477, 11, 10959, 11, 19809, 11, 7690, 323, 507, 627, 85664, 25, 994, 574, 279, 5818, 51067, 6004, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "In(O) 1959(O),(O) Capp(B-writer) recorded(O) and(O) released(O) an(O) album(O) for(O) Folkways(B-organization) Records(I-organization) ((O) now(O) owned(O) by(O) the(O) Smithsonian(B-organization) )(O) on(O) which(O) he(O) identified(O) and(O) described(O) The(B-book) Mechanics(I-book) of(I-book) the(I-book) Comic(I-book) Strip(I-book).(O)"}
{"id": "1014", "dataset": "mit-movie", "split": "dev", "label_list": ["director", "genre", "character", "average ratings", "title", "trailer", "plot", "review", "actor", "rating", "song", "year"], "instance": {"id": "1014", "words": ["who", "starred", "in", "switchuing", "goals"], "labels": ["O", "O", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, genre, character, average ratings, title, trailer, plot, review, actor, rating, song, year and O.\nSentence: who starred in switchuing goals", "prompt_labels": "who(O) starred(O) in(O) switchuing(B-title) goals(I-title)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 17779, 11, 3752, 11, 5578, 18594, 11, 2316, 11, 19809, 11, 7234, 11, 3477, 11, 12360, 11, 10959, 11, 5609, 11, 1060, 323, 507, 627, 85664, 25, 889, 59335, 304, 3480, 7623, 9021, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "im(O) looking(O) for(O) a(O) war(B-genre) film(O) from(O) the(O) past(B-year) ten(I-year) years(I-year) rated(O) nc(B-rating) 17(I-rating) and(O) directed(O) by(O) putipong(B-director) saisikaew(I-director)"}
{"id": "551", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Dish", "Price", "Rating", "Restaurant Name", "Amenity", "Hours", "Location", "Cuisine"], "instance": {"id": "551", "words": ["i", "am", "looking", "for", "a", "restaurant", "that", "allows", "smoking"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Price, Rating, Restaurant Name, Amenity, Hours, Location, Cuisine and O.\nSentence: i am looking for a restaurant that allows smoking", "prompt_labels": "i(O) am(O) looking(O) for(O) a(O) restaurant(O) that(O) allows(B-Amenity) smoking(I-Amenity)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 8650, 11, 19767, 11, 26568, 4076, 11, 3383, 56685, 11, 30192, 11, 10067, 11, 81961, 323, 507, 627, 85664, 25, 602, 1097, 3411, 369, 264, 10960, 430, 6276, 20149, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "in(O) the(O) past(B-year) seven(I-year) decades(I-year) was(O) mimi(B-actor) rogers(I-actor) an(O) many(O) adventure(B-genre) films(O)"}
{"id": "348", "dataset": "crossner_music", "split": "dev", "label_list": ["music genre", "song", "location", "country", "person", "award", "musical instrument", "album", "band", "event", "musical artist", "organization"], "instance": {"id": "348", "words": ["Artists", "popularizing", "more", "traditional", "country", "music", "in", "Sweden", "have", "been", "Ann-Louise", "Hanson", ",", "Hasse", "Andersson", ",", "Kikki", "Danielsson", ",", "Elisabeth", "Andreassen", "and", "Jill", "Johnson", "."], "labels": ["O", "O", "O", "B-music genre", "I-music genre", "I-music genre", "O", "B-country", "O", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, song, location, country, person, award, musical instrument, album, band, event, musical artist, organization and O.\nSentence: Artists popularizing more traditional country music in Sweden have been Ann-Louise Hanson , Hasse Andersson , Kikki Danielsson , Elisabeth Andreassen and Jill Johnson .", "prompt_labels": "Artists(O) popularizing(O) more(O) traditional(B-music genre) country(I-music genre) music(I-music genre) in(O) Sweden(B-country) have(O) been(O) Ann-Louise(B-musical artist) Hanson(I-musical artist) ,(O) Hasse(B-musical artist) Andersson(I-musical artist) ,(O) Kikki(B-musical artist) Danielsson(I-musical artist) ,(O) Elisabeth(B-musical artist) Andreassen(I-musical artist) and(O) Jill(B-musical artist) Johnson(I-musical artist) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 4731, 17779, 11, 5609, 11, 3813, 11, 3224, 11, 1732, 11, 10292, 11, 18273, 14473, 11, 8176, 11, 7200, 11, 1567, 11, 18273, 10255, 11, 7471, 323, 507, 627, 85664, 25, 53204, 5526, 4954, 810, 8776, 3224, 4731, 304, 24067, 617, 1027, 9489, 8288, 283, 1082, 76313, 1174, 11697, 325, 48693, 942, 1174, 735, 84641, 15469, 31031, 1174, 91186, 17862, 27525, 28376, 323, 48311, 11605, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "are(O) there(O) any(O) nc(B-rating) 17(I-rating) kids(B-genre) movies(O) from(O) the(O) past(B-year) four(I-year) decades(I-year)"}
{"id": "966", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Price", "Amenity", "Location", "Hours", "Cuisine", "Dish", "Restaurant Name", "Rating"], "instance": {"id": "966", "words": ["looking", "for", "a", "restaurant", "with", "the", "highest", "approval", "ratings"], "labels": ["O", "O", "O", "O", "O", "O", "B-Rating", "I-Rating", "I-Rating"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Amenity, Location, Hours, Cuisine, Dish, Restaurant Name, Rating and O.\nSentence: looking for a restaurant with the highest approval ratings", "prompt_labels": "looking(O) for(O) a(O) restaurant(O) with(O) the(O) highest(B-Rating) approval(I-Rating) ratings(I-Rating)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 3383, 56685, 11, 10067, 11, 30192, 11, 81961, 11, 49268, 11, 26568, 4076, 11, 19767, 323, 507, 627, 85664, 25, 3411, 369, 264, 10960, 449, 279, 8592, 14765, 18594, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "In(O) the(O) 2010(B-event) Bandy(I-event) World(I-event) Championship(I-event),(O) he(O) scored(O) the(O) golden(O) goal(O) in(O) the(O) final(O),(O) giving(O) the(O) game(O) to(O) Sweden(B-country) with(O) 6-5(O) against(O) Russia(B-country).(O)"}
{"id": "1668", "dataset": "mit-movie", "split": "dev", "label_list": ["average ratings", "character", "genre", "review", "actor", "trailer", "plot", "song", "year", "rating", "director", "title"], "instance": {"id": "1668", "words": ["list", "an", "r", "rated", "highly", "recommended", "political", "film", "from", "the", "past", "year"], "labels": ["O", "O", "B-rating", "O", "B-average ratings", "I-average ratings", "B-genre", "O", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, character, genre, review, actor, trailer, plot, song, year, rating, director, title and O.\nSentence: list an r rated highly recommended political film from the past year", "prompt_labels": "list(O) an(O) r(B-rating) rated(O) highly(B-average ratings) recommended(I-average ratings) political(B-genre) film(O) from(O) the(O) past(B-year) year(I-year)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 3752, 11, 17779, 11, 3477, 11, 12360, 11, 19809, 11, 7234, 11, 5609, 11, 1060, 11, 10959, 11, 7690, 11, 2316, 323, 507, 627, 85664, 25, 1160, 459, 436, 22359, 7701, 11349, 5054, 4632, 505, 279, 3347, 1060, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "who(O) starred(O) in(O) switchuing(B-title) goals(I-title)"}
{"id": "1751", "dataset": "mit-movie", "split": "dev", "label_list": ["average ratings", "song", "genre", "year", "title", "rating", "plot", "director", "actor", "trailer", "review", "character"], "instance": {"id": "1751", "words": ["please", "list", "some", "mediocre", "film", "noir", "movies", "released", "in", "the", "past", "two", "decades", "directed", "by", "robert", "hiltzik"], "labels": ["O", "O", "O", "B-average ratings", "B-genre", "I-genre", "O", "O", "O", "O", "B-year", "I-year", "I-year", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, song, genre, year, title, rating, plot, director, actor, trailer, review, character and O.\nSentence: please list some mediocre film noir movies released in the past two decades directed by robert hiltzik", "prompt_labels": "please(O) list(O) some(O) mediocre(B-average ratings) film(B-genre) noir(I-genre) movies(O) released(O) in(O) the(O) past(B-year) two(I-year) decades(I-year) directed(O) by(O) robert(B-director) hiltzik(I-director)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 5609, 11, 17779, 11, 1060, 11, 2316, 11, 10959, 11, 7234, 11, 7690, 11, 12360, 11, 19809, 11, 3477, 11, 3752, 323, 507, 627, 85664, 25, 4587, 1160, 1063, 68480, 4632, 56662, 9698, 6004, 304, 279, 3347, 1403, 11026, 15910, 555, 89993, 305, 3036, 76574, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "list(O) an(O) r(B-rating) rated(O) highly(B-average ratings) recommended(I-average ratings) political(B-genre) film(O) from(O) the(O) past(B-year) year(I-year)"}
{"id": "517", "dataset": "mit-movie", "split": "dev", "label_list": ["average ratings", "trailer", "plot", "character", "actor", "song", "rating", "year", "director", "genre", "review", "title"], "instance": {"id": "517", "words": ["what", "character", "did", "morgan", "freeman", "play", "in", "shawshank", "redemption"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, trailer, plot, character, actor, song, rating, year, director, genre, review, title and O.\nSentence: what character did morgan freeman play in shawshank redemption", "prompt_labels": "what(O) character(O) did(O) morgan(B-actor) freeman(I-actor) play(O) in(O) shawshank(B-title) redemption(I-title)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 19809, 11, 7234, 11, 3752, 11, 12360, 11, 5609, 11, 10959, 11, 1060, 11, 7690, 11, 17779, 11, 3477, 11, 2316, 323, 507, 627, 85664, 25, 1148, 3752, 1550, 296, 8629, 3541, 16357, 1514, 304, 559, 675, 939, 1201, 56752, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "is(O) there(O) a(O) movie(O) starring(O) james(B-actor) cagney(I-actor)"}
{"id": "737", "dataset": "mit-movie", "split": "dev", "label_list": ["song", "trailer", "rating", "actor", "title", "review", "character", "plot", "year", "genre", "average ratings", "director"], "instance": {"id": "737", "words": ["what", "horror", "movies", "featured", "freddy", "and", "were", "rated", "r"], "labels": ["O", "B-genre", "O", "O", "B-character", "O", "O", "B-rating", "I-rating"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, trailer, rating, actor, title, review, character, plot, year, genre, average ratings, director and O.\nSentence: what horror movies featured freddy and were rated r", "prompt_labels": "what(O) horror(B-genre) movies(O) featured(O) freddy(B-character) and(O) were(O) rated(B-rating) r(I-rating)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 19809, 11, 10959, 11, 12360, 11, 2316, 11, 3477, 11, 3752, 11, 7234, 11, 1060, 11, 17779, 11, 5578, 18594, 11, 7690, 323, 507, 627, 85664, 25, 1148, 22169, 9698, 15109, 3541, 54610, 323, 1051, 22359, 436, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "im(O) hungry(O) and(O) i(O) feel(O) like(O) eating(O) chinese(B-Cuisine)"}
{"id": "1522", "dataset": "mit-movie", "split": "dev", "label_list": ["year", "song", "character", "review", "rating", "director", "actor", "average ratings", "title", "plot", "genre", "trailer"], "instance": {"id": "1522", "words": ["is", "there", "a", "movie", "starring", "james", "cagney"], "labels": ["O", "O", "O", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, song, character, review, rating, director, actor, average ratings, title, plot, genre, trailer and O.\nSentence: is there a movie starring james cagney", "prompt_labels": "is(O) there(O) a(O) movie(O) starring(O) james(B-actor) cagney(I-actor)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 5609, 11, 3752, 11, 3477, 11, 10959, 11, 7690, 11, 12360, 11, 5578, 18594, 11, 2316, 11, 7234, 11, 17779, 11, 19809, 323, 507, 627, 85664, 25, 374, 1070, 264, 5818, 40500, 86046, 272, 351, 3520, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "is(O) anthony(B-actor) hopkins(I-actor) in(O) a(O) musical(B-genre)"}
{"id": "998", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Dish", "Price", "Restaurant Name", "Location", "Rating", "Cuisine", "Amenity", "Hours"], "instance": {"id": "998", "words": ["may", "i", "have", "the", "business", "hours", "for", "the", "nearest", "red", "lobster"], "labels": ["O", "O", "O", "O", "B-Hours", "O", "O", "O", "B-Location", "B-Restaurant Name", "I-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Price, Restaurant Name, Location, Rating, Cuisine, Amenity, Hours and O.\nSentence: may i have the business hours for the nearest red lobster", "prompt_labels": "may(O) i(O) have(O) the(O) business(B-Hours) hours(O) for(O) the(O) nearest(B-Location) red(B-Restaurant Name) lobster(I-Restaurant Name)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 8650, 11, 26568, 4076, 11, 10067, 11, 19767, 11, 81961, 11, 3383, 56685, 11, 30192, 323, 507, 627, 85664, 25, 1253, 602, 617, 279, 2626, 4207, 369, 279, 24379, 2579, 80815, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "In(O) addition(O) to(O) his(O) steady(O) research(O) output(O),(O) Naqvi(B-scientist) has(O) manifested(O) his(O) commitment(O) to(O) teaching(O) by(O) contributing(O) to(O) journals(O) devoted(O) to(O) didactical(O) aspects(O) of(O) science(O) ((O) American(B-academic journal) Journal(I-academic journal),(O) European(B-academic journal) Journal(I-academic journal),(O) Journal(B-academic journal) of(I-academic journal) Chemical(I-academic journal) Education(I-academic journal) )(O).(O)"}
{"id": "83", "dataset": "crossner_literature", "split": "dev", "label_list": ["poem", "literary genre", "country", "person", "writer", "magazine", "book", "event", "location", "award", "organization"], "instance": {"id": "83", "words": [")", "Huxley", "received", "screen", "credit", "for", "Pride", "and", "Prejudice", "(", "1940", ")", "and", "was", "paid", "for", "his", "work", "on", "a", "number", "of", "other", "films", ",", "including", "Jane", "Eyre", "(", "1944", ")", "."], "labels": ["O", "B-writer", "O", "B-award", "I-award", "O", "B-book", "I-book", "I-book", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: poem, literary genre, country, person, writer, magazine, book, event, location, award, organization and O.\nSentence: ) Huxley received screen credit for Pride and Prejudice ( 1940 ) and was paid for his work on a number of other films , including Jane Eyre ( 1944 ) .", "prompt_labels": ")(O) Huxley(B-writer) received(O) screen(B-award) credit(I-award) for(O) Pride(B-book) and(I-book) Prejudice(I-book) ((O) 1940(O) )(O) and(O) was(O) paid(O) for(O) his(O) work(O) on(O) a(O) number(O) of(O) other(O) films(O) ,(O) including(O) Jane(O) Eyre(O) ((O) 1944(O) )(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 33894, 11, 32465, 17779, 11, 3224, 11, 1732, 11, 7061, 11, 14756, 11, 2363, 11, 1567, 11, 3813, 11, 10292, 11, 7471, 323, 507, 627, 85664, 25, 883, 473, 2249, 3258, 4036, 4264, 6807, 369, 43246, 323, 5075, 18631, 560, 320, 220, 6393, 15, 883, 323, 574, 7318, 369, 813, 990, 389, 264, 1396, 315, 1023, 12631, 1174, 2737, 22195, 44511, 265, 320, 220, 6393, 19, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "take(O) me(O) to(O) the(O) closest(B-Location) restaurant(O) i(O) can(O) smoke(B-Amenity) in(I-Amenity)"}
{"id": "135", "dataset": "crossner_literature", "split": "dev", "label_list": ["person", "location", "award", "book", "writer", "magazine", "event", "literary genre", "organization", "poem", "country"], "instance": {"id": "135", "words": ["In", "1959", ",", "Capp", "recorded", "and", "released", "an", "album", "for", "Folkways", "Records", "(", "now", "owned", "by", "the", "Smithsonian", ")", "on", "which", "he", "identified", "and", "described", "The", "Mechanics", "of", "the", "Comic", "Strip", "."], "labels": ["O", "O", "O", "B-writer", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "O", "O", "O", "O", "B-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, location, award, book, writer, magazine, event, literary genre, organization, poem, country and O.\nSentence: In 1959 , Capp recorded and released an album for Folkways Records ( now owned by the Smithsonian ) on which he identified and described The Mechanics of the Comic Strip .", "prompt_labels": "In(O) 1959(O) ,(O) Capp(B-writer) recorded(O) and(O) released(O) an(O) album(O) for(O) Folkways(B-organization) Records(I-organization) ((O) now(O) owned(O) by(O) the(O) Smithsonian(B-organization) )(O) on(O) which(O) he(O) identified(O) and(O) described(O) The(O) Mechanics(O) of(O) the(O) Comic(O) Strip(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 3813, 11, 10292, 11, 2363, 11, 7061, 11, 14756, 11, 1567, 11, 32465, 17779, 11, 7471, 11, 33894, 11, 3224, 323, 507, 627, 85664, 25, 763, 220, 6280, 24, 1174, 356, 680, 12715, 323, 6004, 459, 8176, 369, 65337, 2336, 22293, 320, 1457, 13234, 555, 279, 89289, 883, 389, 902, 568, 11054, 323, 7633, 578, 77923, 315, 279, 41063, 35999, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "did(O) ron(B-director) howard(I-director) direct(O) a(O) science(B-genre) fiction(I-genre) film(O)"}
{"id": "719", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Cuisine", "Price", "Restaurant Name", "Amenity", "Location", "Hours", "Rating", "Dish"], "instance": {"id": "719", "words": ["im", "hungry", "and", "i", "feel", "like", "eating", "chinese"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-Cuisine"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Price, Restaurant Name, Amenity, Location, Hours, Rating, Dish and O.\nSentence: im hungry and i feel like eating chinese", "prompt_labels": "im(O) hungry(O) and(O) i(O) feel(O) like(O) eating(O) chinese(B-Cuisine)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 8650, 11, 26568, 4076, 11, 3383, 56685, 11, 10067, 11, 30192, 11, 19767, 11, 49268, 323, 507, 627, 85664, 25, 737, 30056, 323, 602, 2733, 1093, 12459, 57487, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "i(O) am(O) looking(O) for(O) a(O) restaurant(O) that(O) allows(B-Amenity) smoking(I-Amenity)"}
{"id": "1496", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Price", "Dish", "Location", "Rating", "Restaurant Name", "Hours", "Amenity", "Cuisine"], "instance": {"id": "1496", "words": ["which", "restaurants", "are", "open", "after", "midnight", "on", "a", "wednesday"], "labels": ["O", "O", "O", "B-Hours", "I-Hours", "I-Hours", "I-Hours", "I-Hours", "I-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Dish, Location, Rating, Restaurant Name, Hours, Amenity, Cuisine and O.\nSentence: which restaurants are open after midnight on a wednesday", "prompt_labels": "which(O) restaurants(O) are(O) open(B-Hours) after(I-Hours) midnight(I-Hours) on(I-Hours) a(I-Hours) wednesday(I-Hours)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 49268, 11, 10067, 11, 19767, 11, 26568, 4076, 11, 30192, 11, 3383, 56685, 11, 81961, 323, 507, 627, 85664, 25, 902, 15926, 527, 1825, 1306, 33433, 389, 264, 11077, 7465, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "please(O) list(O) some(O) mediocre(B-average ratings) film(B-genre) noir(I-genre) movies(O) released(O) in(O) the(O) past(B-year) two(I-year) decades(I-year) directed(O) by(O) robert(B-director) hiltzik(I-director)"}
{"id": "1412", "dataset": "mit-movie", "split": "dev", "label_list": ["genre", "average ratings", "review", "actor", "character", "year", "song", "title", "director", "trailer", "plot", "rating"], "instance": {"id": "1412", "words": ["in", "the", "last", "five", "decades", "was", "there", "a", "family", "film", "that", "aaron", "woolf", "directed"], "labels": ["O", "O", "B-year", "I-year", "I-year", "O", "O", "O", "B-genre", "O", "O", "B-director", "I-director", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, average ratings, review, actor, character, year, song, title, director, trailer, plot, rating and O.\nSentence: in the last five decades was there a family film that aaron woolf directed", "prompt_labels": "in(O) the(O) last(B-year) five(I-year) decades(I-year) was(O) there(O) a(O) family(B-genre) film(O) that(O) aaron(B-director) woolf(I-director) directed(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 5578, 18594, 11, 3477, 11, 12360, 11, 3752, 11, 1060, 11, 5609, 11, 2316, 11, 7690, 11, 19809, 11, 7234, 11, 10959, 323, 507, 627, 85664, 25, 304, 279, 1566, 4330, 11026, 574, 1070, 264, 3070, 4632, 430, 264, 13055, 39640, 69, 15910, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "may(O) i(O) have(O) the(O) business(B-Hours) hours(I-Hours) for(O) the(O) nearest(B-Location) red(B-Restaurant Name) lobster(I-Restaurant Name)"}
{"id": "1370", "dataset": "mit-movie", "split": "dev", "label_list": ["review", "rating", "trailer", "character", "actor", "plot", "genre", "average ratings", "title", "song", "director", "year"], "instance": {"id": "1370", "words": ["im", "looking", "for", "a", "war", "film", "from", "the", "past", "ten", "years", "rated", "nc", "17", "and", "directed", "by", "putipong", "saisikaew"], "labels": ["O", "O", "O", "O", "B-genre", "O", "O", "O", "B-year", "I-year", "I-year", "O", "B-rating", "I-rating", "O", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, rating, trailer, character, actor, plot, genre, average ratings, title, song, director, year and O.\nSentence: im looking for a war film from the past ten years rated nc 17 and directed by putipong saisikaew", "prompt_labels": "im(O) looking(O) for(O) a(O) war(B-genre) film(O) from(O) the(O) past(B-year) ten(I-year) years(I-year) rated(O) nc(B-rating) 17(I-rating) and(O) directed(O) by(O) putipong(B-director) saisikaew(I-director)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 10959, 11, 19809, 11, 3752, 11, 12360, 11, 7234, 11, 17779, 11, 5578, 18594, 11, 2316, 11, 5609, 11, 7690, 11, 1060, 323, 507, 627, 85664, 25, 737, 3411, 369, 264, 4208, 4632, 505, 279, 3347, 5899, 1667, 22359, 26183, 220, 1114, 323, 15910, 555, 2231, 575, 647, 63762, 11755, 365, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "which(O) restaurants(O) are(O) open(B-Hours) after(I-Hours) midnight(I-Hours) on(I-Hours) a(I-Hours) wednesday(I-Hours)"}
{"id": "2353", "dataset": "mit-movie", "split": "dev", "label_list": ["title", "plot", "character", "song", "year", "average ratings", "actor", "genre", "review", "rating", "trailer", "director"], "instance": {"id": "2353", "words": ["is", "anthony", "hopkins", "in", "a", "musical"], "labels": ["O", "B-actor", "I-actor", "O", "O", "B-genre"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, plot, character, song, year, average ratings, actor, genre, review, rating, trailer, director and O.\nSentence: is anthony hopkins in a musical", "prompt_labels": "is(O) anthony(B-actor) hopkins(I-actor) in(O) a(O) musical(B-genre)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 7234, 11, 3752, 11, 5609, 11, 1060, 11, 5578, 18594, 11, 12360, 11, 17779, 11, 3477, 11, 10959, 11, 19809, 11, 7690, 323, 507, 627, 85664, 25, 374, 23064, 3633, 7598, 11966, 304, 264, 18273, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "The(O) Conservative(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) took(O) back(O) this(O) historically(O) New(O) Democratic(O) Party(O) ((O) NDP(B-political party) )(O) seat(O) in(O) 2004(B-election) Canadian(I-election) federal(I-election) election(I-election).(O)"}
{"id": "17", "dataset": "crossner_politics", "split": "dev", "label_list": ["event", "organization", "election", "person", "location", "political party", "country", "politician"], "instance": {"id": "17", "words": ["The", "Conservative", "Party", "of", "Canada", "took", "back", "this", "historically", "New", "Democratic", "Party", "(", "NDP", ")", "seat", "in", "2004", "Canadian", "federal", "election", "."], "labels": ["O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "O", "B-political party", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, organization, election, person, location, political party, country, politician and O.\nSentence: The Conservative Party of Canada took back this historically New Democratic Party ( NDP ) seat in 2004 Canadian federal election .", "prompt_labels": "The(O) Conservative(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) took(O) back(O) this(O) historically(O) New(B-political party) Democratic(I-political party) Party(I-political party) ((O) NDP(B-political party) )(O) seat(O) in(O) 2004(B-election) Canadian(I-election) federal(I-election) election(I-election) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 7471, 11, 6355, 11, 1732, 11, 3813, 11, 5054, 4717, 11, 3224, 11, 37038, 323, 507, 627, 85664, 25, 578, 30071, 8722, 315, 7008, 3952, 1203, 420, 35901, 1561, 11650, 8722, 320, 54750, 883, 10954, 304, 220, 1049, 19, 12152, 6918, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "where(O) can(O) a(O) group(B-Amenity) be(I-Amenity) served(I-Amenity) omelets(B-Dish)"}
{"id": "161", "dataset": "crossner_literature", "split": "dev", "label_list": ["person", "poem", "writer", "award", "book", "event", "literary genre", "location", "country", "magazine", "organization"], "instance": {"id": "161", "words": ["Gordon", "continued", "her", "stage", "acting", "career", "in", "the", "1950s", ",", "and", "was", "nominated", "for", "a", "1956", "Tony", "Award", ",", "for", "Tony", "Award", "for", "Best", "Performance", "by", "a", "Leading", "Actress", "in", "a", "Play", ",", "for", "her", "portrayal", "of", "Dolly", "Levi", "in", "Thornton", "Wilder", "'", "s", "The", "Matchmaker", ",", "a", "role", "she", "also", "played", "in", "London", ",", "Edinburgh", "and", "Berlin", "."], "labels": ["B-person", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "B-writer", "I-writer", "O", "O", "B-book", "I-book", "O", "O", "O", "O", "O", "O", "O", "B-location", "O", "B-location", "O", "B-location", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, poem, writer, award, book, event, literary genre, location, country, magazine, organization and O.\nSentence: Gordon continued her stage acting career in the 1950s , and was nominated for a 1956 Tony Award , for Tony Award for Best Performance by a Leading Actress in a Play , for her portrayal of Dolly Levi in Thornton Wilder ' s The Matchmaker , a role she also played in London , Edinburgh and Berlin .", "prompt_labels": "Gordon(B-person) continued(O) her(O) stage(O) acting(O) career(O) in(O) the(O) 1950s(O) ,(O) and(O) was(O) nominated(O) for(O) a(O) 1956(O) Tony(B-award) Award(I-award) ,(O) for(O) Tony(B-award) Award(I-award) for(I-award) Best(I-award) Performance(I-award) by(O) a(O) Leading(O) Actress(O) in(O) a(O) Play(O) ,(O) for(O) her(O) portrayal(O) of(O) Dolly(B-person) Levi(I-person) in(O) Thornton(B-writer) Wilder(I-writer) '(O) s(O) The(B-book) Matchmaker(I-book) ,(O) a(O) role(O) she(O) also(O) played(O) in(O) London(B-location) ,(O) Edinburgh(B-location) and(O) Berlin(B-location) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 33894, 11, 7061, 11, 10292, 11, 2363, 11, 1567, 11, 32465, 17779, 11, 3813, 11, 3224, 11, 14756, 11, 7471, 323, 507, 627, 85664, 25, 26952, 8738, 1077, 6566, 15718, 7076, 304, 279, 220, 6280, 15, 82, 1174, 323, 574, 39048, 369, 264, 220, 6280, 21, 19036, 17768, 1174, 369, 19036, 17768, 369, 7252, 21304, 555, 264, 59143, 79539, 304, 264, 7199, 1174, 369, 1077, 75033, 315, 423, 8788, 56141, 304, 79334, 13944, 261, 364, 274, 578, 14484, 26850, 1174, 264, 3560, 1364, 1101, 6476, 304, 7295, 1174, 41406, 323, 20437, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Carter(B-writer) has(O) been(O) nominated(O) nine(O) times(O) for(O) the(O) Grammy(B-award) Award(I-award) for(I-award) Best(I-award) Spoken(I-award) Word(I-award) Album(I-award) for(I-award) audio(I-award) recordings(I-award) of(I-award) his(I-award) books(I-award),(O) and(O) has(O) won(O) three(O) times(O) -(O) for(O) Our(B-book) Endangered(I-book) Values(I-book) ((O) 2007(O) )(O),(O) A(B-book) Full(I-book) Life(I-book) :(I-book) Reflections(I-book) at(I-book) 90(I-book) ((O) 2016(O) )(O) and(O) Faith(B-book) :(I-book) A(I-book) Journey(I-book) For(I-book) All(I-book) ((O) 2019(O) )(O).(O)"}
{"id": "1425", "dataset": "mit-movie", "split": "dev", "label_list": ["year", "rating", "review", "director", "title", "trailer", "genre", "character", "average ratings", "song", "plot", "actor"], "instance": {"id": "1425", "words": ["in", "the", "past", "seven", "decades", "was", "mimi", "rogers", "an", "many", "adventure", "films"], "labels": ["O", "O", "B-year", "I-year", "I-year", "O", "B-actor", "I-actor", "O", "O", "B-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, rating, review, director, title, trailer, genre, character, average ratings, song, plot, actor and O.\nSentence: in the past seven decades was mimi rogers an many adventure films", "prompt_labels": "in(O) the(O) past(B-year) seven(I-year) decades(I-year) was(O) mimi(B-actor) rogers(I-actor) an(O) many(O) adventure(B-genre) films(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 10959, 11, 3477, 11, 7690, 11, 2316, 11, 19809, 11, 17779, 11, 3752, 11, 5578, 18594, 11, 5609, 11, 7234, 11, 12360, 323, 507, 627, 85664, 25, 304, 279, 3347, 8254, 11026, 574, 296, 25877, 938, 10863, 459, 1690, 18427, 12631, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Writing(O) for(O) The(B-magazine) Spectator(I-magazine) in(O) 1936(O),(O) Graham(B-writer) Greene(I-writer) gave(O) the(O) film(O) a(O) good(O) review(O),(O) describing(O) it(O) as(O) an(O) honest(O),(O) interesting(O) and(O) well-made(O) picture(O).(O)"}
{"id": "13", "dataset": "crossner_science", "split": "dev", "label_list": ["university", "chemical element", "event", "academic journal", "country", "scientist", "location", "protein", "person", "astronomical object", "award", "organization", "discipline", "chemical compound", "enzyme", "theory"], "instance": {"id": "13", "words": ["In", "addition", "to", "his", "steady", "research", "output", ",", "Naqvi", "has", "manifested", "his", "commitment", "to", "teaching", "by", "contributing", "to", "journals", "devoted", "to", "didactical", "aspects", "of", "science", "(", "American", "Journal", "of", "Physics", ",", "European", "Journal", "of", "Physics", ",", "Journal", "of", "Chemical", "Education", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-scientist", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, chemical element, event, academic journal, country, scientist, location, protein, person, astronomical object, award, organization, discipline, chemical compound, enzyme, theory and O.\nSentence: In addition to his steady research output , Naqvi has manifested his commitment to teaching by contributing to journals devoted to didactical aspects of science ( American Journal of Physics , European Journal of Physics , Journal of Chemical Education ) .", "prompt_labels": "In(O) addition(O) to(O) his(O) steady(O) research(O) output(O) ,(O) Naqvi(B-scientist) has(O) manifested(O) his(O) commitment(O) to(O) teaching(O) by(O) contributing(O) to(O) journals(O) devoted(O) to(O) didactical(O) aspects(O) of(O) science(O) ((O) American(B-academic journal) Journal(I-academic journal) of(I-academic journal) Physics(I-academic journal) ,(O) European(B-academic journal) Journal(I-academic journal) of(I-academic journal) Physics(I-academic journal) ,(O) Journal(B-academic journal) of(I-academic journal) Chemical(I-academic journal) Education(I-academic journal) )(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12374, 11, 11742, 2449, 11, 1567, 11, 14584, 8486, 11, 3224, 11, 28568, 11, 3813, 11, 13128, 11, 1732, 11, 87283, 1665, 11, 10292, 11, 7471, 11, 26434, 11, 11742, 24549, 11, 49242, 11, 10334, 323, 507, 627, 85664, 25, 763, 5369, 311, 813, 24981, 3495, 2612, 1174, 13106, 80, 10176, 706, 79754, 813, 15507, 311, 12917, 555, 29820, 311, 42780, 29329, 311, 1550, 37119, 13878, 315, 8198, 320, 3778, 10139, 315, 28415, 1174, 7665, 10139, 315, 28415, 1174, 10139, 315, 36424, 11930, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Artists(O) popularizing(O) more(O) traditional(O) country(O) music(O) in(O) Sweden(B-country) have(O) been(O) Ann-Louise(B-musical artist) Hanson(I-musical artist),(O) Hasse(B-musical artist) Andersson(I-musical artist),(O) Kikki(B-musical artist) Danielsson(I-musical artist),(O) Elisabeth(B-musical artist) Andreassen(I-musical artist) and(O) Jill(B-musical artist) Johnson(I-musical artist).(O)"}
{"id": "1255", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Hours", "Rating", "Dish", "Price", "Restaurant Name", "Amenity", "Location", "Cuisine"], "instance": {"id": "1255", "words": ["where", "can", "a", "group", "be", "served", "omelets"], "labels": ["O", "O", "O", "O", "O", "O", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Rating, Dish, Price, Restaurant Name, Amenity, Location, Cuisine and O.\nSentence: where can a group be served omelets", "prompt_labels": "where(O) can(O) a(O) group(O) be(O) served(O) omelets(B-Dish)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 19767, 11, 49268, 11, 8650, 11, 26568, 4076, 11, 3383, 56685, 11, 10067, 11, 81961, 323, 507, 627, 85664, 25, 1405, 649, 264, 1912, 387, 10434, 297, 2727, 10145, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "what(O) character(O) did(O) morgan(B-actor) freeman(I-actor) play(O) in(O) shawshank(B-title) redemption(I-title)"}
{"id": "254", "dataset": "crossner_science", "split": "dev", "label_list": ["scientist", "country", "academic journal", "enzyme", "university", "location", "discipline", "organization", "chemical compound", "chemical element", "theory", "award", "person", "astronomical object", "protein", "event"], "instance": {"id": "254", "words": ["Gadagkar", "has", "published", "over", "275", "scientific", "papers", "and", "articles", "in", "various", "international", "journals", "as", "well", "as", "in", "Indian", "journals", "like", "Current", "Science", "magazine", ",", "and", "the", "Journal", "of", "Biosciences", "(", "India", ")", ",", "both", "published", "from", "Bangalore", "."], "labels": ["B-scientist", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-academic journal", "I-academic journal", "O", "O", "O", "O", "B-academic journal", "I-academic journal", "I-academic journal", "O", "B-country", "O", "O", "O", "O", "O", "B-location", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, country, academic journal, enzyme, university, location, discipline, organization, chemical compound, chemical element, theory, award, person, astronomical object, protein, event and O.\nSentence: Gadagkar has published over 275 scientific papers and articles in various international journals as well as in Indian journals like Current Science magazine , and the Journal of Biosciences ( India ) , both published from Bangalore .", "prompt_labels": "Gadagkar(B-scientist) has(O) published(O) over(O) 275(O) scientific(O) papers(O) and(O) articles(O) in(O) various(O) international(O) journals(O) as(O) well(O) as(O) in(O) Indian(O) journals(O) like(O) Current(B-academic journal) Science(I-academic journal) magazine(O) ,(O) and(O) the(O) Journal(B-academic journal) of(I-academic journal) Biosciences(I-academic journal) ((O) India(B-country) )(O) ,(O) both(O) published(O) from(O) Bangalore(B-location) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 28568, 11, 3224, 11, 14584, 8486, 11, 49242, 11, 12374, 11, 3813, 11, 26434, 11, 7471, 11, 11742, 24549, 11, 11742, 2449, 11, 10334, 11, 10292, 11, 1732, 11, 87283, 1665, 11, 13128, 11, 1567, 323, 507, 627, 85664, 25, 72042, 351, 29234, 706, 4756, 927, 220, 14417, 12624, 16064, 323, 9908, 304, 5370, 6625, 42780, 439, 1664, 439, 304, 7904, 42780, 1093, 9303, 10170, 14756, 1174, 323, 279, 10139, 315, 77948, 5979, 2436, 320, 6890, 883, 1174, 2225, 4756, 505, 59225, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": ")(O) Huxley(B-writer) received(O) screen(O) credit(O) for(O) Pride(B-title) and(I-title) Prejudice(I-title) ((O) 1940(O) )(O) and(O) was(O) paid(O) for(O) his(O) work(O) on(O) a(O) number(O) of(O) other(O) films(O),(O) including(O) Jane(B-title) Eyre(I-title) ((O) 1944(O) )(O).(O)"}
{"id": "1078", "dataset": "mit-movie", "split": "dev", "label_list": ["character", "plot", "trailer", "rating", "year", "genre", "average ratings", "song", "director", "title", "review", "actor"], "instance": {"id": "1078", "words": ["are", "there", "any", "nc", "17", "kids", "movies", "from", "the", "past", "four", "decades"], "labels": ["O", "O", "O", "B-rating", "I-rating", "B-genre", "O", "O", "O", "B-year", "I-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, plot, trailer, rating, year, genre, average ratings, song, director, title, review, actor and O.\nSentence: are there any nc 17 kids movies from the past four decades", "prompt_labels": "are(O) there(O) any(O) nc(B-rating) 17(I-rating) kids(B-genre) movies(O) from(O) the(O) past(B-year) four(I-year) decades(I-year)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 7234, 11, 19809, 11, 10959, 11, 1060, 11, 17779, 11, 5578, 18594, 11, 5609, 11, 7690, 11, 2316, 11, 3477, 11, 12360, 323, 507, 627, 85664, 25, 527, 1070, 904, 26183, 220, 1114, 6980, 9698, 505, 279, 3347, 3116, 11026, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "in(O) the(O) last(B-year) five(I-year) decades(I-year) was(O) there(O) a(O) family(B-genre) film(O) that(O) aaron(B-director) woolf(I-director) directed(O)"}
{"id": "1076", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Restaurant Name", "Hours", "Amenity", "Location", "Cuisine", "Price", "Rating", "Dish"], "instance": {"id": "1076", "words": ["take", "me", "to", "the", "closest", "restaurant", "i", "can", "smoke", "in"], "labels": ["O", "O", "O", "O", "B-Location", "O", "O", "O", "B-Amenity", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Hours, Amenity, Location, Cuisine, Price, Rating, Dish and O.\nSentence: take me to the closest restaurant i can smoke in", "prompt_labels": "take(O) me(O) to(O) the(O) closest(B-Location) restaurant(O) i(O) can(O) smoke(B-Amenity) in(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 30192, 11, 3383, 56685, 11, 10067, 11, 81961, 11, 8650, 11, 19767, 11, 49268, 323, 507, 627, 85664, 25, 1935, 757, 311, 279, 18585, 10960, 602, 649, 16603, 304, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Gordon(B-person) continued(O) her(O) stage(O) acting(O) career(O) in(O) the(O) 1950s(O),(O) and(O) was(O) nominated(O) for(O) a(O) 1956(B-award) Tony(I-award) Award(I-award),(O) for(O) her(O) portrayal(O) of(O) Dolly(B-character) Levi(I-character) in(O) Thornton(B-writer) Wilder(I-writer) '(O) s(O) The(B-book) Matchmaker(I-book),(O) a(O) role(O) she(O) also(O) played(O) in(O) London(B-location),(O) Edinburgh(B-location) and(O) Berlin(B-location).(O)"}
{"id": "184", "dataset": "crossner_literature", "split": "dev", "label_list": ["writer", "award", "magazine", "book", "country", "event", "poem", "location", "organization", "person", "literary genre"], "instance": {"id": "184", "words": ["Carter", "has", "been", "nominated", "nine", "times", "for", "the", "Grammy", "Award", "for", "Best", "Spoken", "Word", "Album", "for", "audio", "recordings", "of", "his", "books", ",", "and", "has", "won", "three", "times", "-", "for", "Our", "Endangered", "Values", "(", "2007", ")", ",", "A", "Full", "Life", ":", "Reflections", "at", "90", "(", "2016", ")", "and", "Faith", ":", "A", "Journey", "For", "All", "(", "2019", ")", "."], "labels": ["B-person", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-book", "I-book", "I-book", "O", "O", "O", "O", "B-book", "I-book", "I-book", "I-book", "I-book", "I-book", "I-book", "O", "O", "O", "O", "B-book", "I-book", "I-book", "I-book", "I-book", "I-book", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: writer, award, magazine, book, country, event, poem, location, organization, person, literary genre and O.\nSentence: Carter has been nominated nine times for the Grammy Award for Best Spoken Word Album for audio recordings of his books , and has won three times - for Our Endangered Values ( 2007 ) , A Full Life : Reflections at 90 ( 2016 ) and Faith : A Journey For All ( 2019 ) .", "prompt_labels": "Carter(B-person) has(O) been(O) nominated(O) nine(O) times(O) for(O) the(O) Grammy(B-award) Award(I-award) for(I-award) Best(I-award) Spoken(I-award) Word(I-award) Album(I-award) for(O) audio(O) recordings(O) of(O) his(O) books(O) ,(O) and(O) has(O) won(O) three(O) times(O) -(O) for(O) Our(B-book) Endangered(I-book) Values(I-book) ((O) 2007(O) )(O) ,(O) A(B-book) Full(I-book) Life(I-book) :(I-book) Reflections(I-book) at(I-book) 90(I-book) ((O) 2016(O) )(O) and(O) Faith(B-book) :(I-book) A(I-book) Journey(I-book) For(I-book) All(I-book) ((O) 2019(O) )(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7061, 11, 10292, 11, 14756, 11, 2363, 11, 3224, 11, 1567, 11, 33894, 11, 3813, 11, 7471, 11, 1732, 11, 32465, 17779, 323, 507, 627, 85664, 25, 25581, 706, 1027, 39048, 11888, 3115, 369, 279, 74679, 17768, 369, 7252, 3165, 1713, 9506, 26749, 369, 7855, 38140, 315, 813, 6603, 1174, 323, 706, 2834, 2380, 3115, 482, 369, 5751, 4060, 97409, 26028, 320, 220, 1049, 22, 883, 1174, 362, 8797, 9601, 551, 43976, 82, 520, 220, 1954, 320, 220, 679, 21, 883, 323, 34053, 551, 362, 43680, 1789, 2052, 320, 220, 679, 24, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Gadagkar(B-scientist) has(O) published(O) over(O) 275(O) scientific(O) papers(O) and(O) articles(O) in(O) various(O) international(O) journals(O) as(O) well(O) as(O) in(O) Indian(O) journals(O) like(O) Current(B-academic journal) Science(I-academic journal) magazine(I-academic journal),(O) and(O) the(O) Journal(B-academic journal) of(I-academic journal) Biosciences(I-academic journal) ((O) India(B-country) )(O),(O) both(O) published(O) from(O) Bangalore(B-location).(O)"}
{"id": "120", "dataset": "crossner_science", "split": "dev", "label_list": ["scientist", "person", "country", "chemical compound", "enzyme", "theory", "organization", "university", "protein", "event", "academic journal", "award", "discipline", "astronomical object", "location", "chemical element"], "instance": {"id": "120", "words": ["GSK-3", "has", "been", "implicated", "in", "bipolar", "disorder", ",", "as", "bipolar", "medications", "lithium", "and", "valproate", "have", "been", "shown", "to", "increase", "its", "phosphorylation", ",", "thereby", "inhibiting", "it", "."], "labels": ["B-protein", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-chemical element", "O", "B-chemical compound", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, person, country, chemical compound, enzyme, theory, organization, university, protein, event, academic journal, award, discipline, astronomical object, location, chemical element and O.\nSentence: GSK-3 has been implicated in bipolar disorder , as bipolar medications lithium and valproate have been shown to increase its phosphorylation , thereby inhibiting it .", "prompt_labels": "GSK-3(B-protein) has(O) been(O) implicated(O) in(O) bipolar(O) disorder(O) ,(O) as(O) bipolar(O) medications(O) lithium(B-chemical element) and(O) valproate(B-chemical compound) have(O) been(O) shown(O) to(O) increase(O) its(O) phosphorylation(O) ,(O) thereby(O) inhibiting(O) it(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 28568, 11, 1732, 11, 3224, 11, 11742, 24549, 11, 49242, 11, 10334, 11, 7471, 11, 12374, 11, 13128, 11, 1567, 11, 14584, 8486, 11, 10292, 11, 26434, 11, 87283, 1665, 11, 3813, 11, 11742, 2449, 323, 507, 627, 85664, 25, 480, 16074, 12, 18, 706, 1027, 69702, 304, 65919, 19823, 1174, 439, 65919, 31010, 57907, 323, 1062, 782, 349, 617, 1027, 6982, 311, 5376, 1202, 95089, 2354, 1174, 28592, 20747, 5977, 433, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "GSK-3(B-protein) has(O) been(O) implicated(O) in(O) bipolar(B-discipline) disorder(I-discipline),(O) as(O) bipolar(O) medications(O) lithium(B-chemical compound) and(O) valproate(B-chemical compound) have(O) been(O) shown(O) to(O) increase(O) its(O) phosphorylation(O),(O) thereby(O) inhibiting(O) it(O).(O)"}
{"id": "329", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Dish", "Hours", "Cuisine", "Rating", "Amenity", "Price", "Restaurant Name", "Location"], "instance": {"id": "329", "words": ["farmer", "boys", "burgers", "in", "my", "town"], "labels": ["B-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name", "O", "O", "B-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Hours, Cuisine, Rating, Amenity, Price, Restaurant Name, Location and O.\nSentence: farmer boys burgers in my town", "prompt_labels": "farmer(B-Restaurant Name) boys(I-Restaurant Name) burgers(I-Restaurant Name) in(O) my(O) town(B-Location)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 30192, 11, 81961, 11, 19767, 11, 3383, 56685, 11, 8650, 11, 26568, 4076, 11, 10067, 323, 507, 627, 85664, 25, 37500, 13305, 63452, 304, 856, 6424, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "farmer(B-Restaurant Name) boys(I-Restaurant Name) burgers(I-Restaurant Name) in(B-Location) my(I-Location) town(I-Location)"}
{"id": "1243", "dataset": "mit-movie", "split": "dev", "label_list": ["director", "rating", "character", "plot", "genre", "song", "actor", "trailer", "title", "year", "review", "average ratings"], "instance": {"id": "1243", "words": ["find", "a", "movie", "called", "crossover"], "labels": ["O", "O", "O", "O", "B-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, rating, character, plot, genre, song, actor, trailer, title, year, review, average ratings and O.\nSentence: find a movie called crossover", "prompt_labels": "find(O) a(O) movie(O) called(O) crossover(B-title)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 10959, 11, 3752, 11, 7234, 11, 17779, 11, 5609, 11, 12360, 11, 19809, 11, 2316, 11, 1060, 11, 3477, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1505, 264, 5818, 2663, 49480, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "empire(B-title) strikes(I-title) back(I-title)"}
{"id": "335", "dataset": "mit-movie", "split": "dev", "label_list": ["trailer", "genre", "song", "character", "review", "average ratings", "director", "rating", "title", "plot", "actor", "year"], "instance": {"id": "335", "words": ["was", "a", "character", "called", "the", "torch", "in", "a", "flick"], "labels": ["O", "O", "O", "O", "B-character", "I-character", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, genre, song, character, review, average ratings, director, rating, title, plot, actor, year and O.\nSentence: was a character called the torch in a flick", "prompt_labels": "was(O) a(O) character(O) called(O) the(B-character) torch(I-character) in(O) a(O) flick(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 17779, 11, 5609, 11, 3752, 11, 3477, 11, 5578, 18594, 11, 7690, 11, 10959, 11, 2316, 11, 7234, 11, 12360, 11, 1060, 323, 507, 627, 85664, 25, 574, 264, 3752, 2663, 279, 7990, 304, 264, 29447, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "does(O) jaimes(B-Restaurant Name) bakery(I-Restaurant Name) have(O) a(O) great(B-Amenity) decor(I-Amenity)"}
{"id": "327", "dataset": "mit-movie", "split": "dev", "label_list": ["average ratings", "genre", "character", "year", "review", "title", "plot", "song", "director", "rating", "actor", "trailer"], "instance": {"id": "327", "words": ["look", "for", "pirates", "of", "the", "caribbean", "series"], "labels": ["O", "O", "B-title", "I-title", "I-title", "I-title", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, genre, character, year, review, title, plot, song, director, rating, actor, trailer and O.\nSentence: look for pirates of the caribbean series", "prompt_labels": "look(O) for(O) pirates(B-title) of(I-title) the(I-title) caribbean(I-title) series(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 17779, 11, 3752, 11, 1060, 11, 3477, 11, 2316, 11, 7234, 11, 5609, 11, 7690, 11, 10959, 11, 12360, 11, 19809, 323, 507, 627, 85664, 25, 1427, 369, 62575, 315, 279, 1841, 33159, 4101, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "is(O) there(O) a(O) good(O) scary(B-genre) movie(O) that(O) is(O) rated(O) pg(B-rating) 13(I-rating) about(O) extrasensory(B-plot) perception(I-plot)"}
{"id": "2414", "dataset": "mit-movie", "split": "dev", "label_list": ["trailer", "actor", "plot", "director", "song", "title", "character", "genre", "average ratings", "rating", "year", "review"], "instance": {"id": "2414", "words": ["empire", "strikes", "back"], "labels": ["B-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, actor, plot, director, song, title, character, genre, average ratings, rating, year, review and O.\nSentence: empire strikes back", "prompt_labels": "empire(B-title) strikes(I-title) back(I-title)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 12360, 11, 7234, 11, 7690, 11, 5609, 11, 2316, 11, 3752, 11, 17779, 11, 5578, 18594, 11, 10959, 11, 1060, 11, 3477, 323, 507, 627, 85664, 25, 32447, 23170, 1203, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "show(O) me(O) a(O) comedy(B-genre) about(O) a(O) football(B-plot) team(I-plot)"}
{"id": "480", "dataset": "mit-movie", "split": "dev", "label_list": ["actor", "trailer", "review", "director", "song", "genre", "year", "plot", "title", "rating", "average ratings", "character"], "instance": {"id": "480", "words": ["was", "pierce", "brosnan", "in", "sex", "in", "the", "city"], "labels": ["O", "B-actor", "I-actor", "O", "B-title", "I-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, trailer, review, director, song, genre, year, plot, title, rating, average ratings, character and O.\nSentence: was pierce brosnan in sex in the city", "prompt_labels": "was(O) pierce(B-actor) brosnan(I-actor) in(O) sex(B-title) in(I-title) the(I-title) city(I-title)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 19809, 11, 3477, 11, 7690, 11, 5609, 11, 17779, 11, 1060, 11, 7234, 11, 2316, 11, 10959, 11, 5578, 18594, 11, 3752, 323, 507, 627, 85664, 25, 574, 22710, 346, 2967, 9810, 276, 304, 1877, 304, 279, 3363, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "In(O) British(B-location) Columbia(I-location),(O) the(O) British(B-political party) Columbia(I-political party) Party(I-political party) was(O) replaced(O) as(O) the(O) party(O) of(O) the(O) centre-right(O) by(O) the(O) British(B-political party) Columbia(I-political party) Liberal(I-political party) Party(I-political party),(O) and(O) in(O) Alberta(B-location) the(O) Alberta(B-political party) Social(I-political party) Credit(I-political party) Party(I-political party) were(O) completely(O) annihilated(O) by(O) the(O) more(O) moderate(O) Alberta(B-political party) Progressive(I-political party) Conservative(I-political party) Party(I-political party),(O) leaving(O) both(O) parties(O) as(O) marginal(O) political(O) forces(O).(O)"}
{"id": "569", "dataset": "mit-movie", "split": "dev", "label_list": ["genre", "actor", "trailer", "rating", "character", "title", "review", "year", "director", "song", "average ratings", "plot"], "instance": {"id": "569", "words": ["is", "there", "an", "animated", "adult", "horror", "movie"], "labels": ["O", "O", "O", "B-genre", "I-genre", "I-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, actor, trailer, rating, character, title, review, year, director, song, average ratings, plot and O.\nSentence: is there an animated adult horror movie", "prompt_labels": "is(O) there(O) an(O) animated(B-genre) adult(I-genre) horror(I-genre) movie(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 12360, 11, 19809, 11, 10959, 11, 3752, 11, 2316, 11, 3477, 11, 1060, 11, 7690, 11, 5609, 11, 5578, 18594, 11, 7234, 323, 507, 627, 85664, 25, 374, 1070, 459, 11625, 6822, 22169, 5818, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "The(O) call(O) for(O) creation(O) of(O) the(O) Akhand(B-organization) Bharat(I-organization) or(O) Akhand(B-location) Hindusthan(I-location) has(O) on(O) occasions(O) been(O) raised(O) by(O) Hindu(B-political party) nationalist(I-political party) organisations(O) such(O) as(O) the(O) Hindu(B-political party) Mahasabha(I-political party),(O) Kakbhusundi(B-political party) Revolutionary(I-political party) Forum(I-political party) ((O) KRF(B-political party) )(O),(O) Rashtriya(B-political party) Swayamsevak(I-political party) Sangh(I-political party) ((O) RSS(B-political party) )(O),(O) Vishwa(B-political party) Hindu(I-political party) Parishad(I-political party),(O) Shiv(B-political party) Sena(I-political party),(O) Hindu(B-political party) Sena(I-political party),(O) Hindu(B-political party) Janajagruti(I-political party) Samiti(I-political party) and(O) Bharatiya(B-political party) Janata(I-political party) Party(I-political party).(O)"}
{"id": "201", "dataset": "crossner_ai", "split": "dev", "label_list": ["algorithm", "task", "field", "metric", "organization", "person", "product", "university", "programming language", "conference", "location", "country", "researcher"], "instance": {"id": "201", "words": ["Early", "interlingual", "MT", "systems", "were", "also", "built", "at", "Stanford", "in", "the", "1970s", "by", "Roger", "Schank", "and", "Yorick", "Wilks", ";", "the", "former", "became", "the", "basis", "of", "a", "commercial", "system", "for", "the", "transfer", "of", "funds", ",", "and", "the", "latter", "'s", "code", "is", "preserved", "at", "The", "Computer", "Museum", "at", "Boston", "as", "the", "first", "interlingual", "machine", "translation", "system", "."], "labels": ["O", "B-product", "I-product", "I-product", "O", "O", "O", "O", "B-university", "O", "O", "O", "O", "B-researcher", "I-researcher", "O", "B-researcher", "I-researcher", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "I-location", "O", "B-location", "O", "O", "O", "B-product", "I-product", "I-product", "I-product", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, task, field, metric, organization, person, product, university, programming language, conference, location, country, researcher and O.\nSentence: Early interlingual MT systems were also built at Stanford in the 1970s by Roger Schank and Yorick Wilks ; the former became the basis of a commercial system for the transfer of funds , and the latter 's code is preserved at The Computer Museum at Boston as the first interlingual machine translation system .", "prompt_labels": "Early(O) interlingual(B-product) MT(I-product) systems(I-product) were(O) also(O) built(O) at(O) Stanford(B-university) in(O) the(O) 1970s(O) by(O) Roger(B-researcher) Schank(I-researcher) and(O) Yorick(B-researcher) Wilks(I-researcher) ;(O) the(O) former(O) became(O) the(O) basis(O) of(O) a(O) commercial(O) system(O) for(O) the(O) transfer(O) of(O) funds(O) ,(O) and(O) the(O) latter(O) 's(O) code(O) is(O) preserved(O) at(O) The(B-location) Computer(I-location) Museum(I-location) at(O) Boston(B-location) as(O) the(O) first(O) interlingual(B-product) machine(I-product) translation(I-product) system(I-product) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12384, 11, 3465, 11, 2115, 11, 18767, 11, 7471, 11, 1732, 11, 2027, 11, 12374, 11, 15840, 4221, 11, 10017, 11, 3813, 11, 3224, 11, 32185, 323, 507, 627, 85664, 25, 23591, 958, 2785, 940, 19629, 6067, 1051, 1101, 5918, 520, 31788, 304, 279, 220, 4468, 15, 82, 555, 29607, 5124, 1201, 323, 816, 269, 875, 10785, 2857, 2652, 279, 4846, 6244, 279, 8197, 315, 264, 8518, 1887, 369, 279, 8481, 315, 10736, 1174, 323, 279, 15629, 364, 82, 2082, 374, 34683, 520, 578, 17863, 16730, 520, 10406, 439, 279, 1176, 958, 2785, 940, 5780, 14807, 1887, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "how(O) late(O) pfchangs(B-Restaurant Name) in(O) paradise(B-Location) road(I-Location) will(O) be(O) open(O)"}
{"id": "286", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Dish", "Amenity", "Location", "Hours", "Rating", "Price", "Restaurant Name", "Cuisine"], "instance": {"id": "286", "words": ["does", "jaimes", "bakery", "have", "a", "great", "decor"], "labels": ["O", "B-Restaurant Name", "I-Restaurant Name", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Amenity, Location, Hours, Rating, Price, Restaurant Name, Cuisine and O.\nSentence: does jaimes bakery have a great decor", "prompt_labels": "does(O) jaimes(B-Restaurant Name) bakery(I-Restaurant Name) have(O) a(O) great(B-Amenity) decor(I-Amenity)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 3383, 56685, 11, 10067, 11, 30192, 11, 19767, 11, 8650, 11, 26568, 4076, 11, 81961, 323, 507, 627, 85664, 25, 1587, 12203, 1769, 66244, 617, 264, 2294, 10799, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "find(O) a(O) movie(O) called(O) crossover(B-title)"}
{"id": "367", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Dish", "Restaurant Name", "Price", "Hours", "Amenity", "Location", "Cuisine", "Rating"], "instance": {"id": "367", "words": ["find", "me", "a", "dim", "sum", "restaurant", "open", "at", "8", "am"], "labels": ["O", "O", "O", "B-Dish", "I-Dish", "I-Dish", "B-Hours", "I-Hours", "I-Hours", "I-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Restaurant Name, Price, Hours, Amenity, Location, Cuisine, Rating and O.\nSentence: find me a dim sum restaurant open at 8 am", "prompt_labels": "find(O) me(O) a(O) dim(B-Dish) sum(I-Dish) restaurant(I-Dish) open(B-Hours) at(I-Hours) 8(I-Hours) am(I-Hours)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 26568, 4076, 11, 8650, 11, 30192, 11, 3383, 56685, 11, 10067, 11, 81961, 11, 19767, 323, 507, 627, 85664, 25, 1505, 757, 264, 5213, 2694, 10960, 1825, 520, 220, 23, 1097, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "was(O) pierce(B-actor) brosnan(I-actor) in(O) sex(B-title) in(I-title) city(I-title)"}
{"id": "64", "dataset": "mit-movie", "split": "dev", "label_list": ["actor", "rating", "song", "plot", "genre", "character", "year", "trailer", "review", "average ratings", "title", "director"], "instance": {"id": "64", "words": ["whats", "the", "latetest", "foreign", "romantic", "movie", "with", "lots", "of", "sex", "and", "sadness"], "labels": ["O", "O", "B-year", "B-genre", "I-genre", "O", "O", "O", "O", "B-plot", "O", "B-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, rating, song, plot, genre, character, year, trailer, review, average ratings, title, director and O.\nSentence: whats the latetest foreign romantic movie with lots of sex and sadness", "prompt_labels": "whats(O) the(O) latetest(B-year) foreign(B-genre) romantic(I-genre) movie(O) with(O) lots(O) of(O) sex(B-plot) and(O) sadness(B-plot)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 10959, 11, 5609, 11, 7234, 11, 17779, 11, 3752, 11, 1060, 11, 19809, 11, 3477, 11, 5578, 18594, 11, 2316, 11, 7690, 323, 507, 627, 85664, 25, 41209, 279, 6987, 58924, 7362, 24364, 5818, 449, 10283, 315, 1877, 323, 51978, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "find(O) me(O) a(O) dim(B-Cuisine) sum(I-Cuisine) restaurant(O) open(B-Hours) at(I-Hours) 8(I-Hours) am(I-Hours)"}
{"id": "76", "dataset": "crossner_literature", "split": "dev", "label_list": ["writer", "poem", "country", "person", "award", "event", "organization", "book", "literary genre", "location", "magazine"], "instance": {"id": "76", "words": ["Jorge", "Luis", "Borges", "wrote", "a", "contemporary", "bestiary", "of", "sorts", ",", "the", "Book", "of", "Imaginary", "Beings", ",", "which", "collects", "imaginary", "beasts", "from", "bestiaries", "and", "fiction", "."], "labels": ["B-writer", "I-writer", "I-writer", "O", "O", "O", "O", "O", "O", "O", "O", "B-book", "I-book", "I-book", "I-book", "O", "O", "O", "O", "O", "O", "O", "O", "B-literary genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: writer, poem, country, person, award, event, organization, book, literary genre, location, magazine and O.\nSentence: Jorge Luis Borges wrote a contemporary bestiary of sorts , the Book of Imaginary Beings , which collects imaginary beasts from bestiaries and fiction .", "prompt_labels": "Jorge(B-writer) Luis(I-writer) Borges(I-writer) wrote(O) a(O) contemporary(O) bestiary(O) of(O) sorts(O) ,(O) the(O) Book(B-book) of(I-book) Imaginary(I-book) Beings(I-book) ,(O) which(O) collects(O) imaginary(O) beasts(O) from(O) bestiaries(O) and(O) fiction(B-literary genre) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7061, 11, 33894, 11, 3224, 11, 1732, 11, 10292, 11, 1567, 11, 7471, 11, 2363, 11, 32465, 17779, 11, 3813, 11, 14756, 323, 507, 627, 85664, 25, 56500, 34297, 65582, 288, 6267, 264, 19225, 1888, 72, 661, 315, 21522, 1174, 279, 6017, 315, 77533, 3367, 2893, 826, 1174, 902, 52307, 51052, 57536, 505, 1888, 72, 5548, 323, 17422, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "what(O) is(O) a(O) good(O) pg(B-rating) 13(I-rating) drama(B-genre) with(O) andrew(B-actor) keegan(I-actor) in(O) the(O) 2010(B-year) s(I-year)"}
{"id": "1495", "dataset": "mit-movie", "split": "dev", "label_list": ["rating", "review", "genre", "year", "title", "trailer", "song", "actor", "average ratings", "director", "plot", "character"], "instance": {"id": "1495", "words": ["is", "there", "a", "good", "scary", "movie", "that", "is", "rated", "pg", "13", "about", "extrasensory", "perception"], "labels": ["O", "O", "O", "O", "B-genre", "O", "O", "O", "O", "B-rating", "I-rating", "O", "B-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, review, genre, year, title, trailer, song, actor, average ratings, director, plot, character and O.\nSentence: is there a good scary movie that is rated pg 13 about extrasensory perception", "prompt_labels": "is(O) there(O) a(O) good(O) scary(B-genre) movie(O) that(O) is(O) rated(O) pg(B-rating) 13(I-rating) about(O) extrasensory(B-plot) perception(I-plot)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 3477, 11, 17779, 11, 1060, 11, 2316, 11, 19809, 11, 5609, 11, 12360, 11, 5578, 18594, 11, 7690, 11, 7234, 11, 3752, 323, 507, 627, 85664, 25, 374, 1070, 264, 1695, 29565, 5818, 430, 374, 22359, 17953, 220, 1032, 922, 37375, 729, 683, 21063, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Electropop(O) pioneers(O) Haruomi(B-musical artist) Hosono(I-musical artist) and(O) Ryuichi(B-musical artist) Sakamoto(I-musical artist) of(O) the(O) Yellow(B-band) Magic(I-band) Orchestra(I-band) produced(O) a(O) 1978(B-album) Electronic(I-album) music(I-album) album(I-album),(O) Cochin(B-album) Moon(I-album),(O) based(O) on(O) an(O) experimental(O) fusion(O) of(O) electronic(O) music(O) and(O) Bollywood-inspired(O) Indian(O) music(O).(O)"}
{"id": "2383", "dataset": "mit-movie", "split": "dev", "label_list": ["title", "genre", "song", "director", "rating", "review", "year", "actor", "plot", "character", "trailer", "average ratings"], "instance": {"id": "2383", "words": ["what", "is", "a", "good", "pg", "13", "drama", "with", "andrew", "keegan", "in", "the", "2010", "s"], "labels": ["O", "O", "O", "B-average ratings", "B-rating", "I-rating", "B-genre", "O", "B-actor", "I-actor", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, genre, song, director, rating, review, year, actor, plot, character, trailer, average ratings and O.\nSentence: what is a good pg 13 drama with andrew keegan in the 2010 s", "prompt_labels": "what(O) is(O) a(O) good(B-average ratings) pg(B-rating) 13(I-rating) drama(B-genre) with(O) andrew(B-actor) keegan(I-actor) in(O) the(O) 2010(B-year) s(I-year)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 17779, 11, 5609, 11, 7690, 11, 10959, 11, 3477, 11, 1060, 11, 12360, 11, 7234, 11, 3752, 11, 19809, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1148, 374, 264, 1695, 17953, 220, 1032, 20156, 449, 323, 4361, 2004, 16133, 304, 279, 220, 679, 15, 274, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "name(O) a(O) kirk(B-director) douglas(I-director) science(B-genre) fiction(I-genre) film(O)"}
{"id": "1761", "dataset": "mit-movie", "split": "dev", "label_list": ["character", "song", "rating", "director", "genre", "title", "plot", "review", "average ratings", "year", "actor", "trailer"], "instance": {"id": "1761", "words": ["show", "me", "all", "unrated", "scary", "moves", "about", "gore"], "labels": ["O", "O", "O", "B-rating", "B-genre", "O", "O", "B-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, song, rating, director, genre, title, plot, review, average ratings, year, actor, trailer and O.\nSentence: show me all unrated scary moves about gore", "prompt_labels": "show(O) me(O) all(O) unrated(B-rating) scary(B-genre) moves(O) about(O) gore(B-plot)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 5609, 11, 10959, 11, 7690, 11, 17779, 11, 2316, 11, 7234, 11, 3477, 11, 5578, 18594, 11, 1060, 11, 12360, 11, 19809, 323, 507, 627, 85664, 25, 1501, 757, 682, 41480, 660, 29565, 11031, 922, 91532, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "He(O) is(O) the(O) protagonist(O) of(O) Robert(B-writer) Coover(I-writer) '(O) s(O) short(O) story(O) Charlie(B-poem) in(I-poem) the(I-poem) House(I-poem) of(I-poem) Rue(I-poem) ((O) 1980(O) ;(O) reprinted(O) in(O) Coover(I-writer)'s(O) 1987(O) collection(O) A(B-book) Night(I-book) at(I-book) the(I-book) Movies(I-book) )(O),(O) and(O) of(O) Glen(B-writer) David(I-writer) Gold(I-writer) '(O) s(O) Sunnyside(B-book) ((O) 2009(O) )(O),(O) a(O) historical(O) novel(O) set(O) in(O) the(O) First(B-location) World(I-location) War(I-location) period(I-location).(O)"}
{"id": "171", "dataset": "crossner_music", "split": "dev", "label_list": ["song", "country", "person", "music genre", "album", "organization", "musical artist", "musical instrument", "event", "award", "location", "band"], "instance": {"id": "171", "words": ["Juliana", "Hatfield", "is", "an", "American", "musician", "and", "singer-songwriter", "from", "the", "Boston", "area", ",", "formerly", "of", "the", "indie", "rock", "bands", "Blake", "Babies", ",", "Some", "Girls", ",", "and", "The", "Lemonheads", "."], "labels": ["B-musical artist", "I-musical artist", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "O", "O", "O", "O", "O", "B-music genre", "O", "B-band", "I-band", "O", "B-band", "I-band", "O", "O", "B-band", "I-band", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, country, person, music genre, album, organization, musical artist, musical instrument, event, award, location, band and O.\nSentence: Juliana Hatfield is an American musician and singer-songwriter from the Boston area , formerly of the indie rock bands Blake Babies , Some Girls , and The Lemonheads .", "prompt_labels": "Juliana(B-musical artist) Hatfield(I-musical artist) is(O) an(O) American(O) musician(O) and(O) singer-songwriter(O) from(O) the(O) Boston(B-location) area(I-location) ,(O) formerly(O) of(O) the(O) indie(O) rock(B-music genre) bands(O) Blake(B-band) Babies(I-band) ,(O) Some(B-band) Girls(I-band) ,(O) and(O) The(B-band) Lemonheads(I-band) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 3224, 11, 1732, 11, 4731, 17779, 11, 8176, 11, 7471, 11, 18273, 10255, 11, 18273, 14473, 11, 1567, 11, 10292, 11, 3813, 11, 7200, 323, 507, 627, 85664, 25, 10263, 12699, 22050, 2630, 374, 459, 3778, 39844, 323, 23597, 77740, 18688, 505, 279, 10406, 3158, 1174, 34833, 315, 279, 44578, 7091, 21562, 31994, 93792, 1174, 4427, 20666, 1174, 323, 578, 52310, 36910, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "He(O) contested(O) Cardiff(B-location) North(I-location) in(O) October(O) 1974(O) United(B-country) Kingdom(I-country) general(I-country) election(I-country) and(O) 1979(O) United(B-country) Kingdom(I-country) general(I-country) election(I-country) for(O) the(O) Liberals(B-political party),(O) before(O) fighting(O) Cardiff(B-location) Central(I-location) in(O) 1983(O) United(B-country) Kingdom(I-country) general(I-country) election(I-country) and(O) 1987(O) United(B-country) Kingdom(I-country) general(I-country) election(I-country) for(O) the(O) SDP-Liberal(B-political party) Alliance(I-political party),(O) but(O) was(O) unsuccessful(O) on(O) each(O) occasion(O).(O)"}
{"id": "568", "dataset": "mit-movie", "split": "dev", "label_list": ["plot", "genre", "title", "average ratings", "song", "rating", "actor", "director", "trailer", "character", "year", "review"], "instance": {"id": "568", "words": ["show", "me", "a", "comedy", "about", "a", "football", "team"], "labels": ["O", "O", "O", "B-genre", "O", "O", "B-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, genre, title, average ratings, song, rating, actor, director, trailer, character, year, review and O.\nSentence: show me a comedy about a football team", "prompt_labels": "show(O) me(O) a(O) comedy(B-genre) about(O) a(O) football(B-plot) team(I-plot)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 17779, 11, 2316, 11, 5578, 18594, 11, 5609, 11, 10959, 11, 12360, 11, 7690, 11, 19809, 11, 3752, 11, 1060, 11, 3477, 323, 507, 627, 85664, 25, 1501, 757, 264, 23160, 922, 264, 9141, 2128, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "was(O) a(O) character(O) called(O) the(O) torch(B-character) in(O) a(O) flick(O)"}
{"id": "90", "dataset": "crossner_music", "split": "dev", "label_list": ["country", "music genre", "location", "musical artist", "person", "organization", "award", "musical instrument", "event", "song", "band", "album"], "instance": {"id": "90", "words": ["Electropop", "pioneers", "Haruomi", "Hosono", "and", "Ryuichi", "Sakamoto", "of", "the", "Yellow", "Magic", "Orchestra", "produced", "a", "1978", "Electronic", "music", "album", ",", "Cochin", "Moon", ",", "based", "on", "an", "experimental", "fusion", "of", "electronic", "music", "and", "Bollywood-inspired", "Indian", "music", "."], "labels": ["B-music genre", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "O", "B-band", "I-band", "I-band", "O", "O", "O", "B-music genre", "I-music genre", "O", "O", "B-album", "I-album", "O", "O", "O", "O", "O", "O", "O", "B-music genre", "I-music genre", "O", "B-music genre", "I-music genre", "I-music genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, music genre, location, musical artist, person, organization, award, musical instrument, event, song, band, album and O.\nSentence: Electropop pioneers Haruomi Hosono and Ryuichi Sakamoto of the Yellow Magic Orchestra produced a 1978 Electronic music album , Cochin Moon , based on an experimental fusion of electronic music and Bollywood-inspired Indian music .", "prompt_labels": "Electropop(B-music genre) pioneers(O) Haruomi(B-musical artist) Hosono(I-musical artist) and(O) Ryuichi(B-musical artist) Sakamoto(I-musical artist) of(O) the(O) Yellow(B-band) Magic(I-band) Orchestra(I-band) produced(O) a(O) 1978(O) Electronic(B-music genre) music(I-music genre) album(O) ,(O) Cochin(B-album) Moon(I-album) ,(O) based(O) on(O) an(O) experimental(O) fusion(O) of(O) electronic(B-music genre) music(I-music genre) and(O) Bollywood-inspired(B-music genre) Indian(I-music genre) music(I-music genre) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 4731, 17779, 11, 3813, 11, 18273, 10255, 11, 1732, 11, 7471, 11, 10292, 11, 18273, 14473, 11, 1567, 11, 5609, 11, 7200, 11, 8176, 323, 507, 627, 85664, 25, 10085, 897, 454, 83407, 5340, 84, 22157, 65090, 10358, 323, 99331, 41652, 39867, 57960, 315, 279, 26541, 15852, 54617, 9124, 264, 220, 4468, 23, 35269, 4731, 8176, 1174, 3623, 60171, 17781, 1174, 3196, 389, 459, 22772, 37608, 315, 14683, 4731, 323, 65286, 53161, 7904, 4731, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "is(O) there(O) an(O) animated(B-genre) adult(I-genre) horror(I-genre) movie(O)"}
{"id": "113", "dataset": "crossner_music", "split": "dev", "label_list": ["organization", "person", "country", "musical artist", "band", "event", "music genre", "location", "award", "album", "musical instrument", "song"], "instance": {"id": "113", "words": ["They", "have", "won", "two", "Grammy", "Award", "s", ",", "six", "American", "Music", "Awards", ",", "two", "Billboard", "Music", "Award", ",", "four", "MTV", "Video", "Music", "Award", "s", ",", "10", "MTV", "Europe", "Music", "Award", "and", "three", "World", "Music", "Awards", "."], "labels": ["O", "O", "O", "O", "B-award", "I-award", "O", "O", "O", "B-award", "I-award", "I-award", "O", "O", "B-award", "I-award", "I-award", "O", "O", "B-award", "I-award", "I-award", "I-award", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "O", "O", "B-award", "I-award", "I-award", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, person, country, musical artist, band, event, music genre, location, award, album, musical instrument, song and O.\nSentence: They have won two Grammy Award s , six American Music Awards , two Billboard Music Award , four MTV Video Music Award s , 10 MTV Europe Music Award and three World Music Awards .", "prompt_labels": "They(O) have(O) won(O) two(O) Grammy(B-award) Award(I-award) s(O) ,(O) six(O) American(B-award) Music(I-award) Awards(I-award) ,(O) two(O) Billboard(B-award) Music(I-award) Award(I-award) ,(O) four(O) MTV(B-award) Video(I-award) Music(I-award) Award(I-award) s(O) ,(O) 10(O) MTV(B-award) Europe(I-award) Music(I-award) Award(I-award) and(O) three(O) World(B-award) Music(I-award) Awards(I-award) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 1732, 11, 3224, 11, 18273, 10255, 11, 7200, 11, 1567, 11, 4731, 17779, 11, 3813, 11, 10292, 11, 8176, 11, 18273, 14473, 11, 5609, 323, 507, 627, 85664, 25, 2435, 617, 2834, 1403, 74679, 17768, 274, 1174, 4848, 3778, 10948, 23488, 1174, 1403, 67293, 10948, 17768, 1174, 3116, 62199, 8519, 10948, 17768, 274, 1174, 220, 605, 62199, 4606, 10948, 17768, 323, 2380, 4435, 10948, 23488, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "whats(O) the(O) latetest(O) foreign(B-genre) romantic(I-genre) movie(O) with(O) lots(B-plot) of(I-plot) sex(I-plot) and(I-plot) sadness(I-plot)"}
{"id": "1225", "dataset": "mit-movie", "split": "dev", "label_list": ["year", "review", "character", "song", "rating", "title", "genre", "trailer", "average ratings", "director", "actor", "plot"], "instance": {"id": "1225", "words": ["do", "you", "think", "youd", "be", "able", "to", "help", "me", "find", "the", "penguins", "of", "madagascar", "operation", "dvd", "premier"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-title", "I-title", "I-title", "I-title", "I-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, review, character, song, rating, title, genre, trailer, average ratings, director, actor, plot and O.\nSentence: do you think youd be able to help me find the penguins of madagascar operation dvd premier", "prompt_labels": "do(O) you(O) think(O) youd(O) be(O) able(O) to(O) help(O) me(O) find(O) the(B-title) penguins(I-title) of(I-title) madagascar(I-title) operation(I-title) dvd(I-title) premier(I-title)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 3477, 11, 3752, 11, 5609, 11, 10959, 11, 2316, 11, 17779, 11, 19809, 11, 5578, 18594, 11, 7690, 11, 12360, 11, 7234, 323, 507, 627, 85664, 25, 656, 499, 1781, 499, 67, 387, 3025, 311, 1520, 757, 1505, 279, 281, 56458, 315, 13088, 79775, 5784, 51008, 21134, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "show(O) me(O) all(O) unrated(B-rating) scary(B-title) moves(I-title) about(O) gore(B-plot)"}
{"id": "158", "dataset": "crossner_politics", "split": "dev", "label_list": ["politician", "election", "country", "location", "political party", "event", "person", "organization"], "instance": {"id": "158", "words": ["In", "British", "Columbia", ",", "the", "British", "Columbia", "Social", "Credit", "Party", "was", "replaced", "as", "the", "party", "of", "the", "centre-right", "by", "the", "British", "Columbia", "Liberal", "Party", ",", "and", "in", "Alberta", "the", "Alberta", "Social", "Credit", "Party", "were", "completely", "annihilated", "by", "the", "more", "moderate", "Alberta", "Progressive", "Conservative", "Party", ",", "leaving", "both", "parties", "as", "marginal", "political", "forces", "."], "labels": ["O", "B-location", "I-location", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O", "B-location", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, election, country, location, political party, event, person, organization and O.\nSentence: In British Columbia , the British Columbia Social Credit Party was replaced as the party of the centre-right by the British Columbia Liberal Party , and in Alberta the Alberta Social Credit Party were completely annihilated by the more moderate Alberta Progressive Conservative Party , leaving both parties as marginal political forces .", "prompt_labels": "In(O) British(B-location) Columbia(I-location) ,(O) the(O) British(B-political party) Columbia(I-political party) Social(I-political party) Credit(I-political party) Party(I-political party) was(O) replaced(O) as(O) the(O) party(O) of(O) the(O) centre-right(O) by(O) the(O) British(B-political party) Columbia(I-political party) Liberal(I-political party) Party(I-political party) ,(O) and(O) in(O) Alberta(B-location) the(O) Alberta(B-political party) Social(I-political party) Credit(I-political party) Party(I-political party) were(O) completely(O) annihilated(O) by(O) the(O) more(O) moderate(O) Alberta(B-political party) Progressive(I-political party) Conservative(I-political party) Party(I-political party) ,(O) leaving(O) both(O) parties(O) as(O) marginal(O) political(O) forces(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 37038, 11, 6355, 11, 3224, 11, 3813, 11, 5054, 4717, 11, 1567, 11, 1732, 11, 7471, 323, 507, 627, 85664, 25, 763, 8013, 19326, 1174, 279, 8013, 19326, 9983, 16666, 8722, 574, 12860, 439, 279, 4717, 315, 279, 12541, 6840, 555, 279, 8013, 19326, 31158, 8722, 1174, 323, 304, 33654, 279, 33654, 9983, 16666, 8722, 1051, 6724, 98445, 660, 555, 279, 810, 24070, 33654, 52870, 30071, 8722, 1174, 9564, 2225, 9875, 439, 32873, 5054, 8603, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "They(O) have(O) won(O) two(O) Grammy(B-award) Award(I-award) s(I-award),(O) six(O) American(B-award) Music(I-award) Awards(I-award),(O) two(O) Billboard(B-award) Music(I-award) Award(I-award),(O) four(O) MTV(B-award) Video(I-award) Music(I-award) Award(I-award) s(I-award),(O) 10(O) MTV(B-award) Europe(I-award) Music(I-award) Award(I-award) and(O) three(O) World(B-award) Music(I-award) Awards(I-award).(O)"}
{"id": "197", "dataset": "mit-movie", "split": "dev", "label_list": ["review", "genre", "title", "trailer", "actor", "character", "average ratings", "song", "year", "rating", "plot", "director"], "instance": {"id": "197", "words": ["name", "a", "kirk", "douglas", "science", "fiction", "film"], "labels": ["O", "O", "B-actor", "I-actor", "B-genre", "I-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, genre, title, trailer, actor, character, average ratings, song, year, rating, plot, director and O.\nSentence: name a kirk douglas science fiction film", "prompt_labels": "name(O) a(O) kirk(B-actor) douglas(I-actor) science(B-genre) fiction(I-genre) film(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 17779, 11, 2316, 11, 19809, 11, 12360, 11, 3752, 11, 5578, 18594, 11, 5609, 11, 1060, 11, 10959, 11, 7234, 11, 7690, 323, 507, 627, 85664, 25, 836, 264, 597, 14468, 25595, 27481, 8198, 17422, 4632, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "what(O) is(O) eugene(B-title) about(O)"}
{"id": "1976", "dataset": "mit-movie", "split": "dev", "label_list": ["review", "director", "genre", "character", "plot", "song", "year", "average ratings", "title", "trailer", "rating", "actor"], "instance": {"id": "1976", "words": ["what", "is", "eugene", "about"], "labels": ["O", "O", "B-title", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, director, genre, character, plot, song, year, average ratings, title, trailer, rating, actor and O.\nSentence: what is eugene about", "prompt_labels": "what(O) is(O) eugene(B-title) about(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 7690, 11, 17779, 11, 3752, 11, 7234, 11, 5609, 11, 1060, 11, 5578, 18594, 11, 2316, 11, 19809, 11, 10959, 11, 12360, 323, 507, 627, 85664, 25, 1148, 374, 384, 773, 1994, 922, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "what(O) is(O) the(O) movie(O) that(O) has(O) the(O) song(O) zip(B-song) a(I-song) dee(I-song) doo(I-song) dah(I-song)"}
{"id": "241", "dataset": "crossner_music", "split": "dev", "label_list": ["album", "song", "location", "country", "musical artist", "award", "musical instrument", "music genre", "band", "person", "organization", "event"], "instance": {"id": "241", "words": ["On", "19", "July", "2014", ",", "Il", "Divo", "performed", "before", "a", "capacity", "crowd", "at", "Edinburgh", "Castle", "esplanade", "where", "a", "pop", "festival", "took", "place", "ahead", "of", "the", "2014", "Commonwealth", "Games", "."], "labels": ["O", "O", "O", "O", "O", "B-band", "I-band", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "I-location", "O", "O", "B-event", "I-event", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, song, location, country, musical artist, award, musical instrument, music genre, band, person, organization, event and O.\nSentence: On 19 July 2014 , Il Divo performed before a capacity crowd at Edinburgh Castle esplanade where a pop festival took place ahead of the 2014 Commonwealth Games .", "prompt_labels": "On(O) 19(O) July(O) 2014(O) ,(O) Il(B-band) Divo(I-band) performed(O) before(O) a(O) capacity(O) crowd(O) at(O) Edinburgh(B-location) Castle(I-location) esplanade(I-location) where(O) a(O) pop(B-event) festival(I-event) took(O) place(O) ahead(O) of(O) the(O) 2014(B-event) Commonwealth(I-event) Games(I-event) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8176, 11, 5609, 11, 3813, 11, 3224, 11, 18273, 10255, 11, 10292, 11, 18273, 14473, 11, 4731, 17779, 11, 7200, 11, 1732, 11, 7471, 11, 1567, 323, 507, 627, 85664, 25, 1952, 220, 777, 5887, 220, 679, 19, 1174, 7695, 423, 6632, 10887, 1603, 264, 8824, 13734, 520, 41406, 27987, 1560, 10609, 1037, 1405, 264, 2477, 19309, 3952, 2035, 8469, 315, 279, 220, 679, 19, 38298, 11871, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "when(O) did(O) the(O) game(O) come(O) out(O)"}
{"id": "416", "dataset": "crossner_politics", "split": "dev", "label_list": ["location", "country", "politician", "event", "organization", "election", "person", "political party"], "instance": {"id": "416", "words": ["The", "call", "for", "creation", "of", "the", "Akhand", "Bharat", "or", "Akhand", "Hindusthan", "has", "on", "occasions", "been", "raised", "by", "Hindu", "nationalist", "organisations", "such", "as", "the", "Hindu", "Mahasabha", ",", "Kakbhusundi", "Revolutionary", "Forum", "(", "KRF", ")", ",", "Rashtriya", "Swayamsevak", "Sangh", "(", "RSS", ")", ",", "Vishwa", "Hindu", "Parishad", ",", "Shiv", "Sena", ",", "Hindu", "Sena", ",", "Hindu", "Janajagruti", "Samiti", "and", "Bharatiya", "Janata", "Party", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "O", "B-organization", "I-organization", "I-organization", "O", "B-organization", "O", "O", "B-organization", "I-organization", "I-organization", "O", "B-organization", "O", "O", "B-organization", "I-organization", "I-organization", "O", "B-political party", "I-political party", "O", "B-political party", "I-political party", "O", "B-organization", "I-organization", "I-organization", "O", "B-political party", "I-political party", "I-political party", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, country, politician, event, organization, election, person, political party and O.\nSentence: The call for creation of the Akhand Bharat or Akhand Hindusthan has on occasions been raised by Hindu nationalist organisations such as the Hindu Mahasabha , Kakbhusundi Revolutionary Forum ( KRF ) , Rashtriya Swayamsevak Sangh ( RSS ) , Vishwa Hindu Parishad , Shiv Sena , Hindu Sena , Hindu Janajagruti Samiti and Bharatiya Janata Party .", "prompt_labels": "The(O) call(O) for(O) creation(O) of(O) the(O) Akhand(O) Bharat(O) or(O) Akhand(O) Hindusthan(O) has(O) on(O) occasions(O) been(O) raised(O) by(O) Hindu(O) nationalist(O) organisations(O) such(O) as(O) the(O) Hindu(B-political party) Mahasabha(I-political party) ,(O) Kakbhusundi(B-organization) Revolutionary(I-organization) Forum(I-organization) ((O) KRF(B-organization) )(O) ,(O) Rashtriya(B-organization) Swayamsevak(I-organization) Sangh(I-organization) ((O) RSS(B-organization) )(O) ,(O) Vishwa(B-organization) Hindu(I-organization) Parishad(I-organization) ,(O) Shiv(B-political party) Sena(I-political party) ,(O) Hindu(B-political party) Sena(I-political party) ,(O) Hindu(B-organization) Janajagruti(I-organization) Samiti(I-organization) and(O) Bharatiya(B-political party) Janata(I-political party) Party(I-political party) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 3224, 11, 37038, 11, 1567, 11, 7471, 11, 6355, 11, 1732, 11, 5054, 4717, 323, 507, 627, 85664, 25, 578, 1650, 369, 9886, 315, 279, 16762, 10888, 67692, 266, 477, 16762, 10888, 20412, 592, 10118, 706, 389, 25975, 1027, 9408, 555, 36142, 52994, 29533, 1778, 439, 279, 36142, 16566, 300, 370, 4317, 1174, 75571, 65, 13092, 56998, 67679, 17997, 320, 735, 18077, 883, 1174, 60483, 23254, 7911, 328, 3195, 309, 325, 54721, 52022, 71, 320, 30374, 883, 1174, 88252, 10196, 36142, 60347, 329, 1174, 90913, 5476, 64, 1174, 36142, 5476, 64, 1174, 36142, 4448, 1662, 69405, 32973, 8388, 12583, 323, 67692, 9491, 7911, 4448, 460, 8722, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "look(O) for(O) pirates(B-title) of(I-title) the(I-title) caribbean(I-title) series(I-title)"}
{"id": "14", "dataset": "crossner_literature", "split": "dev", "label_list": ["organization", "person", "event", "literary genre", "award", "book", "poem", "writer", "country", "location", "magazine"], "instance": {"id": "14", "words": ["He", "is", "the", "protagonist", "of", "Robert", "Coover", "'", "s", "short", "story", "Charlie", "in", "the", "House", "of", "Rue", "(", "1980", ";", "reprinted", "in", "Coover", "'s", "1987", "collection", "A", "Night", "at", "the", "Movies", ")", ",", "and", "of", "Glen", "David", "Gold", "'", "s", "Sunnyside", "(", "2009", ")", ",", "a", "historical", "novel", "set", "in", "the", "First", "World", "War", "period", "."], "labels": ["O", "O", "O", "O", "O", "B-book", "I-book", "O", "O", "B-literary genre", "I-literary genre", "B-book", "I-book", "I-book", "I-book", "I-book", "I-book", "O", "O", "O", "O", "O", "B-writer", "O", "O", "O", "B-book", "I-book", "I-book", "I-book", "I-book", "O", "O", "O", "O", "B-writer", "I-writer", "I-writer", "O", "O", "B-book", "O", "O", "O", "O", "O", "B-literary genre", "I-literary genre", "O", "O", "O", "B-event", "I-event", "I-event", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, person, event, literary genre, award, book, poem, writer, country, location, magazine and O.\nSentence: He is the protagonist of Robert Coover ' s short story Charlie in the House of Rue ( 1980 ; reprinted in Coover 's 1987 collection A Night at the Movies ) , and of Glen David Gold ' s Sunnyside ( 2009 ) , a historical novel set in the First World War period .", "prompt_labels": "He(O) is(O) the(O) protagonist(O) of(O) Robert(B-book) Coover(I-book) '(O) s(O) short(B-literary genre) story(I-literary genre) Charlie(B-book) in(I-book) the(I-book) House(I-book) of(I-book) Rue(I-book) ((O) 1980(O) ;(O) reprinted(O) in(O) Coover(B-writer) 's(O) 1987(O) collection(O) A(B-book) Night(I-book) at(I-book) the(I-book) Movies(I-book) )(O) ,(O) and(O) of(O) Glen(B-writer) David(I-writer) Gold(I-writer) '(O) s(O) Sunnyside(B-book) ((O) 2009(O) )(O) ,(O) a(O) historical(B-literary genre) novel(I-literary genre) set(O) in(O) the(O) First(B-event) World(I-event) War(I-event) period(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 1732, 11, 1567, 11, 32465, 17779, 11, 10292, 11, 2363, 11, 33894, 11, 7061, 11, 3224, 11, 3813, 11, 14756, 323, 507, 627, 85664, 25, 1283, 374, 279, 46684, 315, 8563, 3623, 2017, 364, 274, 2875, 3446, 25972, 304, 279, 4783, 315, 79151, 320, 220, 3753, 15, 2652, 312, 53313, 304, 3623, 2017, 364, 82, 220, 3753, 22, 4526, 362, 13120, 520, 279, 27019, 883, 1174, 323, 315, 41061, 6941, 7573, 364, 274, 8219, 77, 1065, 579, 320, 220, 1049, 24, 883, 1174, 264, 13970, 11775, 743, 304, 279, 5629, 4435, 5111, 4261, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Early(O) interlingual(B-product) MT(I-product) systems(I-product) were(O) also(O) built(O) at(O) Stanford(B-location) in(O) the(O) 1970s(O) by(O) Roger(B-researcher) Schank(I-researcher) and(O) Yorick(B-researcher) Wilks(I-researcher) ;(O) the(O) former(O) became(O) the(O) basis(O) of(O) a(O) commercial(O) system(O) for(O) the(O) transfer(O) of(O) funds(O),(O) and(O) the(O) latter(O)'s(O) code(O) is(O) preserved(O) at(O) The(B-location) Computer(I-location) Museum(I-location) at(I-location) Boston(I-location) as(O) the(O) first(O) interlingual(O) machine(O) translation(O) system(O).(O)"}
{"id": "392", "dataset": "mit-movie", "split": "dev", "label_list": ["director", "song", "review", "trailer", "average ratings", "year", "rating", "actor", "plot", "character", "title", "genre"], "instance": {"id": "392", "words": ["what", "is", "the", "movie", "that", "has", "the", "song", "zip", "a", "dee", "doo", "dah"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-song", "I-song", "I-song", "I-song", "I-song"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, song, review, trailer, average ratings, year, rating, actor, plot, character, title, genre and O.\nSentence: what is the movie that has the song zip a dee doo dah", "prompt_labels": "what(O) is(O) the(O) movie(O) that(O) has(O) the(O) song(O) zip(B-song) a(I-song) dee(I-song) doo(I-song) dah(I-song)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 5609, 11, 3477, 11, 19809, 11, 5578, 18594, 11, 1060, 11, 10959, 11, 12360, 11, 7234, 11, 3752, 11, 2316, 11, 17779, 323, 507, 627, 85664, 25, 1148, 374, 279, 5818, 430, 706, 279, 5609, 10521, 264, 45833, 656, 78, 53588, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Jorge(B-writer) Luis(I-writer) Borges(I-writer) wrote(O) a(O) contemporary(O) bestiary(O) of(O) sorts(O),(O) the(O) Book(B-book) of(I-book) Imaginary(I-book) Beings(I-book),(O) which(O) collects(O) imaginary(O) beasts(O) from(O) bestiaries(O) and(O) fiction(O).(O)"}
{"id": "27", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Restaurant Name", "Hours", "Dish", "Rating", "Cuisine", "Price", "Amenity", "Location"], "instance": {"id": "27", "words": ["are", "there", "any", "chick", "fil", "as", "in", "the", "city", "open", "on", "sunday"], "labels": ["O", "O", "O", "B-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name", "B-Location", "I-Location", "I-Location", "O", "O", "B-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Hours, Dish, Rating, Cuisine, Price, Amenity, Location and O.\nSentence: are there any chick fil as in the city open on sunday", "prompt_labels": "are(O) there(O) any(O) chick(B-Restaurant Name) fil(I-Restaurant Name) as(I-Restaurant Name) in(B-Location) the(I-Location) city(I-Location) open(O) on(O) sunday(B-Hours)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 30192, 11, 49268, 11, 19767, 11, 81961, 11, 8650, 11, 3383, 56685, 11, 10067, 323, 507, 627, 85664, 25, 527, 1070, 904, 31863, 1488, 439, 304, 279, 3363, 1825, 389, 93463, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Juliana(B-musical artist) Hatfield(I-musical artist) is(O) an(O) American(O) musician(O) and(O) singer-songwriter(O) from(O) the(O) Boston(B-location) area(I-location),(O) formerly(O) of(O) the(O) indie(O) rock(O) bands(O) Blake(B-band) Babies(I-band),(O) Some(B-band) Girls(I-band),(O) and(O) The(B-band) Lemonheads(I-band).(O)"}
{"id": "523", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Cuisine", "Dish", "Price", "Location", "Restaurant Name", "Rating", "Hours", "Amenity"], "instance": {"id": "523", "words": ["how", "late", "pfchangs", "in", "paradise", "road", "will", "be", "open"], "labels": ["O", "O", "B-Restaurant Name", "O", "B-Location", "I-Location", "B-Hours", "I-Hours", "I-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Dish, Price, Location, Restaurant Name, Rating, Hours, Amenity and O.\nSentence: how late pfchangs in paradise road will be open", "prompt_labels": "how(O) late(O) pfchangs(B-Restaurant Name) in(O) paradise(B-Location) road(I-Location) will(B-Hours) be(I-Hours) open(I-Hours)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 49268, 11, 8650, 11, 10067, 11, 26568, 4076, 11, 19767, 11, 30192, 11, 3383, 56685, 323, 507, 627, 85664, 25, 1268, 3389, 28518, 331, 65587, 304, 50852, 5754, 690, 387, 1825, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "do(O) you(O) think(O) youd(O) be(O) able(O) to(O) help(O) me(O) find(O) the(B-title) penguins(I-title) of(I-title) madagascar(I-title) operation(I-title) dvd(I-title) premier(I-title)"}
{"id": "130", "dataset": "crossner_politics", "split": "dev", "label_list": ["election", "politician", "country", "political party", "person", "organization", "event", "location"], "instance": {"id": "130", "words": ["He", "contested", "Cardiff", "North", "in", "October", "1974", "United", "Kingdom", "general", "election", "and", "1979", "United", "Kingdom", "general", "election", "for", "the", "Liberals", ",", "before", "fighting", "Cardiff", "Central", "in", "1983", "United", "Kingdom", "general", "election", "and", "1987", "United", "Kingdom", "general", "election", "for", "the", "SDP-Liberal", "Alliance", ",", "but", "was", "unsuccessful", "on", "each", "occasion", "."], "labels": ["O", "O", "B-politician", "I-politician", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-political party", "O", "O", "O", "B-politician", "I-politician", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, politician, country, political party, person, organization, event, location and O.\nSentence: He contested Cardiff North in October 1974 United Kingdom general election and 1979 United Kingdom general election for the Liberals , before fighting Cardiff Central in 1983 United Kingdom general election and 1987 United Kingdom general election for the SDP-Liberal Alliance , but was unsuccessful on each occasion .", "prompt_labels": "He(O) contested(O) Cardiff(B-politician) North(I-politician) in(O) October(B-election) 1974(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) 1979(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) for(O) the(O) Liberals(B-political party) ,(O) before(O) fighting(O) Cardiff(B-politician) Central(I-politician) in(O) 1983(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) 1987(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) for(O) the(O) SDP-Liberal(B-political party) Alliance(I-political party) ,(O) but(O) was(O) unsuccessful(O) on(O) each(O) occasion(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 6355, 11, 37038, 11, 3224, 11, 5054, 4717, 11, 1732, 11, 7471, 11, 1567, 11, 3813, 323, 507, 627, 85664, 25, 1283, 57310, 61692, 4892, 304, 6664, 220, 4468, 19, 3723, 15422, 4689, 6355, 323, 220, 4468, 24, 3723, 15422, 4689, 6355, 369, 279, 52481, 1174, 1603, 11039, 61692, 10913, 304, 220, 3753, 18, 3723, 15422, 4689, 6355, 323, 220, 3753, 22, 3723, 15422, 4689, 6355, 369, 279, 8189, 47, 8288, 581, 3333, 23590, 1174, 719, 574, 46025, 389, 1855, 13402, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "On(O) 19(O) July(O) 2014(O),(O) Il(B-band) Divo(I-band) performed(O) before(O) a(O) capacity(O) crowd(O) at(O) Edinburgh(B-location) Castle(I-location) esplanade(I-location) where(O) a(O) pop(O) festival(O) took(O) place(O) ahead(O) of(O) the(O) 2014(B-event) Commonwealth(I-event) Games(I-event).(O)"}
{"id": "244", "dataset": "mit-movie", "split": "dev", "label_list": ["plot", "actor", "trailer", "genre", "rating", "year", "character", "average ratings", "song", "title", "director", "review"], "instance": {"id": "244", "words": ["when", "did", "the", "game", "come", "out"], "labels": ["O", "O", "B-title", "I-title", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, actor, trailer, genre, rating, year, character, average ratings, song, title, director, review and O.\nSentence: when did the game come out", "prompt_labels": "when(O) did(O) the(B-title) game(I-title) come(O) out(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 12360, 11, 19809, 11, 17779, 11, 10959, 11, 1060, 11, 3752, 11, 5578, 18594, 11, 5609, 11, 2316, 11, 7690, 11, 3477, 323, 507, 627, 85664, 25, 994, 1550, 279, 1847, 2586, 704, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "are(O) there(O) any(O) chick(B-Restaurant Name) fil(I-Restaurant Name) as(I-Restaurant Name) in(I-Restaurant Name) the(I-Restaurant Name) city(I-Restaurant Name) open(B-Hours) on(I-Hours) sunday(I-Hours)"}
{"id": "2209", "dataset": "mit-movie", "split": "dev", "label_list": ["genre", "actor", "rating", "character", "plot", "title", "year", "director", "trailer", "song", "average ratings", "review"], "instance": {"id": "2209", "words": ["what", "was", "that", "movie", "directed", "by", "yasushi", "muraki", "in", "the", "1990", "s", "that", "was", "rated", "pg", "13", "had", "a", "white", "castle", "and", "that", "people", "said", "was", "average"], "labels": ["O", "O", "O", "O", "O", "O", "B-director", "I-director", "O", "O", "B-year", "I-year", "O", "O", "O", "B-rating", "I-rating", "O", "O", "B-plot", "I-plot", "O", "O", "O", "O", "O", "B-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, actor, rating, character, plot, title, year, director, trailer, song, average ratings, review and O.\nSentence: what was that movie directed by yasushi muraki in the 1990 s that was rated pg 13 had a white castle and that people said was average", "prompt_labels": "what(O) was(O) that(O) movie(O) directed(O) by(O) yasushi(B-director) muraki(I-director) in(O) the(O) 1990(B-year) s(I-year) that(O) was(O) rated(O) pg(B-rating) 13(I-rating) had(O) a(O) white(B-plot) castle(I-plot) and(O) that(O) people(O) said(O) was(O) average(B-average ratings)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 12360, 11, 10959, 11, 3752, 11, 7234, 11, 2316, 11, 1060, 11, 7690, 11, 19809, 11, 5609, 11, 5578, 18594, 11, 3477, 323, 507, 627, 85664, 25, 1148, 574, 430, 5818, 15910, 555, 106989, 38174, 8309, 14966, 304, 279, 220, 2550, 15, 274, 430, 574, 22359, 17953, 220, 1032, 1047, 264, 4251, 33684, 323, 430, 1274, 1071, 574, 5578, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "what(O) was(O) that(O) movie(O) directed(O) by(O) yasushi(B-director) muraki(I-director) in(O) the(O) 1990(B-year) s(I-year) that(O) was(O) rated(O) pg(B-rating) 13(I-rating) had(O) a(O) white(B-plot) castle(I-plot) and(O) that(O) people(O) said(O) was(O) average(B-average ratings)"}
{"id": "1736", "dataset": "mit-movie", "split": "dev", "label_list": ["review", "title", "rating", "song", "year", "average ratings", "character", "genre", "actor", "trailer", "plot", "director"], "instance": {"id": "1736", "words": ["name", "all", "movies", "in", "the", "past", "ten", "decades", "that", "star", "jonathon", "saech"], "labels": ["O", "O", "O", "O", "O", "B-year", "I-year", "I-year", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, title, rating, song, year, average ratings, character, genre, actor, trailer, plot, director and O.\nSentence: name all movies in the past ten decades that star jonathon saech", "prompt_labels": "name(O) all(O) movies(O) in(O) the(O) past(B-year) ten(I-year) decades(I-year) that(O) star(O) jonathon(B-actor) saech(I-actor)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 2316, 11, 10959, 11, 5609, 11, 1060, 11, 5578, 18594, 11, 3752, 11, 17779, 11, 12360, 11, 19809, 11, 7234, 11, 7690, 323, 507, 627, 85664, 25, 836, 682, 9698, 304, 279, 3347, 5899, 11026, 430, 6917, 89604, 24893, 829, 4842, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "name(O) all(O) movies(O) in(O) the(O) past(B-year) ten(I-year) decades(I-year) that(O) star(O) jonathon(B-actor) saech(I-actor)"}
{"id": "175", "dataset": "crossner_science", "split": "dev", "label_list": ["person", "scientist", "university", "chemical compound", "enzyme", "organization", "theory", "protein", "country", "event", "astronomical object", "chemical element", "award", "academic journal", "location", "discipline"], "instance": {"id": "175", "words": ["His", "72", "peer", "reviewed", "scientific", "papers", "have", "been", "cite", "d", "3333", "times", "in", "journals", "such", "as", "the", "Journal", "of", "the", "American", "Chemical", "Society", ",", "the", "Journal", "of", "Physical", "Chemistry", ",", "the", "Journal", "of", "Chemical", "Physics", ",", "the", "Journal", "of", "Computational", "Chemistry", ",", "Chemical", "Physics", "Letters", "and", "Theoretical", "Chemistry", "Accounts", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O", "B-academic journal", "I-academic journal", "I-academic journal", "O", "B-academic journal", "I-academic journal", "I-academic journal", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, scientist, university, chemical compound, enzyme, organization, theory, protein, country, event, astronomical object, chemical element, award, academic journal, location, discipline and O.\nSentence: His 72 peer reviewed scientific papers have been cite d 3333 times in journals such as the Journal of the American Chemical Society , the Journal of Physical Chemistry , the Journal of Chemical Physics , the Journal of Computational Chemistry , Chemical Physics Letters and Theoretical Chemistry Accounts .", "prompt_labels": "His(O) 72(O) peer(O) reviewed(O) scientific(O) papers(O) have(O) been(O) cite(O) d(O) 3333(O) times(O) in(O) journals(O) such(O) as(O) the(O) Journal(B-academic journal) of(I-academic journal) the(I-academic journal) American(I-academic journal) Chemical(I-academic journal) Society(I-academic journal) ,(O) the(O) Journal(B-academic journal) of(I-academic journal) Physical(I-academic journal) Chemistry(I-academic journal) ,(O) the(O) Journal(B-academic journal) of(I-academic journal) Chemical(I-academic journal) Physics(I-academic journal) ,(O) the(O) Journal(B-academic journal) of(I-academic journal) Computational(I-academic journal) Chemistry(I-academic journal) ,(O) Chemical(B-academic journal) Physics(I-academic journal) Letters(I-academic journal) and(O) Theoretical(B-academic journal) Chemistry(I-academic journal) Accounts(I-academic journal) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 28568, 11, 12374, 11, 11742, 24549, 11, 49242, 11, 7471, 11, 10334, 11, 13128, 11, 3224, 11, 1567, 11, 87283, 1665, 11, 11742, 2449, 11, 10292, 11, 14584, 8486, 11, 3813, 11, 26434, 323, 507, 627, 85664, 25, 5414, 220, 5332, 14734, 22690, 12624, 16064, 617, 1027, 39396, 294, 220, 8765, 18, 3115, 304, 42780, 1778, 439, 279, 10139, 315, 279, 3778, 36424, 13581, 1174, 279, 10139, 315, 28479, 42846, 1174, 279, 10139, 315, 36424, 28415, 1174, 279, 10139, 315, 93028, 42846, 1174, 36424, 28415, 45397, 323, 578, 91867, 42846, 41755, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Lysostaphin(B-protein) can(O) lyse(O) Staphylococcus(B-astronomical object),(O) but(O) Micrococcus(B-astronomical object) bacteria(O) are(O) resistant(O) to(O) the(O) chemical(O).(O)"}
{"id": "1401", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Price", "Cuisine", "Amenity", "Location", "Dish", "Restaurant Name", "Hours", "Rating"], "instance": {"id": "1401", "words": ["where", "is", "the", "apple", "store", "in", "the", "area"], "labels": ["O", "O", "O", "B-Restaurant Name", "I-Restaurant Name", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Cuisine, Amenity, Location, Dish, Restaurant Name, Hours, Rating and O.\nSentence: where is the apple store in the area", "prompt_labels": "where(O) is(O) the(O) apple(B-Restaurant Name) store(I-Restaurant Name) in(B-Location) the(I-Location) area(I-Location)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 81961, 11, 3383, 56685, 11, 10067, 11, 49268, 11, 26568, 4076, 11, 30192, 11, 19767, 323, 507, 627, 85664, 25, 1405, 374, 279, 24149, 3637, 304, 279, 3158, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "what(O) was(O) the(O) last(O) film(O) elizabeth(B-actor) montgomery(I-actor) starred(O) in(O)"}
{"id": "302", "dataset": "crossner_politics", "split": "dev", "label_list": ["event", "person", "political party", "location", "election", "organization", "politician", "country"], "instance": {"id": "302", "words": ["This", "region", "has", "been", "dominated", "by", "the", "Conservative", "Party", "of", "Canada", "and", "the", "former", "Reform", "Party", "of", "Canada", "and", "Canadian", "Alliance", "parties", "for", "most", "of", "the", "time", "from", "1993", "to", "2011", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "B-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, person, political party, location, election, organization, politician, country and O.\nSentence: This region has been dominated by the Conservative Party of Canada and the former Reform Party of Canada and Canadian Alliance parties for most of the time from 1993 to 2011 .", "prompt_labels": "This(O) region(O) has(O) been(O) dominated(O) by(O) the(O) Conservative(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) and(O) the(O) former(O) Reform(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) and(O) Canadian(B-political party) Alliance(I-political party) parties(O) for(O) most(O) of(O) the(O) time(O) from(O) 1993(O) to(O) 2011(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 1732, 11, 5054, 4717, 11, 3813, 11, 6355, 11, 7471, 11, 37038, 11, 3224, 323, 507, 627, 85664, 25, 1115, 5654, 706, 1027, 30801, 555, 279, 30071, 8722, 315, 7008, 323, 279, 4846, 40365, 8722, 315, 7008, 323, 12152, 23590, 9875, 369, 1455, 315, 279, 892, 505, 220, 2550, 18, 311, 220, 679, 16, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "what(O) restaurants(O) nearby(B-Location) serve(O) ribs(B-Dish) and(O) ice(B-Dish) cream(I-Dish) sundaes(I-Dish)"}
{"id": "182", "dataset": "crossner_science", "split": "dev", "label_list": ["location", "enzyme", "university", "scientist", "organization", "event", "chemical element", "theory", "protein", "discipline", "astronomical object", "person", "country", "academic journal", "award", "chemical compound"], "instance": {"id": "182", "words": ["Lysostaphin", "can", "lyse", "Staphylococcus", ",", "but", "Micrococcus", "bacteria", "are", "resistant", "to", "the", "chemical", "."], "labels": ["B-enzyme", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, enzyme, university, scientist, organization, event, chemical element, theory, protein, discipline, astronomical object, person, country, academic journal, award, chemical compound and O.\nSentence: Lysostaphin can lyse Staphylococcus , but Micrococcus bacteria are resistant to the chemical .", "prompt_labels": "Lysostaphin(B-enzyme) can(O) lyse(O) Staphylococcus(O) ,(O) but(O) Micrococcus(O) bacteria(O) are(O) resistant(O) to(O) the(O) chemical(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 49242, 11, 12374, 11, 28568, 11, 7471, 11, 1567, 11, 11742, 2449, 11, 10334, 11, 13128, 11, 26434, 11, 87283, 1665, 11, 1732, 11, 3224, 11, 14584, 8486, 11, 10292, 11, 11742, 24549, 323, 507, 627, 85664, 25, 445, 1065, 537, 1366, 258, 649, 14869, 325, 800, 1366, 88, 1092, 92411, 1174, 719, 18654, 66, 92411, 24032, 527, 31785, 311, 279, 11742, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "find(O) me(O) a(O) fantasy(B-genre) movie(O) made(O) withing(O) the(O) past(B-year) eight(I-year) decades(I-year)"}
{"id": "652", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Amenity", "Location", "Cuisine", "Restaurant Name", "Dish", "Rating", "Hours", "Price"], "instance": {"id": "652", "words": ["i", "want", "to", "find", "a", "burger", "that", "isnt", "fast", "food"], "labels": ["O", "O", "O", "O", "O", "B-Dish", "O", "B-Rating", "I-Rating", "I-Rating"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Location, Cuisine, Restaurant Name, Dish, Rating, Hours, Price and O.\nSentence: i want to find a burger that isnt fast food", "prompt_labels": "i(O) want(O) to(O) find(O) a(O) burger(B-Dish) that(O) isnt(B-Rating) fast(I-Rating) food(I-Rating)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 10067, 11, 81961, 11, 26568, 4076, 11, 49268, 11, 19767, 11, 30192, 11, 8650, 323, 507, 627, 85664, 25, 602, 1390, 311, 1505, 264, 45723, 430, 70058, 5043, 3691, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "what(O) is(O) the(O) most(B-Price) expensive(I-Price) restaurant(O) with(O) a(O) dress(B-Amenity) code(I-Amenity) and(O) valet(B-Amenity) parking(I-Amenity) within(B-Location) 15(I-Location) miles(I-Location)"}
{"id": "1253", "dataset": "mit-movie", "split": "dev", "label_list": ["genre", "actor", "director", "average ratings", "review", "trailer", "song", "rating", "title", "character", "year", "plot"], "instance": {"id": "1253", "words": ["give", "me", "more", "details", "about", "the", "movie", "top", "gun"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, actor, director, average ratings, review, trailer, song, rating, title, character, year, plot and O.\nSentence: give me more details about the movie top gun", "prompt_labels": "give(O) me(O) more(O) details(O) about(O) the(O) movie(O) top(B-title) gun(I-title)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 12360, 11, 7690, 11, 5578, 18594, 11, 3477, 11, 19809, 11, 5609, 11, 10959, 11, 2316, 11, 3752, 11, 1060, 11, 7234, 323, 507, 627, 85664, 25, 3041, 757, 810, 3649, 922, 279, 5818, 1948, 6166, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "During(O) World(B-event) War(I-event) I(I-event) K\u00e4hler(I-event) supported(O) left(O) wing(O) SPD(O) politicians(O),(O) that(O) included(O) Clara(B-politician) Zetkin(I-politician) and(O) Rosa(B-politician) Luxemburg(I-politician) in(O) rejecting(O) the(O) party(O)'s(O) policy(O) of(O) Burgfrieden(B-event) ((O) a(O) truce(O) with(O) the(O) government(O),(O) promising(O) to(O) refrain(O) from(O) any(O) strikes(O) during(O) the(O) war(O) )(O) and(O) attended(O) an(O) international(O) socialist(O) women(O)'s(O) anti-war(O) conference(O) in(O) Berlin(B-location) organised(O) by(O) Zetkin(B-politician) in(O) 1915(O).(O)"}
{"id": "495", "dataset": "crossner_politics", "split": "dev", "label_list": ["politician", "country", "organization", "person", "political party", "event", "election", "location"], "instance": {"id": "495", "words": ["Kamerun", "were", "carried", "out", "by", "German", "Empire", "and", "Allies", "of", "World", "War", "I", "forces", "during", "the", "Kamerun", "Campaign", "of", "the", "First", "World", "War", "from", "August", "to", "September", "1914", "."], "labels": ["B-country", "O", "O", "O", "O", "B-country", "I-country", "O", "B-country", "O", "B-event", "I-event", "I-event", "O", "O", "O", "B-event", "I-event", "O", "O", "B-event", "I-event", "I-event", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, country, organization, person, political party, event, election, location and O.\nSentence: Kamerun were carried out by German Empire and Allies of World War I forces during the Kamerun Campaign of the First World War from August to September 1914 .", "prompt_labels": "Kamerun(B-country) were(O) carried(O) out(O) by(O) German(B-country) Empire(I-country) and(O) Allies(B-country) of(O) World(B-event) War(I-event) I(I-event) forces(O) during(O) the(O) Kamerun(B-event) Campaign(I-event) of(O) the(O) First(B-event) World(I-event) War(I-event) from(O) August(O) to(O) September(O) 1914(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 37038, 11, 3224, 11, 7471, 11, 1732, 11, 5054, 4717, 11, 1567, 11, 6355, 11, 3813, 323, 507, 627, 85664, 25, 735, 15589, 359, 1051, 11953, 704, 555, 6063, 21080, 323, 81774, 315, 4435, 5111, 358, 8603, 2391, 279, 735, 15589, 359, 27643, 315, 279, 5629, 4435, 5111, 505, 6287, 311, 6250, 220, 7529, 19, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "The(O) 38th(B-event) G8(I-event) summit(I-event) was(O) the(O) first(O) summit(O) for(O) French(O) President(O) Fran\u00e7ois(B-politician) Hollande(I-politician) and(O) was(O) the(O) last(O) summit(O) for(O) Dmitry(B-politician) Medvedev(I-politician) as(O) the(O) leader(O) of(O) Russia(B-country).(O)"}
{"id": "34", "dataset": "mit-movie", "split": "dev", "label_list": ["plot", "director", "rating", "trailer", "year", "genre", "title", "character", "review", "song", "actor", "average ratings"], "instance": {"id": "34", "words": ["what", "was", "the", "last", "film", "elizabeth", "montgomery", "starred", "in"], "labels": ["O", "O", "O", "B-year", "O", "B-actor", "I-actor", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, director, rating, trailer, year, genre, title, character, review, song, actor, average ratings and O.\nSentence: what was the last film elizabeth montgomery starred in", "prompt_labels": "what(O) was(O) the(O) last(B-year) film(O) elizabeth(B-actor) montgomery(I-actor) starred(O) in(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 7690, 11, 10959, 11, 19809, 11, 1060, 11, 17779, 11, 2316, 11, 3752, 11, 3477, 11, 5609, 11, 12360, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1148, 574, 279, 1566, 4632, 658, 19049, 20605, 39330, 59335, 304, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "His(O) 72(O) peer(O) reviewed(O) scientific(O) papers(O) have(O) been(O) cite(O) d(O) 3333(O) times(O) in(O) journals(O) such(O) as(O) the(O) Journal(B-academic journal) of(I-academic journal) the(I-academic journal) American(I-academic journal) Chemical(I-academic journal) Society(I-academic journal),(O) the(O) Journal(B-academic journal) of(I-academic journal) Physical(I-academic journal) Chemistry(I-academic journal),(O) the(O) Journal(B-academic journal) of(I-academic journal) Chemical(I-academic journal) Physics(I-academic journal),(O) the(O) Journal(B-academic journal) of(I-academic journal) Computational(I-academic journal) Chemistry(I-academic journal),(O) Chemical(B-academic journal) Physics(I-academic journal) Letters(I-academic journal) and(O) Theoretical(B-academic journal) Chemistry(I-academic journal) Accounts(I-academic journal).(O)"}
{"id": "474", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Hours", "Location", "Dish", "Rating", "Cuisine", "Price", "Amenity", "Restaurant Name"], "instance": {"id": "474", "words": ["hard", "rock", "hotel", "restaurant", "near", "me"], "labels": ["B-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Location, Dish, Rating, Cuisine, Price, Amenity, Restaurant Name and O.\nSentence: hard rock hotel restaurant near me", "prompt_labels": "hard(B-Restaurant Name) rock(I-Restaurant Name) hotel(I-Restaurant Name) restaurant(O) near(B-Location) me(I-Location)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 10067, 11, 49268, 11, 19767, 11, 81961, 11, 8650, 11, 3383, 56685, 11, 26568, 4076, 323, 507, 627, 85664, 25, 2653, 7091, 9689, 10960, 3221, 757, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "i(O) want(O) to(O) find(O) a(O) burger(B-Dish) that(O) isnt(B-Cuisine) fast(I-Cuisine) food(I-Cuisine)"}
{"id": "200", "dataset": "crossner_science", "split": "dev", "label_list": ["enzyme", "protein", "award", "location", "country", "chemical compound", "scientist", "academic journal", "chemical element", "event", "discipline", "organization", "astronomical object", "person", "theory", "university"], "instance": {"id": "200", "words": ["For", "example", ",", "Venus", "'", "s", "year", "(", "sidereal", "period", ")", "is", "225", "days", ",", "and", "Earth", "'", "s", "is", "365", "days", "."], "labels": ["O", "O", "O", "B-astronomical object", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-astronomical object", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: enzyme, protein, award, location, country, chemical compound, scientist, academic journal, chemical element, event, discipline, organization, astronomical object, person, theory, university and O.\nSentence: For example , Venus ' s year ( sidereal period ) is 225 days , and Earth ' s is 365 days .", "prompt_labels": "For(O) example(O) ,(O) Venus(B-astronomical object) '(O) s(O) year(O) ((O) sidereal(O) period(O) )(O) is(O) 225(O) days(O) ,(O) and(O) Earth(B-astronomical object) '(O) s(O) is(O) 365(O) days(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49242, 11, 13128, 11, 10292, 11, 3813, 11, 3224, 11, 11742, 24549, 11, 28568, 11, 14584, 8486, 11, 11742, 2449, 11, 1567, 11, 26434, 11, 7471, 11, 87283, 1665, 11, 1732, 11, 10334, 11, 12374, 323, 507, 627, 85664, 25, 1789, 3187, 1174, 50076, 364, 274, 1060, 320, 14414, 44353, 4261, 883, 374, 220, 11057, 2919, 1174, 323, 9420, 364, 274, 374, 220, 12676, 2919, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "hard(B-Restaurant Name) rock(I-Restaurant Name) hotel(I-Restaurant Name) restaurant(I-Restaurant Name) near(B-Location) me(I-Location)"}
{"id": "413", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Dish", "Price", "Location", "Hours", "Cuisine", "Amenity", "Rating", "Restaurant Name"], "instance": {"id": "413", "words": ["find", "me", "a", "thai", "restaurant", "with", "a", "great", "rating"], "labels": ["O", "O", "O", "B-Cuisine", "O", "O", "O", "B-Rating", "I-Rating"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Price, Location, Hours, Cuisine, Amenity, Rating, Restaurant Name and O.\nSentence: find me a thai restaurant with a great rating", "prompt_labels": "find(O) me(O) a(O) thai(B-Cuisine) restaurant(O) with(O) a(O) great(B-Rating) rating(I-Rating)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 8650, 11, 10067, 11, 30192, 11, 81961, 11, 3383, 56685, 11, 19767, 11, 26568, 4076, 323, 507, 627, 85664, 25, 1505, 757, 264, 18420, 10960, 449, 264, 2294, 10959, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "what(O) is(O) the(O) movie(O) directed(O) by(O) george(B-director) lucas(I-director) which(O) casts(O) darth(B-character) vader(I-character) and(O) yoda(B-character) in(O) it(O)"}
{"id": "1197", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Cuisine", "Rating", "Location", "Price", "Amenity", "Hours", "Restaurant Name", "Dish"], "instance": {"id": "1197", "words": ["what", "restaurants", "nearby", "serve", "ribs", "and", "ice", "cream", "sundaes"], "labels": ["O", "O", "B-Location", "O", "B-Dish", "O", "B-Dish", "I-Dish", "I-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Rating, Location, Price, Amenity, Hours, Restaurant Name, Dish and O.\nSentence: what restaurants nearby serve ribs and ice cream sundaes", "prompt_labels": "what(O) restaurants(O) nearby(B-Location) serve(O) ribs(B-Dish) and(O) ice(B-Dish) cream(I-Dish) sundaes(I-Dish)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 19767, 11, 10067, 11, 8650, 11, 3383, 56685, 11, 30192, 11, 26568, 4076, 11, 49268, 323, 507, 627, 85664, 25, 1148, 15926, 14373, 8854, 56249, 323, 10054, 12932, 924, 28996, 288, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "find(O) me(O) the(O) number(O) of(O) samurai(B-genre) films(O) made(O) in(O) the(O) 1960s(B-year)"}
{"id": "2402", "dataset": "mit-movie", "split": "dev", "label_list": ["director", "average ratings", "song", "plot", "title", "trailer", "actor", "genre", "rating", "character", "year", "review"], "instance": {"id": "2402", "words": ["what", "is", "the", "movie", "directed", "by", "george", "lucas", "which", "casts", "darth", "vader", "and", "yoda", "in", "it"], "labels": ["O", "O", "O", "O", "O", "O", "B-director", "I-director", "O", "O", "B-character", "I-character", "O", "B-character", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, average ratings, song, plot, title, trailer, actor, genre, rating, character, year, review and O.\nSentence: what is the movie directed by george lucas which casts darth vader and yoda in it", "prompt_labels": "what(O) is(O) the(O) movie(O) directed(O) by(O) george(B-director) lucas(I-director) which(O) casts(O) darth(B-character) vader(I-character) and(O) yoda(B-character) in(O) it(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 5578, 18594, 11, 5609, 11, 7234, 11, 2316, 11, 19809, 11, 12360, 11, 17779, 11, 10959, 11, 3752, 11, 1060, 11, 3477, 323, 507, 627, 85664, 25, 1148, 374, 279, 5818, 15910, 555, 3980, 6809, 27016, 300, 902, 57133, 15627, 339, 348, 1013, 323, 379, 14320, 304, 433, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "are(O) there(O) any(O) pg(B-rating) movies(O) with(O) car(B-plot) chases(I-plot)"}
{"id": "361", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Location", "Cuisine", "Rating", "Dish", "Price", "Restaurant Name", "Hours", "Amenity"], "instance": {"id": "361", "words": ["find", "me", "a", "chinese", "restaurant", "nearby"], "labels": ["O", "O", "O", "B-Cuisine", "O", "B-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Cuisine, Rating, Dish, Price, Restaurant Name, Hours, Amenity and O.\nSentence: find me a chinese restaurant nearby", "prompt_labels": "find(O) me(O) a(O) chinese(B-Cuisine) restaurant(O) nearby(B-Location)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 81961, 11, 19767, 11, 49268, 11, 8650, 11, 26568, 4076, 11, 30192, 11, 3383, 56685, 323, 507, 627, 85664, 25, 1505, 757, 264, 57487, 10960, 14373, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "The(O) organization(O) was(O) founded(O) in(O) October(O) 2002(O) during(O) the(O) build-up(O) to(O) the(O) United(B-country) States(I-country) '(O) 2003(O) invasion(O) of(O) Iraq(O) by(O) dozens(O) of(O) groups(O) including(O) the(O) National(B-organization) Organization(I-organization) for(I-organization) Women(I-organization),(O) National(B-organization) Council(I-organization) of(I-organization) Churches(I-organization),(O) Peace(B-organization) Action(I-organization),(O) the(O) American(B-organization) Friends(I-organization) Service(I-organization) Committee(I-organization),(O) Black(B-organization) Voices(I-organization) for(I-organization) Peace(I-organization),(O) Not(B-organization) In(I-organization) Our(I-organization) Name(I-organization),(O) September(B-organization) Eleventh(I-organization) Families(I-organization) for(I-organization) Peaceful(I-organization) Tomorrows(I-organization),(O) and(O) Veterans(B-organization) for(I-organization) Peace(I-organization).(O)"}
{"id": "900", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Location", "Rating", "Amenity", "Price", "Dish", "Hours", "Cuisine", "Restaurant Name"], "instance": {"id": "900", "words": ["is", "there", "any", "24", "hour", "deli", "on", "the", "west", "side", "of", "town"], "labels": ["O", "O", "O", "B-Hours", "I-Hours", "B-Cuisine", "O", "O", "B-Location", "I-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Rating, Amenity, Price, Dish, Hours, Cuisine, Restaurant Name and O.\nSentence: is there any 24 hour deli on the west side of town", "prompt_labels": "is(O) there(O) any(O) 24(B-Hours) hour(I-Hours) deli(B-Cuisine) on(O) the(O) west(B-Location) side(I-Location) of(I-Location) town(I-Location)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 19767, 11, 3383, 56685, 11, 8650, 11, 49268, 11, 30192, 11, 81961, 11, 26568, 4076, 323, 507, 627, 85664, 25, 374, 1070, 904, 220, 1187, 6596, 1624, 72, 389, 279, 9909, 3185, 315, 6424, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "help(O) me(O) find(O) jack(B-Restaurant Name) in(I-Restaurant Name) the(I-Restaurant Name) box(I-Restaurant Name) in(O) beverly(B-Location) hills(I-Location)"}
{"id": "1249", "dataset": "mit-movie", "split": "dev", "label_list": ["trailer", "year", "director", "average ratings", "character", "rating", "actor", "genre", "title", "review", "song", "plot"], "instance": {"id": "1249", "words": ["find", "me", "a", "fantasy", "movie", "made", "withing", "the", "past", "eight", "decades"], "labels": ["O", "O", "O", "B-genre", "O", "O", "O", "O", "B-year", "I-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, year, director, average ratings, character, rating, actor, genre, title, review, song, plot and O.\nSentence: find me a fantasy movie made withing the past eight decades", "prompt_labels": "find(O) me(O) a(O) fantasy(B-genre) movie(O) made(O) withing(O) the(O) past(B-year) eight(I-year) decades(I-year)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 1060, 11, 7690, 11, 5578, 18594, 11, 3752, 11, 10959, 11, 12360, 11, 17779, 11, 2316, 11, 3477, 11, 5609, 11, 7234, 323, 507, 627, 85664, 25, 1505, 757, 264, 18884, 5818, 1903, 449, 287, 279, 3347, 8223, 11026, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "where(O) is(O) the(O) apple(B-Restaurant Name) store(I-Restaurant Name) in(B-Location) the(I-Location) area(I-Location)"}
{"id": "269", "dataset": "mit-movie", "split": "dev", "label_list": ["genre", "title", "song", "actor", "director", "rating", "year", "character", "average ratings", "trailer", "review", "plot"], "instance": {"id": "269", "words": ["find", "me", "the", "number", "of", "samurai", "films", "made", "in", "the", "1960s"], "labels": ["O", "O", "O", "O", "O", "B-plot", "O", "O", "O", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, title, song, actor, director, rating, year, character, average ratings, trailer, review, plot and O.\nSentence: find me the number of samurai films made in the 1960s", "prompt_labels": "find(O) me(O) the(O) number(O) of(O) samurai(B-plot) films(O) made(O) in(O) the(O) 1960s(B-year)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 2316, 11, 5609, 11, 12360, 11, 7690, 11, 10959, 11, 1060, 11, 3752, 11, 5578, 18594, 11, 19809, 11, 3477, 11, 7234, 323, 507, 627, 85664, 25, 1505, 757, 279, 1396, 315, 10167, 49013, 12631, 1903, 304, 279, 220, 5162, 15, 82, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "give(O) me(O) more(O) details(O) about(O) the(O) movie(O) top(B-title) gun(I-title)"}
{"id": "426", "dataset": "crossner_science", "split": "dev", "label_list": ["theory", "academic journal", "chemical compound", "astronomical object", "discipline", "organization", "enzyme", "award", "protein", "country", "event", "person", "location", "university", "chemical element", "scientist"], "instance": {"id": "426", "words": ["Arkadelphia", "is", "home", "to", "two", "liberal", "arts", "institutions", ":", "Henderson", "State", "University", "(", "founded", "in", "1890", "as", "Arkadelphia", "Methodist", "College", ")", ",", "which", "is", "the", "only", "member", "of", "the", "Council", "of", "Public", "Liberal", "Arts", "Colleges", "based", "in", "Arkansas", "and", "announced", "plans", "to", "join", "the", "Arkansas", "State", "University", "System", "in", "October", "2019", ",", "and", "Ouachita", "Baptist", "University", ",", "a", "private", ",", "Baptist", "college", "affiliated", "with", "the", "Arkansas", "Baptist", "State", "Convention", "(", "opened", "in", "1886", ")", "."], "labels": ["B-location", "O", "O", "O", "O", "O", "O", "O", "O", "B-university", "I-university", "I-university", "O", "O", "O", "O", "O", "B-university", "I-university", "I-university", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-location", "O", "O", "O", "O", "O", "O", "B-university", "I-university", "I-university", "I-university", "O", "O", "O", "O", "O", "B-university", "I-university", "I-university", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: theory, academic journal, chemical compound, astronomical object, discipline, organization, enzyme, award, protein, country, event, person, location, university, chemical element, scientist and O.\nSentence: Arkadelphia is home to two liberal arts institutions : Henderson State University ( founded in 1890 as Arkadelphia Methodist College ) , which is the only member of the Council of Public Liberal Arts Colleges based in Arkansas and announced plans to join the Arkansas State University System in October 2019 , and Ouachita Baptist University , a private , Baptist college affiliated with the Arkansas Baptist State Convention ( opened in 1886 ) .", "prompt_labels": "Arkadelphia(B-location) is(O) home(O) to(O) two(O) liberal(O) arts(O) institutions(O) :(O) Henderson(B-university) State(I-university) University(I-university) ((O) founded(O) in(O) 1890(O) as(O) Arkadelphia(B-university) Methodist(I-university) College(I-university) )(O) ,(O) which(O) is(O) the(O) only(O) member(O) of(O) the(O) Council(B-organization) of(I-organization) Public(I-organization) Liberal(I-organization) Arts(I-organization) Colleges(I-organization) based(O) in(O) Arkansas(B-location) and(O) announced(O) plans(O) to(O) join(O) the(O) Arkansas(B-university) State(I-university) University(I-university) System(I-university) in(O) October(O) 2019(O) ,(O) and(O) Ouachita(B-university) Baptist(I-university) University(I-university) ,(O) a(O) private(O) ,(O) Baptist(O) college(O) affiliated(O) with(O) the(O) Arkansas(B-organization) Baptist(I-organization) State(I-organization) Convention(I-organization) ((O) opened(O) in(O) 1886(O) )(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10334, 11, 14584, 8486, 11, 11742, 24549, 11, 87283, 1665, 11, 26434, 11, 7471, 11, 49242, 11, 10292, 11, 13128, 11, 3224, 11, 1567, 11, 1732, 11, 3813, 11, 12374, 11, 11742, 2449, 11, 28568, 323, 507, 627, 85664, 25, 22791, 18281, 374, 2162, 311, 1403, 18250, 19071, 14673, 551, 45677, 3314, 3907, 320, 18538, 304, 220, 9378, 15, 439, 22791, 18281, 68601, 9304, 883, 1174, 902, 374, 279, 1193, 4562, 315, 279, 9251, 315, 3142, 31158, 17979, 79219, 3196, 304, 32790, 323, 7376, 6787, 311, 5249, 279, 32790, 3314, 3907, 744, 304, 6664, 220, 679, 24, 1174, 323, 69327, 613, 6388, 43748, 3907, 1174, 264, 879, 1174, 43748, 7926, 37506, 449, 279, 32790, 43748, 3314, 26958, 320, 9107, 304, 220, 9367, 21, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "For(O) example(O),(O) Venus(B-astronomical object)'s(O) year(O) ((O) sidereal(O) period(O) )(O) is(O) 225(O) days(O),(O) and(O) Earth(B-astronomical object)'s(O) is(O) 365(O) days(O).(O)"}
{"id": "644", "dataset": "mit-movie", "split": "dev", "label_list": ["director", "year", "average ratings", "genre", "song", "plot", "title", "character", "trailer", "rating", "review", "actor"], "instance": {"id": "644", "words": ["whats", "a", "mainstream", "movie", "about", "super", "heros"], "labels": ["O", "O", "B-genre", "O", "O", "B-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, year, average ratings, genre, song, plot, title, character, trailer, rating, review, actor and O.\nSentence: whats a mainstream movie about super heros", "prompt_labels": "whats(O) a(O) mainstream(B-genre) movie(O) about(O) super(B-plot) heros(I-plot)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 1060, 11, 5578, 18594, 11, 17779, 11, 5609, 11, 7234, 11, 2316, 11, 3752, 11, 19809, 11, 10959, 11, 3477, 11, 12360, 323, 507, 627, 85664, 25, 41209, 264, 21391, 5818, 922, 2307, 1077, 437, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "find(O) me(O) a(O) chinese(B-Cuisine) restaurant(O) nearby(B-Location)"}
{"id": "1137", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Location", "Rating", "Cuisine", "Amenity", "Restaurant Name", "Hours", "Dish", "Price"], "instance": {"id": "1137", "words": ["what", "is", "the", "most", "expensive", "restaurant", "with", "a", "dress", "code", "and", "valet", "parking", "within", "15", "miles"], "labels": ["O", "O", "O", "B-Price", "I-Price", "O", "O", "O", "B-Amenity", "I-Amenity", "O", "B-Amenity", "I-Amenity", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Rating, Cuisine, Amenity, Restaurant Name, Hours, Dish, Price and O.\nSentence: what is the most expensive restaurant with a dress code and valet parking within 15 miles", "prompt_labels": "what(O) is(O) the(O) most(B-Price) expensive(I-Price) restaurant(O) with(O) a(O) dress(B-Amenity) code(I-Amenity) and(O) valet(B-Amenity) parking(I-Amenity) within(B-Location) 15(I-Location) miles(I-Location)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 19767, 11, 81961, 11, 3383, 56685, 11, 26568, 4076, 11, 30192, 11, 49268, 11, 8650, 323, 507, 627, 85664, 25, 1148, 374, 279, 1455, 11646, 10960, 449, 264, 8679, 2082, 323, 11412, 1169, 13217, 2949, 220, 868, 8931, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Arkadelphia(B-location) is(O) home(O) to(O) two(O) liberal(O) arts(O) institutions(O) :(O) Henderson(B-university) State(I-university) University(I-university) ((O) founded(O) in(O) 1890(O) as(O) Arkadelphia(B-location) Methodist(I-location) College(I-location) )(O),(O) which(O) is(O) the(O) only(O) member(O) of(O) the(O) Council(B-organization) of(I-organization) Public(I-organization) Liberal(I-organization) Arts(I-organization) Colleges(I-organization) based(O) in(O) Arkansas(B-location) and(O) announced(O) plans(O) to(O) join(O) the(O) Arkansas(B-location) State(I-location) University(I-location) System(I-location) in(O) October(O) 2019(O),(O) and(O) Ouachita(B-university) Baptist(I-university) University(I-university),(O) a(O) private(O),(O) Baptist(B-organization) college(I-organization) affiliated(O) with(O) the(O) Arkansas(B-location) Baptist(I-location) State(I-location) Convention(I-location) ((O) opened(O) in(O) 1886(O) )(O).(O)"}
{"id": "113", "dataset": "mit-movie", "split": "dev", "label_list": ["character", "plot", "genre", "director", "title", "review", "trailer", "song", "year", "average ratings", "rating", "actor"], "instance": {"id": "113", "words": ["are", "there", "any", "pg", "movies", "with", "car", "chases"], "labels": ["O", "O", "O", "B-rating", "I-rating", "O", "B-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, plot, genre, director, title, review, trailer, song, year, average ratings, rating, actor and O.\nSentence: are there any pg movies with car chases", "prompt_labels": "are(O) there(O) any(O) pg(B-rating) movies(I-rating) with(O) car(B-plot) chases(I-plot)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 7234, 11, 17779, 11, 7690, 11, 2316, 11, 3477, 11, 19809, 11, 5609, 11, 1060, 11, 5578, 18594, 11, 10959, 11, 12360, 323, 507, 627, 85664, 25, 527, 1070, 904, 17953, 9698, 449, 1841, 523, 2315, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "find(O) me(O) a(O) good(B-Rating) buffet(B-Amenity) near(B-Location) stockton(I-Location) ca(I-Location)"}
{"id": "371", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Restaurant Name", "Price", "Rating", "Hours", "Amenity", "Cuisine", "Location", "Dish"], "instance": {"id": "371", "words": ["find", "me", "a", "good", "buffet", "near", "stockton", "ca"], "labels": ["O", "O", "O", "O", "B-Cuisine", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Price, Rating, Hours, Amenity, Cuisine, Location, Dish and O.\nSentence: find me a good buffet near stockton ca", "prompt_labels": "find(O) me(O) a(O) good(O) buffet(B-Cuisine) near(B-Location) stockton(I-Location) ca(I-Location)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 8650, 11, 19767, 11, 30192, 11, 3383, 56685, 11, 81961, 11, 10067, 11, 49268, 323, 507, 627, 85664, 25, 1505, 757, 264, 1695, 61886, 3221, 5708, 783, 2211, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "find(O) me(O) the(O) movie(O) that(O) has(O) a(O) aerosmith(B-song) song(O)"}
{"id": "394", "dataset": "crossner_politics", "split": "dev", "label_list": ["location", "political party", "organization", "election", "person", "politician", "country", "event"], "instance": {"id": "394", "words": ["Incumbent", "Democrat", "Carl", "Levin", "won", "re-election", "to", "a", "fourth", "term", "over", "Ronna", "Romney", "radio", "talk", "show", "host", "and", "former", "daughter-in-law", "of", "Michigan", "governor", "George", "W.", "Romney", "."], "labels": ["O", "O", "B-politician", "I-politician", "O", "O", "O", "O", "O", "O", "O", "B-politician", "I-politician", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "O", "B-politician", "I-politician", "I-politician", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, political party, organization, election, person, politician, country, event and O.\nSentence: Incumbent Democrat Carl Levin won re-election to a fourth term over Ronna Romney radio talk show host and former daughter-in-law of Michigan governor George W. Romney .", "prompt_labels": "Incumbent(O) Democrat(O) Carl(B-politician) Levin(I-politician) won(O) re-election(O) to(O) a(O) fourth(O) term(O) over(O) Ronna(B-politician) Romney(I-politician) radio(O) talk(O) show(O) host(O) and(O) former(O) daughter-in-law(O) of(O) Michigan(B-location) governor(O) George(B-politician) W.(I-politician) Romney(I-politician) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 5054, 4717, 11, 7471, 11, 6355, 11, 1732, 11, 37038, 11, 3224, 11, 1567, 323, 507, 627, 85664, 25, 4953, 3635, 306, 24846, 22770, 67977, 2834, 312, 43733, 311, 264, 11999, 4751, 927, 432, 13767, 26386, 9063, 3137, 1501, 3552, 323, 4846, 10003, 3502, 31412, 315, 14972, 19582, 10058, 468, 13, 26386, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Text(B-field) analysis(I-field) involves(O) information(B-field) retrieval(I-field),(O) lexical(B-field) analysis(I-field) to(O) study(O) word(O) frequency(O) distributions(O),(O) pattern(B-field) recognition(I-field),(O) tagging(B-field) /(O) annotation(O),(O) information(B-field) extraction(I-field),(O) data(B-field) mining(I-field) techniques(I-field) including(O) link(B-field) and(I-field) association(I-field) analysis(I-field),(O) visualization(B-field),(O) and(O) predictive(B-field) analytics(I-field).(O)"}
{"id": "484", "dataset": "crossner_politics", "split": "dev", "label_list": ["political party", "politician", "country", "person", "location", "event", "election", "organization"], "instance": {"id": "484", "words": ["During", "World", "War", "I", "K\u00e4hler", "supported", "left", "wing", "SPD", "politicians", ",", "that", "included", "Clara", "Zetkin", "and", "Rosa", "Luxemburg", "in", "rejecting", "the", "party", "'s", "policy", "of", "Burgfrieden", "(", "a", "truce", "with", "the", "government", ",", "promising", "to", "refrain", "from", "any", "strikes", "during", "the", "war", ")", "and", "attended", "an", "international", "socialist", "women", "'s", "anti-war", "conference", "in", "Berlin", "organised", "by", "Zetkin", "in", "1915", "."], "labels": ["O", "B-event", "I-event", "I-event", "B-politician", "O", "O", "O", "B-political party", "O", "O", "O", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "I-event", "I-event", "I-event", "O", "B-location", "O", "O", "B-person", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, politician, country, person, location, event, election, organization and O.\nSentence: During World War I K\u00e4hler supported left wing SPD politicians , that included Clara Zetkin and Rosa Luxemburg in rejecting the party 's policy of Burgfrieden ( a truce with the government , promising to refrain from any strikes during the war ) and attended an international socialist women 's anti-war conference in Berlin organised by Zetkin in 1915 .", "prompt_labels": "During(O) World(B-event) War(I-event) I(I-event) K\u00e4hler(B-politician) supported(O) left(O) wing(O) SPD(B-political party) politicians(O) ,(O) that(O) included(O) Clara(B-person) Zetkin(I-person) and(O) Rosa(B-person) Luxemburg(I-person) in(O) rejecting(O) the(O) party(O) 's(O) policy(O) of(O) Burgfrieden(O) ((O) a(O) truce(O) with(O) the(O) government(O) ,(O) promising(O) to(O) refrain(O) from(O) any(O) strikes(O) during(O) the(O) war(O) )(O) and(O) attended(O) an(O) international(B-event) socialist(I-event) women(I-event) 's(I-event) anti-war(I-event) conference(I-event) in(O) Berlin(B-location) organised(O) by(O) Zetkin(B-person) in(O) 1915(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5054, 4717, 11, 37038, 11, 3224, 11, 1732, 11, 3813, 11, 1567, 11, 6355, 11, 7471, 323, 507, 627, 85664, 25, 12220, 4435, 5111, 358, 735, 22243, 1565, 7396, 2163, 20611, 63824, 19287, 1174, 430, 5343, 51657, 1901, 295, 8148, 323, 47930, 27466, 9034, 5673, 304, 63686, 279, 4717, 364, 82, 4947, 315, 41109, 98625, 268, 320, 264, 490, 10743, 449, 279, 3109, 1174, 26455, 311, 58608, 505, 904, 23170, 2391, 279, 4208, 883, 323, 18677, 459, 6625, 41289, 3278, 364, 82, 7294, 48260, 10017, 304, 20437, 39433, 555, 1901, 295, 8148, 304, 220, 7529, 20, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "This(O) region(O) has(O) been(O) dominated(O) by(O) the(O) Conservative(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) and(O) the(O) former(O) Reform(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) and(O) Canadian(B-political party) Alliance(I-political party) parties(O) for(O) most(O) of(O) the(O) time(O) from(O) 1993(O) to(O) 2011(O).(O)"}
{"id": "78", "dataset": "crossner_politics", "split": "dev", "label_list": ["country", "election", "politician", "political party", "person", "location", "event", "organization"], "instance": {"id": "78", "words": ["The", "organization", "was", "founded", "in", "October", "2002", "during", "the", "build-up", "to", "the", "United", "States", "'", "2003", "invasion", "of", "Iraq", "by", "dozens", "of", "groups", "including", "the", "National", "Organization", "for", "Women", ",", "National", "Council", "of", "Churches", ",", "Peace", "Action", ",", "the", "American", "Friends", "Service", "Committee", ",", "Black", "Voices", "for", "Peace", ",", "Not", "In", "Our", "Name", ",", "September", "Eleventh", "Families", "for", "Peaceful", "Tomorrows", ",", "and", "Veterans", "for", "Peace", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-country", "I-country", "O", "B-event", "I-event", "I-event", "I-event", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, election, politician, political party, person, location, event, organization and O.\nSentence: The organization was founded in October 2002 during the build-up to the United States ' 2003 invasion of Iraq by dozens of groups including the National Organization for Women , National Council of Churches , Peace Action , the American Friends Service Committee , Black Voices for Peace , Not In Our Name , September Eleventh Families for Peaceful Tomorrows , and Veterans for Peace .", "prompt_labels": "The(O) organization(O) was(O) founded(O) in(O) October(O) 2002(O) during(O) the(O) build-up(O) to(O) the(O) United(B-country) States(I-country) '(O) 2003(B-event) invasion(I-event) of(I-event) Iraq(I-event) by(O) dozens(O) of(O) groups(O) including(O) the(O) National(B-organization) Organization(I-organization) for(I-organization) Women(I-organization) ,(O) National(B-organization) Council(I-organization) of(I-organization) Churches(I-organization) ,(O) Peace(B-organization) Action(I-organization) ,(O) the(O) American(B-organization) Friends(I-organization) Service(I-organization) Committee(I-organization) ,(O) Black(B-organization) Voices(I-organization) for(I-organization) Peace(I-organization) ,(O) Not(B-organization) In(I-organization) Our(I-organization) Name(I-organization) ,(O) September(B-organization) Eleventh(I-organization) Families(I-organization) for(I-organization) Peaceful(I-organization) Tomorrows(I-organization) ,(O) and(O) Veterans(B-organization) for(I-organization) Peace(I-organization) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 6355, 11, 37038, 11, 5054, 4717, 11, 1732, 11, 3813, 11, 1567, 11, 7471, 323, 507, 627, 85664, 25, 578, 7471, 574, 18538, 304, 6664, 220, 1049, 17, 2391, 279, 1977, 5352, 311, 279, 3723, 4273, 364, 220, 1049, 18, 30215, 315, 11340, 555, 22700, 315, 5315, 2737, 279, 5165, 21021, 369, 11215, 1174, 5165, 9251, 315, 94641, 1174, 26888, 5703, 1174, 279, 3778, 23323, 5475, 10554, 1174, 5348, 83426, 369, 26888, 1174, 2876, 763, 5751, 4076, 1174, 6250, 27039, 45707, 50556, 369, 26888, 1285, 8529, 269, 1849, 1174, 323, 40432, 369, 26888, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Kamerun(B-location) were(O) carried(O) out(O) by(O) German(B-country) Empire(I-country) and(O) Allies(O) of(O) World(B-event) War(I-event) I(I-event) forces(O) during(O) the(O) Kamerun(B-location) Campaign(I-location) of(I-location) the(I-location) First(I-location) World(I-location) War(I-location) I(I-location) forces(O) during(O) the(O) Kamerun(B-location) Campaign(I-location) of(I-location) the(I-location) First(I-location) World(I-location) War(I-location) I(I-location) forces(O) during(O) the(O) Kamerun(B-location) Campaign(I-location) of(I-location) the(I-location) First(I-location) World(I-location) War(I-location) I(I-location) forces(O) during(O) the(O) Kamerun(B-location) Campaign(I-location) of(I-location) the(I-location) First(I-location) World(I-location) War(I-location) I(I-location) forces(O) during(O) the(O) Kamerun(B-location) Campaign(I-location) of(I-location) the(I-location) First(I-location) World(I-location) War(I-location) I(I-location) forces(O) during(O) the(O) Kamerun(B-location) Campaign(I-location) of(I-location) the(I-location) First(I-location) World(I-location) War(I-location) I(I-location) forces(O) during(O) the(O) Kamerun(B-location) Campaign(I-location) of(I-location) the(I-location) First(I-location) World(I-location) War(I-location) I(I-location) forces(O) during(O) the(O) Kamerun(B-location) Campaign(I-location) of(I-location) the(I-location) First(I-location) World(I-location) War(I-location) I(I-location) forces(O) during(O) the(O) Kamerun(B-location) Campaign(I-location) of(I-location) the(I-location) First(I-location) World(I-location) War(I-location) I(I-location) forces(O) during(O) the(O) Kamerun(B-location) Campaign(I-location) of(I-location) the(I-location) First(I-location) World(I-location) War(I-location) I(I-location) forces(O) during(O) the(O) Kamerun(B-location) Campaign(I-location) of(I-location) the(I-location) First(I-location) World(I-location) War(I-location) I(I-location) forces(O) during(O) the(O) Kamerun(B-location) Campaign(I-location) of(I-location) the(I-location) First(I-location) World(I-location) War(I-location) I(I-location) forces(O) during(O) the(O) Kamerun(B-location) Campaign(I-location) of(I-location) the(I-location) First(I-location) World(I-location) War(I-location) I(I-location) forces(O) during(O) the(O) Kamerun(B-location) Campaign(I-location) of(I-location) the(I-location) First(I-location) World(I-location) War(I-location) I(I-location) forces(O) during(O) the(O) Kamerun(B-location) Campaign(I-location) of(I-location) the(I-location) First(I-location) World(I-location) War(I-location) I(I-location) forces(O) during(O) the(O) Kamerun(B-location) Campaign(I-location) of(I-location) the(I-location) First(I-location) World(I-location) War(I-location) I(I-location) forces(O) during(O) the(O) Kamerun(B-location) Campaign(I-location) of(I-location) the(I-location) First(I-location) World(I-location) War(I-location) I(I-location) forces(O) during(O) the(O) Kamerun(B-location) Campaign(I-location) of(I-location) the(I-location) First(I-location) World(I-location) War(I-location) I(I-location) forces(O) during(O) the(O) Kamerun(B-location) Campaign(I-location) of(I-location) the(I-location) First(I-location) World(I-location) War(I-location) I(I-location) forces(O) during(O) the(O) Kamerun(B-location) Campaign(I-location) of(I-location) the(I-location) First(I-location) World(I-location) War(I-location) I(I-location) forces(O) during(O) the(O) Kamerun(B-location) Campaign(I-location) of(I-location) the(I-location) First(I-location) World(I-location) War(I-location) I(I-location) forces(O) during(O) the(O) Kamerun(B-location) Campaign(I-location) of(I-location) the(I-location) First(I-location) World(I-location) War(I-location) I(I-location) forces(O) during(O) the(O) Kamerun(B-location) Campaign(I-location) of(I-location) the(I-location) First(I-location) World(I-location) War(I-location) I(I-location) forces(O) during(O) the(O) Kamerun(B-location) Campaign(I-location) of(I-location) the(I-location) First(I-location) World(I-location) War(I-location) I(I-location) forces(O) during(O) the(O) Kamerun(B-location) Campaign(I"}
{"id": "37", "dataset": "mit-movie", "split": "dev", "label_list": ["actor", "genre", "character", "review", "year", "average ratings", "song", "trailer", "rating", "plot", "director", "title"], "instance": {"id": "37", "words": ["find", "me", "the", "movie", "that", "has", "a", "aerosmith", "song"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-song", "I-song"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, genre, character, review, year, average ratings, song, trailer, rating, plot, director, title and O.\nSentence: find me the movie that has a aerosmith song", "prompt_labels": "find(O) me(O) the(O) movie(O) that(O) has(O) a(O) aerosmith(B-song) song(I-song)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 17779, 11, 3752, 11, 3477, 11, 1060, 11, 5578, 18594, 11, 5609, 11, 19809, 11, 10959, 11, 7234, 11, 7690, 11, 2316, 323, 507, 627, 85664, 25, 1505, 757, 279, 5818, 430, 706, 264, 49825, 44774, 5609, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "find(O) me(O) a(O) thai(B-Cuisine) restaurant(O) with(O) a(O) great(B-Rating) rating(I-Rating)"}
{"id": "473", "dataset": "mit-movie", "split": "dev", "label_list": ["average ratings", "song", "plot", "year", "title", "rating", "actor", "director", "trailer", "character", "genre", "review"], "instance": {"id": "473", "words": ["which", "movie", "stars", "emma", "watson", "playing", "another", "role", "aside", "from", "hermione", "granger"], "labels": ["O", "O", "O", "B-actor", "I-actor", "B-plot", "I-plot", "I-plot", "I-plot", "I-plot", "B-character", "I-character"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, song, plot, year, title, rating, actor, director, trailer, character, genre, review and O.\nSentence: which movie stars emma watson playing another role aside from hermione granger", "prompt_labels": "which(O) movie(O) stars(O) emma(B-actor) watson(I-actor) playing(B-plot) another(I-plot) role(I-plot) aside(I-plot) from(I-plot) hermione(B-character) granger(I-character)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 5609, 11, 7234, 11, 1060, 11, 2316, 11, 10959, 11, 12360, 11, 7690, 11, 19809, 11, 3752, 11, 17779, 11, 3477, 323, 507, 627, 85664, 25, 902, 5818, 9958, 991, 1764, 30125, 942, 5737, 2500, 3560, 16038, 505, 1077, 76, 6473, 1099, 4091, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "is(O) there(O) any(O) 24(B-Hours) hour(I-Hours) deli(B-Cuisine) on(O) the(O) west(B-Location) side(I-Location) of(I-Location) town(I-Location)"}
{"id": "479", "dataset": "crossner_politics", "split": "dev", "label_list": ["organization", "politician", "political party", "election", "location", "person", "country", "event"], "instance": {"id": "479", "words": ["The", "38th", "G8", "summit", "was", "the", "first", "summit", "for", "French", "President", "Fran\u00e7ois", "Hollande", "and", "was", "the", "last", "summit", "for", "Dmitry", "Medvedev", "as", "the", "leader", "of", "Russia", "."], "labels": ["O", "B-event", "I-event", "I-event", "O", "O", "O", "O", "O", "O", "O", "B-politician", "I-politician", "O", "O", "O", "O", "O", "O", "B-politician", "I-politician", "O", "O", "O", "O", "B-country", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, politician, political party, election, location, person, country, event and O.\nSentence: The 38th G8 summit was the first summit for French President Fran\u00e7ois Hollande and was the last summit for Dmitry Medvedev as the leader of Russia .", "prompt_labels": "The(O) 38th(B-event) G8(I-event) summit(I-event) was(O) the(O) first(O) summit(O) for(O) French(O) President(O) Fran\u00e7ois(B-politician) Hollande(I-politician) and(O) was(O) the(O) last(O) summit(O) for(O) Dmitry(B-politician) Medvedev(I-politician) as(O) the(O) leader(O) of(O) Russia(B-country) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 37038, 11, 5054, 4717, 11, 6355, 11, 3813, 11, 1732, 11, 3224, 11, 1567, 323, 507, 627, 85664, 25, 578, 220, 1987, 339, 480, 23, 30048, 574, 279, 1176, 30048, 369, 8753, 4900, 85807, 94431, 323, 574, 279, 1566, 30048, 369, 88231, 3344, 2111, 5230, 439, 279, 7808, 315, 8524, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "whats(O) a(O) mainstream(B-average ratings) movie(O) about(O) super(B-plot) heros(I-plot)"}
{"id": "484", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Dish", "Location", "Price", "Rating", "Amenity", "Hours", "Restaurant Name", "Cuisine"], "instance": {"id": "484", "words": ["help", "me", "find", "jack", "in", "the", "box", "in", "beverly", "hills"], "labels": ["O", "O", "O", "B-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Location, Price, Rating, Amenity, Hours, Restaurant Name, Cuisine and O.\nSentence: help me find jack in the box in beverly hills", "prompt_labels": "help(O) me(O) find(O) jack(B-Restaurant Name) in(I-Restaurant Name) the(I-Restaurant Name) box(I-Restaurant Name) in(O) beverly(B-Location) hills(I-Location)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 10067, 11, 8650, 11, 19767, 11, 3383, 56685, 11, 30192, 11, 26568, 4076, 11, 81961, 323, 507, 627, 85664, 25, 1520, 757, 1505, 26128, 304, 279, 3830, 304, 387, 424, 398, 35231, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Incumbent(O) Democrat(O) Carl(B-politician) Levin(I-politician) won(O) re-election(O) to(O) a(O) fourth(O) term(O) over(O) Ronna(B-politician) Romney(I-politician) radio(O) talk(O) show(O) host(O) and(O) former(O) daughter-in-law(O) of(O) Michigan(O) governor(O) George(B-politician) W.(I-politician) Romney(I-politician).(O)"}
{"id": "78", "dataset": "crossner_ai", "split": "dev", "label_list": ["university", "field", "organization", "location", "metric", "country", "product", "person", "programming language", "algorithm", "conference", "researcher", "task"], "instance": {"id": "78", "words": ["Text", "analysis", "involves", "information", "retrieval", ",", "lexical", "analysis", "to", "study", "word", "frequency", "distributions", ",", "pattern", "recognition", ",", "tagging", "/", "annotation", ",", "information", "extraction", ",", "data", "mining", "techniques", "including", "link", "and", "association", "analysis", ",", "visualization", ",", "and", "predictive", "analytics", "."], "labels": ["B-field", "I-field", "O", "B-task", "I-task", "O", "B-task", "I-task", "O", "O", "O", "O", "O", "O", "B-field", "I-field", "O", "B-task", "I-task", "I-task", "O", "B-task", "I-task", "O", "B-field", "I-field", "O", "O", "B-task", "I-task", "I-task", "I-task", "O", "B-task", "O", "O", "B-task", "I-task", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, field, organization, location, metric, country, product, person, programming language, algorithm, conference, researcher, task and O.\nSentence: Text analysis involves information retrieval , lexical analysis to study word frequency distributions , pattern recognition , tagging / annotation , information extraction , data mining techniques including link and association analysis , visualization , and predictive analytics .", "prompt_labels": "Text(B-field) analysis(I-field) involves(O) information(B-task) retrieval(I-task) ,(O) lexical(B-task) analysis(I-task) to(O) study(O) word(O) frequency(O) distributions(O) ,(O) pattern(B-field) recognition(I-field) ,(O) tagging(B-task) /(I-task) annotation(I-task) ,(O) information(B-task) extraction(I-task) ,(O) data(B-field) mining(I-field) techniques(O) including(O) link(B-task) and(I-task) association(I-task) analysis(I-task) ,(O) visualization(B-task) ,(O) and(O) predictive(B-task) analytics(I-task) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12374, 11, 2115, 11, 7471, 11, 3813, 11, 18767, 11, 3224, 11, 2027, 11, 1732, 11, 15840, 4221, 11, 12384, 11, 10017, 11, 32185, 11, 3465, 323, 507, 627, 85664, 25, 2991, 6492, 18065, 2038, 57470, 1174, 78686, 6492, 311, 4007, 3492, 11900, 43785, 1174, 5497, 18324, 1174, 79253, 611, 21917, 1174, 2038, 33289, 1174, 828, 11935, 12823, 2737, 2723, 323, 15360, 6492, 1174, 42148, 1174, 323, 60336, 28975, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "which(O) movie(O) stars(O) emma(B-actor) watson(I-actor) playing(O) another(O) role(O) aside(O) from(O) hermione(B-character) granger(I-character)"}
{"id": "1965", "dataset": "mit-movie", "split": "dev", "label_list": ["title", "rating", "review", "character", "year", "trailer", "song", "genre", "average ratings", "director", "plot", "actor"], "instance": {"id": "1965", "words": ["what", "good", "romantic", "comedy", "can", "i", "watch", "that", "is", "about", "star", "crossed", "lovers"], "labels": ["O", "O", "B-genre", "I-genre", "O", "O", "O", "O", "O", "O", "B-plot", "I-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, rating, review, character, year, trailer, song, genre, average ratings, director, plot, actor and O.\nSentence: what good romantic comedy can i watch that is about star crossed lovers", "prompt_labels": "what(O) good(O) romantic(B-genre) comedy(I-genre) can(O) i(O) watch(O) that(O) is(O) about(O) star(B-plot) crossed(I-plot) lovers(I-plot)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 10959, 11, 3477, 11, 3752, 11, 1060, 11, 19809, 11, 5609, 11, 17779, 11, 5578, 18594, 11, 7690, 11, 7234, 11, 12360, 323, 507, 627, 85664, 25, 1148, 1695, 24364, 23160, 649, 602, 3821, 430, 374, 922, 6917, 28129, 33218, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "what(O) good(O) romantic(B-genre) comedy(I-genre) can(O) i(O) watch(O) that(O) is(O) about(O) star(B-plot) crossed(I-plot) lovers(I-plot)"}
{"id": "1054", "dataset": "mit-movie", "split": "dev", "label_list": ["plot", "review", "actor", "title", "rating", "genre", "year", "director", "trailer", "song", "average ratings", "character"], "instance": {"id": "1054", "words": ["a", "1980", "well", "rated", "pg", "13", "that", "involves", "fighting", "of", "any", "kind"], "labels": ["O", "B-year", "B-average ratings", "I-average ratings", "B-rating", "I-rating", "O", "O", "B-plot", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, review, actor, title, rating, genre, year, director, trailer, song, average ratings, character and O.\nSentence: a 1980 well rated pg 13 that involves fighting of any kind", "prompt_labels": "a(O) 1980(B-year) well(B-average ratings) rated(I-average ratings) pg(B-rating) 13(I-rating) that(O) involves(O) fighting(B-plot) of(O) any(O) kind(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 3477, 11, 12360, 11, 2316, 11, 10959, 11, 17779, 11, 1060, 11, 7690, 11, 19809, 11, 5609, 11, 5578, 18594, 11, 3752, 323, 507, 627, 85664, 25, 264, 220, 3753, 15, 1664, 22359, 17953, 220, 1032, 430, 18065, 11039, 315, 904, 3169, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "a(O) 1980(B-year) well(B-average ratings) rated(I-average ratings) pg(B-rating) 13(I-rating) that(O) involves(O) fighting(B-plot) of(I-plot) any(I-plot) kind(I-plot)"}
{"id": "2015", "dataset": "mit-movie", "split": "dev", "label_list": ["rating", "plot", "actor", "song", "review", "average ratings", "genre", "character", "title", "director", "trailer", "year"], "instance": {"id": "2015", "words": ["what", "is", "a", "good", "comedy", "from", "the", "1990", "s"], "labels": ["O", "O", "O", "O", "B-genre", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, plot, actor, song, review, average ratings, genre, character, title, director, trailer, year and O.\nSentence: what is a good comedy from the 1990 s", "prompt_labels": "what(O) is(O) a(O) good(O) comedy(B-genre) from(O) the(O) 1990(B-year) s(I-year)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 7234, 11, 12360, 11, 5609, 11, 3477, 11, 5578, 18594, 11, 17779, 11, 3752, 11, 2316, 11, 7690, 11, 19809, 11, 1060, 323, 507, 627, 85664, 25, 1148, 374, 264, 1695, 23160, 505, 279, 220, 2550, 15, 274, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "This(O) led(O) also(O) to(O) group(O)'s(O) various(O) theoretical(O) efforts(O),(O) such(O) as(O) development(O) of(O) electric(O) field-driven(O) torque(O) models(O) of(O) the(O) mitochondrial(O) motor(O) ATP(O) synthase(O) and(O) efforts(O) to(O) understand(O) mechanisms(O) of(O) disease-implicated(O) mitochondrial(O) mutations(O) in(O) the(O) Electron(B-discipline) transport(I-discipline) chain(I-discipline),(O) E.(Prodan(B-scientist),(O) C.(Prodan(I-scientist),(O) and(O) J.(H.(Miller(I-scientist),(O) Jr(O).(O)"}
{"id": "2073", "dataset": "mit-movie", "split": "dev", "label_list": ["actor", "director", "character", "song", "plot", "trailer", "average ratings", "review", "genre", "rating", "year", "title"], "instance": {"id": "2073", "words": ["what", "is", "the", "last", "teen", "movie", "that", "john", "huston", "directed"], "labels": ["O", "O", "O", "O", "B-genre", "O", "O", "B-director", "I-director", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, director, character, song, plot, trailer, average ratings, review, genre, rating, year, title and O.\nSentence: what is the last teen movie that john huston directed", "prompt_labels": "what(O) is(O) the(O) last(O) teen(B-genre) movie(O) that(O) john(B-director) huston(I-director) directed(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 7690, 11, 3752, 11, 5609, 11, 7234, 11, 19809, 11, 5578, 18594, 11, 3477, 11, 17779, 11, 10959, 11, 1060, 11, 2316, 323, 507, 627, 85664, 25, 1148, 374, 279, 1566, 9562, 5818, 430, 40742, 59750, 263, 15910, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "do(O) you(O) know(O) the(O) title(O) to(O) the(O) documentary(B-genre) that(O) rutger(B-actor) hauer(I-actor) appeared(O) in(O) some(O) time(O) around(O) 1950(B-year)"}
{"id": "178", "dataset": "crossner_politics", "split": "dev", "label_list": ["country", "location", "political party", "event", "election", "organization", "person", "politician"], "instance": {"id": "178", "words": ["A", "cash", "book", "kept", "by", "Flick", "company", "accountant", "Rudolph", "Diehl", "listed", "that", "next", "to", "other", "transfers", ",", "250,000", "Deutschemark", "was", "transferred", "to", "Christian", "Social", "Union", "in", "Bavaria", "chairman", "Franz", "Josef", "Strauss", "and", "565,000", "Deutschemark", "were", "transferred", "to", "Christian", "Democratic", "Union", "of", "Germany", "chairman", "Helmut", "Kohl", ",", "as", "well", "as", "payments", "to", "FDP", "and", "Social", "Democratic", "Party", "of", "Germany", "politicians", "."], "labels": ["O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "B-person", "I-person", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "B-politician", "I-politician", "I-politician", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "B-politician", "I-politician", "O", "O", "O", "O", "O", "O", "B-political party", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, location, political party, event, election, organization, person, politician and O.\nSentence: A cash book kept by Flick company accountant Rudolph Diehl listed that next to other transfers , 250,000 Deutschemark was transferred to Christian Social Union in Bavaria chairman Franz Josef Strauss and 565,000 Deutschemark were transferred to Christian Democratic Union of Germany chairman Helmut Kohl , as well as payments to FDP and Social Democratic Party of Germany politicians .", "prompt_labels": "A(O) cash(O) book(O) kept(O) by(O) Flick(B-organization) company(I-organization) accountant(O) Rudolph(B-person) Diehl(I-person) listed(O) that(O) next(O) to(O) other(O) transfers(O) ,(O) 250,000(O) Deutschemark(O) was(O) transferred(O) to(O) Christian(B-political party) Social(I-political party) Union(I-political party) in(I-political party) Bavaria(I-political party) chairman(O) Franz(B-politician) Josef(I-politician) Strauss(I-politician) and(O) 565,000(O) Deutschemark(O) were(O) transferred(O) to(O) Christian(B-political party) Democratic(I-political party) Union(I-political party) of(I-political party) Germany(I-political party) chairman(O) Helmut(B-politician) Kohl(I-politician) ,(O) as(O) well(O) as(O) payments(O) to(O) FDP(B-political party) and(O) Social(B-political party) Democratic(I-political party) Party(I-political party) of(I-political party) Germany(I-political party) politicians(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 3813, 11, 5054, 4717, 11, 1567, 11, 6355, 11, 7471, 11, 1732, 11, 37038, 323, 507, 627, 85664, 25, 362, 8515, 2363, 8774, 555, 435, 1228, 2883, 76021, 48538, 44070, 8574, 18442, 10212, 430, 1828, 311, 1023, 31711, 1174, 220, 5154, 11, 931, 1611, 6256, 2464, 847, 574, 23217, 311, 9052, 9983, 9323, 304, 78080, 10649, 21892, 66620, 98541, 94511, 323, 220, 20943, 11, 931, 1611, 6256, 2464, 847, 1051, 23217, 311, 9052, 11650, 9323, 315, 10057, 21892, 16183, 7129, 34975, 75, 1174, 439, 1664, 439, 14507, 311, 435, 10510, 323, 9983, 11650, 8722, 315, 10057, 19287, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "VoiceOver(B-product) was(O) for(O) the(O) first(O) time(O) featured(O) in(O) 2005(O) in(O) Mac(B-product) OS(I-product) X(I-product) Tiger(I-product) ((O) 10.4(O) )(O).(O)"}
{"id": "367", "dataset": "crossner_science", "split": "dev", "label_list": ["award", "discipline", "academic journal", "astronomical object", "scientist", "enzyme", "location", "person", "chemical element", "event", "university", "organization", "country", "theory", "chemical compound", "protein"], "instance": {"id": "367", "words": ["This", "led", "also", "to", "group", "'s", "various", "theoretical", "efforts", ",", "such", "as", "development", "of", "electric", "field-driven", "torque", "models", "of", "the", "mitochondrial", "motor", "ATP", "synthase", "and", "efforts", "to", "understand", "mechanisms", "of", "disease-implicated", "mitochondrial", "mutations", "in", "the", "Electron", "transport", "chain", ",", "E.", "Prodan", ",", "C.", "Prodan", ",", "and", "J.", "H.", "Miller", ",", "Jr", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-enzyme", "I-enzyme", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "O", "O", "B-scientist", "I-scientist", "I-scientist", "I-scientist", "I-scientist", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, discipline, academic journal, astronomical object, scientist, enzyme, location, person, chemical element, event, university, organization, country, theory, chemical compound, protein and O.\nSentence: This led also to group 's various theoretical efforts , such as development of electric field-driven torque models of the mitochondrial motor ATP synthase and efforts to understand mechanisms of disease-implicated mitochondrial mutations in the Electron transport chain , E. Prodan , C. Prodan , and J. H. Miller , Jr .", "prompt_labels": "This(O) led(O) also(O) to(O) group(O) 's(O) various(O) theoretical(O) efforts(O) ,(O) such(O) as(O) development(O) of(O) electric(O) field-driven(O) torque(O) models(O) of(O) the(O) mitochondrial(O) motor(O) ATP(B-enzyme) synthase(I-enzyme) and(O) efforts(O) to(O) understand(O) mechanisms(O) of(O) disease-implicated(O) mitochondrial(O) mutations(O) in(O) the(O) Electron(O) transport(O) chain(O) ,(O) E.(B-scientist) Prodan(I-scientist) ,(O) C.(B-scientist) Prodan(I-scientist) ,(O) and(O) J.(B-scientist) H.(I-scientist) Miller(I-scientist) ,(I-scientist) Jr(I-scientist) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10292, 11, 26434, 11, 14584, 8486, 11, 87283, 1665, 11, 28568, 11, 49242, 11, 3813, 11, 1732, 11, 11742, 2449, 11, 1567, 11, 12374, 11, 7471, 11, 3224, 11, 10334, 11, 11742, 24549, 11, 13128, 323, 507, 627, 85664, 25, 1115, 6197, 1101, 311, 1912, 364, 82, 5370, 32887, 9045, 1174, 1778, 439, 4500, 315, 9249, 2115, 32505, 42131, 4211, 315, 279, 72061, 9048, 67656, 43998, 521, 323, 9045, 311, 3619, 24717, 315, 8624, 12, 6802, 14040, 72061, 34684, 304, 279, 77976, 7710, 8957, 1174, 469, 13, 1322, 36255, 1174, 356, 13, 1322, 36255, 1174, 323, 622, 13, 473, 13, 17472, 1174, 16014, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "find(O) a(O) critically(B-average ratings) acclaimed(I-average ratings) 1980(B-year) sci(B-genre) fi(I-genre) film(O)"}
{"id": "383", "dataset": "crossner_science", "split": "dev", "label_list": ["chemical element", "astronomical object", "country", "enzyme", "chemical compound", "award", "event", "academic journal", "university", "organization", "discipline", "location", "scientist", "protein", "theory", "person"], "instance": {"id": "383", "words": ["The", "following", "asteroids", "were", "named", "in", "memory", "of", "the", "other", "six", "members", "of", "STS-107", ":", "51823", "Rickhusband", ",", "51825", "Davidbrown", ",", "51826", "Kalpanachawla", ",", "51827", "Laurelclark", ",", "51828", "Ilanramon", "and", "51829", "Williemccool", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-event", "O", "B-astronomical object", "I-astronomical object", "O", "B-astronomical object", "I-astronomical object", "O", "B-astronomical object", "I-astronomical object", "O", "B-astronomical object", "I-astronomical object", "O", "B-astronomical object", "I-astronomical object", "O", "B-astronomical object", "I-astronomical object", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical element, astronomical object, country, enzyme, chemical compound, award, event, academic journal, university, organization, discipline, location, scientist, protein, theory, person and O.\nSentence: The following asteroids were named in memory of the other six members of STS-107 : 51823 Rickhusband , 51825 Davidbrown , 51826 Kalpanachawla , 51827 Laurelclark , 51828 Ilanramon and 51829 Williemccool .", "prompt_labels": "The(O) following(O) asteroids(O) were(O) named(O) in(O) memory(O) of(O) the(O) other(O) six(O) members(O) of(O) STS-107(B-event) :(O) 51823(B-astronomical object) Rickhusband(I-astronomical object) ,(O) 51825(B-astronomical object) Davidbrown(I-astronomical object) ,(O) 51826(B-astronomical object) Kalpanachawla(I-astronomical object) ,(O) 51827(B-astronomical object) Laurelclark(I-astronomical object) ,(O) 51828(B-astronomical object) Ilanramon(I-astronomical object) and(O) 51829(B-astronomical object) Williemccool(I-astronomical object) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 11742, 2449, 11, 87283, 1665, 11, 3224, 11, 49242, 11, 11742, 24549, 11, 10292, 11, 1567, 11, 14584, 8486, 11, 12374, 11, 7471, 11, 26434, 11, 3813, 11, 28568, 11, 13128, 11, 10334, 11, 1732, 323, 507, 627, 85664, 25, 578, 2768, 85322, 1051, 7086, 304, 5044, 315, 279, 1023, 4848, 3697, 315, 4015, 50, 12, 7699, 551, 220, 21312, 1419, 23194, 13092, 7198, 1174, 220, 21312, 914, 6941, 65561, 1174, 220, 21312, 1627, 27930, 857, 613, 675, 4355, 1174, 220, 21312, 1544, 81564, 566, 847, 1174, 220, 21312, 1591, 7695, 276, 2453, 263, 323, 220, 21312, 1682, 4946, 27960, 641, 1786, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "In(O) 1968(B-election) New(I-election) York(I-election) Post(I-election) Also(O) in(O) 1968(O),(O) he(O) was(O) asked(O) by(O) Black(B-political party) Panther(I-political party) Party(I-political party) leader(O) Eldridge(B-politician) Cleaver(I-politician) to(O) serve(O) as(O) his(O) running(O) mate(O) on(O) the(O) Peace(B-political party) and(I-political party) Freedom(I-political party) Party(I-political party) ticket(O) in(O) 1968(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ((O) he(O) declined(O) the(O) offer(O) )(O).(O)"}
{"id": "1739", "dataset": "mit-movie", "split": "dev", "label_list": ["year", "average ratings", "song", "director", "rating", "review", "trailer", "character", "genre", "actor", "title", "plot"], "instance": {"id": "1739", "words": ["name", "an", "emotional", "film", "from", "2000", "that", "is", "highly", "liked"], "labels": ["O", "O", "B-genre", "O", "O", "B-year", "O", "O", "B-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, average ratings, song, director, rating, review, trailer, character, genre, actor, title, plot and O.\nSentence: name an emotional film from 2000 that is highly liked", "prompt_labels": "name(O) an(O) emotional(B-genre) film(O) from(O) 2000(B-year) that(O) is(O) highly(B-average ratings) liked(I-average ratings)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 5578, 18594, 11, 5609, 11, 7690, 11, 10959, 11, 3477, 11, 19809, 11, 3752, 11, 17779, 11, 12360, 11, 2316, 11, 7234, 323, 507, 627, 85664, 25, 836, 459, 14604, 4632, 505, 220, 1049, 15, 430, 374, 7701, 15262, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Like(O) rural(O) Alberta(O),(O) Calgary(B-location) was(O) a(O) clean(O) sweep(O) for(O) the(O) politically(O) rightmost(O) party(O) in(O) all(O) but(O) one(O) election(O) from(O) 1972(O) to(O) 2011(O) :(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) of(I-political party) Canada(I-political party) through(O) 1988(O),(O) Reform(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) in(O) 1993(O) and(O) 1997(O),(O) the(O) Canadian(B-political party) Alliance(I-political party) in(O) 2000(O) and(O) 2004(O).(O)"}
{"id": "90", "dataset": "crossner_politics", "split": "dev", "label_list": ["politician", "event", "location", "organization", "election", "political party", "person", "country"], "instance": {"id": "90", "words": ["Other", "political", "parties", "that", "have", "practiced", "fusion", "include", "the", "Conservative", "Party", "of", "New", "York", "State", ",", "the", "Working", "Families", "Party", "and", "the", "Liberal", "Party", "of", "New", "York", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, event, location, organization, election, political party, person, country and O.\nSentence: Other political parties that have practiced fusion include the Conservative Party of New York State , the Working Families Party and the Liberal Party of New York .", "prompt_labels": "Other(O) political(O) parties(O) that(O) have(O) practiced(O) fusion(O) include(O) the(O) Conservative(B-political party) Party(I-political party) of(I-political party) New(I-political party) York(I-political party) State(I-political party) ,(O) the(O) Working(B-political party) Families(I-political party) Party(I-political party) and(O) the(O) Liberal(B-political party) Party(I-political party) of(I-political party) New(I-political party) York(I-political party) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 37038, 11, 1567, 11, 3813, 11, 7471, 11, 6355, 11, 5054, 4717, 11, 1732, 11, 3224, 323, 507, 627, 85664, 25, 7089, 5054, 9875, 430, 617, 44664, 37608, 2997, 279, 30071, 8722, 315, 1561, 4356, 3314, 1174, 279, 22938, 50556, 8722, 323, 279, 31158, 8722, 315, 1561, 4356, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "show(O) me(O) a(O) list(O) of(O) independent(B-genre) comedy(I-genre) films(O) made(O) in(O) 2009(B-year)"}
{"id": "1216", "dataset": "mit-movie", "split": "dev", "label_list": ["average ratings", "actor", "review", "genre", "title", "character", "director", "rating", "plot", "year", "trailer", "song"], "instance": {"id": "1216", "words": ["do", "you", "know", "the", "title", "to", "the", "documentary", "that", "rutger", "hauer", "appeared", "in", "some", "time", "around", "1950"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-genre", "O", "B-actor", "I-actor", "O", "O", "O", "O", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, actor, review, genre, title, character, director, rating, plot, year, trailer, song and O.\nSentence: do you know the title to the documentary that rutger hauer appeared in some time around 1950", "prompt_labels": "do(O) you(O) know(O) the(O) title(O) to(O) the(O) documentary(B-genre) that(O) rutger(B-actor) hauer(I-actor) appeared(O) in(O) some(O) time(O) around(O) 1950(B-year)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 12360, 11, 3477, 11, 17779, 11, 2316, 11, 3752, 11, 7690, 11, 10959, 11, 7234, 11, 1060, 11, 19809, 11, 5609, 323, 507, 627, 85664, 25, 656, 499, 1440, 279, 2316, 311, 279, 25999, 430, 55719, 1414, 305, 28196, 9922, 304, 1063, 892, 2212, 220, 6280, 15, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "what(O) is(O) a(O) good(O) comedy(B-genre) from(O) the(O) 1990(B-year) s(I-year)"}
{"id": "1430", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Cuisine", "Amenity", "Rating", "Dish", "Hours", "Location", "Restaurant Name", "Price"], "instance": {"id": "1430", "words": ["where", "is", "the", "nearest", "burger", "place"], "labels": ["O", "O", "O", "B-Location", "B-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Amenity, Rating, Dish, Hours, Location, Restaurant Name, Price and O.\nSentence: where is the nearest burger place", "prompt_labels": "where(O) is(O) the(O) nearest(B-Location) burger(B-Cuisine) place(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 3383, 56685, 11, 19767, 11, 49268, 11, 30192, 11, 10067, 11, 26568, 4076, 11, 8650, 323, 507, 627, 85664, 25, 1405, 374, 279, 24379, 45723, 2035, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "The(O) following(O) asteroids(O) were(O) named(O) in(O) memory(O) of(O) the(O) other(O) six(O) members(O) of(O) STS-107(O) :(O) 51823(B-chemical compound) Rickhusband(I-chemical compound),(O) 51825(B-chemical compound) Davidbrown(I-chemical compound),(O) 51826(B-chemical compound) Kalpanachawla(I-chemical compound),(O) 51827(B-chemical compound) Laurelclark(I-chemical compound),(O) 51828(I-chemical compound) Ilanramon(I-chemical compound) and(O) 51829(B-chemical compound) Williemccool(I-chemical compound).(O)"}
{"id": "398", "dataset": "crossner_science", "split": "dev", "label_list": ["academic journal", "event", "scientist", "discipline", "astronomical object", "location", "theory", "award", "enzyme", "chemical element", "person", "organization", "chemical compound", "university", "country", "protein"], "instance": {"id": "398", "words": ["CoRoT", "discovered", "its", "first", "two", "planets", "in", "2007", ":", "the", "hot", "Jupiter", "s", "CoRoT-1b", "and", "CoRoT-2b", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-astronomical object", "I-astronomical object", "O", "B-astronomical object", "O", "B-astronomical object", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: academic journal, event, scientist, discipline, astronomical object, location, theory, award, enzyme, chemical element, person, organization, chemical compound, university, country, protein and O.\nSentence: CoRoT discovered its first two planets in 2007 : the hot Jupiter s CoRoT-1b and CoRoT-2b .", "prompt_labels": "CoRoT(O) discovered(O) its(O) first(O) two(O) planets(O) in(O) 2007(O) :(O) the(O) hot(B-astronomical object) Jupiter(I-astronomical object) s(O) CoRoT-1b(B-astronomical object) and(O) CoRoT-2b(B-astronomical object) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 14584, 8486, 11, 1567, 11, 28568, 11, 26434, 11, 87283, 1665, 11, 3813, 11, 10334, 11, 10292, 11, 49242, 11, 11742, 2449, 11, 1732, 11, 7471, 11, 11742, 24549, 11, 12374, 11, 3224, 11, 13128, 323, 507, 627, 85664, 25, 3623, 39972, 51, 11352, 1202, 1176, 1403, 33975, 304, 220, 1049, 22, 551, 279, 4106, 50789, 274, 3623, 39972, 51, 12, 16, 65, 323, 3623, 39972, 51, 12, 17, 65, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "where(O) is(O) the(O) nearest(B-Location) burger(B-Cuisine) place(O)"}
{"id": "255", "dataset": "crossner_music", "split": "dev", "label_list": ["organization", "musical instrument", "musical artist", "album", "award", "location", "song", "event", "country", "music genre", "person", "band"], "instance": {"id": "255", "words": ["Since", "2001", ",", "the", "dominance", "of", "traditional", "boy", "bands", "on", "pop", "charts", "began", "to", "fade", "in", "the", "western", "hemisphere", ",", "although", "Gil", "Kaufman", "of", "MTV", "has", "described", "new", "boy", "bands", "that", "are", "more", "likely", "to", "resemble", "My", "Chemical", "Romance", ",", "Sum", "41", ",", "and", "Simple", "Plan", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-music genre", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-musical artist", "I-musical artist", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-band", "I-band", "I-band", "O", "B-band", "I-band", "O", "O", "B-band", "I-band", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, musical instrument, musical artist, album, award, location, song, event, country, music genre, person, band and O.\nSentence: Since 2001 , the dominance of traditional boy bands on pop charts began to fade in the western hemisphere , although Gil Kaufman of MTV has described new boy bands that are more likely to resemble My Chemical Romance , Sum 41 , and Simple Plan .", "prompt_labels": "Since(O) 2001(O) ,(O) the(O) dominance(O) of(O) traditional(O) boy(O) bands(O) on(O) pop(B-music genre) charts(O) began(O) to(O) fade(O) in(O) the(O) western(O) hemisphere(O) ,(O) although(O) Gil(B-musical artist) Kaufman(I-musical artist) of(O) MTV(O) has(O) described(O) new(O) boy(O) bands(O) that(O) are(O) more(O) likely(O) to(O) resemble(O) My(B-band) Chemical(I-band) Romance(I-band) ,(O) Sum(B-band) 41(I-band) ,(O) and(O) Simple(B-band) Plan(I-band) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 18273, 14473, 11, 18273, 10255, 11, 8176, 11, 10292, 11, 3813, 11, 5609, 11, 1567, 11, 3224, 11, 4731, 17779, 11, 1732, 11, 7200, 323, 507, 627, 85664, 25, 8876, 220, 1049, 16, 1174, 279, 44592, 315, 8776, 8334, 21562, 389, 2477, 27223, 6137, 311, 15366, 304, 279, 19001, 69766, 1174, 8051, 21456, 59254, 1543, 315, 62199, 706, 7633, 502, 8334, 21562, 430, 527, 810, 4461, 311, 52280, 3092, 36424, 52256, 1174, 8279, 220, 3174, 1174, 323, 9170, 9878, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "hi(O) please(O) find(O) me(O) a(O) sushi(B-Cuisine) restaurant(O) that(O) has(O) good(B-Rating) reviews(I-Rating) and(O) that(O) isnt(B-Price) too(I-Price) expensive(I-Price)"}
{"id": "281", "dataset": "crossner_ai", "split": "dev", "label_list": ["algorithm", "country", "organization", "task", "metric", "conference", "researcher", "programming language", "product", "person", "field", "location", "university"], "instance": {"id": "281", "words": ["VoiceOver", "was", "for", "the", "first", "time", "featured", "in", "2005", "in", "Mac", "OS", "X", "Tiger", "(", "10.4", ")", "."], "labels": ["B-product", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-product", "I-product", "I-product", "I-product", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, country, organization, task, metric, conference, researcher, programming language, product, person, field, location, university and O.\nSentence: VoiceOver was for the first time featured in 2005 in Mac OS X Tiger ( 10.4 ) .", "prompt_labels": "VoiceOver(B-product) was(O) for(O) the(O) first(O) time(O) featured(O) in(O) 2005(O) in(O) Mac(B-product) OS(I-product) X(I-product) Tiger(I-product) ((O) 10.4(O) )(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12384, 11, 3224, 11, 7471, 11, 3465, 11, 18767, 11, 10017, 11, 32185, 11, 15840, 4221, 11, 2027, 11, 1732, 11, 2115, 11, 3813, 11, 12374, 323, 507, 627, 85664, 25, 29030, 1959, 574, 369, 279, 1176, 892, 15109, 304, 220, 1049, 20, 304, 7553, 10293, 1630, 36845, 320, 220, 605, 13, 19, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "whats(O) the(O) cheapest(B-Price) fast(B-Cuisine) food(I-Cuisine) restaurant(O) that(O) has(O) a(O) play(B-Amenity) area(I-Amenity) for(I-Amenity) children(I-Amenity)"}
{"id": "491", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Cuisine", "Dish", "Location", "Hours", "Price", "Rating", "Amenity", "Restaurant Name"], "instance": {"id": "491", "words": ["hi", "please", "find", "me", "a", "sushi", "restaurant", "that", "has", "good", "reviews", "and", "that", "isnt", "too", "expensive"], "labels": ["O", "O", "O", "O", "O", "B-Cuisine", "O", "O", "O", "B-Rating", "I-Rating", "O", "O", "B-Price", "I-Price", "I-Price"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Dish, Location, Hours, Price, Rating, Amenity, Restaurant Name and O.\nSentence: hi please find me a sushi restaurant that has good reviews and that isnt too expensive", "prompt_labels": "hi(O) please(O) find(O) me(O) a(O) sushi(B-Cuisine) restaurant(O) that(O) has(O) good(B-Rating) reviews(I-Rating) and(O) that(O) isnt(B-Price) too(I-Price) expensive(I-Price)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 49268, 11, 10067, 11, 30192, 11, 8650, 11, 19767, 11, 3383, 56685, 11, 26568, 4076, 323, 507, 627, 85664, 25, 15960, 4587, 1505, 757, 264, 67322, 10960, 430, 706, 1695, 8544, 323, 430, 70058, 2288, 11646, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "i(O) need(O) directions(O) to(O) the(O) nearest(B-Location) ethiopian(B-Cuisine) restaurant(O)"}
{"id": "234", "dataset": "crossner_politics", "split": "dev", "label_list": ["event", "political party", "politician", "organization", "election", "country", "person", "location"], "instance": {"id": "234", "words": ["In", "1983", "United", "Kingdom", "general", "election", ",", "as", "a", "DUP", "candidate", ",", "Seawright", "finished", "second", "with", "8,260", "votes", "behind", "Cecil", "Walker", "of", "the", "UUP", ",", "whilst", "in", "1987", "United", "Kingdom", "general", "election", "he", "finished", "third", "behind", "Walker", "and", "Alban", "Maginness", "(", "Social", "Democratic", "and", "Labour", "Party", ")", "with", "5,671", "votes", "as", "a", "Protestant", "Unionist", "candidate", "(", "although", "the", "DUP", "did", "not", "contest", "the", "seat", "due", "to", "an", "electoral", "pact", "between", "the", "DUP", "and", "UUP", "at", "the", "time", ")", "."], "labels": ["O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "O", "B-political party", "O", "O", "B-politician", "O", "O", "O", "O", "O", "O", "B-politician", "I-politician", "O", "O", "B-political party", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "B-politician", "O", "B-politician", "I-politician", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "O", "O", "O", "O", "B-political party", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "O", "B-political party", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, political party, politician, organization, election, country, person, location and O.\nSentence: In 1983 United Kingdom general election , as a DUP candidate , Seawright finished second with 8,260 votes behind Cecil Walker of the UUP , whilst in 1987 United Kingdom general election he finished third behind Walker and Alban Maginness ( Social Democratic and Labour Party ) with 5,671 votes as a Protestant Unionist candidate ( although the DUP did not contest the seat due to an electoral pact between the DUP and UUP at the time ) .", "prompt_labels": "In(O) 1983(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) as(O) a(O) DUP(B-political party) candidate(O) ,(O) Seawright(B-politician) finished(O) second(O) with(O) 8,260(O) votes(O) behind(O) Cecil(B-politician) Walker(I-politician) of(O) the(O) UUP(B-political party) ,(O) whilst(O) in(O) 1987(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) he(O) finished(O) third(O) behind(O) Walker(B-politician) and(O) Alban(B-politician) Maginness(I-politician) ((O) Social(B-political party) Democratic(I-political party) and(I-political party) Labour(I-political party) Party(I-political party) )(O) with(O) 5,671(O) votes(O) as(O) a(O) Protestant(B-political party) Unionist(I-political party) candidate(O) ((O) although(O) the(O) DUP(B-political party) did(O) not(O) contest(O) the(O) seat(O) due(O) to(O) an(O) electoral(O) pact(O) between(O) the(O) DUP(B-political party) and(O) UUP(B-political party) at(O) the(O) time(O) )(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 5054, 4717, 11, 37038, 11, 7471, 11, 6355, 11, 3224, 11, 1732, 11, 3813, 323, 507, 627, 85664, 25, 763, 220, 3753, 18, 3723, 15422, 4689, 6355, 1174, 439, 264, 88624, 9322, 1174, 1369, 675, 1315, 8220, 2132, 449, 220, 23, 11, 11387, 12973, 4920, 90227, 23074, 315, 279, 549, 3202, 1174, 24797, 304, 220, 3753, 22, 3723, 15422, 4689, 6355, 568, 8220, 4948, 4920, 23074, 323, 57991, 7023, 71773, 320, 9983, 11650, 323, 18993, 8722, 883, 449, 220, 20, 11, 23403, 12973, 439, 264, 60753, 9323, 380, 9322, 320, 8051, 279, 88624, 1550, 539, 14130, 279, 10954, 4245, 311, 459, 34941, 60821, 1990, 279, 88624, 323, 549, 3202, 520, 279, 892, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "im(O) trying(O) to(O) find(O) a(O) family(B-Amenity) friendly(I-Amenity) restaurant(O) with(O) a(O) gift(B-Amenity) shop(I-Amenity) within(B-Location) 10(I-Location) miles(I-Location) of(I-Location) sunswept(I-Location) hotel(I-Location) in(I-Location) orange(I-Location) beach(I-Location)"}
{"id": "443", "dataset": "crossner_politics", "split": "dev", "label_list": ["organization", "location", "country", "politician", "political party", "person", "election", "event"], "instance": {"id": "443", "words": ["The", "film", "features", "Ranjith", "and", "Anamika", "in", "lead", "roles", ",", "with", "Ravichandran", ",", "Pyramid", "Natarajan", ",", "Manivannan", ",", "Vasu", "Vikram", ",", "Rajesh", ",", "Raj", "Kapoor", ",", "T.", "P.", "Gajendran", ",", "Alex", "and", "Pandu", "playing", "supporting", "roles", "."], "labels": ["O", "O", "O", "B-person", "O", "B-person", "O", "O", "O", "O", "O", "B-person", "O", "B-person", "I-person", "O", "B-person", "O", "B-person", "I-person", "O", "B-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "I-person", "O", "B-person", "O", "B-person", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, location, country, politician, political party, person, election, event and O.\nSentence: The film features Ranjith and Anamika in lead roles , with Ravichandran , Pyramid Natarajan , Manivannan , Vasu Vikram , Rajesh , Raj Kapoor , T. P. Gajendran , Alex and Pandu playing supporting roles .", "prompt_labels": "The(O) film(O) features(O) Ranjith(B-person) and(O) Anamika(B-person) in(O) lead(O) roles(O) ,(O) with(O) Ravichandran(B-person) ,(O) Pyramid(B-person) Natarajan(I-person) ,(O) Manivannan(B-person) ,(O) Vasu(B-person) Vikram(I-person) ,(O) Rajesh(B-person) ,(O) Raj(B-person) Kapoor(I-person) ,(O) T.(B-person) P.(I-person) Gajendran(I-person) ,(O) Alex(B-person) and(O) Pandu(B-person) playing(O) supporting(O) roles(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 3813, 11, 3224, 11, 37038, 11, 5054, 4717, 11, 1732, 11, 6355, 11, 1567, 323, 507, 627, 85664, 25, 578, 4632, 4519, 39431, 73, 411, 323, 1556, 309, 11755, 304, 3063, 13073, 1174, 449, 35074, 718, 438, 6713, 1174, 83495, 452, 6526, 97386, 1174, 2418, 344, 1036, 276, 1174, 53934, 84, 29476, 2453, 1174, 26291, 4385, 1174, 26291, 82469, 1174, 350, 13, 393, 13, 480, 1662, 408, 6713, 1174, 8683, 323, 34606, 84, 5737, 12899, 13073, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "show(O) me(O) an(O) r(B-rating) rated(O) comedy(B-genre) called(O) american(B-title) pie(I-title)"}
{"id": "1236", "dataset": "mit-movie", "split": "dev", "label_list": ["director", "song", "actor", "plot", "title", "character", "genre", "year", "review", "average ratings", "rating", "trailer"], "instance": {"id": "1236", "words": ["find", "a", "critically", "acclaimed", "1980", "sci", "fi", "film"], "labels": ["O", "O", "B-average ratings", "I-average ratings", "B-year", "B-genre", "I-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, song, actor, plot, title, character, genre, year, review, average ratings, rating, trailer and O.\nSentence: find a critically acclaimed 1980 sci fi film", "prompt_labels": "find(O) a(O) critically(B-average ratings) acclaimed(I-average ratings) 1980(B-year) sci(B-genre) fi(I-genre) film(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 5609, 11, 12360, 11, 7234, 11, 2316, 11, 3752, 11, 17779, 11, 1060, 11, 3477, 11, 5578, 18594, 11, 10959, 11, 19809, 323, 507, 627, 85664, 25, 1505, 264, 41440, 50082, 220, 3753, 15, 39074, 9314, 4632, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "what(O) is(O) the(O) last(O) teen(B-genre) movie(O) that(O) john(B-director) huston(I-director) directed(O)"}
{"id": "1234", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Restaurant Name", "Dish", "Amenity", "Cuisine", "Price", "Hours", "Rating", "Location"], "instance": {"id": "1234", "words": ["whats", "the", "cheapest", "fast", "food", "restaurant", "that", "has", "a", "play", "area", "for", "children"], "labels": ["O", "O", "B-Price", "B-Cuisine", "I-Cuisine", "O", "O", "O", "O", "B-Amenity", "I-Amenity", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Dish, Amenity, Cuisine, Price, Hours, Rating, Location and O.\nSentence: whats the cheapest fast food restaurant that has a play area for children", "prompt_labels": "whats(O) the(O) cheapest(B-Price) fast(B-Cuisine) food(I-Cuisine) restaurant(O) that(O) has(O) a(O) play(B-Amenity) area(I-Amenity) for(O) children(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 49268, 11, 3383, 56685, 11, 81961, 11, 8650, 11, 30192, 11, 19767, 11, 10067, 323, 507, 627, 85664, 25, 41209, 279, 43149, 5043, 3691, 10960, 430, 706, 264, 1514, 3158, 369, 2911, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "name(O) an(O) emotional(B-genre) film(O) from(O) 2000(B-year) that(O) is(O) highly(B-average ratings) liked(I-average ratings)"}
{"id": "1214", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Price", "Location", "Dish", "Amenity", "Hours", "Rating", "Restaurant Name", "Cuisine"], "instance": {"id": "1214", "words": ["what", "time", "does", "the", "nearest", "chipotle", "close"], "labels": ["O", "O", "O", "O", "B-Location", "B-Restaurant Name", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Location, Dish, Amenity, Hours, Rating, Restaurant Name, Cuisine and O.\nSentence: what time does the nearest chipotle close", "prompt_labels": "what(O) time(O) does(O) the(O) nearest(B-Location) chipotle(B-Restaurant Name) close(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 10067, 11, 49268, 11, 3383, 56685, 11, 30192, 11, 19767, 11, 26568, 4076, 11, 81961, 323, 507, 627, 85664, 25, 1148, 892, 1587, 279, 24379, 16797, 51626, 3345, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "CoRoT(O) discovered(O) its(O) first(O) two(O) planets(O) in(O) 2007(O) :(O) the(O) hot(O) Jupiter(O) s(O) CoRoT-1b(O) and(O) CoRoT-2b(O).(O)"}
{"id": "1024", "dataset": "mit-movie", "split": "dev", "label_list": ["title", "year", "average ratings", "genre", "character", "actor", "plot", "rating", "song", "director", "trailer", "review"], "instance": {"id": "1024", "words": ["find", "an", "action", "flick", "with", "john", "wayne"], "labels": ["O", "O", "B-genre", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, year, average ratings, genre, character, actor, plot, rating, song, director, trailer, review and O.\nSentence: find an action flick with john wayne", "prompt_labels": "find(O) an(O) action(B-genre) flick(O) with(O) john(B-actor) wayne(I-actor)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 1060, 11, 5578, 18594, 11, 17779, 11, 3752, 11, 12360, 11, 7234, 11, 10959, 11, 5609, 11, 7690, 11, 19809, 11, 3477, 323, 507, 627, 85664, 25, 1505, 459, 1957, 29447, 449, 40742, 1648, 818, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "In(O) 1983(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) as(O) a(O) DUP(O) candidate(O),(O) Seawright(B-politician) finished(O) second(O) with(O) 8,260(O) votes(O) behind(O) Cecil(B-politician) Walker(I-politician) of(O) the(O) UUP(B-political party),(O) whilst(O) in(O) 1987(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) he(O) finished(O) third(O) behind(O) Walker(B-politician) and(O) Alban(B-politician) Maginness(I-politician) ((O) Social(B-political party) Democratic(I-political party) and(I-political party) Labour(I-political party) Party(I-political party) )(O) with(O) 5,671(O) votes(O) as(O) a(O) Protestant(B-political party) Unionist(I-political party) candidate(O) ((O) although(O) the(O) DUP(B-political party) did(O) not(O) contest(O) the(O) seat(O) due(O) to(O) an(O) electoral(O) pact(O) between(O) the(O) DUP(B-political party) and(O) UUP(B-political party) at(O) the(O) time(O) )(O).(O)"}
{"id": "289", "dataset": "crossner_politics", "split": "dev", "label_list": ["election", "person", "event", "political party", "politician", "location", "country", "organization"], "instance": {"id": "289", "words": ["In", "1968", "New", "York", "Post", "Also", "in", "1968", ",", "he", "was", "asked", "by", "Black", "Panther", "Party", "leader", "Eldridge", "Cleaver", "to", "serve", "as", "his", "running", "mate", "on", "the", "Peace", "and", "Freedom", "Party", "ticket", "in", "1968", "United", "States", "presidential", "election", "(", "he", "declined", "the", "offer", ")", "."], "labels": ["O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "O", "B-politician", "I-politician", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, person, event, political party, politician, location, country, organization and O.\nSentence: In 1968 New York Post Also in 1968 , he was asked by Black Panther Party leader Eldridge Cleaver to serve as his running mate on the Peace and Freedom Party ticket in 1968 United States presidential election ( he declined the offer ) .", "prompt_labels": "In(O) 1968(O) New(B-organization) York(I-organization) Post(I-organization) Also(O) in(O) 1968(O) ,(O) he(O) was(O) asked(O) by(O) Black(B-political party) Panther(I-political party) Party(I-political party) leader(O) Eldridge(B-politician) Cleaver(I-politician) to(O) serve(O) as(O) his(O) running(O) mate(O) on(O) the(O) Peace(B-political party) and(I-political party) Freedom(I-political party) Party(I-political party) ticket(O) in(O) 1968(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ((O) he(O) declined(O) the(O) offer(O) )(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 6355, 11, 1732, 11, 1567, 11, 5054, 4717, 11, 37038, 11, 3813, 11, 3224, 11, 7471, 323, 507, 627, 85664, 25, 763, 220, 5162, 23, 1561, 4356, 3962, 7429, 304, 220, 5162, 23, 1174, 568, 574, 4691, 555, 5348, 59612, 8722, 7808, 27965, 11431, 37102, 7403, 311, 8854, 439, 813, 4401, 30276, 389, 279, 26888, 323, 25320, 8722, 11989, 304, 220, 5162, 23, 3723, 4273, 13621, 6355, 320, 568, 19284, 279, 3085, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "what(O) time(O) does(O) the(O) nearest(B-Location) chipotle(B-Restaurant Name) close(O)"}
{"id": "596", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Dish", "Price", "Cuisine", "Hours", "Amenity", "Restaurant Name", "Rating", "Location"], "instance": {"id": "596", "words": ["i", "need", "directions", "to", "the", "nearest", "ethiopian", "restaurant"], "labels": ["O", "O", "O", "O", "O", "B-Location", "B-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Price, Cuisine, Hours, Amenity, Restaurant Name, Rating, Location and O.\nSentence: i need directions to the nearest ethiopian restaurant", "prompt_labels": "i(O) need(O) directions(O) to(O) the(O) nearest(B-Location) ethiopian(B-Cuisine) restaurant(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 8650, 11, 81961, 11, 30192, 11, 3383, 56685, 11, 26568, 4076, 11, 19767, 11, 10067, 323, 507, 627, 85664, 25, 602, 1205, 18445, 311, 279, 24379, 8537, 72, 48748, 10960, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Napoleon(B-politician) coined(O) the(O) War(B-event) of(I-event) the(I-event) Fourth(I-event) Coalition(I-event) as(O) the(O) first(O) Polish(O) war(O) because(O) one(O) of(O) the(O) official(O) declared(O) goals(O) of(O) this(O) war(O) was(O) the(O) Duchy(B-location) of(I-location) Warsaw(I-location) on(O) territories(O) of(O) the(O) former(O) Polish-Lithuanian(B-location) Commonwealth(I-location).(O)"}
{"id": "472", "dataset": "crossner_politics", "split": "dev", "label_list": ["event", "person", "country", "politician", "political party", "location", "election", "organization"], "instance": {"id": "472", "words": ["Napoleon", "coined", "the", "War", "of", "the", "Fourth", "Coalition", "as", "the", "first", "Polish", "war", "because", "one", "of", "the", "official", "declared", "goals", "of", "this", "war", "was", "the", "Duchy", "of", "Warsaw", "on", "territories", "of", "the", "former", "Polish-Lithuanian", "Commonwealth", "."], "labels": ["B-politician", "O", "O", "B-event", "I-event", "I-event", "I-event", "I-event", "O", "O", "O", "B-event", "I-event", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-country", "I-country", "I-country", "O", "O", "O", "O", "O", "B-country", "I-country", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, person, country, politician, political party, location, election, organization and O.\nSentence: Napoleon coined the War of the Fourth Coalition as the first Polish war because one of the official declared goals of this war was the Duchy of Warsaw on territories of the former Polish-Lithuanian Commonwealth .", "prompt_labels": "Napoleon(B-politician) coined(O) the(O) War(B-event) of(I-event) the(I-event) Fourth(I-event) Coalition(I-event) as(O) the(O) first(O) Polish(B-event) war(I-event) because(O) one(O) of(O) the(O) official(O) declared(O) goals(O) of(O) this(O) war(O) was(O) the(O) Duchy(B-country) of(I-country) Warsaw(I-country) on(O) territories(O) of(O) the(O) former(O) Polish-Lithuanian(B-country) Commonwealth(I-country) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 1732, 11, 3224, 11, 37038, 11, 5054, 4717, 11, 3813, 11, 6355, 11, 7471, 323, 507, 627, 85664, 25, 70527, 78718, 279, 5111, 315, 279, 36174, 36892, 439, 279, 1176, 33084, 4208, 1606, 832, 315, 279, 4033, 14610, 9021, 315, 420, 4208, 574, 279, 61122, 88, 315, 73276, 389, 39543, 315, 279, 4846, 33084, 8288, 411, 10602, 1122, 38298, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "who(O) directed(O) fight(B-title) club(I-title)"}
{"id": "1339", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Hours", "Restaurant Name", "Rating", "Amenity", "Cuisine", "Location", "Price", "Dish"], "instance": {"id": "1339", "words": ["where", "can", "i", "get", "some", "shrimp"], "labels": ["O", "O", "O", "O", "O", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Restaurant Name, Rating, Amenity, Cuisine, Location, Price, Dish and O.\nSentence: where can i get some shrimp", "prompt_labels": "where(O) can(O) i(O) get(O) some(O) shrimp(B-Dish)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 26568, 4076, 11, 19767, 11, 3383, 56685, 11, 81961, 11, 10067, 11, 8650, 11, 49268, 323, 507, 627, 85664, 25, 1405, 649, 602, 636, 1063, 56626, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "tell(O) me(O) where(O) i(O) can(O) find(O) a(O) good(B-Rating) meal(O) in(B-Location) this(I-Location) town(I-Location)"}
{"id": "298", "dataset": "crossner_politics", "split": "dev", "label_list": ["election", "country", "politician", "organization", "event", "political party", "location", "person"], "instance": {"id": "298", "words": ["Like", "rural", "Alberta", ",", "Calgary", "was", "a", "clean", "sweep", "for", "the", "politically", "rightmost", "party", "in", "all", "but", "one", "election", "from", "1972", "to", "2011", ":", "Progressive", "Conservative", "Party", "of", "Canada", "through", "1988", ",", "Reform", "Party", "of", "Canada", "in", "1993", "and", "1997", ",", "the", "Canadian", "Alliance", "in", "2000", "and", "Conservative", "Party", "of", "Canada", "since", "2004", "."], "labels": ["O", "O", "B-location", "O", "B-location", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, country, politician, organization, event, political party, location, person and O.\nSentence: Like rural Alberta , Calgary was a clean sweep for the politically rightmost party in all but one election from 1972 to 2011 : Progressive Conservative Party of Canada through 1988 , Reform Party of Canada in 1993 and 1997 , the Canadian Alliance in 2000 and Conservative Party of Canada since 2004 .", "prompt_labels": "Like(O) rural(O) Alberta(B-location) ,(O) Calgary(B-location) was(O) a(O) clean(O) sweep(O) for(O) the(O) politically(O) rightmost(O) party(O) in(O) all(O) but(O) one(O) election(O) from(O) 1972(O) to(O) 2011(O) :(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) of(I-political party) Canada(I-political party) through(O) 1988(O) ,(O) Reform(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) in(O) 1993(O) and(O) 1997(O) ,(O) the(O) Canadian(B-political party) Alliance(I-political party) in(O) 2000(O) and(O) Conservative(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) since(O) 2004(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 6355, 11, 3224, 11, 37038, 11, 7471, 11, 1567, 11, 5054, 4717, 11, 3813, 11, 1732, 323, 507, 627, 85664, 25, 9086, 19624, 33654, 1174, 38975, 574, 264, 4335, 24021, 369, 279, 31205, 1314, 3646, 4717, 304, 682, 719, 832, 6355, 505, 220, 4468, 17, 311, 220, 679, 16, 551, 52870, 30071, 8722, 315, 7008, 1555, 220, 3753, 23, 1174, 40365, 8722, 315, 7008, 304, 220, 2550, 18, 323, 220, 2550, 22, 1174, 279, 12152, 23590, 304, 220, 1049, 15, 323, 30071, 8722, 315, 7008, 2533, 220, 1049, 19, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "A(O) cash(O) book(O) kept(O) by(O) Flick(O) company(O) accountant(O) Rudolph(B-person) Diehl(I-person) listed(O) that(O) next(O) to(O) other(O) transfers(O),(O) 250,000(B-organization) Deutschemark(I-organization) was(O) transferred(O) to(O) Christian(B-organization) Social(I-organization) Union(I-organization) in(I-organization) Bavaria(I-organization) chairman(O) Franz(B-politician) Josef(I-politician) Strauss(I-politician) and(O) 565,000(B-organization) Deutschemark(I-organization) were(O) transferred(O) to(O) Christian(B-organization) Democratic(I-organization) Union(I-organization) of(I-organization) Germany(I-organization) chairman(O) Helmut(B-politician) Kohl(I-politician),(O) as(O) well(O) as(O) payments(O) to(O) FDP(B-political party) and(O) Social(B-political party) Democratic(I-political party) Party(I-political party) of(I-political party) Germany(I-political party) politicians(O).(O)"}
{"id": "757", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Price", "Restaurant Name", "Hours", "Amenity", "Location", "Rating", "Dish", "Cuisine"], "instance": {"id": "757", "words": ["im", "trying", "to", "find", "a", "family", "friendly", "restaurant", "with", "a", "gift", "shop", "within", "10", "miles", "of", "sunswept", "hotel", "in", "orange", "beach"], "labels": ["O", "O", "O", "O", "O", "B-Amenity", "I-Amenity", "O", "O", "O", "B-Amenity", "I-Amenity", "B-Location", "I-Location", "I-Location", "I-Location", "I-Location", "I-Location", "I-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Restaurant Name, Hours, Amenity, Location, Rating, Dish, Cuisine and O.\nSentence: im trying to find a family friendly restaurant with a gift shop within 10 miles of sunswept hotel in orange beach", "prompt_labels": "im(O) trying(O) to(O) find(O) a(O) family(B-Amenity) friendly(I-Amenity) restaurant(O) with(O) a(O) gift(B-Amenity) shop(I-Amenity) within(B-Location) 10(I-Location) miles(I-Location) of(I-Location) sunswept(I-Location) hotel(I-Location) in(I-Location) orange(I-Location) beach(I-Location)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 26568, 4076, 11, 30192, 11, 3383, 56685, 11, 10067, 11, 19767, 11, 49268, 11, 81961, 323, 507, 627, 85664, 25, 737, 4560, 311, 1505, 264, 3070, 11919, 10960, 449, 264, 8352, 8221, 2949, 220, 605, 8931, 315, 7160, 82, 906, 418, 9689, 304, 19087, 11573, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Other(O) political(O) parties(O) that(O) have(O) practiced(O) fusion(O) include(O) the(O) Conservative(B-political party) Party(I-political party) of(I-political party) New(I-political party) York(I-political party).(O) the(O) Working(B-political party) Families(I-political party) Party(I-political party) and(O) the(O) Liberal(B-political party) Party(I-political party) of(I-political party) New(I-political party) York(I-political party).(O)"}
{"id": "540", "dataset": "mit-movie", "split": "dev", "label_list": ["character", "review", "actor", "director", "plot", "song", "trailer", "rating", "title", "year", "genre", "average ratings"], "instance": {"id": "540", "words": ["who", "directed", "fight", "club"], "labels": ["O", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, review, actor, director, plot, song, trailer, rating, title, year, genre, average ratings and O.\nSentence: who directed fight club", "prompt_labels": "who(O) directed(O) fight(B-title) club(I-title)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 3477, 11, 12360, 11, 7690, 11, 7234, 11, 5609, 11, 19809, 11, 10959, 11, 2316, 11, 1060, 11, 17779, 11, 5578, 18594, 323, 507, 627, 85664, 25, 889, 15910, 4465, 6469, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Since(O) 2001(O),(O) the(O) dominance(O) of(O) traditional(O) boy(O) bands(O) on(O) pop(O) charts(O) began(O) to(O) fade(O) in(O) the(O) western(O) hemisphere(O),(O) although(O) Gil(B-musical artist) Kaufman(I-musical artist) of(O) MTV(B-location) has(O) described(O) new(O) boy(O) bands(O) that(O) are(O) more(O) likely(O) to(O) resemble(O) My(B-band) Chemical(I-band) Romance(I-band),(O) Sum(B-band) 41(I-band),(O) and(O) Simple(B-band) Plan(I-band).(O)"}
{"id": "248", "dataset": "crossner_politics", "split": "dev", "label_list": ["election", "politician", "country", "event", "political party", "person", "organization", "location"], "instance": {"id": "248", "words": ["She", "campaigned", "for", "the", "federal", "New", "Democratic", "Party", "in", "the", "1993", "Canadian", "federal", "election", "and", "received", "3,029", "votes", "(", "8.49", "%", ")", "in", "the", "riding", "of", "Portage", "-", "Interlake", ",", "finishing", "fourth", "against", "Liberal", "Party", "of", "Canada", "candidate", "Jon", "Gerrard", "."], "labels": ["O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "I-location", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "B-politician", "I-politician", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, politician, country, event, political party, person, organization, location and O.\nSentence: She campaigned for the federal New Democratic Party in the 1993 Canadian federal election and received 3,029 votes ( 8.49 % ) in the riding of Portage - Interlake , finishing fourth against Liberal Party of Canada candidate Jon Gerrard .", "prompt_labels": "She(O) campaigned(O) for(O) the(O) federal(O) New(B-political party) Democratic(I-political party) Party(I-political party) in(O) the(O) 1993(B-election) Canadian(I-election) federal(I-election) election(I-election) and(O) received(O) 3,029(O) votes(O) ((O) 8.49(O) %(O) )(O) in(O) the(O) riding(O) of(O) Portage(B-location) -(I-location) Interlake(I-location) ,(O) finishing(O) fourth(O) against(O) Liberal(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) candidate(O) Jon(B-politician) Gerrard(I-politician) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 6355, 11, 37038, 11, 3224, 11, 1567, 11, 5054, 4717, 11, 1732, 11, 7471, 11, 3813, 323, 507, 627, 85664, 25, 3005, 87296, 369, 279, 6918, 1561, 11650, 8722, 304, 279, 220, 2550, 18, 12152, 6918, 6355, 323, 4036, 220, 18, 11, 23273, 12973, 320, 220, 23, 13, 2491, 1034, 883, 304, 279, 20427, 315, 5896, 425, 482, 5783, 63210, 1174, 25270, 11999, 2403, 31158, 8722, 315, 7008, 9322, 12565, 86965, 569, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "The(O) film(O) features(O) Ranjith(B-actor) and(O) Anamika(B-actor) in(O) lead(O) roles(O),(O) with(O) Ravichandran(B-actor),(O) Pyramid(B-actor) Natarajan(I-actor),(O) Manivannan(B-actor),(O) Vasu(B-actor) Vikram(I-actor),(O) Rajesh(B-actor),(O) Raj(B-actor) Kapoor(I-actor),(O) T. P.(B-actor) Gajendran(I-actor),(O) Alex(B-actor) and(O) Pandu(B-actor) playing(O) supporting(O) roles(O).(O)"}
{"id": "378", "dataset": "mit-movie", "split": "dev", "label_list": ["title", "director", "character", "plot", "review", "rating", "trailer", "year", "genre", "average ratings", "song", "actor"], "instance": {"id": "378", "words": ["show", "me", "a", "list", "of", "independent", "comedy", "films", "made", "in", "2009"], "labels": ["O", "O", "O", "O", "O", "B-title", "I-title", "O", "O", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, director, character, plot, review, rating, trailer, year, genre, average ratings, song, actor and O.\nSentence: show me a list of independent comedy films made in 2009", "prompt_labels": "show(O) me(O) a(O) list(O) of(O) independent(B-title) comedy(I-title) films(O) made(O) in(O) 2009(B-year)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 7690, 11, 3752, 11, 7234, 11, 3477, 11, 10959, 11, 19809, 11, 1060, 11, 17779, 11, 5578, 18594, 11, 5609, 11, 12360, 323, 507, 627, 85664, 25, 1501, 757, 264, 1160, 315, 9678, 23160, 12631, 1903, 304, 220, 1049, 24, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "find(O) an(O) action(B-genre) flick(O) with(O) john(B-actor) wayne(I-actor)"}
{"id": "720", "dataset": "mit-movie", "split": "dev", "label_list": ["genre", "average ratings", "trailer", "title", "director", "year", "character", "review", "rating", "actor", "plot", "song"], "instance": {"id": "720", "words": ["show", "me", "an", "r", "rated", "comedy", "called", "american", "pie"], "labels": ["O", "O", "O", "B-rating", "I-rating", "B-genre", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, average ratings, trailer, title, director, year, character, review, rating, actor, plot, song and O.\nSentence: show me an r rated comedy called american pie", "prompt_labels": "show(O) me(O) an(O) r(B-rating) rated(I-rating) comedy(B-genre) called(O) american(B-title) pie(I-title)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 5578, 18594, 11, 19809, 11, 2316, 11, 7690, 11, 1060, 11, 3752, 11, 3477, 11, 10959, 11, 12360, 11, 7234, 11, 5609, 323, 507, 627, 85664, 25, 1501, 757, 459, 436, 22359, 23160, 2663, 39542, 4447, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "where(O) can(O) i(O) get(O) some(O) shrimp(B-Dish)"}
{"id": "1080", "dataset": "mit-restaurant", "split": "dev", "label_list": ["Amenity", "Location", "Rating", "Cuisine", "Restaurant Name", "Dish", "Hours", "Price"], "instance": {"id": "1080", "words": ["tell", "me", "where", "i", "can", "find", "a", "good", "meal", "in", "this", "town"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-Rating", "O", "O", "O", "B-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Location, Rating, Cuisine, Restaurant Name, Dish, Hours, Price and O.\nSentence: tell me where i can find a good meal in this town", "prompt_labels": "tell(O) me(O) where(O) i(O) can(O) find(O) a(O) good(B-Rating) meal(O) in(O) this(O) town(B-Location)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 10067, 11, 19767, 11, 81961, 11, 26568, 4076, 11, 49268, 11, 30192, 11, 8650, 323, 507, 627, 85664, 25, 3371, 757, 1405, 602, 649, 1505, 264, 1695, 15496, 304, 420, 6424, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "She(O) campaigned(O) for(O) the(O) federal(O) New(B-political party) Democratic(I-political party) Party(I-political party) in(O) the(O) 1993(B-election) Canadian(I-election) federal(I-election) election(I-election) and(O) received(O) 3,029(O) votes(O) ((O) 8.49(O) %(O) )(O) in(O) the(O) riding(O) of(O) Portage(B-location) -I-location),(O) finishing(O) fourth(O) against(O) Liberal(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) candidate(O) Jon(B-politician) Gerrard(I-politician).(O)"}
{"id": "2379", "dataset": "mit-movie", "split": "dev", "label_list": ["song", "director", "genre", "review", "character", "year", "rating", "plot", "average ratings", "title", "trailer", "actor"], "instance": {"id": "2379", "words": ["name", "some", "movies", "starring", "robert", "redford"], "labels": ["O", "O", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, director, genre, review, character, year, rating, plot, average ratings, title, trailer, actor and O.\nSentence: name some movies starring robert redford", "prompt_labels": "name(O) some(O) movies(O) starring(O) robert(B-actor) redford(I-actor)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 7690, 11, 17779, 11, 3477, 11, 3752, 11, 1060, 11, 10959, 11, 7234, 11, 5578, 18594, 11, 2316, 11, 19809, 11, 12360, 323, 507, 627, 85664, 25, 836, 1063, 9698, 40500, 89993, 2579, 8350, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "name(O) some(O) movies(O) starring(O) robert(B-actor) redford(I-actor)"}
