{"id": "82", "dataset": "crossner_ai", "split": "dev", "prediction": "Researchers(O) have(O) attempted(O) a(O) number(O) of(O) methods(O) such(O) as(O) optical(B-algorithm) flow(I-algorithm),(O) Kalman(B-algorithm) filtering(I-algorithm),(O) Hidden(B-algorithm) Markov(I-algorithm) model(I-algorithm) s(I-algorithm),(O) etc(O).(O)", "instance": {"id": "82", "words": ["Researchers", "have", "attempted", "a", "number", "of", "methods", "such", "as", "optical", "flow", ",", "Kalman", "filtering", ",", "Hidden", "Markov", "model", "s", ",", "etc", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-algorithm", "I-algorithm", "O", "B-algorithm", "I-algorithm", "O", "B-algorithm", "I-algorithm", "I-algorithm", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, field, task, researcher, location, country, product, programming language, metric, algorithm, conference, person, university and O.\nSentence: Researchers have attempted a number of methods such as optical flow , Kalman filtering , Hidden Markov model s , etc .", "prompt_labels": "Researchers(O) have(O) attempted(O) a(O) number(O) of(O) methods(O) such(O) as(O) optical(B-algorithm) flow(I-algorithm) ,(O) Kalman(B-algorithm) filtering(I-algorithm) ,(O) Hidden(B-algorithm) Markov(I-algorithm) model(I-algorithm) s(O) ,(O) etc(O) .(O)"}, "label_list": ["organization", "field", "task", "researcher", "location", "country", "product", "programming language", "metric", "algorithm", "conference", "person", "university"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 2115, 11, 3465, 11, 32185, 11, 3813, 11, 3224, 11, 2027, 11, 15840, 4221, 11, 18767, 11, 12384, 11, 10017, 11, 1732, 11, 12374, 323, 507, 627, 85664, 25, 59250, 617, 17644, 264, 1396, 315, 5528, 1778, 439, 29393, 6530, 1174, 27930, 1543, 30770, 1174, 35342, 4488, 869, 1646, 274, 1174, 5099, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "778", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) santa(B-Restaurant Name) ramen(I-Restaurant Name) in(O) san(B-Location) mateo(I-Location) busy(O) on(O) thursday(O) nights(O)", "instance": {"id": "778", "words": ["is", "santa", "ramen", "in", "san", "mateo", "busy", "on", "thursday", "nights"], "labels": ["O", "B-Restaurant Name", "I-Restaurant Name", "O", "B-Location", "I-Location", "O", "O", "B-Hours", "I-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Dish, Amenity, Rating, Cuisine, Restaurant Name, Price, Location and O.\nSentence: is santa ramen in san mateo busy on thursday nights", "prompt_labels": "is(O) santa(B-Restaurant Name) ramen(I-Restaurant Name) in(O) san(B-Location) mateo(I-Location) busy(O) on(O) thursday(B-Hours) nights(I-Hours)"}, "label_list": ["Hours", "Dish", "Amenity", "Rating", "Cuisine", "Restaurant Name", "Price", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 49268, 11, 3383, 56685, 11, 19767, 11, 81961, 11, 26568, 4076, 11, 8650, 11, 10067, 323, 507, 627, 85664, 25, 374, 72851, 123537, 304, 8528, 30276, 78, 13326, 389, 270, 7329, 22178, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "264", "dataset": "crossner_literature", "split": "dev", "prediction": "Ireland(B-country)'s(O) 1990(B-event) FIFA(I-event) World(I-event) Cup(I-event) Group(I-event) F(I-event) opponents(O) in(O) Italy(B-country)'90(O) were(O) England(B-country),(O) Egypt(B-country) and(O) the(O) Netherlands(B-country).(O)", "instance": {"id": "264", "words": ["Ireland", "'s", "1990", "FIFA", "World", "Cup", "Group", "F", "opponents", "in", "Italy", "'", "90", "were", "England", ",", "Egypt", "and", "the", "Netherlands", "."], "labels": ["B-country", "O", "B-event", "I-event", "I-event", "I-event", "I-event", "I-event", "O", "O", "B-country", "O", "O", "O", "B-country", "O", "B-country", "O", "O", "B-country", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, book, country, event, poem, magazine, location, writer, award, person, organization and O.\nSentence: Ireland 's 1990 FIFA World Cup Group F opponents in Italy ' 90 were England , Egypt and the Netherlands .", "prompt_labels": "Ireland(B-country) 's(O) 1990(B-event) FIFA(I-event) World(I-event) Cup(I-event) Group(I-event) F(I-event) opponents(O) in(O) Italy(B-country) '(O) 90(O) were(O) England(B-country) ,(O) Egypt(B-country) and(O) the(O) Netherlands(B-country) .(O)"}, "label_list": ["literary genre", "book", "country", "event", "poem", "magazine", "location", "writer", "award", "person", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 32465, 17779, 11, 2363, 11, 3224, 11, 1567, 11, 33894, 11, 14756, 11, 3813, 11, 7061, 11, 10292, 11, 1732, 11, 7471, 323, 507, 627, 85664, 25, 14990, 364, 82, 220, 2550, 15, 44742, 4435, 11098, 5856, 435, 19949, 304, 15704, 364, 220, 1954, 1051, 9635, 1174, 15212, 323, 279, 26746, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1228", "dataset": "mit-movie", "split": "dev", "prediction": "does(O) julia(B-actor) roberts(I-actor) have(O) a(O) voice(O) in(O) wall(B-title) e(I-title)", "instance": {"id": "1228", "words": ["does", "julia", "roberts", "have", "a", "voice", "in", "wall", "e"], "labels": ["O", "B-actor", "I-actor", "O", "O", "O", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, average ratings, rating, genre, title, director, song, plot, actor, trailer, review, year and O.\nSentence: does julia roberts have a voice in wall e", "prompt_labels": "does(O) julia(B-actor) roberts(I-actor) have(O) a(O) voice(O) in(O) wall(B-title) e(I-title)"}, "label_list": ["character", "average ratings", "rating", "genre", "title", "director", "song", "plot", "actor", "trailer", "review", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 5578, 18594, 11, 10959, 11, 17779, 11, 2316, 11, 7690, 11, 5609, 11, 7234, 11, 12360, 11, 19809, 11, 3477, 11, 1060, 323, 507, 627, 85664, 25, 1587, 41638, 689, 89993, 82, 617, 264, 7899, 304, 7147, 384, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1605", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) a(O) chick(B-genre) film(O) in(O) the(O) past(B-year) ten(I-year) decades(I-year)", "instance": {"id": "1605", "words": ["list", "a", "chick", "film", "in", "the", "past", "ten", "decades"], "labels": ["O", "O", "B-genre", "O", "O", "O", "B-year", "I-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, rating, song, review, title, plot, genre, year, trailer, average ratings, director, character and O.\nSentence: list a chick film in the past ten decades", "prompt_labels": "list(O) a(O) chick(B-genre) film(O) in(O) the(O) past(B-year) ten(I-year) decades(I-year)"}, "label_list": ["actor", "rating", "song", "review", "title", "plot", "genre", "year", "trailer", "average ratings", "director", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 10959, 11, 5609, 11, 3477, 11, 2316, 11, 7234, 11, 17779, 11, 1060, 11, 19809, 11, 5578, 18594, 11, 7690, 11, 3752, 323, 507, 627, 85664, 25, 1160, 264, 31863, 4632, 304, 279, 3347, 5899, 11026, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "872", "dataset": "mit-movie", "split": "dev", "prediction": "are(O) there(O) any(O) movies(O) about(O) the(O) korean(B-plot) war(I-plot)", "instance": {"id": "872", "words": ["are", "there", "any", "movies", "about", "the", "korean", "war"], "labels": ["O", "O", "O", "O", "O", "O", "B-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, director, trailer, year, actor, rating, title, song, genre, character, average ratings, plot and O.\nSentence: are there any movies about the korean war", "prompt_labels": "are(O) there(O) any(O) movies(O) about(O) the(O) korean(B-plot) war(I-plot)"}, "label_list": ["review", "director", "trailer", "year", "actor", "rating", "title", "song", "genre", "character", "average ratings", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 7690, 11, 19809, 11, 1060, 11, 12360, 11, 10959, 11, 2316, 11, 5609, 11, 17779, 11, 3752, 11, 5578, 18594, 11, 7234, 323, 507, 627, 85664, 25, 527, 1070, 904, 9698, 922, 279, 597, 46295, 4208, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2140", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movie(O) is(O) known(O) as(O) oliver(B-director) stones(I-director) best(B-review) work(I-review)", "instance": {"id": "2140", "words": ["what", "movie", "is", "known", "as", "oliver", "stones", "best", "work"], "labels": ["O", "O", "O", "O", "O", "B-director", "I-director", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, rating, review, year, song, title, average ratings, actor, genre, director, trailer, plot and O.\nSentence: what movie is known as oliver stones best work", "prompt_labels": "what(O) movie(O) is(O) known(O) as(O) oliver(B-director) stones(I-director) best(O) work(O)"}, "label_list": ["character", "rating", "review", "year", "song", "title", "average ratings", "actor", "genre", "director", "trailer", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 10959, 11, 3477, 11, 1060, 11, 5609, 11, 2316, 11, 5578, 18594, 11, 12360, 11, 17779, 11, 7690, 11, 19809, 11, 7234, 323, 507, 627, 85664, 25, 1148, 5818, 374, 3967, 439, 8492, 1553, 27302, 1888, 990, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "199", "dataset": "crossner_ai", "split": "dev", "prediction": "The(O) term(O) Semantic(B-field) Web(I-field) was(O) coined(O) by(O) Tim(B-researcher) Berners-Lee(I-researcher),(O) the(O) inventor(O) of(O) the(O) World(B-organization) Wide(I-organization) Web(I-organization) and(O) director(O) of(O) the(O) World(B-organization) Wide(I-organization) Web(I-organization) Consortium(I-organization) ((O) W3C(B-organization) )(O),(O) which(O) oversees(O) the(O) development(O) of(O) proposed(O) Semantic(B-field) Web(I-field) standards(O).(O)", "instance": {"id": "199", "words": ["The", "term", "Semantic", "Web", "was", "coined", "by", "Tim", "Berners-Lee", ",", "the", "inventor", "of", "the", "World", "Wide", "Web", "and", "director", "of", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "which", "oversees", "the", "development", "of", "proposed", "Semantic", "Web", "standards", "."], "labels": ["O", "O", "B-product", "I-product", "O", "O", "O", "B-researcher", "I-researcher", "O", "O", "O", "O", "O", "B-product", "I-product", "I-product", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "O", "O", "O", "O", "O", "O", "O", "O", "B-product", "I-product", "I-product", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, task, conference, location, university, metric, person, field, country, organization, algorithm, researcher, product and O.\nSentence: The term Semantic Web was coined by Tim Berners-Lee , the inventor of the World Wide Web and director of the World Wide Web Consortium ( W3C ) , which oversees the development of proposed Semantic Web standards .", "prompt_labels": "The(O) term(O) Semantic(B-product) Web(I-product) was(O) coined(O) by(O) Tim(B-researcher) Berners-Lee(I-researcher) ,(O) the(O) inventor(O) of(O) the(O) World(B-product) Wide(I-product) Web(I-product) and(O) director(O) of(O) the(O) World(B-organization) Wide(I-organization) Web(I-organization) Consortium(I-organization) ((O) W3C(B-organization) )(O) ,(O) which(O) oversees(O) the(O) development(O) of(O) proposed(O) Semantic(B-product) Web(I-product) standards(I-product) .(O)"}, "label_list": ["programming language", "task", "conference", "location", "university", "metric", "person", "field", "country", "organization", "algorithm", "researcher", "product"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 15840, 4221, 11, 3465, 11, 10017, 11, 3813, 11, 12374, 11, 18767, 11, 1732, 11, 2115, 11, 3224, 11, 7471, 11, 12384, 11, 32185, 11, 2027, 323, 507, 627, 85664, 25, 578, 4751, 75433, 5000, 574, 78718, 555, 9538, 14502, 388, 8288, 2176, 1174, 279, 72001, 315, 279, 4435, 33845, 5000, 323, 7690, 315, 279, 4435, 33845, 5000, 73547, 320, 468, 18, 34, 883, 1174, 902, 71945, 279, 4500, 315, 11223, 75433, 5000, 10886, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "329", "dataset": "crossner_politics", "split": "dev", "prediction": "Alex(B-politician) T.(I-politician) Atamanenko(I-politician) MP(O) ((O) born(O) January(O) 24(O),(O) 1945(O) )(O) is(O) a(O) Canadian(O) politician(O),(O) who(O) was(O) elected(O) to(O) the(O) House(O) of(O) Commons(O) in(O) 2006(O),(O) winning(O) the(O) riding(O) of(O) British(B-location) Columbia(I-location) Southern(I-location) Interior(I-location) for(O) the(O) New(O) Democratic(O) Party(O) in(O) the(O) 2006(O) Canadian(O) federal(O) election(O),(O) and(O) served(O) in(O) parliament(O) until(O) his(O) retirement(O) at(O) the(O) 2015(O) Canadian(O) federal(O) election(O).(O)", "instance": {"id": "329", "words": ["Alex", "T.", "Atamanenko", "MP", "(", "born", "January", "24", ",", "1945", ")", "is", "a", "Canadian", "politician", ",", "who", "was", "elected", "to", "the", "House", "of", "Commons", "in", "2006", ",", "winning", "the", "riding", "of", "British", "Columbia", "Southern", "Interior", "for", "the", "New", "Democratic", "Party", "in", "the", "2006", "Canadian", "federal", "election", ",", "and", "served", "in", "parliament", "until", "his", "retirement", "at", "the", "2015", "Canadian", "federal", "election", "."], "labels": ["B-politician", "I-politician", "I-politician", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-political party", "I-political party", "I-political party", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, politician, person, country, location, organization, political party, event and O.\nSentence: Alex T. Atamanenko MP ( born January 24 , 1945 ) is a Canadian politician , who was elected to the House of Commons in 2006 , winning the riding of British Columbia Southern Interior for the New Democratic Party in the 2006 Canadian federal election , and served in parliament until his retirement at the 2015 Canadian federal election .", "prompt_labels": "Alex(B-politician) T.(I-politician) Atamanenko(I-politician) MP(O) ((O) born(O) January(O) 24(O) ,(O) 1945(O) )(O) is(O) a(O) Canadian(O) politician(O) ,(O) who(O) was(O) elected(O) to(O) the(O) House(B-organization) of(I-organization) Commons(I-organization) in(O) 2006(O) ,(O) winning(O) the(O) riding(O) of(O) British(B-organization) Columbia(I-organization) Southern(I-organization) Interior(I-organization) for(O) the(O) New(B-political party) Democratic(I-political party) Party(I-political party) in(O) the(O) 2006(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) and(O) served(O) in(O) parliament(O) until(O) his(O) retirement(O) at(O) the(O) 2015(B-election) Canadian(I-election) federal(I-election) election(I-election) .(O)"}, "label_list": ["election", "politician", "person", "country", "location", "organization", "political party", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 6355, 11, 37038, 11, 1732, 11, 3224, 11, 3813, 11, 7471, 11, 5054, 4717, 11, 1567, 323, 507, 627, 85664, 25, 8683, 350, 13, 2468, 13005, 56155, 9599, 320, 9405, 6186, 220, 1187, 1174, 220, 6393, 20, 883, 374, 264, 12152, 37038, 1174, 889, 574, 16689, 311, 279, 4783, 315, 26667, 304, 220, 1049, 21, 1174, 11230, 279, 20427, 315, 8013, 19326, 16642, 29958, 369, 279, 1561, 11650, 8722, 304, 279, 220, 1049, 21, 12152, 6918, 6355, 1174, 323, 10434, 304, 21814, 3156, 813, 21624, 520, 279, 220, 679, 20, 12152, 6918, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "257", "dataset": "crossner_ai", "split": "dev", "prediction": "Sub-domains(O) of(O) computer(B-field) vision(I-field) include(O) scene(O) reconstruction(O),(O) event(O) detection(O),(O) video(B-task) tracking(I-task),(O) object(O) recognition(O),(O) 3D(B-plot) pose(I-plot) estimation(I-plot),(O) learning(O),(O) indexing(O),(O) motion(O) estimation(O),(O) visual(O) servoing(O),(O) 3D(O) scene(O) modeling(O),(O) and(O) image(O) restoration(O).(O)", "instance": {"id": "257", "words": ["Sub-domains", "of", "computer", "vision", "include", "scene", "reconstruction", ",", "event", "detection", ",", "video", "tracking", ",", "object", "recognition", ",", "3D", "pose", "estimation", ",", "learning", ",", "indexing", ",", "motion", "estimation", ",", "visual", "servoing", ",", "3D", "scene", "modeling", ",", "and", "image", "restoration", "."], "labels": ["O", "O", "B-field", "I-field", "O", "B-task", "I-task", "O", "B-task", "I-task", "O", "B-task", "I-task", "O", "B-task", "I-task", "O", "B-task", "I-task", "I-task", "O", "B-task", "O", "B-task", "O", "B-task", "I-task", "O", "B-task", "I-task", "O", "B-task", "I-task", "I-task", "O", "O", "B-task", "I-task", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, task, country, field, programming language, conference, product, metric, organization, researcher, university, algorithm, person and O.\nSentence: Sub-domains of computer vision include scene reconstruction , event detection , video tracking , object recognition , 3D pose estimation , learning , indexing , motion estimation , visual servoing , 3D scene modeling , and image restoration .", "prompt_labels": "Sub-domains(O) of(O) computer(B-field) vision(I-field) include(O) scene(B-task) reconstruction(I-task) ,(O) event(B-task) detection(I-task) ,(O) video(B-task) tracking(I-task) ,(O) object(B-task) recognition(I-task) ,(O) 3D(B-task) pose(I-task) estimation(I-task) ,(O) learning(B-task) ,(O) indexing(B-task) ,(O) motion(B-task) estimation(I-task) ,(O) visual(B-task) servoing(I-task) ,(O) 3D(B-task) scene(I-task) modeling(I-task) ,(O) and(O) image(B-task) restoration(I-task) .(O)"}, "label_list": ["location", "task", "country", "field", "programming language", "conference", "product", "metric", "organization", "researcher", "university", "algorithm", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 3465, 11, 3224, 11, 2115, 11, 15840, 4221, 11, 10017, 11, 2027, 11, 18767, 11, 7471, 11, 32185, 11, 12374, 11, 12384, 11, 1732, 323, 507, 627, 85664, 25, 3804, 14766, 1771, 315, 6500, 11376, 2997, 6237, 43738, 1174, 1567, 18468, 1174, 2835, 15194, 1174, 1665, 18324, 1174, 220, 18, 35, 17477, 42304, 1174, 6975, 1174, 53080, 1174, 11633, 42304, 1174, 9302, 59412, 287, 1174, 220, 18, 35, 6237, 34579, 1174, 323, 2217, 35093, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "884", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) a(O) white(B-Restaurant Name) castle(I-Restaurant Name) on(O) berkeley(B-Location) avenue(I-Location)", "instance": {"id": "884", "words": ["is", "there", "a", "white", "castle", "on", "berkeley", "avenue"], "labels": ["O", "O", "O", "B-Restaurant Name", "I-Restaurant Name", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Location, Cuisine, Rating, Amenity, Restaurant Name, Hours, Dish and O.\nSentence: is there a white castle on berkeley avenue", "prompt_labels": "is(O) there(O) a(O) white(B-Restaurant Name) castle(I-Restaurant Name) on(O) berkeley(B-Location) avenue(I-Location)"}, "label_list": ["Price", "Location", "Cuisine", "Rating", "Amenity", "Restaurant Name", "Hours", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 10067, 11, 81961, 11, 19767, 11, 3383, 56685, 11, 26568, 4076, 11, 30192, 11, 49268, 323, 507, 627, 85664, 25, 374, 1070, 264, 4251, 33684, 389, 10418, 28399, 62803, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "107", "dataset": "crossner_politics", "split": "dev", "prediction": "The(O) following(O) parties(O) have(O) won(O) the(O) special(O) seats(O) reserved(O) for(O) national(O) minority(O) representatives(O) ((O) also(O) in(O) alphabetical(O) order(O) )(O) :(O) the(O) Bosnian(B-political party) Democratic(I-political party) Party(I-political party) of(I-political party) Croatia(I-political party),(O) the(O) Democratic(B-political party) Union(I-political party) of(I-political party) Hungarians(I-political party) of(I-political party) Croatia(I-political party),(O) the(O) German(B-political party) People(I-political party)'s(I-political party) Union(I-political party) -(O) National(O) Association(O) of(O) Danube(B-political party) Swabians(I-political party) in(O) Croatia(B-country),(O) the(O) Independent(B-political party) Democratic(I-political party) Serb(I-political party) Party(I-political party),(O) the(O) Party(O) of(O) Democratic(B-political party) Action(I-political party) of(I-political party) Croatia(I-political party) and(O) the(O) Serb(B-political party) People(I-political party)'s(I-political party) Party(I-political party).(O)", "instance": {"id": "107", "words": ["The", "following", "parties", "have", "won", "the", "special", "seats", "reserved", "for", "national", "minority", "representatives", "(", "also", "in", "alphabetical", "order", ")", ":", "the", "Bosnian", "Democratic", "Party", "of", "Croatia", ",", "the", "Democratic", "Union", "of", "Hungarians", "of", "Croatia", ",", "the", "German", "People", "'s", "Union", "-", "National", "Association", "of", "Danube", "Swabians", "in", "Croatia", ",", "the", "Independent", "Democratic", "Serb", "Party", ",", "the", "Party", "of", "Democratic", "Action", "of", "Croatia", "and", "the", "Serb", "People", "'s", "Party", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, politician, location, organization, election, country, event, person and O.\nSentence: The following parties have won the special seats reserved for national minority representatives ( also in alphabetical order ) : the Bosnian Democratic Party of Croatia , the Democratic Union of Hungarians of Croatia , the German People 's Union - National Association of Danube Swabians in Croatia , the Independent Democratic Serb Party , the Party of Democratic Action of Croatia and the Serb People 's Party .", "prompt_labels": "The(O) following(O) parties(O) have(O) won(O) the(O) special(O) seats(O) reserved(O) for(O) national(O) minority(O) representatives(O) ((O) also(O) in(O) alphabetical(O) order(O) )(O) :(O) the(O) Bosnian(B-political party) Democratic(I-political party) Party(I-political party) of(I-political party) Croatia(I-political party) ,(O) the(O) Democratic(B-political party) Union(I-political party) of(I-political party) Hungarians(I-political party) of(I-political party) Croatia(I-political party) ,(O) the(O) German(B-political party) People(I-political party) 's(I-political party) Union(I-political party) -(I-political party) National(I-political party) Association(I-political party) of(I-political party) Danube(I-political party) Swabians(I-political party) in(I-political party) Croatia(I-political party) ,(O) the(O) Independent(B-political party) Democratic(I-political party) Serb(I-political party) Party(I-political party) ,(O) the(O) Party(B-political party) of(I-political party) Democratic(I-political party) Action(I-political party) of(I-political party) Croatia(I-political party) and(O) the(O) Serb(B-political party) People(I-political party) 's(I-political party) Party(I-political party) .(O)"}, "label_list": ["political party", "politician", "location", "organization", "election", "country", "event", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5054, 4717, 11, 37038, 11, 3813, 11, 7471, 11, 6355, 11, 3224, 11, 1567, 11, 1732, 323, 507, 627, 85664, 25, 578, 2768, 9875, 617, 2834, 279, 3361, 16712, 4694, 369, 5426, 23413, 24005, 320, 1101, 304, 84398, 2015, 883, 551, 279, 29071, 77, 1122, 11650, 8722, 315, 58311, 1174, 279, 11650, 9323, 315, 26604, 30627, 315, 58311, 1174, 279, 6063, 9029, 364, 82, 9323, 482, 5165, 10229, 315, 11824, 3845, 4593, 370, 5493, 304, 58311, 1174, 279, 22765, 11650, 8409, 65, 8722, 1174, 279, 8722, 315, 11650, 5703, 315, 58311, 323, 279, 8409, 65, 9029, 364, 82, 8722, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "281", "dataset": "crossner_literature", "split": "dev", "prediction": "Meanwhile(O),(O) Housman(B-writer) pursued(O) his(O) classical(O) studies(O) independently(O),(O) and(O) published(O) scholarly(O) articles(O) on(O) Horace(B-writer),(O) Propertius(B-writer),(O) Ovid(B-writer),(O) Aeschylus(B-writer),(O) Euripides(B-writer) and(O) Sophocles(B-writer).(O)ref(O) Name(O) =(O) Poets(O) /(O) He(O) also(O) completed(O) an(O) edition(O) of(O) Propertius(B-writer),(O) which(O) however(O) was(O) rejected(O) by(O) both(O) Oxford(B-organization) University(I-organization) Press(I-organization) and(O) Macmillan(B-organization) in(O) 1885(O),(O) and(O) was(O) destroyed(O) after(O) his(O) death(O).(O)", "instance": {"id": "281", "words": ["Meanwhile", ",", "Housman", "pursued", "his", "classical", "studies", "independently", ",", "and", "published", "scholarly", "articles", "on", "Horace", ",", "Propertius", ",", "Ovid", ",", "Aeschylus", ",", "Euripides", "and", "Sophocles", ".ref", "Name", "=", "Poets", "/", "He", "also", "completed", "an", "edition", "of", "Propertius", ",", "which", "however", "was", "rejected", "by", "both", "Oxford", "University", "Press", "and", "Macmillan", "in", "1885", ",", "and", "was", "destroyed", "after", "his", "death", "."], "labels": ["O", "O", "B-writer", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-writer", "O", "B-writer", "O", "B-writer", "O", "B-writer", "O", "B-writer", "O", "B-writer", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-writer", "O", "O", "O", "O", "O", "O", "O", "B-magazine", "I-magazine", "I-magazine", "O", "B-magazine", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, book, award, country, writer, literary genre, poem, magazine, location, organization, event and O.\nSentence: Meanwhile , Housman pursued his classical studies independently , and published scholarly articles on Horace , Propertius , Ovid , Aeschylus , Euripides and Sophocles .ref Name = Poets / He also completed an edition of Propertius , which however was rejected by both Oxford University Press and Macmillan in 1885 , and was destroyed after his death .", "prompt_labels": "Meanwhile(O) ,(O) Housman(B-writer) pursued(O) his(O) classical(O) studies(O) independently(O) ,(O) and(O) published(O) scholarly(O) articles(O) on(O) Horace(B-writer) ,(O) Propertius(B-writer) ,(O) Ovid(B-writer) ,(O) Aeschylus(B-writer) ,(O) Euripides(B-writer) and(O) Sophocles(B-writer) .ref(O) Name(O) =(O) Poets(O) /(O) He(O) also(O) completed(O) an(O) edition(O) of(O) Propertius(B-writer) ,(O) which(O) however(O) was(O) rejected(O) by(O) both(O) Oxford(B-magazine) University(I-magazine) Press(I-magazine) and(O) Macmillan(B-magazine) in(O) 1885(O) ,(O) and(O) was(O) destroyed(O) after(O) his(O) death(O) .(O)"}, "label_list": ["person", "book", "award", "country", "writer", "literary genre", "poem", "magazine", "location", "organization", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 2363, 11, 10292, 11, 3224, 11, 7061, 11, 32465, 17779, 11, 33894, 11, 14756, 11, 3813, 11, 7471, 11, 1567, 323, 507, 627, 85664, 25, 26982, 1174, 473, 788, 1543, 46531, 813, 29924, 7978, 29235, 1174, 323, 4756, 63681, 9908, 389, 15083, 580, 1174, 3998, 531, 9334, 1174, 507, 1325, 1174, 362, 60478, 4010, 355, 1174, 85477, 575, 3422, 323, 34940, 511, 645, 662, 1116, 4076, 284, 14128, 1441, 611, 1283, 1101, 8308, 459, 14002, 315, 3998, 531, 9334, 1174, 902, 4869, 574, 18010, 555, 2225, 26275, 3907, 8612, 323, 7553, 26064, 276, 304, 220, 9367, 20, 1174, 323, 574, 14763, 1306, 813, 4648, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "231", "dataset": "crossner_music", "split": "dev", "prediction": "Soca(B-music genre) is(O) an(O) offshoot(O) of(O) kaiso(B-music genre) /(O) Calypso(B-music genre) music(O),(O) with(O) influences(O) from(O) Music(O) of(O) Latin(B-country) America(I-country),(O) Cadence(B-musical instrument) rampa(I-musical instrument),(O) funk(B-music genre) and(O) Soul(B-music genre) music(O).(O)", "instance": {"id": "231", "words": ["Soca", "is", "an", "offshoot", "of", "kaiso", "/", "Calypso", "music", ",", "with", "influences", "from", "Music", "of", "Latin", "America", ",", "Cadence", "rampa", ",", "funk", "and", "Soul", "music", "."], "labels": ["B-music genre", "O", "O", "O", "O", "B-music genre", "O", "B-music genre", "I-music genre", "O", "O", "O", "O", "B-music genre", "I-music genre", "I-music genre", "I-music genre", "O", "B-music genre", "I-music genre", "O", "B-music genre", "O", "B-music genre", "I-music genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, album, musical artist, award, event, person, song, band, location, country, organization, musical instrument and O.\nSentence: Soca is an offshoot of kaiso / Calypso music , with influences from Music of Latin America , Cadence rampa , funk and Soul music .", "prompt_labels": "Soca(B-music genre) is(O) an(O) offshoot(O) of(O) kaiso(B-music genre) /(O) Calypso(B-music genre) music(I-music genre) ,(O) with(O) influences(O) from(O) Music(B-music genre) of(I-music genre) Latin(I-music genre) America(I-music genre) ,(O) Cadence(B-music genre) rampa(I-music genre) ,(O) funk(B-music genre) and(O) Soul(B-music genre) music(I-music genre) .(O)"}, "label_list": ["music genre", "album", "musical artist", "award", "event", "person", "song", "band", "location", "country", "organization", "musical instrument"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 4731, 17779, 11, 8176, 11, 18273, 10255, 11, 10292, 11, 1567, 11, 1732, 11, 5609, 11, 7200, 11, 3813, 11, 3224, 11, 7471, 11, 18273, 14473, 323, 507, 627, 85664, 25, 328, 17270, 374, 459, 1022, 68392, 315, 597, 2852, 78, 611, 3400, 1100, 708, 4731, 1174, 449, 34453, 505, 10948, 315, 20023, 5270, 1174, 33160, 768, 23091, 64, 1174, 69392, 323, 30242, 4731, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1382", "dataset": "mit-movie", "split": "dev", "prediction": "im(O) looking(O) for(O) the(O) 1950(B-year) g(B-rating) rated(O) psychological(B-genre) movie(O) about(O) a(O) missing(B-plot) prisoner(I-plot) directed(O) by(O) michael(B-director) staininger(I-director)", "instance": {"id": "1382", "words": ["im", "looking", "for", "the", "1950", "g", "rated", "psychological", "movie", "about", "a", "missing", "prisoner", "directed", "by", "michael", "staininger"], "labels": ["O", "O", "O", "O", "B-year", "B-rating", "O", "B-genre", "O", "O", "O", "B-plot", "I-plot", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, average ratings, trailer, character, year, song, rating, plot, director, title, review, actor and O.\nSentence: im looking for the 1950 g rated psychological movie about a missing prisoner directed by michael staininger", "prompt_labels": "im(O) looking(O) for(O) the(O) 1950(B-year) g(B-rating) rated(O) psychological(B-genre) movie(O) about(O) a(O) missing(B-plot) prisoner(I-plot) directed(O) by(O) michael(B-director) staininger(I-director)"}, "label_list": ["genre", "average ratings", "trailer", "character", "year", "song", "rating", "plot", "director", "title", "review", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 5578, 18594, 11, 19809, 11, 3752, 11, 1060, 11, 5609, 11, 10959, 11, 7234, 11, 7690, 11, 2316, 11, 3477, 11, 12360, 323, 507, 627, 85664, 25, 737, 3411, 369, 279, 220, 6280, 15, 342, 22359, 24064, 5818, 922, 264, 7554, 42950, 15910, 555, 89006, 88896, 261, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "549", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movie(O) had(O) jim(B-actor) carrey(I-actor) as(O) a(O) dr(B-character) seuss(I-character) character(O)", "instance": {"id": "549", "words": ["what", "movie", "had", "jim", "carrey", "as", "a", "dr", "seuss", "character"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O", "O", "B-character", "I-character", "I-character"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, character, song, year, rating, director, trailer, plot, genre, average ratings, title, review and O.\nSentence: what movie had jim carrey as a dr seuss character", "prompt_labels": "what(O) movie(O) had(O) jim(B-actor) carrey(I-actor) as(O) a(O) dr(B-character) seuss(I-character) character(I-character)"}, "label_list": ["actor", "character", "song", "year", "rating", "director", "trailer", "plot", "genre", "average ratings", "title", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 3752, 11, 5609, 11, 1060, 11, 10959, 11, 7690, 11, 19809, 11, 7234, 11, 17779, 11, 5578, 18594, 11, 2316, 11, 3477, 323, 507, 627, 85664, 25, 1148, 5818, 1047, 96544, 1841, 8233, 439, 264, 1377, 513, 1892, 3752, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "83", "dataset": "mit-movie", "split": "dev", "prediction": "find(O) action(B-genre) movies(O) featuring(O) comic(B-plot) book(I-plot) characters(O)", "instance": {"id": "83", "words": ["find", "action", "movies", "featuring", "comic", "book", "characters"], "labels": ["O", "B-genre", "O", "O", "B-plot", "I-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, plot, genre, title, character, director, average ratings, trailer, review, rating, song, actor and O.\nSentence: find action movies featuring comic book characters", "prompt_labels": "find(O) action(B-genre) movies(O) featuring(O) comic(B-plot) book(I-plot) characters(I-plot)"}, "label_list": ["year", "plot", "genre", "title", "character", "director", "average ratings", "trailer", "review", "rating", "song", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 7234, 11, 17779, 11, 2316, 11, 3752, 11, 7690, 11, 5578, 18594, 11, 19809, 11, 3477, 11, 10959, 11, 5609, 11, 12360, 323, 507, 627, 85664, 25, 1505, 1957, 9698, 16850, 20303, 2363, 5885, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "289", "dataset": "crossner_music", "split": "dev", "prediction": "The(O) success(O) of(O) this(O) performance(O) lead(O) to(O) them(O) embarking(O) on(O) a(O) string(O) of(O) other(O) live(O) performances(O) in(O) 2009(O) and(O) 2010(O),(O) selling(O) out(O) prestigious(O) venues(O),(O) such(O) as(O) the(O) Queen(B-venue) Elizabeth(I-venue) Hall(I-venue) in(O) London(B-venue),(O) Volksb\u00fchne(B-venue) in(O) Berlin(B-venue) and(O) La(B-venue) Cigale(I-venue) in(O) Paris(B-venue) before(O) they(O) returned(O) to(O) their(O) homeland(O) for(O) their(O) performance(O) at(O) The(O) Norwegian(B-venue) Opera(I-venue) House(I-venue).(O)", "instance": {"id": "289", "words": ["The", "success", "of", "this", "performance", "lead", "to", "them", "embarking", "on", "a", "string", "of", "other", "live", "performances", "in", "2009", "and", "2010", ",", "selling", "out", "prestigious", "venues", ",", "such", "as", "the", "Queen", "Elizabeth", "Hall", "in", "London", ",", "Volksb\u00fchne", "in", "Berlin", "and", "La", "Cigale", "in", "Paris", "before", "they", "returned", "to", "their", "homeland", "for", "their", "performance", "at", "The", "Norwegian", "Opera", "House", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "I-location", "O", "B-location", "O", "B-location", "O", "B-band", "O", "B-location", "I-location", "O", "B-location", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "I-location", "I-location", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, song, musical artist, location, organization, person, album, band, country, award, music genre, event and O.\nSentence: The success of this performance lead to them embarking on a string of other live performances in 2009 and 2010 , selling out prestigious venues , such as the Queen Elizabeth Hall in London , Volksb\u00fchne in Berlin and La Cigale in Paris before they returned to their homeland for their performance at The Norwegian Opera House .", "prompt_labels": "The(O) success(O) of(O) this(O) performance(O) lead(O) to(O) them(O) embarking(O) on(O) a(O) string(O) of(O) other(O) live(O) performances(O) in(O) 2009(O) and(O) 2010(O) ,(O) selling(O) out(O) prestigious(O) venues(O) ,(O) such(O) as(O) the(O) Queen(B-location) Elizabeth(I-location) Hall(I-location) in(O) London(B-location) ,(O) Volksb\u00fchne(B-location) in(O) Berlin(B-band) and(O) La(B-location) Cigale(I-location) in(O) Paris(B-location) before(O) they(O) returned(O) to(O) their(O) homeland(O) for(O) their(O) performance(O) at(O) The(B-location) Norwegian(I-location) Opera(I-location) House(I-location) .(O)"}, "label_list": ["musical instrument", "song", "musical artist", "location", "organization", "person", "album", "band", "country", "award", "music genre", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18273, 14473, 11, 5609, 11, 18273, 10255, 11, 3813, 11, 7471, 11, 1732, 11, 8176, 11, 7200, 11, 3224, 11, 10292, 11, 4731, 17779, 11, 1567, 323, 507, 627, 85664, 25, 578, 2450, 315, 420, 5178, 3063, 311, 1124, 8126, 34552, 389, 264, 925, 315, 1023, 3974, 24601, 304, 220, 1049, 24, 323, 220, 679, 15, 1174, 11486, 704, 41385, 37278, 1174, 1778, 439, 279, 16657, 21393, 11166, 304, 7295, 1174, 11119, 2857, 65, 22284, 818, 304, 20437, 323, 5034, 356, 343, 1604, 304, 12366, 1603, 814, 6052, 311, 872, 56336, 369, 872, 5178, 520, 578, 45721, 39679, 4783, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "761", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) animated(B-genre) movies(O) were(O) nominated(B-average ratings) for(I-average ratings) oscars(I-average ratings)", "instance": {"id": "761", "words": ["what", "animated", "movies", "were", "nominated", "for", "oscars"], "labels": ["O", "B-genre", "O", "O", "B-average ratings", "I-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, rating, plot, director, trailer, actor, character, average ratings, genre, song, title, review and O.\nSentence: what animated movies were nominated for oscars", "prompt_labels": "what(O) animated(B-genre) movies(O) were(O) nominated(B-average ratings) for(I-average ratings) oscars(I-average ratings)"}, "label_list": ["year", "rating", "plot", "director", "trailer", "actor", "character", "average ratings", "genre", "song", "title", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 10959, 11, 7234, 11, 7690, 11, 19809, 11, 12360, 11, 3752, 11, 5578, 18594, 11, 17779, 11, 5609, 11, 2316, 11, 3477, 323, 507, 627, 85664, 25, 1148, 11625, 9698, 1051, 39048, 369, 32047, 1590, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1104", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) asian(B-Cuisine) restaurants(O) offer(O) carry(B-Amenity) out(I-Amenity)", "instance": {"id": "1104", "words": ["what", "asian", "restaurants", "offer", "carry", "out"], "labels": ["O", "B-Cuisine", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Amenity, Dish, Restaurant Name, Location, Hours, Price, Cuisine and O.\nSentence: what asian restaurants offer carry out", "prompt_labels": "what(O) asian(B-Cuisine) restaurants(O) offer(O) carry(B-Amenity) out(I-Amenity)"}, "label_list": ["Rating", "Amenity", "Dish", "Restaurant Name", "Location", "Hours", "Price", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 3383, 56685, 11, 49268, 11, 26568, 4076, 11, 10067, 11, 30192, 11, 8650, 11, 81961, 323, 507, 627, 85664, 25, 1148, 36725, 15926, 3085, 6920, 704, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2353", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) anthony(B-actor) hopkins(I-actor) in(O) a(O) musical(B-genre)", "instance": {"id": "2353", "words": ["is", "anthony", "hopkins", "in", "a", "musical"], "labels": ["O", "B-actor", "I-actor", "O", "O", "B-genre"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, plot, character, song, year, average ratings, actor, genre, review, rating, trailer, director and O.\nSentence: is anthony hopkins in a musical", "prompt_labels": "is(O) anthony(B-actor) hopkins(I-actor) in(O) a(O) musical(B-genre)"}, "label_list": ["title", "plot", "character", "song", "year", "average ratings", "actor", "genre", "review", "rating", "trailer", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 7234, 11, 3752, 11, 5609, 11, 1060, 11, 5578, 18594, 11, 12360, 11, 17779, 11, 3477, 11, 10959, 11, 19809, 11, 7690, 323, 507, 627, 85664, 25, 374, 23064, 3633, 7598, 11966, 304, 264, 18273, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "144", "dataset": "mit-restaurant", "split": "dev", "prediction": "can(O) you(O) find(O) a(O) site(O) where(O) i(O) can(O) see(O) reviews(O) on(O) restaurant(O) downtown(B-Location)", "instance": {"id": "144", "words": ["can", "you", "find", "a", "site", "where", "i", "can", "see", "reviews", "on", "restaurant", "downtown"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Hours, Cuisine, Restaurant Name, Price, Rating, Location, Amenity and O.\nSentence: can you find a site where i can see reviews on restaurant downtown", "prompt_labels": "can(O) you(O) find(O) a(O) site(O) where(O) i(O) can(O) see(O) reviews(O) on(O) restaurant(O) downtown(B-Location)"}, "label_list": ["Dish", "Hours", "Cuisine", "Restaurant Name", "Price", "Rating", "Location", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 30192, 11, 81961, 11, 26568, 4076, 11, 8650, 11, 19767, 11, 10067, 11, 3383, 56685, 323, 507, 627, 85664, 25, 649, 499, 1505, 264, 2816, 1405, 602, 649, 1518, 8544, 389, 10960, 19441, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "446", "dataset": "mit-restaurant", "split": "dev", "prediction": "find(O) restaurants(O) within(B-Location) 5(I-Location) miles(I-Location) with(O) entrees(O) under(B-Price) 15(I-Price)", "instance": {"id": "446", "words": ["find", "restaurants", "within", "5", "miles", "with", "entrees", "under", "15"], "labels": ["O", "O", "B-Location", "I-Location", "I-Location", "O", "B-Price", "I-Price", "I-Price"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Dish, Location, Hours, Restaurant Name, Price, Cuisine, Rating and O.\nSentence: find restaurants within 5 miles with entrees under 15", "prompt_labels": "find(O) restaurants(O) within(B-Location) 5(I-Location) miles(I-Location) with(O) entrees(B-Price) under(I-Price) 15(I-Price)"}, "label_list": ["Amenity", "Dish", "Location", "Hours", "Restaurant Name", "Price", "Cuisine", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 49268, 11, 10067, 11, 30192, 11, 26568, 4076, 11, 8650, 11, 81961, 11, 19767, 323, 507, 627, 85664, 25, 1505, 15926, 2949, 220, 20, 8931, 449, 1218, 8016, 1234, 220, 868, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "409", "dataset": "crossner_science", "split": "dev", "prediction": "He(O) won(O) silver(B-award) medals(I-award) at(O) the(O) 1989(B-event) Southeast(I-event) Asian(I-event) Games(I-event),(O) 1991(B-event) Southeast(I-event) Asian(I-event) Games(I-event),(O) and(O) 1993(B-event) Southeast(I-event) Asian(I-event) Games(I-event).(O)", "instance": {"id": "409", "words": ["He", "won", "silver", "medals", "at", "the", "1989", "Southeast", "Asian", "Games", ",", "1991", "Southeast", "Asian", "Games", ",", "and", "1993", "Southeast", "Asian", "Games", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "I-event", "O", "B-event", "I-event", "I-event", "I-event", "O", "O", "B-event", "I-event", "I-event", "I-event", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, person, scientist, protein, academic journal, organization, award, university, theory, location, chemical element, astronomical object, discipline, chemical compound, country, enzyme and O.\nSentence: He won silver medals at the 1989 Southeast Asian Games , 1991 Southeast Asian Games , and 1993 Southeast Asian Games .", "prompt_labels": "He(O) won(O) silver(O) medals(O) at(O) the(O) 1989(B-event) Southeast(I-event) Asian(I-event) Games(I-event) ,(O) 1991(B-event) Southeast(I-event) Asian(I-event) Games(I-event) ,(O) and(O) 1993(B-event) Southeast(I-event) Asian(I-event) Games(I-event) .(O)"}, "label_list": ["event", "person", "scientist", "protein", "academic journal", "organization", "award", "university", "theory", "location", "chemical element", "astronomical object", "discipline", "chemical compound", "country", "enzyme"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 1732, 11, 28568, 11, 13128, 11, 14584, 8486, 11, 7471, 11, 10292, 11, 12374, 11, 10334, 11, 3813, 11, 11742, 2449, 11, 87283, 1665, 11, 26434, 11, 11742, 24549, 11, 3224, 11, 49242, 323, 507, 627, 85664, 25, 1283, 2834, 15310, 60082, 520, 279, 220, 3753, 24, 36664, 14875, 11871, 1174, 220, 2550, 16, 36664, 14875, 11871, 1174, 323, 220, 2550, 18, 36664, 14875, 11871, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1238", "dataset": "mit-restaurant", "split": "dev", "prediction": "whats(O) the(O) closest(B-Location) restaurant(O) with(O) a(O) full(B-Amenity) salad(I-Amenity) bar(I-Amenity)", "instance": {"id": "1238", "words": ["whats", "the", "closest", "restaurant", "with", "a", "full", "salad", "bar"], "labels": ["O", "O", "B-Location", "O", "O", "O", "B-Cuisine", "I-Cuisine", "I-Cuisine"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Amenity, Price, Cuisine, Hours, Dish, Rating, Restaurant Name and O.\nSentence: whats the closest restaurant with a full salad bar", "prompt_labels": "whats(O) the(O) closest(B-Location) restaurant(O) with(O) a(O) full(B-Cuisine) salad(I-Cuisine) bar(I-Cuisine)"}, "label_list": ["Location", "Amenity", "Price", "Cuisine", "Hours", "Dish", "Rating", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 3383, 56685, 11, 8650, 11, 81961, 11, 30192, 11, 49268, 11, 19767, 11, 26568, 4076, 323, 507, 627, 85664, 25, 41209, 279, 18585, 10960, 449, 264, 2539, 33566, 3703, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "202", "dataset": "crossner_politics", "split": "dev", "prediction": "She(O) was(O) re-elected(O) to(O) additional(O) terms(O) in(O) 1974(O) Australian(O) federal(O) election(O),(O) 1975(O) Australian(O) federal(O) election(O),(O) and(O) 1980(O) Australian(O) federal(O) election(O),(O) retiring(O) on(O) 5(O) June(O) 1987(O) at(O) the(O) end(O) of(O) her(O) final(O) term(O).(O)", "instance": {"id": "202", "words": ["She", "was", "re-elected", "to", "additional", "terms", "in", "1974", "Australian", "federal", "election", ",", "1975", "Australian", "federal", "election", ",", "and", "1980", "Australian", "federal", "election", ",", "retiring", "on", "5", "June", "1987", "at", "the", "end", "of", "her", "final", "term", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, politician, election, organization, event, political party, location, country and O.\nSentence: She was re-elected to additional terms in 1974 Australian federal election , 1975 Australian federal election , and 1980 Australian federal election , retiring on 5 June 1987 at the end of her final term .", "prompt_labels": "She(O) was(O) re-elected(O) to(O) additional(O) terms(O) in(O) 1974(B-election) Australian(I-election) federal(I-election) election(I-election) ,(O) 1975(B-election) Australian(I-election) federal(I-election) election(I-election) ,(O) and(O) 1980(B-election) Australian(I-election) federal(I-election) election(I-election) ,(O) retiring(O) on(O) 5(O) June(O) 1987(O) at(O) the(O) end(O) of(O) her(O) final(O) term(O) .(O)"}, "label_list": ["person", "politician", "election", "organization", "event", "political party", "location", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 37038, 11, 6355, 11, 7471, 11, 1567, 11, 5054, 4717, 11, 3813, 11, 3224, 323, 507, 627, 85664, 25, 3005, 574, 312, 96805, 311, 5217, 3878, 304, 220, 4468, 19, 13673, 6918, 6355, 1174, 220, 4468, 20, 13673, 6918, 6355, 1174, 323, 220, 3753, 15, 13673, 6918, 6355, 1174, 60873, 389, 220, 20, 5651, 220, 3753, 22, 520, 279, 842, 315, 1077, 1620, 4751, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "971", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) scariest(O) horror(B-genre) movie(O) from(O) the(O) 90s(B-year)", "instance": {"id": "971", "words": ["what", "is", "the", "scariest", "horror", "movie", "from", "the", "90s"], "labels": ["O", "O", "O", "B-genre", "I-genre", "O", "O", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, song, plot, director, trailer, actor, review, title, rating, character, year, average ratings and O.\nSentence: what is the scariest horror movie from the 90s", "prompt_labels": "what(O) is(O) the(O) scariest(B-genre) horror(I-genre) movie(O) from(O) the(O) 90s(B-year)"}, "label_list": ["genre", "song", "plot", "director", "trailer", "actor", "review", "title", "rating", "character", "year", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 5609, 11, 7234, 11, 7690, 11, 19809, 11, 12360, 11, 3477, 11, 2316, 11, 10959, 11, 3752, 11, 1060, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1148, 374, 279, 1156, 2850, 478, 22169, 5818, 505, 279, 220, 1954, 82, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "272", "dataset": "mit-restaurant", "split": "dev", "prediction": "do(O) you(O) think(O) tin(B-Restaurant Name) whistle(I-Restaurant Name) has(O) fabulous(B-Amenity) service(I-Amenity)", "instance": {"id": "272", "words": ["do", "you", "think", "tin", "whistle", "has", "fabulous", "service"], "labels": ["O", "O", "O", "B-Restaurant Name", "I-Restaurant Name", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Dish, Price, Rating, Restaurant Name, Hours, Amenity, Location and O.\nSentence: do you think tin whistle has fabulous service", "prompt_labels": "do(O) you(O) think(O) tin(B-Restaurant Name) whistle(I-Restaurant Name) has(O) fabulous(B-Amenity) service(I-Amenity)"}, "label_list": ["Cuisine", "Dish", "Price", "Rating", "Restaurant Name", "Hours", "Amenity", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 49268, 11, 8650, 11, 19767, 11, 26568, 4076, 11, 30192, 11, 3383, 56685, 11, 10067, 323, 507, 627, 85664, 25, 656, 499, 1781, 25826, 40649, 706, 35631, 2532, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "782", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) the(O) chateau(B-Restaurant Name) restaurant(O) affordable(B-Price)", "instance": {"id": "782", "words": ["is", "the", "chateau", "restaurant", "affordable"], "labels": ["O", "O", "B-Restaurant Name", "I-Restaurant Name", "B-Price"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Hours, Dish, Cuisine, Rating, Location, Restaurant Name, Price and O.\nSentence: is the chateau restaurant affordable", "prompt_labels": "is(O) the(O) chateau(B-Restaurant Name) restaurant(I-Restaurant Name) affordable(B-Price)"}, "label_list": ["Amenity", "Hours", "Dish", "Cuisine", "Rating", "Location", "Restaurant Name", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 30192, 11, 49268, 11, 81961, 11, 19767, 11, 10067, 11, 26568, 4076, 11, 8650, 323, 507, 627, 85664, 25, 374, 279, 523, 77725, 10960, 17049, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "329", "dataset": "crossner_music", "split": "dev", "prediction": "Jimmie(B-musical artist) Rodgers(I-musical artist),(O) Moon(B-musical artist) Mullican(I-musical artist),(O) Bob(B-musical artist) Wills(I-musical artist),(O) Bill(B-musical artist) Monroe(I-musical artist) and(O) Hank(B-musical artist) Williams(I-musical artist) have(O) all(O) described(O) themselves(O) as(O) blues(B-music genre) singers(O) and(O) their(O) music(O) has(O) a(O) blues(B-music genre) feel(O) that(O) is(O) different(O),(O) at(O) first(O) glance(O) at(O) least(O),(O) from(O) the(O) later(O) country(B-music genre) pop(I-music genre) of(O) artists(O) like(O) Eddy(B-musical artist) Arnold(I-musical artist).(O)", "instance": {"id": "329", "words": ["Jimmie", "Rodgers", ",", "Moon", "Mullican", ",", "Bob", "Wills", ",", "Bill", "Monroe", "and", "Hank", "Williams", "have", "all", "described", "themselves", "as", "blues", "singers", "and", "their", "music", "has", "a", "blues", "feel", "that", "is", "different", ",", "at", "first", "glance", "at", "least", ",", "from", "the", "later", "country", "pop", "of", "artists", "like", "Eddy", "Arnold", "."], "labels": ["B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "O", "O", "O", "O", "B-music genre", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-music genre", "I-music genre", "O", "O", "O", "B-musical artist", "I-musical artist", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, band, location, person, event, organization, country, musical instrument, album, musical artist, music genre, award and O.\nSentence: Jimmie Rodgers , Moon Mullican , Bob Wills , Bill Monroe and Hank Williams have all described themselves as blues singers and their music has a blues feel that is different , at first glance at least , from the later country pop of artists like Eddy Arnold .", "prompt_labels": "Jimmie(B-musical artist) Rodgers(I-musical artist) ,(O) Moon(B-musical artist) Mullican(I-musical artist) ,(O) Bob(B-musical artist) Wills(I-musical artist) ,(O) Bill(B-musical artist) Monroe(I-musical artist) and(O) Hank(B-musical artist) Williams(I-musical artist) have(O) all(O) described(O) themselves(O) as(O) blues(B-music genre) singers(O) and(O) their(O) music(O) has(O) a(O) blues(O) feel(O) that(O) is(O) different(O) ,(O) at(O) first(O) glance(O) at(O) least(O) ,(O) from(O) the(O) later(O) country(B-music genre) pop(I-music genre) of(O) artists(O) like(O) Eddy(B-musical artist) Arnold(I-musical artist) .(O)"}, "label_list": ["song", "band", "location", "person", "event", "organization", "country", "musical instrument", "album", "musical artist", "music genre", "award"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 7200, 11, 3813, 11, 1732, 11, 1567, 11, 7471, 11, 3224, 11, 18273, 14473, 11, 8176, 11, 18273, 10255, 11, 4731, 17779, 11, 10292, 323, 507, 627, 85664, 25, 11641, 74696, 50117, 1174, 17781, 30451, 416, 276, 1174, 14596, 468, 3385, 1174, 8766, 50887, 323, 55761, 13926, 617, 682, 7633, 5694, 439, 44695, 68141, 323, 872, 4731, 706, 264, 44695, 2733, 430, 374, 2204, 1174, 520, 1176, 34522, 520, 3325, 1174, 505, 279, 3010, 3224, 2477, 315, 13820, 1093, 469, 54610, 44312, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "98", "dataset": "crossner_politics", "split": "dev", "prediction": "Hugo(B-politician) Ch\u00e1vez(I-politician),(O) the(O) central(O) figure(O) of(O) the(O) Venezuelan(O) political(O) landscape(O) since(O) 1998(O) Venezuelan(O) presidential(O) election(O) as(O) a(O) political(O) outsider(O),(O) died(O) in(O) office(O) in(O) early(O) 2013(O),(O) and(O) was(O) succeeded(O) by(O) Nicol\u00e1s(B-politician) Maduro(I-politician),(O) initially(O) as(O) interim(O) President(O),(O) before(O) winning(O) 2013(O) Venezuelan(O) presidential(O) election(O) and(O) re-election(O) in(O) 2018(O) Venezuelan(O) presidential(O) election(O).(O)", "instance": {"id": "98", "words": ["Hugo", "Ch\u00e1vez", ",", "the", "central", "figure", "of", "the", "Venezuelan", "political", "landscape", "since", "1998", "Venezuelan", "presidential", "election", "as", "a", "political", "outsider", ",", "died", "in", "office", "in", "early", "2013", ",", "and", "was", "succeeded", "by", "Nicol\u00e1s", "Maduro", ",", "initially", "as", "interim", "President", ",", "before", "winning", "2013", "Venezuelan", "presidential", "election", "and", "re-election", "in", "2018", "Venezuelan", "presidential", "election", "."], "labels": ["B-politician", "I-politician", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-politician", "I-politician", "O", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, election, country, political party, event, person, location, politician and O.\nSentence: Hugo Ch\u00e1vez , the central figure of the Venezuelan political landscape since 1998 Venezuelan presidential election as a political outsider , died in office in early 2013 , and was succeeded by Nicol\u00e1s Maduro , initially as interim President , before winning 2013 Venezuelan presidential election and re-election in 2018 Venezuelan presidential election .", "prompt_labels": "Hugo(B-politician) Ch\u00e1vez(I-politician) ,(O) the(O) central(O) figure(O) of(O) the(O) Venezuelan(O) political(O) landscape(O) since(O) 1998(B-election) Venezuelan(I-election) presidential(I-election) election(I-election) as(O) a(O) political(O) outsider(O) ,(O) died(O) in(O) office(O) in(O) early(O) 2013(O) ,(O) and(O) was(O) succeeded(O) by(O) Nicol\u00e1s(B-politician) Maduro(I-politician) ,(O) initially(O) as(O) interim(O) President(O) ,(O) before(O) winning(O) 2013(B-election) Venezuelan(I-election) presidential(I-election) election(I-election) and(O) re-election(O) in(O) 2018(B-election) Venezuelan(I-election) presidential(I-election) election(I-election) .(O)"}, "label_list": ["organization", "election", "country", "political party", "event", "person", "location", "politician"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 6355, 11, 3224, 11, 5054, 4717, 11, 1567, 11, 1732, 11, 3813, 11, 37038, 323, 507, 627, 85664, 25, 52194, 921, 1995, 19610, 1174, 279, 8792, 7216, 315, 279, 83749, 5054, 18921, 2533, 220, 2550, 23, 83749, 13621, 6355, 439, 264, 5054, 75683, 1174, 8636, 304, 5274, 304, 4216, 220, 679, 18, 1174, 323, 574, 26399, 555, 83440, 7206, 78802, 1174, 15453, 439, 41653, 4900, 1174, 1603, 11230, 220, 679, 18, 83749, 13621, 6355, 323, 312, 43733, 304, 220, 679, 23, 83749, 13621, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "204", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) people(O) like(O) or(O) hate(O) the(O) last(O) twilight(B-title) movie(O)", "instance": {"id": "204", "words": ["did", "people", "like", "or", "hate", "the", "last", "twilight", "movie"], "labels": ["O", "O", "B-review", "O", "B-review", "O", "O", "B-title", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, actor, year, average ratings, character, song, review, title, rating, trailer, genre, plot and O.\nSentence: did people like or hate the last twilight movie", "prompt_labels": "did(O) people(O) like(B-review) or(O) hate(B-review) the(O) last(O) twilight(B-title) movie(O)"}, "label_list": ["director", "actor", "year", "average ratings", "character", "song", "review", "title", "rating", "trailer", "genre", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 12360, 11, 1060, 11, 5578, 18594, 11, 3752, 11, 5609, 11, 3477, 11, 2316, 11, 10959, 11, 19809, 11, 17779, 11, 7234, 323, 507, 627, 85664, 25, 1550, 1274, 1093, 477, 12491, 279, 1566, 93722, 5818, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1017", "dataset": "mit-restaurant", "split": "dev", "prediction": "please(O) find(O) a(O) japanese(B-Cuisine) place(O) that(O) near(B-Location) an(I-Location) indian(B-Cuisine) restaurant(O)", "instance": {"id": "1017", "words": ["please", "find", "a", "japanese", "place", "that", "near", "an", "indian", "restaurant"], "labels": ["O", "O", "O", "B-Cuisine", "O", "O", "B-Location", "O", "B-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Restaurant Name, Cuisine, Hours, Location, Amenity, Rating, Dish and O.\nSentence: please find a japanese place that near an indian restaurant", "prompt_labels": "please(O) find(O) a(O) japanese(B-Cuisine) place(O) that(O) near(B-Location) an(O) indian(B-Cuisine) restaurant(O)"}, "label_list": ["Price", "Restaurant Name", "Cuisine", "Hours", "Location", "Amenity", "Rating", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 26568, 4076, 11, 81961, 11, 30192, 11, 10067, 11, 3383, 56685, 11, 19767, 11, 49268, 323, 507, 627, 85664, 25, 4587, 1505, 264, 54048, 2035, 430, 3221, 459, 43325, 10960, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1146", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) jacob(B-character) ransom(I-character) have(O) a(O) movie(O) about(O) fear(B-genre) of(I-genre) marriage(I-genre) that(O) was(O) rated(O) seven(B-average ratings) in(O) the(O) last(B-year) five(I-year) decades(I-year)", "instance": {"id": "1146", "words": ["did", "jacob", "ransom", "have", "a", "movie", "about", "fear", "of", "marriage", "that", "was", "rated", "seven", "in", "the", "last", "five", "decades"], "labels": ["O", "B-director", "I-director", "O", "O", "O", "O", "B-plot", "I-plot", "I-plot", "O", "O", "O", "B-average ratings", "O", "O", "B-year", "I-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, title, plot, trailer, rating, genre, average ratings, character, director, year, actor, review and O.\nSentence: did jacob ransom have a movie about fear of marriage that was rated seven in the last five decades", "prompt_labels": "did(O) jacob(B-director) ransom(I-director) have(O) a(O) movie(O) about(O) fear(B-plot) of(I-plot) marriage(I-plot) that(O) was(O) rated(O) seven(B-average ratings) in(O) the(O) last(B-year) five(I-year) decades(I-year)"}, "label_list": ["song", "title", "plot", "trailer", "rating", "genre", "average ratings", "character", "director", "year", "actor", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 2316, 11, 7234, 11, 19809, 11, 10959, 11, 17779, 11, 5578, 18594, 11, 3752, 11, 7690, 11, 1060, 11, 12360, 11, 3477, 323, 507, 627, 85664, 25, 1550, 503, 40051, 58686, 617, 264, 5818, 922, 8850, 315, 11103, 430, 574, 22359, 8254, 304, 279, 1566, 4330, 11026, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "246", "dataset": "crossner_literature", "split": "dev", "prediction": "He(O) also(O) led(O) the(O) trend(O) for(O) pastoral(B-literary genre) poetry(I-literary genre) and(O) his(O) pastoral(B-book) opera(I-book) The(B-book) Gentle(I-book) Shepherd(I-book) was(O) one(O) of(O) the(O) most(O) influential(O) works(O) of(O) the(O) era(O).(O)", "instance": {"id": "246", "words": ["He", "also", "led", "the", "trend", "for", "pastoral", "poetry", "and", "his", "pastoral", "opera", "The", "Gentle", "Shepherd", "was", "one", "of", "the", "most", "influential", "works", "of", "the", "era", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-literary genre", "I-literary genre", "O", "O", "B-literary genre", "I-literary genre", "B-poem", "I-poem", "I-poem", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, award, person, country, event, magazine, writer, organization, location, book, poem and O.\nSentence: He also led the trend for pastoral poetry and his pastoral opera The Gentle Shepherd was one of the most influential works of the era .", "prompt_labels": "He(O) also(O) led(O) the(O) trend(O) for(O) pastoral(B-literary genre) poetry(I-literary genre) and(O) his(O) pastoral(B-literary genre) opera(I-literary genre) The(B-poem) Gentle(I-poem) Shepherd(I-poem) was(O) one(O) of(O) the(O) most(O) influential(O) works(O) of(O) the(O) era(O) .(O)"}, "label_list": ["literary genre", "award", "person", "country", "event", "magazine", "writer", "organization", "location", "book", "poem"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 32465, 17779, 11, 10292, 11, 1732, 11, 3224, 11, 1567, 11, 14756, 11, 7061, 11, 7471, 11, 3813, 11, 2363, 11, 33894, 323, 507, 627, 85664, 25, 1283, 1101, 6197, 279, 9327, 369, 90371, 32349, 323, 813, 90371, 43516, 578, 74569, 59646, 574, 832, 315, 279, 1455, 32549, 4375, 315, 279, 11639, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "79", "dataset": "crossner_politics", "split": "dev", "prediction": "He(O) was(O) the(O) American(B-political party) Independent(I-political party) Party(I-political party) vice(O) presidential(O) nominee(O) under(O) John(B-politician) G.(I-politician) Schmitz(I-politician) in(O) 1972(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) and(O) the(O) American(B-political party) Party(I-political party) presidential(O) nominee(O) in(O) 1976(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election).(O)", "instance": {"id": "79", "words": ["He", "was", "the", "American", "Independent", "Party", "vice", "presidential", "nominee", "under", "John", "G.", "Schmitz", "in", "1972", "United", "States", "presidential", "election", "and", "the", "American", "Party", "presidential", "nominee", "in", "1976", "United", "States", "presidential", "election", "."], "labels": ["O", "O", "O", "B-political party", "I-political party", "I-political party", "O", "O", "O", "O", "B-politician", "I-politician", "I-politician", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, event, location, organization, political party, election, politician, country and O.\nSentence: He was the American Independent Party vice presidential nominee under John G. Schmitz in 1972 United States presidential election and the American Party presidential nominee in 1976 United States presidential election .", "prompt_labels": "He(O) was(O) the(O) American(B-political party) Independent(I-political party) Party(I-political party) vice(O) presidential(O) nominee(O) under(O) John(B-politician) G.(I-politician) Schmitz(I-politician) in(O) 1972(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) and(O) the(O) American(O) Party(O) presidential(O) nominee(O) in(O) 1976(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) .(O)"}, "label_list": ["person", "event", "location", "organization", "political party", "election", "politician", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 1567, 11, 3813, 11, 7471, 11, 5054, 4717, 11, 6355, 11, 37038, 11, 3224, 323, 507, 627, 85664, 25, 1283, 574, 279, 3778, 22765, 8722, 17192, 13621, 29311, 1234, 3842, 480, 13, 5124, 1800, 89, 304, 220, 4468, 17, 3723, 4273, 13621, 6355, 323, 279, 3778, 8722, 13621, 29311, 304, 220, 4468, 21, 3723, 4273, 13621, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "223", "dataset": "crossner_politics", "split": "dev", "prediction": "In(O) 1966(O),(O) he(O) used(O) some(O) of(O) his(O) wealth(O) to(O) form(O) the(O) Liberal(B-political party) Reform(I-political party) Group(I-political party),(O) a(O) splinter(O) group(O) of(O) members(O) of(O) the(O) Liberal(B-political party) Party(I-political party) of(I-political party) Australia(I-political party) disenchanted(O) with(O) their(O) party(O)'s(O) support(O) for(O) the(O) Vietnam(B-Location) War(I-Location) ;(O) this(O) became(O) the(O) Australian(B-Location) Reform(I-Location) Movement(I-Location) and(O) then(O) the(O) Australia(B-Location) Party(I-Location),(O) the(O) precursor(O) of(O) the(O) Australian(B-Location) Democrats(I-Location).(O)", "instance": {"id": "223", "words": ["In", "1966", ",", "he", "used", "some", "of", "his", "wealth", "to", "form", "the", "Liberal", "Reform", "Group", ",", "a", "splinter", "group", "of", "members", "of", "the", "Liberal", "Party", "of", "Australia", "disenchanted", "with", "their", "party", "'s", "support", "for", "the", "Vietnam", "War", ";", "this", "became", "the", "Australian", "Reform", "Movement", "and", "then", "the", "Australia", "Party", ",", "the", "precursor", "of", "the", "Australian", "Democrats", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "O", "O", "O", "B-political party", "I-political party", "O", "O", "O", "O", "O", "B-political party", "I-political party", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, country, political party, organization, location, politician, person, event and O.\nSentence: In 1966 , he used some of his wealth to form the Liberal Reform Group , a splinter group of members of the Liberal Party of Australia disenchanted with their party 's support for the Vietnam War ; this became the Australian Reform Movement and then the Australia Party , the precursor of the Australian Democrats .", "prompt_labels": "In(O) 1966(O) ,(O) he(O) used(O) some(O) of(O) his(O) wealth(O) to(O) form(O) the(O) Liberal(B-political party) Reform(I-political party) Group(I-political party) ,(O) a(O) splinter(O) group(O) of(O) members(O) of(O) the(O) Liberal(B-political party) Party(I-political party) of(I-political party) Australia(I-political party) disenchanted(O) with(O) their(O) party(O) 's(O) support(O) for(O) the(O) Vietnam(B-event) War(I-event) ;(O) this(O) became(O) the(O) Australian(B-political party) Reform(I-political party) Movement(I-political party) and(O) then(O) the(O) Australia(B-political party) Party(I-political party) ,(O) the(O) precursor(O) of(O) the(O) Australian(B-political party) Democrats(I-political party) .(O)"}, "label_list": ["election", "country", "political party", "organization", "location", "politician", "person", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 6355, 11, 3224, 11, 5054, 4717, 11, 7471, 11, 3813, 11, 37038, 11, 1732, 11, 1567, 323, 507, 627, 85664, 25, 763, 220, 5162, 21, 1174, 568, 1511, 1063, 315, 813, 12205, 311, 1376, 279, 31158, 40365, 5856, 1174, 264, 12786, 2295, 1912, 315, 3697, 315, 279, 31158, 8722, 315, 8494, 834, 20345, 7719, 449, 872, 4717, 364, 82, 1862, 369, 279, 23315, 5111, 2652, 420, 6244, 279, 13673, 40365, 29098, 323, 1243, 279, 8494, 8722, 1174, 279, 71261, 315, 279, 13673, 12643, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "188", "dataset": "crossner_music", "split": "dev", "prediction": "They(O) were(O) inducted(O) by(O) Chuck(B-musical artist) D(I-musical artist) and(O) LL(B-musical artist) Cool(I-musical artist) J(I-musical artist) on(O) April(O) 14(O),(O) 2012(O) therefore(O) the(O) group(O) didn(O) 't(O) perform(O) ;(O) instead(O) Black(B-musical artist) Thought(I-musical artist),(O) Travie(B-musical artist) from(O) Gym(B-band) Class(I-band) Heroes(I-band) and(O) Kid(B-musical artist) Rock(I-musical artist) performed(O) a(O) medley(O) of(O) their(O) songs(O).(O)", "instance": {"id": "188", "words": ["They", "were", "inducted", "by", "Chuck", "D", "and", "LL", "Cool", "J", "on", "April", "14", ",", "2012", "therefore", "the", "group", "didn", "'t", "perform", ";", "instead", "Black", "Thought", ",", "Travie", "from", "Gym", "Class", "Heroes", "and", "Kid", "Rock", "performed", "a", "medley", "of", "their", "songs", "."], "labels": ["O", "O", "O", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "I-musical artist", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "O", "B-band", "I-band", "I-band", "O", "B-musical artist", "I-musical artist", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, song, music genre, event, musical artist, award, band, organization, person, location, musical instrument, country and O.\nSentence: They were inducted by Chuck D and LL Cool J on April 14 , 2012 therefore the group didn 't perform ; instead Black Thought , Travie from Gym Class Heroes and Kid Rock performed a medley of their songs .", "prompt_labels": "They(O) were(O) inducted(O) by(O) Chuck(B-musical artist) D(I-musical artist) and(O) LL(B-musical artist) Cool(I-musical artist) J(I-musical artist) on(O) April(O) 14(O) ,(O) 2012(O) therefore(O) the(O) group(O) didn(O) 't(O) perform(O) ;(O) instead(O) Black(B-musical artist) Thought(I-musical artist) ,(O) Travie(B-musical artist) from(O) Gym(B-band) Class(I-band) Heroes(I-band) and(O) Kid(B-musical artist) Rock(I-musical artist) performed(O) a(O) medley(O) of(O) their(O) songs(O) .(O)"}, "label_list": ["album", "song", "music genre", "event", "musical artist", "award", "band", "organization", "person", "location", "musical instrument", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8176, 11, 5609, 11, 4731, 17779, 11, 1567, 11, 18273, 10255, 11, 10292, 11, 7200, 11, 7471, 11, 1732, 11, 3813, 11, 18273, 14473, 11, 3224, 323, 507, 627, 85664, 25, 2435, 1051, 304, 55015, 555, 34349, 423, 323, 20072, 24882, 622, 389, 5936, 220, 975, 1174, 220, 679, 17, 9093, 279, 1912, 3287, 364, 83, 2804, 2652, 4619, 5348, 36287, 1174, 43359, 648, 505, 46631, 3308, 38099, 323, 32666, 9305, 10887, 264, 1812, 3258, 315, 872, 11936, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "270", "dataset": "crossner_music", "split": "dev", "prediction": "In(O) 1974(O) he(O) returned(O) to(O) the(O) No.(O) 1(O) spot(O) on(O) the(O) R(B-music genre) and(I-music genre) B(I-music genre) charts(O) with(O) The(B-album) Payback(I-album),(O) with(O) the(O) The(B-album) Payback(I-album) reaching(O) the(O) same(O) spot(O) on(O) the(O) album(O) charts(O) ;(O) he(O) would(O) reach(O) No.(O) 1(O) two(O) more(O) times(O) in(O) 1974(O),(O) with(O) My(B-album) Thang(I-album) and(O) Papa(B-album) Don(I-album) 't(I-album) Take(I-album) No(I-album) Mess(I-album).(O)", "instance": {"id": "270", "words": ["In", "1974", "he", "returned", "to", "the", "No.", "1", "spot", "on", "the", "R", "&", "B", "charts", "with", "The", "Payback", ",", "with", "the", "The", "Payback", "reaching", "the", "same", "spot", "on", "the", "album", "charts", ";", "he", "would", "reach", "No.", "1", "two", "more", "times", "in", "1974", ",", "with", "My", "Thang", "and", "Papa", "Don", "'t", "Take", "No", "Mess", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-music genre", "I-music genre", "I-music genre", "O", "O", "B-album", "I-album", "O", "O", "O", "B-album", "I-album", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-song", "I-song", "O", "B-song", "I-song", "I-song", "I-song", "I-song", "I-song", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, music genre, album, organization, band, musical artist, musical instrument, person, country, event, location, song and O.\nSentence: In 1974 he returned to the No. 1 spot on the R & B charts with The Payback , with the The Payback reaching the same spot on the album charts ; he would reach No. 1 two more times in 1974 , with My Thang and Papa Don 't Take No Mess .", "prompt_labels": "In(O) 1974(O) he(O) returned(O) to(O) the(O) No.(O) 1(O) spot(O) on(O) the(O) R(B-music genre) &(I-music genre) B(I-music genre) charts(O) with(O) The(B-album) Payback(I-album) ,(O) with(O) the(O) The(B-album) Payback(I-album) reaching(O) the(O) same(O) spot(O) on(O) the(O) album(O) charts(O) ;(O) he(O) would(O) reach(O) No.(O) 1(O) two(O) more(O) times(O) in(O) 1974(O) ,(O) with(O) My(B-song) Thang(I-song) and(O) Papa(B-song) Don(I-song) 't(I-song) Take(I-song) No(I-song) Mess(I-song) .(O)"}, "label_list": ["award", "music genre", "album", "organization", "band", "musical artist", "musical instrument", "person", "country", "event", "location", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10292, 11, 4731, 17779, 11, 8176, 11, 7471, 11, 7200, 11, 18273, 10255, 11, 18273, 14473, 11, 1732, 11, 3224, 11, 1567, 11, 3813, 11, 5609, 323, 507, 627, 85664, 25, 763, 220, 4468, 19, 568, 6052, 311, 279, 2360, 13, 220, 16, 7858, 389, 279, 432, 612, 426, 27223, 449, 578, 11728, 1445, 1174, 449, 279, 578, 11728, 1445, 19261, 279, 1890, 7858, 389, 279, 8176, 27223, 2652, 568, 1053, 5662, 2360, 13, 220, 16, 1403, 810, 3115, 304, 220, 4468, 19, 1174, 449, 3092, 666, 526, 323, 65673, 4418, 364, 83, 12040, 2360, 19234, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "8", "dataset": "crossner_music", "split": "dev", "prediction": "The(O) album(O) was(O) certified(O) seven-times(O) platinum(O) in(O) Australia(O) by(O) the(O) Australian(B-organization) Recording(I-organization) Industry(I-organization) Association(I-organization) ((O) ARIA(B-organization) )(O),(O) five-times(O) platinum(O) in(O) the(O) UK(B-organization) by(O) the(O) British(B-organization) Phonographic(I-organization) Industry(I-organization) ((O) BPI(I-organization) )(O),(O) and(O) platinum(O) in(O) the(O) US(O) by(O) the(O) Recording(O) Industry(O) Association(O) of(O) America(O) ((O) RIAA(I-organization) )(O).(O)", "instance": {"id": "8", "words": ["The", "album", "was", "certified", "seven-times", "platinum", "in", "Australia", "by", "the", "Australian", "Recording", "Industry", "Association", "(", "ARIA", ")", ",", "five-times", "platinum", "in", "the", "UK", "by", "the", "British", "Phonographic", "Industry", "(", "BPI", ")", ",", "and", "platinum", "in", "the", "US", "by", "the", "Recording", "Industry", "Association", "of", "America", "(", "RIAA", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-country", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "O", "O", "O", "O", "O", "O", "B-country", "O", "O", "B-organization", "I-organization", "I-organization", "O", "B-organization", "O", "O", "O", "O", "O", "O", "B-country", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, organization, location, country, album, music genre, musical instrument, song, musical artist, award, person, event and O.\nSentence: The album was certified seven-times platinum in Australia by the Australian Recording Industry Association ( ARIA ) , five-times platinum in the UK by the British Phonographic Industry ( BPI ) , and platinum in the US by the Recording Industry Association of America ( RIAA ) .", "prompt_labels": "The(O) album(O) was(O) certified(O) seven-times(O) platinum(O) in(O) Australia(B-country) by(O) the(O) Australian(B-organization) Recording(I-organization) Industry(I-organization) Association(I-organization) ((O) ARIA(B-organization) )(O) ,(O) five-times(O) platinum(O) in(O) the(O) UK(B-country) by(O) the(O) British(B-organization) Phonographic(I-organization) Industry(I-organization) ((O) BPI(B-organization) )(O) ,(O) and(O) platinum(O) in(O) the(O) US(B-country) by(O) the(O) Recording(B-organization) Industry(I-organization) Association(I-organization) of(I-organization) America(I-organization) ((O) RIAA(B-organization) )(O) .(O)"}, "label_list": ["band", "organization", "location", "country", "album", "music genre", "musical instrument", "song", "musical artist", "award", "person", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7200, 11, 7471, 11, 3813, 11, 3224, 11, 8176, 11, 4731, 17779, 11, 18273, 14473, 11, 5609, 11, 18273, 10255, 11, 10292, 11, 1732, 11, 1567, 323, 507, 627, 85664, 25, 578, 8176, 574, 23759, 8254, 45548, 63327, 304, 8494, 555, 279, 13673, 61647, 24780, 10229, 320, 362, 79363, 883, 1174, 4330, 45548, 63327, 304, 279, 6560, 555, 279, 8013, 71424, 12968, 24780, 320, 426, 1932, 883, 1174, 323, 63327, 304, 279, 2326, 555, 279, 61647, 24780, 10229, 315, 5270, 320, 432, 5987, 32, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "696", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) would(O) like(O) to(O) find(O) a(O) vegeterian(B-Cuisine) restaurant(O)", "instance": {"id": "696", "words": ["i", "would", "like", "to", "find", "a", "vegeterian", "restaurant"], "labels": ["O", "O", "O", "O", "O", "O", "B-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Rating, Hours, Location, Cuisine, Price, Amenity, Dish and O.\nSentence: i would like to find a vegeterian restaurant", "prompt_labels": "i(O) would(O) like(O) to(O) find(O) a(O) vegeterian(B-Cuisine) restaurant(O)"}, "label_list": ["Restaurant Name", "Rating", "Hours", "Location", "Cuisine", "Price", "Amenity", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 19767, 11, 30192, 11, 10067, 11, 81961, 11, 8650, 11, 3383, 56685, 11, 49268, 323, 507, 627, 85664, 25, 602, 1053, 1093, 311, 1505, 264, 13294, 261, 1122, 10960, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1462", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) there(O) a(O) restaurant(O) located(O) within(B-Location) 1(I-Location) mile(I-Location) from(I-Location) here(I-Location)", "instance": {"id": "1462", "words": ["where", "there", "a", "restaurant", "located", "within", "1", "mile", "from", "here"], "labels": ["O", "O", "O", "O", "O", "B-Location", "I-Location", "I-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Price, Rating, Restaurant Name, Hours, Location, Cuisine, Dish and O.\nSentence: where there a restaurant located within 1 mile from here", "prompt_labels": "where(O) there(O) a(O) restaurant(O) located(O) within(B-Location) 1(I-Location) mile(I-Location) from(I-Location) here(I-Location)"}, "label_list": ["Amenity", "Price", "Rating", "Restaurant Name", "Hours", "Location", "Cuisine", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 8650, 11, 19767, 11, 26568, 4076, 11, 30192, 11, 10067, 11, 81961, 11, 49268, 323, 507, 627, 85664, 25, 1405, 1070, 264, 10960, 7559, 2949, 220, 16, 14929, 505, 1618, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "516", "dataset": "mit-restaurant", "split": "dev", "prediction": "how(O) far(O) is(O) the(O) english(B-Cuisine) pub(I-Cuisine) that(O) serves(O) a(O) fry(B-Dish) up(I-Dish)", "instance": {"id": "516", "words": ["how", "far", "is", "the", "english", "pub", "that", "serves", "a", "fry", "up"], "labels": ["O", "O", "O", "O", "B-Amenity", "I-Amenity", "O", "O", "O", "B-Dish", "I-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Cuisine, Restaurant Name, Rating, Amenity, Location, Price, Dish and O.\nSentence: how far is the english pub that serves a fry up", "prompt_labels": "how(O) far(O) is(O) the(O) english(B-Amenity) pub(I-Amenity) that(O) serves(O) a(O) fry(B-Dish) up(I-Dish)"}, "label_list": ["Hours", "Cuisine", "Restaurant Name", "Rating", "Amenity", "Location", "Price", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 81961, 11, 26568, 4076, 11, 19767, 11, 3383, 56685, 11, 10067, 11, 8650, 11, 49268, 323, 507, 627, 85664, 25, 1268, 3117, 374, 279, 30063, 6814, 430, 17482, 264, 53646, 709, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2394", "dataset": "mit-movie", "split": "dev", "prediction": "could(O) you(O) send(O) me(O) to(O) a(O) website(O) with(O) user(O) reviews(O) of(O) willy(B-title) wonka(I-title) the(I-title) chocolate(I-title) factory(I-title)", "instance": {"id": "2394", "words": ["could", "you", "send", "me", "to", "a", "website", "with", "user", "reviews", "of", "willy", "wonka", "the", "chocolate", "factory"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-review", "O", "B-title", "I-title", "I-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, review, rating, title, trailer, year, average ratings, plot, actor, character, genre, song and O.\nSentence: could you send me to a website with user reviews of willy wonka the chocolate factory", "prompt_labels": "could(O) you(O) send(O) me(O) to(O) a(O) website(O) with(O) user(O) reviews(B-review) of(O) willy(B-title) wonka(I-title) the(I-title) chocolate(I-title) factory(I-title)"}, "label_list": ["director", "review", "rating", "title", "trailer", "year", "average ratings", "plot", "actor", "character", "genre", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 3477, 11, 10959, 11, 2316, 11, 19809, 11, 1060, 11, 5578, 18594, 11, 7234, 11, 12360, 11, 3752, 11, 17779, 11, 5609, 323, 507, 627, 85664, 25, 1436, 499, 3708, 757, 311, 264, 3997, 449, 1217, 8544, 315, 289, 14722, 2834, 4657, 279, 18414, 8803, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "86", "dataset": "mit-restaurant", "split": "dev", "prediction": "are(O) there(O) any(O) restaurants(O) within(B-Location) 5(I-Location) miles(I-Location) that(O) accept(B-Amenity) travelers(I-Amenity) checks(I-Amenity)", "instance": {"id": "86", "words": ["are", "there", "any", "restaurants", "within", "5", "miles", "that", "accept", "travelers", "checks"], "labels": ["O", "O", "O", "O", "B-Location", "I-Location", "I-Location", "O", "B-Amenity", "I-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Restaurant Name, Amenity, Dish, Price, Hours, Rating, Cuisine and O.\nSentence: are there any restaurants within 5 miles that accept travelers checks", "prompt_labels": "are(O) there(O) any(O) restaurants(O) within(B-Location) 5(I-Location) miles(I-Location) that(O) accept(B-Amenity) travelers(I-Amenity) checks(I-Amenity)"}, "label_list": ["Location", "Restaurant Name", "Amenity", "Dish", "Price", "Hours", "Rating", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 26568, 4076, 11, 3383, 56685, 11, 49268, 11, 8650, 11, 30192, 11, 19767, 11, 81961, 323, 507, 627, 85664, 25, 527, 1070, 904, 15926, 2949, 220, 20, 8931, 430, 4287, 40386, 12621, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1498", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) there(O) a(O) good(O) thriller(B-genre) that(O) is(O) rated(O) pg(B-rating) 13(I-rating) that(O) came(O) out(O) in(O) the(O) 2010(B-year) s(I-year)", "instance": {"id": "1498", "words": ["is", "there", "a", "good", "thriller", "that", "is", "rated", "pg", "13", "that", "came", "out", "in", "the", "2010", "s"], "labels": ["O", "O", "O", "O", "B-genre", "O", "O", "O", "B-rating", "I-rating", "O", "O", "O", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, trailer, plot, song, title, character, average ratings, actor, rating, director, review, year and O.\nSentence: is there a good thriller that is rated pg 13 that came out in the 2010 s", "prompt_labels": "is(O) there(O) a(O) good(O) thriller(B-genre) that(O) is(O) rated(O) pg(B-rating) 13(I-rating) that(O) came(O) out(O) in(O) the(O) 2010(B-year) s(I-year)"}, "label_list": ["genre", "trailer", "plot", "song", "title", "character", "average ratings", "actor", "rating", "director", "review", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 19809, 11, 7234, 11, 5609, 11, 2316, 11, 3752, 11, 5578, 18594, 11, 12360, 11, 10959, 11, 7690, 11, 3477, 11, 1060, 323, 507, 627, 85664, 25, 374, 1070, 264, 1695, 54461, 430, 374, 22359, 17953, 220, 1032, 430, 3782, 704, 304, 279, 220, 679, 15, 274, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "255", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) any(O) action(B-genre) movies(O) that(O) are(O) in(O) theatres(B-year) right(I-year) now(I-year)", "instance": {"id": "255", "words": ["show", "me", "any", "action", "movies", "that", "are", "in", "theatres", "right", "now"], "labels": ["O", "O", "O", "B-genre", "O", "O", "O", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, title, average ratings, trailer, song, year, genre, character, director, rating, plot, actor and O.\nSentence: show me any action movies that are in theatres right now", "prompt_labels": "show(O) me(O) any(O) action(B-genre) movies(O) that(O) are(O) in(O) theatres(O) right(B-year) now(I-year)"}, "label_list": ["review", "title", "average ratings", "trailer", "song", "year", "genre", "character", "director", "rating", "plot", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 2316, 11, 5578, 18594, 11, 19809, 11, 5609, 11, 1060, 11, 17779, 11, 3752, 11, 7690, 11, 10959, 11, 7234, 11, 12360, 323, 507, 627, 85664, 25, 1501, 757, 904, 1957, 9698, 430, 527, 304, 47213, 417, 1314, 1457, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "876", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) a(O) list(O) of(O) r(B-rating) rated(O) movies(O) about(O) aliens(B-plot)", "instance": {"id": "876", "words": ["show", "me", "a", "list", "of", "r", "rated", "movies", "about", "aliens"], "labels": ["O", "O", "O", "O", "O", "B-rating", "I-rating", "O", "O", "B-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, year, plot, rating, title, average ratings, song, character, review, genre, trailer, director and O.\nSentence: show me a list of r rated movies about aliens", "prompt_labels": "show(O) me(O) a(O) list(O) of(O) r(B-rating) rated(I-rating) movies(O) about(O) aliens(B-plot)"}, "label_list": ["actor", "year", "plot", "rating", "title", "average ratings", "song", "character", "review", "genre", "trailer", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 1060, 11, 7234, 11, 10959, 11, 2316, 11, 5578, 18594, 11, 5609, 11, 3752, 11, 3477, 11, 17779, 11, 19809, 11, 7690, 323, 507, 627, 85664, 25, 1501, 757, 264, 1160, 315, 436, 22359, 9698, 922, 37219, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "258", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) a(O) good(O) romance(B-genre) movie(O) with(O) jennifer(B-actor) aniston(I-actor)", "instance": {"id": "258", "words": ["what", "is", "a", "good", "romance", "movie", "with", "jennifer", "aniston"], "labels": ["O", "O", "O", "B-review", "B-genre", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, average ratings, trailer, plot, year, genre, character, song, actor, director, title, review and O.\nSentence: what is a good romance movie with jennifer aniston", "prompt_labels": "what(O) is(O) a(O) good(B-review) romance(B-genre) movie(O) with(O) jennifer(B-actor) aniston(I-actor)"}, "label_list": ["rating", "average ratings", "trailer", "plot", "year", "genre", "character", "song", "actor", "director", "title", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 5578, 18594, 11, 19809, 11, 7234, 11, 1060, 11, 17779, 11, 3752, 11, 5609, 11, 12360, 11, 7690, 11, 2316, 11, 3477, 323, 507, 627, 85664, 25, 1148, 374, 264, 1695, 30363, 5818, 449, 503, 60070, 459, 59919, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "393", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) stared(O) in(O) the(O) movie(O) the(B-title) bank(I-title) job(I-title)", "instance": {"id": "393", "words": ["who", "stared", "in", "the", "movie", "the", "bank", "job"], "labels": ["O", "O", "O", "O", "O", "B-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, title, genre, plot, actor, character, trailer, rating, average ratings, director, song, review and O.\nSentence: who stared in the movie the bank job", "prompt_labels": "who(O) stared(O) in(O) the(O) movie(O) the(B-title) bank(I-title) job(I-title)"}, "label_list": ["year", "title", "genre", "plot", "actor", "character", "trailer", "rating", "average ratings", "director", "song", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 2316, 11, 17779, 11, 7234, 11, 12360, 11, 3752, 11, 19809, 11, 10959, 11, 5578, 18594, 11, 7690, 11, 5609, 11, 3477, 323, 507, 627, 85664, 25, 889, 45135, 304, 279, 5818, 279, 6201, 2683, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "159", "dataset": "crossner_science", "split": "dev", "prediction": "Bennett(B-person) was(O) the(O) flight(O) safety(O) manager(O) for(O) the(O) radioisotope(O) power(O) sources(O) currently(O) in(O) use(O) on(O) the(O) Voyager(B-astronomical object) 1(I-astronomical object) and(O) Voyager(B-astronomical object) 2(I-astronomical object) spacecraft(O) ((O) which(O) went(O) to(O) Jupiter(B-astronomical object),(O) Saturn(B-astronomical object),(O) Uranus(B-astronomical object),(O) Neptune(B-astronomical object) and(O) beyond(O) )(O) and(O) on(O) Lincoln(B-organization) Laboratory(I-organization)'s(O) LES(B-organization) 8(I-organization) and(O) LES(B-organization) 9(I-organization) communications(O) satellites(O).(O)", "instance": {"id": "159", "words": ["Bennett", "was", "the", "flight", "safety", "manager", "for", "the", "radioisotope", "power", "sources", "currently", "in", "use", "on", "the", "Voyager", "1", "and", "Voyager", "2", "spacecraft", "(", "which", "went", "to", "Jupiter", ",", "Saturn", ",", "Uranus", ",", "Neptune", "and", "beyond", ")", "and", "on", "Lincoln", "Laboratory", "'", "s", "LES", "8", "and", "LES", "9", "communications", "satellites", "."], "labels": ["B-person", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-astronomical object", "O", "B-astronomical object", "O", "B-astronomical object", "O", "B-astronomical object", "O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: astronomical object, chemical compound, theory, chemical element, academic journal, enzyme, country, discipline, scientist, location, university, person, event, award, organization, protein and O.\nSentence: Bennett was the flight safety manager for the radioisotope power sources currently in use on the Voyager 1 and Voyager 2 spacecraft ( which went to Jupiter , Saturn , Uranus , Neptune and beyond ) and on Lincoln Laboratory ' s LES 8 and LES 9 communications satellites .", "prompt_labels": "Bennett(B-person) was(O) the(O) flight(O) safety(O) manager(O) for(O) the(O) radioisotope(O) power(O) sources(O) currently(O) in(O) use(O) on(O) the(O) Voyager(O) 1(O) and(O) Voyager(O) 2(O) spacecraft(O) ((O) which(O) went(O) to(O) Jupiter(B-astronomical object) ,(O) Saturn(B-astronomical object) ,(O) Uranus(B-astronomical object) ,(O) Neptune(B-astronomical object) and(O) beyond(O) )(O) and(O) on(O) Lincoln(B-organization) Laboratory(I-organization) '(O) s(O) LES(O) 8(O) and(O) LES(O) 9(O) communications(O) satellites(O) .(O)"}, "label_list": ["astronomical object", "chemical compound", "theory", "chemical element", "academic journal", "enzyme", "country", "discipline", "scientist", "location", "university", "person", "event", "award", "organization", "protein"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 87283, 1665, 11, 11742, 24549, 11, 10334, 11, 11742, 2449, 11, 14584, 8486, 11, 49242, 11, 3224, 11, 26434, 11, 28568, 11, 3813, 11, 12374, 11, 1732, 11, 1567, 11, 10292, 11, 7471, 11, 13128, 323, 507, 627, 85664, 25, 39386, 574, 279, 11213, 7296, 6783, 369, 279, 9063, 285, 51782, 2410, 8336, 5131, 304, 1005, 389, 279, 86260, 220, 16, 323, 86260, 220, 17, 42640, 320, 902, 4024, 311, 50789, 1174, 50253, 1174, 80770, 355, 1174, 80724, 323, 7953, 883, 323, 389, 25379, 32184, 364, 274, 97529, 220, 23, 323, 97529, 220, 24, 17320, 47710, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "223", "dataset": "crossner_ai", "split": "dev", "prediction": "Time(O) series(O) are(O) used(O) in(O) statistics(O),(O) signal(B-field) processing(I-field),(O) pattern(B-field) recognition(I-field),(O) econometrics(B-field),(O) mathematical(B-field) finance(I-field),(O) weather(B-weather) forecasting(I-weather),(O) earthquake(B-weather) prediction(I-weather),(O) electroencephalography(B-technology),(O) control(B-technology) engineering(I-technology),(O) astronomy(B-field),(O) communications(B-field) engineering(I-field),(O) and(O) largely(O) in(O) any(O) domain(O) of(O) applied(O) science(O) and(O) engineering(O) which(O) involves(O) temporal(O) measurements(O).(O)", "instance": {"id": "223", "words": ["Time", "series", "are", "used", "in", "statistics", ",", "signal", "processing", ",", "pattern", "recognition", ",", "econometrics", ",", "mathematical", "finance", ",", "weather", "forecasting", ",", "earthquake", "prediction", ",", "electroencephalography", ",", "control", "engineering", ",", "astronomy", ",", "communications", "engineering", ",", "and", "largely", "in", "any", "domain", "of", "applied", "science", "and", "engineering", "which", "involves", "temporal", "measurements", "."], "labels": ["O", "O", "O", "O", "O", "B-field", "O", "B-field", "I-field", "O", "B-field", "I-field", "O", "B-field", "O", "B-field", "I-field", "O", "B-field", "I-field", "O", "B-field", "I-field", "O", "B-field", "O", "B-field", "I-field", "O", "B-field", "O", "B-field", "I-field", "O", "O", "O", "O", "O", "O", "O", "B-field", "I-field", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, metric, country, programming language, university, algorithm, organization, product, researcher, task, conference, location, field and O.\nSentence: Time series are used in statistics , signal processing , pattern recognition , econometrics , mathematical finance , weather forecasting , earthquake prediction , electroencephalography , control engineering , astronomy , communications engineering , and largely in any domain of applied science and engineering which involves temporal measurements .", "prompt_labels": "Time(O) series(O) are(O) used(O) in(O) statistics(B-field) ,(O) signal(B-field) processing(I-field) ,(O) pattern(B-field) recognition(I-field) ,(O) econometrics(B-field) ,(O) mathematical(B-field) finance(I-field) ,(O) weather(B-field) forecasting(I-field) ,(O) earthquake(B-field) prediction(I-field) ,(O) electroencephalography(B-field) ,(O) control(B-field) engineering(I-field) ,(O) astronomy(B-field) ,(O) communications(B-field) engineering(I-field) ,(O) and(O) largely(O) in(O) any(O) domain(O) of(O) applied(B-field) science(I-field) and(O) engineering(O) which(O) involves(O) temporal(O) measurements(O) .(O)"}, "label_list": ["person", "metric", "country", "programming language", "university", "algorithm", "organization", "product", "researcher", "task", "conference", "location", "field"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 18767, 11, 3224, 11, 15840, 4221, 11, 12374, 11, 12384, 11, 7471, 11, 2027, 11, 32185, 11, 3465, 11, 10017, 11, 3813, 11, 2115, 323, 507, 627, 85664, 25, 4212, 4101, 527, 1511, 304, 13443, 1174, 8450, 8863, 1174, 5497, 18324, 1174, 3898, 92891, 1174, 37072, 17452, 1174, 9282, 79482, 1174, 38413, 20212, 1174, 25396, 768, 764, 278, 5814, 1174, 2585, 15009, 1174, 82213, 1174, 17320, 15009, 1174, 323, 14090, 304, 904, 8106, 315, 9435, 8198, 323, 15009, 902, 18065, 37015, 22323, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "375", "dataset": "mit-restaurant", "split": "dev", "prediction": "find(O) me(O) a(O) good(B-Rating) pub(B-Cuisine) that(O) has(O) a(O) dance(B-Amenity) floor(I-Amenity)", "instance": {"id": "375", "words": ["find", "me", "a", "good", "pub", "that", "has", "a", "dance", "floor"], "labels": ["O", "O", "O", "B-Rating", "B-Cuisine", "O", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Price, Hours, Location, Amenity, Cuisine, Rating, Restaurant Name and O.\nSentence: find me a good pub that has a dance floor", "prompt_labels": "find(O) me(O) a(O) good(B-Rating) pub(B-Cuisine) that(O) has(O) a(O) dance(B-Amenity) floor(I-Amenity)"}, "label_list": ["Dish", "Price", "Hours", "Location", "Amenity", "Cuisine", "Rating", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 8650, 11, 30192, 11, 10067, 11, 3383, 56685, 11, 81961, 11, 19767, 11, 26568, 4076, 323, 507, 627, 85664, 25, 1505, 757, 264, 1695, 6814, 430, 706, 264, 15612, 6558, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "739", "dataset": "mit-restaurant", "split": "dev", "prediction": "im(O) looking(O) for(O) a(O) romantic(B-Amenity) restaurant(O) where(O) are(O) some(O) near(B-Location) me(I-Location)", "instance": {"id": "739", "words": ["im", "looking", "for", "a", "romantic", "restaurant", "where", "are", "some", "near", "me"], "labels": ["O", "O", "O", "O", "B-Amenity", "O", "O", "O", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Dish, Hours, Location, Cuisine, Amenity, Restaurant Name, Rating and O.\nSentence: im looking for a romantic restaurant where are some near me", "prompt_labels": "im(O) looking(O) for(O) a(O) romantic(B-Amenity) restaurant(O) where(O) are(O) some(O) near(B-Location) me(I-Location)"}, "label_list": ["Price", "Dish", "Hours", "Location", "Cuisine", "Amenity", "Restaurant Name", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 49268, 11, 30192, 11, 10067, 11, 81961, 11, 3383, 56685, 11, 26568, 4076, 11, 19767, 323, 507, 627, 85664, 25, 737, 3411, 369, 264, 24364, 10960, 1405, 527, 1063, 3221, 757, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1207", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) time(O) does(O) on(B-Restaurant Name) the(I-Restaurant Name) rocks(I-Restaurant Name) on(I-Restaurant Name) seminary(I-Restaurant Name) stop(I-Restaurant Name) serving(O) food(O)", "instance": {"id": "1207", "words": ["what", "time", "does", "on", "the", "rocks", "on", "seminary", "stop", "serving", "food"], "labels": ["O", "B-Hours", "O", "B-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name", "O", "B-Location", "B-Hours", "I-Hours", "I-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Rating, Amenity, Location, Hours, Dish, Restaurant Name, Price and O.\nSentence: what time does on the rocks on seminary stop serving food", "prompt_labels": "what(O) time(B-Hours) does(O) on(B-Restaurant Name) the(I-Restaurant Name) rocks(I-Restaurant Name) on(O) seminary(B-Location) stop(B-Hours) serving(I-Hours) food(I-Hours)"}, "label_list": ["Cuisine", "Rating", "Amenity", "Location", "Hours", "Dish", "Restaurant Name", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 19767, 11, 3383, 56685, 11, 10067, 11, 30192, 11, 49268, 11, 26568, 4076, 11, 8650, 323, 507, 627, 85664, 25, 1148, 892, 1587, 389, 279, 23902, 389, 5347, 3367, 3009, 13788, 3691, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "33", "dataset": "crossner_literature", "split": "dev", "prediction": "The(O) poem(O) is(O) quoted(O) by(O) Sue(B-writer) Bridehead(I-writer) in(O) Thomas(B-writer) Hardy(I-writer)'s(O) 1895(O) novel(O),(O) Jude(B-book) the(I-book) Obscure(I-book) and(O) also(O) by(O) Edward(B-writer) Ashburnham(I-writer) in(O) Ford(B-writer) Madox(I-writer).(O) Ford(B-writer)'s(O) The(B-book) Good(I-book) Soldier(I-book).(O)", "instance": {"id": "33", "words": ["The", "poem", "is", "quoted", "by", "Sue", "Bridehead", "in", "Thomas", "Hardy", "'", "s", "1895", "novel", ",", "Jude", "the", "Obscure", "and", "also", "by", "Edward", "Ashburnham", "in", "Ford", "Madox", ".", "Ford", "'", "s", "The", "Good", "Soldier", "."], "labels": ["O", "B-literary genre", "O", "O", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "O", "O", "B-literary genre", "O", "B-book", "I-book", "I-book", "O", "O", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "B-writer", "O", "O", "B-book", "I-book", "I-book", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, magazine, award, book, literary genre, poem, country, organization, event, writer, location and O.\nSentence: The poem is quoted by Sue Bridehead in Thomas Hardy ' s 1895 novel , Jude the Obscure and also by Edward Ashburnham in Ford Madox . Ford ' s The Good Soldier .", "prompt_labels": "The(O) poem(B-literary genre) is(O) quoted(O) by(O) Sue(B-writer) Bridehead(I-writer) in(O) Thomas(B-writer) Hardy(I-writer) '(O) s(O) 1895(O) novel(B-literary genre) ,(O) Jude(B-book) the(I-book) Obscure(I-book) and(O) also(O) by(O) Edward(B-writer) Ashburnham(I-writer) in(O) Ford(B-writer) Madox(I-writer) .(O) Ford(B-writer) '(O) s(O) The(B-book) Good(I-book) Soldier(I-book) .(O)"}, "label_list": ["person", "magazine", "award", "book", "literary genre", "poem", "country", "organization", "event", "writer", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 14756, 11, 10292, 11, 2363, 11, 32465, 17779, 11, 33894, 11, 3224, 11, 7471, 11, 1567, 11, 7061, 11, 3813, 323, 507, 627, 85664, 25, 578, 33894, 374, 24116, 555, 48749, 78160, 2025, 304, 11355, 58374, 364, 274, 220, 9378, 20, 11775, 1174, 62734, 279, 51541, 66, 554, 323, 1101, 555, 22653, 14937, 22464, 5721, 304, 14337, 386, 40197, 662, 14337, 364, 274, 578, 7839, 53529, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "98", "dataset": "crossner_science", "split": "dev", "prediction": "It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O),(O) by(O) Ingrid(B-scientist) van(I-scientist) Houten-I-scientist) and(O) Cornelis(B-scientist) van(I-scientist) Houten-I-scientist) at(O) Leiden(B-location),(O) and(O) Tom(B-scientist) Gehrels(I-scientist) at(O) Palomar(B-location) Observatory(I-location) in(O) California(O).(O)", "instance": {"id": "98", "words": ["It", "was", "discovered", "on", "24", "September", "1960", ",", "by", "Ingrid", "van", "Houten-Groeneveld", "and", "Cornelis", "van", "Houten", "at", "Leiden", ",", "and", "Tom", "Gehrels", "at", "Palomar", "Observatory", "in", "California", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-scientist", "I-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "I-scientist", "O", "B-location", "O", "O", "B-scientist", "I-scientist", "O", "B-location", "I-location", "O", "B-location", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, enzyme, discipline, astronomical object, scientist, academic journal, chemical compound, chemical element, person, location, theory, country, event, university, award, protein and O.\nSentence: It was discovered on 24 September 1960 , by Ingrid van Houten-Groeneveld and Cornelis van Houten at Leiden , and Tom Gehrels at Palomar Observatory in California .", "prompt_labels": "It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O) ,(O) by(O) Ingrid(B-scientist) van(I-scientist) Houten-Groeneveld(I-scientist) and(O) Cornelis(B-scientist) van(I-scientist) Houten(I-scientist) at(O) Leiden(B-location) ,(O) and(O) Tom(B-scientist) Gehrels(I-scientist) at(O) Palomar(B-location) Observatory(I-location) in(O) California(B-location) .(O)"}, "label_list": ["organization", "enzyme", "discipline", "astronomical object", "scientist", "academic journal", "chemical compound", "chemical element", "person", "location", "theory", "country", "event", "university", "award", "protein"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 49242, 11, 26434, 11, 87283, 1665, 11, 28568, 11, 14584, 8486, 11, 11742, 24549, 11, 11742, 2449, 11, 1732, 11, 3813, 11, 10334, 11, 3224, 11, 1567, 11, 12374, 11, 10292, 11, 13128, 323, 507, 627, 85664, 25, 1102, 574, 11352, 389, 220, 1187, 6250, 220, 5162, 15, 1174, 555, 763, 4297, 5355, 473, 412, 268, 12279, 299, 1994, 85, 789, 323, 99045, 285, 5355, 473, 412, 268, 520, 2009, 12770, 1174, 323, 8529, 74680, 54883, 520, 11165, 316, 277, 58974, 304, 7188, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "186", "dataset": "crossner_science", "split": "dev", "prediction": "He(O) was(O) awarded(O) honorary(O) doctorate(O) degrees(O) by(O) Princeton(B-university) University(I-university) ((O) 1958(O) )(O),(O) Moscow(B-university) State(I-university) University(I-university) ((O) 1992(O) )(O),(O) and(O) the(O) Chinese(B-university) University(I-university) of(I-university) Hong(I-university) Kong(I-university) ((O) 1997(O) )(O).(O)", "instance": {"id": "186", "words": ["He", "was", "awarded", "honorary", "doctorate", "degrees", "by", "Princeton", "University", "(", "1958", ")", ",", "Moscow", "State", "University", "(", "1992", ")", ",", "and", "the", "Chinese", "University", "of", "Hong", "Kong", "(", "1997", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-university", "I-university", "O", "O", "O", "O", "B-university", "I-university", "I-university", "O", "O", "O", "O", "O", "O", "B-university", "I-university", "I-university", "I-university", "I-university", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: protein, university, enzyme, event, astronomical object, chemical compound, country, academic journal, discipline, person, award, scientist, location, chemical element, organization, theory and O.\nSentence: He was awarded honorary doctorate degrees by Princeton University ( 1958 ) , Moscow State University ( 1992 ) , and the Chinese University of Hong Kong ( 1997 ) .", "prompt_labels": "He(O) was(O) awarded(O) honorary(O) doctorate(O) degrees(O) by(O) Princeton(B-university) University(I-university) ((O) 1958(O) )(O) ,(O) Moscow(B-university) State(I-university) University(I-university) ((O) 1992(O) )(O) ,(O) and(O) the(O) Chinese(B-university) University(I-university) of(I-university) Hong(I-university) Kong(I-university) ((O) 1997(O) )(O) .(O)"}, "label_list": ["protein", "university", "enzyme", "event", "astronomical object", "chemical compound", "country", "academic journal", "discipline", "person", "award", "scientist", "location", "chemical element", "organization", "theory"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 13128, 11, 12374, 11, 49242, 11, 1567, 11, 87283, 1665, 11, 11742, 24549, 11, 3224, 11, 14584, 8486, 11, 26434, 11, 1732, 11, 10292, 11, 28568, 11, 3813, 11, 11742, 2449, 11, 7471, 11, 10334, 323, 507, 627, 85664, 25, 1283, 574, 22034, 99119, 10896, 349, 12628, 555, 50421, 3907, 320, 220, 6280, 23, 883, 1174, 23223, 3314, 3907, 320, 220, 2550, 17, 883, 1174, 323, 279, 8620, 3907, 315, 19730, 18711, 320, 220, 2550, 22, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "7", "dataset": "mit-movie", "split": "dev", "prediction": "can(O) you(O) get(O) a(O) soundtrac(B-trailer) for(O) the(O) harry(B-title) potter(I-title) films(O)", "instance": {"id": "7", "words": ["can", "you", "get", "a", "soundtrac", "for", "the", "harry", "potter", "films"], "labels": ["O", "O", "O", "O", "B-song", "O", "O", "B-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, director, average ratings, genre, year, song, rating, title, review, plot, trailer, actor and O.\nSentence: can you get a soundtrac for the harry potter films", "prompt_labels": "can(O) you(O) get(O) a(O) soundtrac(B-song) for(O) the(O) harry(B-title) potter(I-title) films(I-title)"}, "label_list": ["character", "director", "average ratings", "genre", "year", "song", "rating", "title", "review", "plot", "trailer", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 7690, 11, 5578, 18594, 11, 17779, 11, 1060, 11, 5609, 11, 10959, 11, 2316, 11, 3477, 11, 7234, 11, 19809, 11, 12360, 323, 507, 627, 85664, 25, 649, 499, 636, 264, 5222, 376, 582, 369, 279, 4960, 894, 3419, 466, 12631, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "425", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) said(O) asta(B-title) la(I-title) vista(I-title) baby(I-title)", "instance": {"id": "425", "words": ["who", "said", "asta", "la", "vista", "baby"], "labels": ["O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, review, director, year, trailer, genre, character, plot, average ratings, title, rating, song and O.\nSentence: who said asta la vista baby", "prompt_labels": "who(O) said(O) asta(O) la(O) vista(O) baby(O)"}, "label_list": ["actor", "review", "director", "year", "trailer", "genre", "character", "plot", "average ratings", "title", "rating", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 3477, 11, 7690, 11, 1060, 11, 19809, 11, 17779, 11, 3752, 11, 7234, 11, 5578, 18594, 11, 2316, 11, 10959, 11, 5609, 323, 507, 627, 85664, 25, 889, 1071, 12025, 64, 1208, 40136, 8945, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "64", "dataset": "crossner_literature", "split": "dev", "prediction": "Among(O) his(O) childhood(O) favorites(O) were(O) Charles(B-writer) Dickens(I-writer),(O) Tobias(B-writer) Smollett(I-writer),(O) Mark(B-writer) Twain(I-writer),(O) Booth(B-writer) Tarkington(I-writer),(O) and(O) later(O),(O) Robert(B-writer) Benchley(I-writer) and(O) S.(I-writer) J.(I-writer) Perelman(I-writer).(O)", "instance": {"id": "64", "words": ["Among", "his", "childhood", "favorites", "were", "Charles", "Dickens", ",", "Tobias", "Smollett", ",", "Mark", "Twain", ",", "Booth", "Tarkington", ",", "and", "later", ",", "Robert", "Benchley", "and", "S.", "J.", "Perelman", "."], "labels": ["O", "O", "O", "O", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "O", "O", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "I-writer", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: poem, event, literary genre, country, organization, location, writer, magazine, person, book, award and O.\nSentence: Among his childhood favorites were Charles Dickens , Tobias Smollett , Mark Twain , Booth Tarkington , and later , Robert Benchley and S. J. Perelman .", "prompt_labels": "Among(O) his(O) childhood(O) favorites(O) were(O) Charles(B-writer) Dickens(I-writer) ,(O) Tobias(B-writer) Smollett(I-writer) ,(O) Mark(B-writer) Twain(I-writer) ,(O) Booth(B-writer) Tarkington(I-writer) ,(O) and(O) later(O) ,(O) Robert(B-writer) Benchley(I-writer) and(O) S.(B-writer) J.(I-writer) Perelman(I-writer) .(O)"}, "label_list": ["poem", "event", "literary genre", "country", "organization", "location", "writer", "magazine", "person", "book", "award"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 33894, 11, 1567, 11, 32465, 17779, 11, 3224, 11, 7471, 11, 3813, 11, 7061, 11, 14756, 11, 1732, 11, 2363, 11, 10292, 323, 507, 627, 85664, 25, 22395, 813, 20587, 27672, 1051, 15274, 93999, 1174, 80102, 4487, 337, 28163, 1174, 4488, 12015, 467, 1174, 64370, 350, 847, 4910, 1174, 323, 3010, 1174, 8563, 36358, 3258, 323, 328, 13, 622, 13, 3700, 64641, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "853", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) a(O) rancho(B-Restaurant Name) veo(I-Restaurant Name) restaurant(O) in(O) north(B-Location) memphis(I-Location)", "instance": {"id": "853", "words": ["is", "there", "a", "rancho", "veo", "restaurant", "in", "north", "memphis"], "labels": ["O", "O", "O", "B-Restaurant Name", "I-Restaurant Name", "O", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Location, Price, Restaurant Name, Rating, Amenity, Dish, Cuisine and O.\nSentence: is there a rancho veo restaurant in north memphis", "prompt_labels": "is(O) there(O) a(O) rancho(B-Restaurant Name) veo(I-Restaurant Name) restaurant(O) in(O) north(B-Location) memphis(I-Location)"}, "label_list": ["Hours", "Location", "Price", "Restaurant Name", "Rating", "Amenity", "Dish", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 10067, 11, 8650, 11, 26568, 4076, 11, 19767, 11, 3383, 56685, 11, 49268, 11, 81961, 323, 507, 627, 85664, 25, 374, 1070, 264, 10837, 971, 5320, 78, 10960, 304, 10411, 1871, 37889, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "169", "dataset": "crossner_literature", "split": "dev", "prediction": "It(O) is(O) based(O) on(O) H.(person) P.(person) Lovecraft(B-writer) '(O) s(O) Cthulhu(B-plot) Mythos(I-plot),(O) particularly(O) At(O) the(O) Mountains(O) of(O) Madness(O),(O) and(O) is(O) a(O) follow-up(O) to(O) Infogrames(B-organization)'s(O) earlier(O) Shadow(O) of(O) the(O) Comet(O).(O)", "instance": {"id": "169", "words": ["It", "is", "based", "on", "H.", "P.", "Lovecraft", "'", "s", "Cthulhu", "Mythos", ",", "particularly", "At", "the", "Mountains", "of", "Madness", ",", "and", "is", "a", "follow-up", "to", "Infogrames", "'", "earlier", "Shadow", "of", "the", "Comet", "."], "labels": ["O", "O", "O", "O", "B-writer", "I-writer", "I-writer", "O", "O", "O", "O", "O", "O", "B-book", "I-book", "I-book", "I-book", "I-book", "O", "O", "O", "O", "O", "O", "B-organization", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: writer, location, book, poem, literary genre, person, organization, country, award, event, magazine and O.\nSentence: It is based on H. P. Lovecraft ' s Cthulhu Mythos , particularly At the Mountains of Madness , and is a follow-up to Infogrames ' earlier Shadow of the Comet .", "prompt_labels": "It(O) is(O) based(O) on(O) H.(B-writer) P.(I-writer) Lovecraft(I-writer) '(O) s(O) Cthulhu(O) Mythos(O) ,(O) particularly(O) At(B-book) the(I-book) Mountains(I-book) of(I-book) Madness(I-book) ,(O) and(O) is(O) a(O) follow-up(O) to(O) Infogrames(B-organization) '(O) earlier(O) Shadow(O) of(O) the(O) Comet(O) .(O)"}, "label_list": ["writer", "location", "book", "poem", "literary genre", "person", "organization", "country", "award", "event", "magazine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7061, 11, 3813, 11, 2363, 11, 33894, 11, 32465, 17779, 11, 1732, 11, 7471, 11, 3224, 11, 10292, 11, 1567, 11, 14756, 323, 507, 627, 85664, 25, 1102, 374, 3196, 389, 473, 13, 393, 13, 10919, 7868, 364, 274, 356, 339, 360, 17156, 47595, 437, 1174, 8104, 2468, 279, 41114, 315, 71428, 1174, 323, 374, 264, 1833, 5352, 311, 15268, 540, 15988, 364, 6931, 25284, 315, 279, 99198, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "301", "dataset": "crossner_music", "split": "dev", "prediction": "He(O) was(O) the(O) direct(O) inspiration(O) for(O) three(O) Beatles(B-musical artist)'songs(O) :(O) Lucy(B-song) in(I-song) the(I-song) Sky(I-song) with(I-song) Diamonds(I-song) ((O) 1967(O) )(O),(O) Hey(B-song) Jude(I-song) ((O) 1968(O) )(O),(O) and(O) Good(B-song) Night(I-song) ((O) 1968(O) )(O).(O)", "instance": {"id": "301", "words": ["He", "was", "the", "direct", "inspiration", "for", "three", "Beatles", "'", "songs", ":", "Lucy", "in", "the", "Sky", "with", "Diamonds", "(", "1967", ")", ",", "Hey", "Jude", "(", "1968", ")", ",", "and", "Good", "Night", "(", "1968", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-band", "O", "O", "O", "B-song", "I-song", "I-song", "I-song", "I-song", "I-song", "O", "O", "O", "O", "B-song", "I-song", "O", "O", "O", "O", "O", "B-song", "I-song", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, person, award, album, musical artist, location, event, country, band, song, music genre, musical instrument and O.\nSentence: He was the direct inspiration for three Beatles ' songs : Lucy in the Sky with Diamonds ( 1967 ) , Hey Jude ( 1968 ) , and Good Night ( 1968 ) .", "prompt_labels": "He(O) was(O) the(O) direct(O) inspiration(O) for(O) three(O) Beatles(B-band) '(O) songs(O) :(O) Lucy(B-song) in(I-song) the(I-song) Sky(I-song) with(I-song) Diamonds(I-song) ((O) 1967(O) )(O) ,(O) Hey(B-song) Jude(I-song) ((O) 1968(O) )(O) ,(O) and(O) Good(B-song) Night(I-song) ((O) 1968(O) )(O) .(O)"}, "label_list": ["organization", "person", "award", "album", "musical artist", "location", "event", "country", "band", "song", "music genre", "musical instrument"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 1732, 11, 10292, 11, 8176, 11, 18273, 10255, 11, 3813, 11, 1567, 11, 3224, 11, 7200, 11, 5609, 11, 4731, 17779, 11, 18273, 14473, 323, 507, 627, 85664, 25, 1283, 574, 279, 2167, 20343, 369, 2380, 55957, 364, 11936, 551, 45170, 304, 279, 15064, 449, 91210, 320, 220, 5162, 22, 883, 1174, 28653, 62734, 320, 220, 5162, 23, 883, 1174, 323, 7839, 13120, 320, 220, 5162, 23, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "80", "dataset": "crossner_politics", "split": "dev", "prediction": "In(O) 1997(B-election) Canadian(I-election) federal(I-election) election(O) and(O) again(O) in(O) 2000(B-election) Canadian(I-election) federal(I-election) election(O) Timbrell(B-politician) campaigned(O) for(O) a(O) seat(O) in(O) the(O) House(O) of(O) Commons(O) of(O) Canada(O) as(O) the(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) of(I-political party) Canada(I-political party) candidate(O) in(O) the(O) eastern(O) Ontario(O) riding(O) of(O) Prince(B-location) Edward(I-location) -(I-location) Hastings(I-location) In(O) the(O) 1997(B-election) federal(I-election) election(O),(O) Timbrell(O) placed(O) second(O) to(O) Liberal(O) Lyle(B-politician) Vanclief(I-politician),(O) with(O) 21.5(O) %(O) of(O) the(O) vote(O).(O)", "instance": {"id": "80", "words": ["In", "1997", "Canadian", "federal", "election", "and", "again", "in", "2000", "Canadian", "federal", "election", "Timbrell", "campaigned", "for", "a", "seat", "in", "the", "House", "of", "Commons", "of", "Canada", "as", "the", "Progressive", "Conservative", "Party", "of", "Canada", "candidate", "in", "the", "eastern", "Ontario", "riding", "of", "Prince", "Edward", "-", "Hastings", "In", "the", "1997", "federal", "election", ",", "Timbrell", "placed", "second", "to", "Liberal", "Lyle", "Vanclief", ",", "with", "21.5", "%", "of", "the", "vote", "."], "labels": ["O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "B-politician", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "I-location", "I-location", "O", "O", "O", "O", "O", "O", "B-politician", "O", "O", "O", "O", "B-politician", "I-politician", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, country, political party, politician, person, location, event, election and O.\nSentence: In 1997 Canadian federal election and again in 2000 Canadian federal election Timbrell campaigned for a seat in the House of Commons of Canada as the Progressive Conservative Party of Canada candidate in the eastern Ontario riding of Prince Edward - Hastings In the 1997 federal election , Timbrell placed second to Liberal Lyle Vanclief , with 21.5 % of the vote .", "prompt_labels": "In(O) 1997(B-election) Canadian(I-election) federal(I-election) election(I-election) and(O) again(O) in(O) 2000(B-election) Canadian(I-election) federal(I-election) election(I-election) Timbrell(B-politician) campaigned(O) for(O) a(O) seat(O) in(O) the(O) House(B-organization) of(I-organization) Commons(I-organization) of(I-organization) Canada(I-organization) as(O) the(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) of(I-political party) Canada(I-political party) candidate(O) in(O) the(O) eastern(O) Ontario(O) riding(O) of(O) Prince(B-location) Edward(I-location) -(I-location) Hastings(I-location) In(O) the(O) 1997(O) federal(O) election(O) ,(O) Timbrell(B-politician) placed(O) second(O) to(O) Liberal(O) Lyle(B-politician) Vanclief(I-politician) ,(O) with(O) 21.5(O) %(O) of(O) the(O) vote(O) .(O)"}, "label_list": ["organization", "country", "political party", "politician", "person", "location", "event", "election"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 3224, 11, 5054, 4717, 11, 37038, 11, 1732, 11, 3813, 11, 1567, 11, 6355, 323, 507, 627, 85664, 25, 763, 220, 2550, 22, 12152, 6918, 6355, 323, 1578, 304, 220, 1049, 15, 12152, 6918, 6355, 9538, 65, 16684, 87296, 369, 264, 10954, 304, 279, 4783, 315, 26667, 315, 7008, 439, 279, 52870, 30071, 8722, 315, 7008, 9322, 304, 279, 24024, 21193, 20427, 315, 19912, 22653, 482, 79844, 763, 279, 220, 2550, 22, 6918, 6355, 1174, 9538, 65, 16684, 9277, 2132, 311, 31158, 445, 982, 13000, 566, 4843, 1174, 449, 220, 1691, 13, 20, 1034, 315, 279, 7055, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "254", "dataset": "crossner_music", "split": "dev", "prediction": "He(O) is(O) the(O) only(O) person(O) ever(O) to(O) have(O) won(O) Academy(B-award) Awards(I-award),(O) Emmy(B-award) Award(I-award),(O) and(O) Tony(B-award) Award(I-award) awards(O) in(O) the(O) same(O) year(O) ((O) 1973(O) )(O).(O)", "instance": {"id": "254", "words": ["He", "is", "the", "only", "person", "ever", "to", "have", "won", "Academy", "Awards", ",", "Emmy", "Award", ",", "and", "Tony", "Award", "awards", "in", "the", "same", "year", "(", "1973", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "O", "B-award", "I-award", "O", "O", "B-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, music genre, album, person, musical artist, band, location, country, event, organization, award, musical instrument and O.\nSentence: He is the only person ever to have won Academy Awards , Emmy Award , and Tony Award awards in the same year ( 1973 ) .", "prompt_labels": "He(O) is(O) the(O) only(O) person(O) ever(O) to(O) have(O) won(O) Academy(B-award) Awards(I-award) ,(O) Emmy(B-award) Award(I-award) ,(O) and(O) Tony(B-award) Award(I-award) awards(O) in(O) the(O) same(O) year(O) ((O) 1973(O) )(O) .(O)"}, "label_list": ["song", "music genre", "album", "person", "musical artist", "band", "location", "country", "event", "organization", "award", "musical instrument"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 4731, 17779, 11, 8176, 11, 1732, 11, 18273, 10255, 11, 7200, 11, 3813, 11, 3224, 11, 1567, 11, 7471, 11, 10292, 11, 18273, 14473, 323, 507, 627, 85664, 25, 1283, 374, 279, 1193, 1732, 3596, 311, 617, 2834, 16192, 23488, 1174, 67112, 17768, 1174, 323, 19036, 17768, 23146, 304, 279, 1890, 1060, 320, 220, 4468, 18, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "10", "dataset": "crossner_science", "split": "dev", "prediction": "He(O) is(O) currently(O) Director(O) of(O) the(O) Yale(B-organization) Center(I-organization) for(I-organization) the(I-organization) Study(I-organization) of(I-organization) Globalization(I-organization) at(O) Yale(B-university) University(I-university),(O) is(O) the(O) Latin(B-organization) American(I-organization) co-chair(I-organization) of(I-organization) the(I-organization) Inter-American(I-organization) Dialogue(I-organization),(O) and(O) is(O) on(O) the(O) board(O) of(O) directors(O) of(O) Citigroup(B-organization).(O)", "instance": {"id": "10", "words": ["He", "is", "currently", "Director", "of", "the", "Yale", "Center", "for", "the", "Study", "of", "Globalization", "at", "Yale", "University", ",", "is", "the", "Latin", "American", "co-chair", "of", "the", "Inter-American", "Dialogue", ",", "and", "is", "on", "the", "board", "of", "directors", "of", "Citigroup", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "B-university", "I-university", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, location, protein, event, organization, theory, country, scientist, award, enzyme, discipline, chemical element, person, university, academic journal, astronomical object and O.\nSentence: He is currently Director of the Yale Center for the Study of Globalization at Yale University , is the Latin American co-chair of the Inter-American Dialogue , and is on the board of directors of Citigroup .", "prompt_labels": "He(O) is(O) currently(O) Director(O) of(O) the(O) Yale(B-organization) Center(I-organization) for(I-organization) the(I-organization) Study(I-organization) of(I-organization) Globalization(I-organization) at(O) Yale(B-university) University(I-university) ,(O) is(O) the(O) Latin(O) American(O) co-chair(O) of(O) the(O) Inter-American(B-organization) Dialogue(I-organization) ,(O) and(O) is(O) on(O) the(O) board(O) of(O) directors(O) of(O) Citigroup(B-organization) .(O)"}, "label_list": ["chemical compound", "location", "protein", "event", "organization", "theory", "country", "scientist", "award", "enzyme", "discipline", "chemical element", "person", "university", "academic journal", "astronomical object"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 11742, 24549, 11, 3813, 11, 13128, 11, 1567, 11, 7471, 11, 10334, 11, 3224, 11, 28568, 11, 10292, 11, 49242, 11, 26434, 11, 11742, 2449, 11, 1732, 11, 12374, 11, 14584, 8486, 11, 87283, 1665, 323, 507, 627, 85664, 25, 1283, 374, 5131, 10783, 315, 279, 44552, 5955, 369, 279, 19723, 315, 8121, 2065, 520, 44552, 3907, 1174, 374, 279, 20023, 3778, 1080, 79781, 315, 279, 5783, 24145, 70589, 1174, 323, 374, 389, 279, 4580, 315, 28454, 315, 18002, 75758, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2136", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movie(O) does(O) kenneth(B-actor) branagh(I-actor) star(O) in(O) that(O) was(O) made(O) in(O) the(O) 1940(B-year) s(I-year) with(O) a(O) megacorporation(B-plot) plot(O) that(O) was(O) liked(B-average ratings) by(I-average ratings) many(I-average ratings)", "instance": {"id": "2136", "words": ["what", "movie", "does", "kenneth", "branagh", "star", "in", "that", "was", "made", "in", "the", "1940", "s", "with", "a", "megacorporation", "plot", "that", "was", "liked", "by", "many"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O", "O", "O", "O", "O", "O", "O", "B-year", "I-year", "O", "O", "B-plot", "O", "O", "O", "B-average ratings", "I-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, trailer, character, year, actor, review, average ratings, plot, song, title, genre, director and O.\nSentence: what movie does kenneth branagh star in that was made in the 1940 s with a megacorporation plot that was liked by many", "prompt_labels": "what(O) movie(O) does(O) kenneth(B-actor) branagh(I-actor) star(O) in(O) that(O) was(O) made(O) in(O) the(O) 1940(B-year) s(I-year) with(O) a(O) megacorporation(B-plot) plot(O) that(O) was(O) liked(B-average ratings) by(I-average ratings) many(I-average ratings)"}, "label_list": ["rating", "trailer", "character", "year", "actor", "review", "average ratings", "plot", "song", "title", "genre", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 19809, 11, 3752, 11, 1060, 11, 12360, 11, 3477, 11, 5578, 18594, 11, 7234, 11, 5609, 11, 2316, 11, 17779, 11, 7690, 323, 507, 627, 85664, 25, 1148, 5818, 1587, 75361, 774, 53358, 34856, 6917, 304, 430, 574, 1903, 304, 279, 220, 6393, 15, 274, 449, 264, 19262, 582, 39382, 367, 7234, 430, 574, 15262, 555, 1690, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1987", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) wall(B-title) e(I-title) about(O)", "instance": {"id": "1987", "words": ["what", "is", "wall", "e", "about"], "labels": ["O", "O", "B-title", "I-title", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, average ratings, plot, character, review, director, genre, actor, year, rating, title, trailer and O.\nSentence: what is wall e about", "prompt_labels": "what(O) is(O) wall(B-title) e(I-title) about(O)"}, "label_list": ["song", "average ratings", "plot", "character", "review", "director", "genre", "actor", "year", "rating", "title", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 5578, 18594, 11, 7234, 11, 3752, 11, 3477, 11, 7690, 11, 17779, 11, 12360, 11, 1060, 11, 10959, 11, 2316, 11, 19809, 323, 507, 627, 85664, 25, 1148, 374, 7147, 384, 922, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "34", "dataset": "crossner_science", "split": "dev", "prediction": "Helicase(O) s(O) unwind(O) the(O) strands(O) to(O) facilitate(O) the(O) advance(O) of(O) sequence-reading(O) enzymes(O) such(O) as(O) DNA(O) polymerase(O).(O)", "instance": {"id": "34", "words": ["Helicase", "s", "unwind", "the", "strands", "to", "facilitate", "the", "advance", "of", "sequence-reading", "enzymes", "such", "as", "DNA", "polymerase", "."], "labels": ["B-enzyme", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-enzyme", "I-enzyme", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, country, event, person, scientist, organization, location, academic journal, discipline, university, theory, protein, astronomical object, chemical element, enzyme, award and O.\nSentence: Helicase s unwind the strands to facilitate the advance of sequence-reading enzymes such as DNA polymerase .", "prompt_labels": "Helicase(B-enzyme) s(O) unwind(O) the(O) strands(O) to(O) facilitate(O) the(O) advance(O) of(O) sequence-reading(O) enzymes(O) such(O) as(O) DNA(B-enzyme) polymerase(I-enzyme) .(O)"}, "label_list": ["chemical compound", "country", "event", "person", "scientist", "organization", "location", "academic journal", "discipline", "university", "theory", "protein", "astronomical object", "chemical element", "enzyme", "award"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 11742, 24549, 11, 3224, 11, 1567, 11, 1732, 11, 28568, 11, 7471, 11, 3813, 11, 14584, 8486, 11, 26434, 11, 12374, 11, 10334, 11, 13128, 11, 87283, 1665, 11, 11742, 2449, 11, 49242, 11, 10292, 323, 507, 627, 85664, 25, 16183, 292, 521, 274, 82610, 279, 69864, 311, 28696, 279, 12178, 315, 8668, 12, 6285, 56067, 1778, 439, 15922, 47393, 521, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "76", "dataset": "crossner_music", "split": "dev", "prediction": "It(O) comprises(O) the(O) music(O) of(O) Bosnia(B-country) and(I-country) Herzegovina(I-country),(O) Bulgaria(B-country),(O) Croatia(B-country),(O) Music(O) of(O) Greece(B-country),(O) Montenegro(B-country),(O) Serbia(B-country),(O) Romania(B-country),(O) Republic(B-country) of(I-country) Macedonia(I-country),(O) Albania(B-country),(O) some(O) of(O) the(O) historical(O) states(O) of(O) Yugoslavia(B-organization) or(O) the(O) State(O) Union(O) of(O) Serbia(B-country) and(I-country) Montenegro(I-country) and(O) geographical(O) regions(O) such(O) as(O) Thrace(B-organization).(O)", "instance": {"id": "76", "words": ["It", "comprises", "the", "music", "of", "Bosnia", "and", "Herzegovina", ",", "Bulgaria", ",", "Croatia", ",", "Music", "of", "Greece", ",", "Montenegro", ",", "Serbia", ",", "Romania", ",", "Republic", "of", "Macedonia", ",", "Albania", ",", "some", "of", "the", "historical", "states", "of", "Yugoslavia", "or", "the", "State", "Union", "of", "Serbia", "and", "Montenegro", "and", "geographical", "regions", "such", "as", "Thrace", "."], "labels": ["O", "O", "O", "B-music genre", "I-music genre", "I-music genre", "I-music genre", "I-music genre", "O", "B-country", "O", "B-country", "O", "B-music genre", "I-music genre", "I-music genre", "O", "B-country", "O", "B-country", "O", "B-country", "O", "B-country", "I-country", "I-country", "O", "B-country", "O", "O", "O", "O", "O", "O", "O", "B-country", "O", "O", "B-country", "I-country", "I-country", "I-country", "I-country", "I-country", "O", "O", "O", "O", "O", "B-location", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, award, country, organization, musical artist, song, musical instrument, album, music genre, location, band, person and O.\nSentence: It comprises the music of Bosnia and Herzegovina , Bulgaria , Croatia , Music of Greece , Montenegro , Serbia , Romania , Republic of Macedonia , Albania , some of the historical states of Yugoslavia or the State Union of Serbia and Montenegro and geographical regions such as Thrace .", "prompt_labels": "It(O) comprises(O) the(O) music(B-music genre) of(I-music genre) Bosnia(I-music genre) and(I-music genre) Herzegovina(I-music genre) ,(O) Bulgaria(B-country) ,(O) Croatia(B-country) ,(O) Music(B-music genre) of(I-music genre) Greece(I-music genre) ,(O) Montenegro(B-country) ,(O) Serbia(B-country) ,(O) Romania(B-country) ,(O) Republic(B-country) of(I-country) Macedonia(I-country) ,(O) Albania(B-country) ,(O) some(O) of(O) the(O) historical(O) states(O) of(O) Yugoslavia(B-country) or(O) the(O) State(B-country) Union(I-country) of(I-country) Serbia(I-country) and(I-country) Montenegro(I-country) and(O) geographical(O) regions(O) such(O) as(O) Thrace(B-location) .(O)"}, "label_list": ["event", "award", "country", "organization", "musical artist", "song", "musical instrument", "album", "music genre", "location", "band", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 10292, 11, 3224, 11, 7471, 11, 18273, 10255, 11, 5609, 11, 18273, 14473, 11, 8176, 11, 4731, 17779, 11, 3813, 11, 7200, 11, 1732, 323, 507, 627, 85664, 25, 1102, 41095, 279, 4731, 315, 77428, 323, 53739, 75287, 2259, 1174, 59819, 1174, 58311, 1174, 10948, 315, 25431, 1174, 9995, 88921, 1174, 59814, 1174, 47149, 1174, 5545, 315, 77509, 1174, 95733, 1174, 1063, 315, 279, 13970, 5415, 315, 97877, 477, 279, 3314, 9323, 315, 59814, 323, 9995, 88921, 323, 54001, 13918, 1778, 439, 30665, 580, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "298", "dataset": "crossner_literature", "split": "dev", "prediction": "In(O) Vertigo(B-title) ((O) 1958(B-year) )(O) and(O) North(B-title) by(I-title) Northwest(I-title) ((O) 1959(B-year) )(O) respectively(O),(O) Kim(B-actor) Novak(I-actor) and(O) Eva(B-actor) Marie(I-actor) Saint(I-actor) play(O) the(O) blonde(O) heroines(O).(O)", "instance": {"id": "298", "words": ["In", "Vertigo", "(", "1958", ")", "and", "North", "by", "Northwest", "(", "1959", ")", "respectively", ",", "Kim", "Novak", "and", "Eva", "Marie", "Saint", "play", "the", "blonde", "heroines", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "B-person", "I-person", "I-person", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, person, magazine, country, poem, writer, organization, book, event, location, award and O.\nSentence: In Vertigo ( 1958 ) and North by Northwest ( 1959 ) respectively , Kim Novak and Eva Marie Saint play the blonde heroines .", "prompt_labels": "In(O) Vertigo(O) ((O) 1958(O) )(O) and(O) North(O) by(O) Northwest(O) ((O) 1959(O) )(O) respectively(O) ,(O) Kim(B-person) Novak(I-person) and(O) Eva(B-person) Marie(I-person) Saint(I-person) play(O) the(O) blonde(O) heroines(O) .(O)"}, "label_list": ["literary genre", "person", "magazine", "country", "poem", "writer", "organization", "book", "event", "location", "award"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 32465, 17779, 11, 1732, 11, 14756, 11, 3224, 11, 33894, 11, 7061, 11, 7471, 11, 2363, 11, 1567, 11, 3813, 11, 10292, 323, 507, 627, 85664, 25, 763, 15408, 7992, 320, 220, 6280, 23, 883, 323, 4892, 555, 40505, 320, 220, 6280, 24, 883, 15947, 1174, 13818, 4723, 587, 323, 55492, 33116, 14539, 1514, 279, 27117, 12084, 1572, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2112", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) rated(O) r(B-rating) movie(O) that(O) marleen(B-director) gorris(I-director) directed(O) with(O) the(O) emotional(B-genre) decision(I-genre) aspect(O) to(O) it(O) receiving(O) an(O) average(B-average ratings) rating(O)", "instance": {"id": "2112", "words": ["what", "is", "the", "rated", "r", "movie", "that", "marleen", "gorris", "directed", "with", "the", "emotional", "decision", "aspect", "to", "it", "receiving", "an", "average", "rating"], "labels": ["O", "O", "O", "O", "B-rating", "O", "O", "B-director", "I-director", "O", "O", "O", "B-genre", "B-plot", "O", "O", "O", "O", "O", "B-average ratings", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, genre, character, actor, year, song, plot, review, title, director, rating, average ratings and O.\nSentence: what is the rated r movie that marleen gorris directed with the emotional decision aspect to it receiving an average rating", "prompt_labels": "what(O) is(O) the(O) rated(O) r(B-rating) movie(O) that(O) marleen(B-director) gorris(I-director) directed(O) with(O) the(O) emotional(B-genre) decision(B-plot) aspect(O) to(O) it(O) receiving(O) an(O) average(B-average ratings) rating(O)"}, "label_list": ["trailer", "genre", "character", "actor", "year", "song", "plot", "review", "title", "director", "rating", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 17779, 11, 3752, 11, 12360, 11, 1060, 11, 5609, 11, 7234, 11, 3477, 11, 2316, 11, 7690, 11, 10959, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1148, 374, 279, 22359, 436, 5818, 430, 3678, 40762, 46298, 6091, 15910, 449, 279, 14604, 5597, 13189, 311, 433, 12588, 459, 5578, 10959, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "47", "dataset": "crossner_literature", "split": "dev", "prediction": "In(O) March(O) 2020(O),(O) a(O) third(O) season(O) of(O) Cosmos(B-book) named(O) Cosmos(B-book) :Possible(I-book) Worlds(I-book),(O) for(O) which(O) Druyan(O) was(O) executive(O) producer(O),(O) writer(O),(O) and(O) director(O) premiered(O) on(O) National(B-location) Geographic(I-location).(O)", "instance": {"id": "47", "words": ["In", "March", "2020", ",", "a", "third", "season", "of", "Cosmos", "named", "Cosmos", ":", "Possible", "Worlds", ",", "for", "which", "Druyan", "was", "executive", "producer", ",", "writer", ",", "and", "director", "premiered", "on", "National", "Geographic", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-writer", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-magazine", "I-magazine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: book, person, location, organization, magazine, award, literary genre, country, writer, poem, event and O.\nSentence: In March 2020 , a third season of Cosmos named Cosmos : Possible Worlds , for which Druyan was executive producer , writer , and director premiered on National Geographic .", "prompt_labels": "In(O) March(O) 2020(O) ,(O) a(O) third(O) season(O) of(O) Cosmos(O) named(O) Cosmos(O) :(O) Possible(O) Worlds(O) ,(O) for(O) which(O) Druyan(B-writer) was(O) executive(O) producer(O) ,(O) writer(O) ,(O) and(O) director(O) premiered(O) on(O) National(B-magazine) Geographic(I-magazine) .(O)"}, "label_list": ["book", "person", "location", "organization", "magazine", "award", "literary genre", "country", "writer", "poem", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2363, 11, 1732, 11, 3813, 11, 7471, 11, 14756, 11, 10292, 11, 32465, 17779, 11, 3224, 11, 7061, 11, 33894, 11, 1567, 323, 507, 627, 85664, 25, 763, 5587, 220, 2366, 15, 1174, 264, 4948, 3280, 315, 84524, 7086, 84524, 551, 37207, 52947, 1174, 369, 902, 423, 2739, 8503, 574, 11145, 17276, 1174, 7061, 1174, 323, 7690, 85170, 389, 5165, 66542, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1469", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) there(O) a(O) animation(B-genre) pg(B-rating) 13(I-rating) movie(O) with(O) trisha(B-actor) romance(B-genre)", "instance": {"id": "1469", "words": ["is", "there", "a", "animation", "pg", "13", "movie", "with", "trisha", "romance"], "labels": ["O", "O", "O", "B-genre", "B-rating", "I-rating", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, title, rating, director, character, year, review, average ratings, actor, plot, genre, song and O.\nSentence: is there a animation pg 13 movie with trisha romance", "prompt_labels": "is(O) there(O) a(O) animation(B-genre) pg(B-rating) 13(I-rating) movie(O) with(O) trisha(B-actor) romance(I-actor)"}, "label_list": ["trailer", "title", "rating", "director", "character", "year", "review", "average ratings", "actor", "plot", "genre", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 2316, 11, 10959, 11, 7690, 11, 3752, 11, 1060, 11, 3477, 11, 5578, 18594, 11, 12360, 11, 7234, 11, 17779, 11, 5609, 323, 507, 627, 85664, 25, 374, 1070, 264, 10571, 17953, 220, 1032, 5818, 449, 490, 36040, 30363, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "208", "dataset": "crossner_music", "split": "dev", "prediction": "The(O) song(O)'s(O) popularity(O) resulted(O) in(O) its(O) being(O) covered(O) by(O) other(O) musicians(O),(O) such(O) as(O) The(B-musical artist) Disposable(I-musical artist) Heroes(I-musical artist) of(I-musical artist) Hiphoprisy(I-musical artist) ((O) who(O) rewrote(O) the(O) lyrics(O) to(O) parody(O) Pete(B-musical artist) Wilson(I-musical artist) )(O),(O) John(B-musical artist) Linnell(I-musical artist) of(O) They(B-musical artist) Might(I-musical artist) Be(I-musical artist) Giants(I-musical artist) and(O) Six(B-musical artist) Feet(I-musical artist) Under(I-musical artist) on(O) their(O) Graveyard(B-album) Classics(I-album) album(O) of(O) cover(O) versions(O).(O)", "instance": {"id": "208", "words": ["The", "song", "'s", "popularity", "resulted", "in", "its", "being", "covered", "by", "other", "musicians", ",", "such", "as", "The", "Disposable", "Heroes", "of", "Hiphoprisy", "(", "who", "rewrote", "the", "lyrics", "to", "parody", "Pete", "Wilson", ")", ",", "John", "Linnell", "of", "They", "Might", "Be", "Giants", "and", "Six", "Feet", "Under", "on", "their", "Graveyard", "Classics", "album", "of", "cover", "versions", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-band", "I-band", "I-band", "I-band", "I-band", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "O", "B-musical artist", "I-musical artist", "O", "B-band", "I-band", "I-band", "I-band", "O", "B-band", "I-band", "I-band", "O", "O", "B-album", "I-album", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, country, event, person, musical instrument, location, band, musical artist, award, music genre, album, organization and O.\nSentence: The song 's popularity resulted in its being covered by other musicians , such as The Disposable Heroes of Hiphoprisy ( who rewrote the lyrics to parody Pete Wilson ) , John Linnell of They Might Be Giants and Six Feet Under on their Graveyard Classics album of cover versions .", "prompt_labels": "The(O) song(O) 's(O) popularity(O) resulted(O) in(O) its(O) being(O) covered(O) by(O) other(O) musicians(O) ,(O) such(O) as(O) The(B-band) Disposable(I-band) Heroes(I-band) of(I-band) Hiphoprisy(I-band) ((O) who(O) rewrote(O) the(O) lyrics(O) to(O) parody(O) Pete(B-person) Wilson(I-person) )(O) ,(O) John(B-musical artist) Linnell(I-musical artist) of(O) They(B-band) Might(I-band) Be(I-band) Giants(I-band) and(O) Six(B-band) Feet(I-band) Under(I-band) on(O) their(O) Graveyard(B-album) Classics(I-album) album(O) of(O) cover(O) versions(O) .(O)"}, "label_list": ["song", "country", "event", "person", "musical instrument", "location", "band", "musical artist", "award", "music genre", "album", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 3224, 11, 1567, 11, 1732, 11, 18273, 14473, 11, 3813, 11, 7200, 11, 18273, 10255, 11, 10292, 11, 4731, 17779, 11, 8176, 11, 7471, 323, 507, 627, 85664, 25, 578, 5609, 364, 82, 23354, 19543, 304, 1202, 1694, 9960, 555, 1023, 32629, 1174, 1778, 439, 578, 52386, 38099, 315, 473, 15619, 454, 6091, 88, 320, 889, 79722, 5646, 279, 24142, 311, 67265, 37373, 17882, 883, 1174, 3842, 445, 6258, 616, 315, 2435, 34351, 2893, 30835, 323, 19198, 62289, 9636, 389, 872, 74842, 17884, 73415, 8176, 315, 3504, 11028, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1003", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) films(O) use(O) the(O) song(O) zippity(B-song) do(I-song) da(I-song)", "instance": {"id": "1003", "words": ["what", "films", "use", "the", "song", "zippity", "do", "da"], "labels": ["O", "O", "O", "O", "O", "B-song", "I-song", "I-song"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, plot, title, actor, trailer, song, director, year, character, review, genre, rating and O.\nSentence: what films use the song zippity do da", "prompt_labels": "what(O) films(O) use(O) the(O) song(O) zippity(B-song) do(I-song) da(I-song)"}, "label_list": ["average ratings", "plot", "title", "actor", "trailer", "song", "director", "year", "character", "review", "genre", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 7234, 11, 2316, 11, 12360, 11, 19809, 11, 5609, 11, 7690, 11, 1060, 11, 3752, 11, 3477, 11, 17779, 11, 10959, 323, 507, 627, 85664, 25, 1148, 12631, 1005, 279, 5609, 1167, 2877, 488, 656, 3067, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "370", "dataset": "crossner_literature", "split": "dev", "prediction": "Lawrence(B-writer) Hill(I-writer)'s(O) Book(O) of(O) Negroes(B-book) won(O) the(O) 2008(B-year) Commonwealth(I-year) Writers(I-year)'s(I-year) Prize(I-year) Overall(I-year) Best(I-year) Book(I-year) Award(I-year),(O) while(O) Alice(B-writer) Munro(I-writer) became(O) the(O) first(O) Canadian(O) to(O) win(O) the(O) Nobel(B-award) Prize(I-award) in(I-award) Literature(I-award) in(O) 2013(O).(O)", "instance": {"id": "370", "words": ["Lawrence", "Hill", "'", "s", "Book", "of", "Negroes", "won", "the", "2008", "Commonwealth", "Writers", "'", "Prize", "Overall", "Best", "Book", "Award", ",", "while", "Alice", "Munro", "became", "the", "first", "Canadian", "to", "win", "the", "Nobel", "Prize", "in", "Literature", "in", "2013", "."], "labels": ["B-writer", "I-writer", "O", "O", "B-book", "I-book", "I-book", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O", "O", "B-writer", "I-writer", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, book, writer, magazine, person, organization, country, event, award, poem, literary genre and O.\nSentence: Lawrence Hill ' s Book of Negroes won the 2008 Commonwealth Writers ' Prize Overall Best Book Award , while Alice Munro became the first Canadian to win the Nobel Prize in Literature in 2013 .", "prompt_labels": "Lawrence(B-writer) Hill(I-writer) '(O) s(O) Book(B-book) of(I-book) Negroes(I-book) won(O) the(O) 2008(O) Commonwealth(B-award) Writers(I-award) '(I-award) Prize(I-award) Overall(I-award) Best(I-award) Book(I-award) Award(I-award) ,(O) while(O) Alice(B-writer) Munro(I-writer) became(O) the(O) first(O) Canadian(O) to(O) win(O) the(O) Nobel(B-award) Prize(I-award) in(I-award) Literature(I-award) in(O) 2013(O) .(O)"}, "label_list": ["location", "book", "writer", "magazine", "person", "organization", "country", "event", "award", "poem", "literary genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 2363, 11, 7061, 11, 14756, 11, 1732, 11, 7471, 11, 3224, 11, 1567, 11, 10292, 11, 33894, 11, 32465, 17779, 323, 507, 627, 85664, 25, 28574, 8270, 364, 274, 6017, 315, 57147, 288, 2834, 279, 220, 1049, 23, 38298, 59798, 364, 32293, 28993, 7252, 6017, 17768, 1174, 1418, 30505, 28982, 299, 6244, 279, 1176, 12152, 311, 3243, 279, 48078, 32293, 304, 47470, 304, 220, 679, 18, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "317", "dataset": "crossner_literature", "split": "dev", "prediction": "The(O) Ghost(B-title) Writer(I-title),(O) a(O) thriller(B-genre) focusing(O) on(O) a(O) ghost(B-plot) writer(I-plot) working(O) on(O) the(O) memoirs(O) of(O) a(O) character(O) based(O) loosely(O) on(O) former(O) British(O) prime(O) minister(O) Tony(B-writer) Blair(I-writer),(O) swept(O) the(O) European(B-award) Film(I-award) Awards(I-award) in(O) 2010(O),(O) winning(O) six(O) awards(O),(O) including(O) best(O) movie(O),(O) director(O),(O) actor(O) and(O) screenplay(O).(O)", "instance": {"id": "317", "words": ["The", "Ghost", "Writer", ",", "a", "thriller", "focusing", "on", "a", "ghostwriter", "working", "on", "the", "memoirs", "of", "a", "character", "based", "loosely", "on", "former", "British", "prime", "minister", "Tony", "Blair", ",", "swept", "the", "European", "Film", "Awards", "in", "2010", ",", "winning", "six", "awards", ",", "including", "best", "movie", ",", "director", ",", "actor", "and", "screenplay", "."], "labels": ["B-book", "I-book", "I-book", "O", "O", "B-literary genre", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "O", "O", "B-award", "I-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, award, country, literary genre, writer, event, person, book, poem, location, magazine and O.\nSentence: The Ghost Writer , a thriller focusing on a ghostwriter working on the memoirs of a character based loosely on former British prime minister Tony Blair , swept the European Film Awards in 2010 , winning six awards , including best movie , director , actor and screenplay .", "prompt_labels": "The(B-book) Ghost(I-book) Writer(I-book) ,(O) a(O) thriller(B-literary genre) focusing(O) on(O) a(O) ghostwriter(O) working(O) on(O) the(O) memoirs(O) of(O) a(O) character(O) based(O) loosely(O) on(O) former(O) British(O) prime(O) minister(O) Tony(B-person) Blair(I-person) ,(O) swept(O) the(O) European(B-award) Film(I-award) Awards(I-award) in(O) 2010(O) ,(O) winning(O) six(O) awards(O) ,(O) including(O) best(O) movie(O) ,(O) director(O) ,(O) actor(O) and(O) screenplay(O) .(O)"}, "label_list": ["organization", "award", "country", "literary genre", "writer", "event", "person", "book", "poem", "location", "magazine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 10292, 11, 3224, 11, 32465, 17779, 11, 7061, 11, 1567, 11, 1732, 11, 2363, 11, 33894, 11, 3813, 11, 14756, 323, 507, 627, 85664, 25, 578, 26099, 30504, 1174, 264, 54461, 21760, 389, 264, 20457, 18688, 3318, 389, 279, 51342, 82, 315, 264, 3752, 3196, 63557, 389, 4846, 8013, 10461, 13015, 19036, 42969, 1174, 41323, 279, 7665, 17042, 23488, 304, 220, 679, 15, 1174, 11230, 4848, 23146, 1174, 2737, 1888, 5818, 1174, 7690, 1174, 12360, 323, 85875, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2069", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) last(O) rated(O) r(B-rating) fantasy(B-genre) movie(O) that(O) came(O) out(O)", "instance": {"id": "2069", "words": ["what", "is", "the", "last", "rated", "r", "fantasy", "movie", "that", "came", "out"], "labels": ["O", "O", "O", "O", "O", "B-rating", "B-genre", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, genre, review, title, character, year, plot, song, actor, trailer, director, rating and O.\nSentence: what is the last rated r fantasy movie that came out", "prompt_labels": "what(O) is(O) the(O) last(O) rated(O) r(B-rating) fantasy(B-genre) movie(O) that(O) came(O) out(O)"}, "label_list": ["average ratings", "genre", "review", "title", "character", "year", "plot", "song", "actor", "trailer", "director", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 17779, 11, 3477, 11, 2316, 11, 3752, 11, 1060, 11, 7234, 11, 5609, 11, 12360, 11, 19809, 11, 7690, 11, 10959, 323, 507, 627, 85664, 25, 1148, 374, 279, 1566, 22359, 436, 18884, 5818, 430, 3782, 704, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2094", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) name(O) of(O) an(O) animated(B-genre) film(O) from(O) the(O) 1990(B-year) s(I-year) directed(O) by(O) fritz(B-director) lang(I-director)", "instance": {"id": "2094", "words": ["what", "is", "the", "name", "of", "an", "animated", "film", "from", "the", "1990", "s", "directed", "by", "fritz", "lang"], "labels": ["O", "O", "O", "O", "O", "O", "B-genre", "O", "O", "O", "B-year", "I-year", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, actor, plot, review, genre, title, song, character, trailer, year, rating, average ratings and O.\nSentence: what is the name of an animated film from the 1990 s directed by fritz lang", "prompt_labels": "what(O) is(O) the(O) name(O) of(O) an(O) animated(B-genre) film(O) from(O) the(O) 1990(B-year) s(I-year) directed(O) by(O) fritz(B-director) lang(I-director)"}, "label_list": ["director", "actor", "plot", "review", "genre", "title", "song", "character", "trailer", "year", "rating", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 12360, 11, 7234, 11, 3477, 11, 17779, 11, 2316, 11, 5609, 11, 3752, 11, 19809, 11, 1060, 11, 10959, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1148, 374, 279, 836, 315, 459, 11625, 4632, 505, 279, 220, 2550, 15, 274, 15910, 555, 282, 57821, 8859, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "509", "dataset": "crossner_politics", "split": "dev", "prediction": "The(O) party(O) seeks(O) the(O) removal(O) of(O) Northern(B-Location) Ireland(I-Location) from(O) the(O) United(B-Location) Kingdom(I-Location),(O) the(O) Right2Water(B-organization) Campaign(I-organization),(O) the(O) campaign(O) to(O) Repeal(B-organization) The(I-organization) 8th(I-organization) Amendment(I-organization),(O) and(O) their(O) Public(B-organization) Housing(I-organization) For(O) all(O) campaign(O),(O) which(O) calls(O) for(O) the(O) state(O) to(O) introduce(O) a(O) housing(O) system(O) where(O) all(O) citizens(O) have(O) the(O) legal(O) right(O) to(O) rent(O) a(O) high-quality(O),(O) affordable(O) home(O) regardless(O) of(O) their(O) income(O).(O)", "instance": {"id": "509", "words": ["The", "party", "seeks", "the", "removal", "of", "Northern", "Ireland", "from", "the", "United", "Kingdom", ",", "the", "Right2Water", "Campaign", ",", "the", "campaign", "to", "Repeal", "The", "8th", "Amendment", ",", "and", "their", "Public", "Housing", "For", "all", "campaign", ",", "which", "calls", "for", "the", "state", "to", "introduce", "a", "housing", "system", "where", "all", "citizens", "have", "the", "legal", "right", "to", "rent", "a", "high-quality", ",", "affordable", "home", "regardless", "of", "their", "income", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-country", "I-country", "O", "O", "B-country", "I-country", "O", "O", "B-event", "I-event", "O", "O", "B-event", "I-event", "I-event", "I-event", "I-event", "I-event", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, organization, event, election, location, country, person, politician and O.\nSentence: The party seeks the removal of Northern Ireland from the United Kingdom , the Right2Water Campaign , the campaign to Repeal The 8th Amendment , and their Public Housing For all campaign , which calls for the state to introduce a housing system where all citizens have the legal right to rent a high-quality , affordable home regardless of their income .", "prompt_labels": "The(O) party(O) seeks(O) the(O) removal(O) of(O) Northern(B-country) Ireland(I-country) from(O) the(O) United(B-country) Kingdom(I-country) ,(O) the(O) Right2Water(B-event) Campaign(I-event) ,(O) the(O) campaign(B-event) to(I-event) Repeal(I-event) The(I-event) 8th(I-event) Amendment(I-event) ,(O) and(O) their(O) Public(O) Housing(O) For(O) all(O) campaign(O) ,(O) which(O) calls(O) for(O) the(O) state(O) to(O) introduce(O) a(O) housing(O) system(O) where(O) all(O) citizens(O) have(O) the(O) legal(O) right(O) to(O) rent(O) a(O) high-quality(O) ,(O) affordable(O) home(O) regardless(O) of(O) their(O) income(O) .(O)"}, "label_list": ["political party", "organization", "event", "election", "location", "country", "person", "politician"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5054, 4717, 11, 7471, 11, 1567, 11, 6355, 11, 3813, 11, 3224, 11, 1732, 11, 37038, 323, 507, 627, 85664, 25, 578, 4717, 26737, 279, 17065, 315, 17355, 14990, 505, 279, 3723, 15422, 1174, 279, 10291, 17, 29353, 27643, 1174, 279, 4901, 311, 1050, 375, 278, 578, 220, 23, 339, 22454, 1174, 323, 872, 3142, 31433, 1789, 682, 4901, 1174, 902, 6880, 369, 279, 1614, 311, 19678, 264, 11983, 1887, 1405, 682, 10495, 617, 279, 5897, 1314, 311, 8175, 264, 1579, 22867, 1174, 17049, 2162, 15851, 315, 872, 8070, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1730", "dataset": "mit-movie", "split": "dev", "prediction": "name(O) a(O) musical(B-genre) that(O) was(O) directed(O) by(O) billy(B-director) wilder(I-director)", "instance": {"id": "1730", "words": ["name", "a", "musical", "that", "was", "directed", "by", "billy", "wilder"], "labels": ["O", "O", "B-genre", "O", "O", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, genre, plot, title, rating, trailer, character, review, song, year, director, average ratings and O.\nSentence: name a musical that was directed by billy wilder", "prompt_labels": "name(O) a(O) musical(B-genre) that(O) was(O) directed(O) by(O) billy(B-director) wilder(I-director)"}, "label_list": ["actor", "genre", "plot", "title", "rating", "trailer", "character", "review", "song", "year", "director", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 17779, 11, 7234, 11, 2316, 11, 10959, 11, 19809, 11, 3752, 11, 3477, 11, 5609, 11, 1060, 11, 7690, 11, 5578, 18594, 323, 507, 627, 85664, 25, 836, 264, 18273, 430, 574, 15910, 555, 293, 14722, 8545, 261, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1118", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) is(O) the(O) best(B-Rating) coffee(B-Cuisine) house(I-Cuisine) near(B-Location) here(I-Location)", "instance": {"id": "1118", "words": ["what", "is", "the", "best", "coffee", "house", "near", "here"], "labels": ["O", "O", "O", "B-Rating", "B-Cuisine", "I-Cuisine", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Cuisine, Price, Restaurant Name, Dish, Hours, Rating, Amenity and O.\nSentence: what is the best coffee house near here", "prompt_labels": "what(O) is(O) the(O) best(B-Rating) coffee(B-Cuisine) house(I-Cuisine) near(B-Location) here(I-Location)"}, "label_list": ["Location", "Cuisine", "Price", "Restaurant Name", "Dish", "Hours", "Rating", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 81961, 11, 8650, 11, 26568, 4076, 11, 49268, 11, 30192, 11, 19767, 11, 3383, 56685, 323, 507, 627, 85664, 25, 1148, 374, 279, 1888, 11033, 3838, 3221, 1618, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "511", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) year(O) did(O) star(B-title) wars(I-title) a(I-title) new(I-title) hope(I-title) come(O) out(O)", "instance": {"id": "511", "words": ["what", "year", "did", "star", "wars", "a", "new", "hope", "come", "out"], "labels": ["O", "O", "O", "B-title", "I-title", "I-title", "I-title", "I-title", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, actor, character, trailer, genre, average ratings, year, rating, song, plot, title, director and O.\nSentence: what year did star wars a new hope come out", "prompt_labels": "what(O) year(O) did(O) star(B-title) wars(I-title) a(I-title) new(I-title) hope(I-title) come(O) out(O)"}, "label_list": ["review", "actor", "character", "trailer", "genre", "average ratings", "year", "rating", "song", "plot", "title", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 12360, 11, 3752, 11, 19809, 11, 17779, 11, 5578, 18594, 11, 1060, 11, 10959, 11, 5609, 11, 7234, 11, 2316, 11, 7690, 323, 507, 627, 85664, 25, 1148, 1060, 1550, 6917, 25981, 264, 502, 3987, 2586, 704, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "356", "dataset": "crossner_literature", "split": "dev", "prediction": "Only(O) The(O) Graveyard(B-book) Book(I-book) by(O) Neil(B-writer) Gaiman(I-writer) ((O) 2009(O) )(O) has(O) won(O) both(O) the(O) Carnegie(B-award) Medal(I-award) and(O) the(O) equivalent(O) American(O) award(O),(O) the(O) Newbery(B-award) Medal(I-award).(O)", "instance": {"id": "356", "words": ["Only", "The", "Graveyard", "Book", "by", "Neil", "Gaiman", "(", "2009", ")", "has", "won", "both", "the", "Carnegie", "Medal", "and", "the", "equivalent", "American", "award", ",", "the", "Newbery", "Medal", "."], "labels": ["O", "B-book", "I-book", "I-book", "O", "B-writer", "I-writer", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, person, location, organization, writer, literary genre, award, country, poem, book, magazine and O.\nSentence: Only The Graveyard Book by Neil Gaiman ( 2009 ) has won both the Carnegie Medal and the equivalent American award , the Newbery Medal .", "prompt_labels": "Only(O) The(B-book) Graveyard(I-book) Book(I-book) by(O) Neil(B-writer) Gaiman(I-writer) ((O) 2009(O) )(O) has(O) won(O) both(O) the(O) Carnegie(B-award) Medal(I-award) and(O) the(O) equivalent(O) American(O) award(O) ,(O) the(O) Newbery(B-award) Medal(I-award) .(O)"}, "label_list": ["event", "person", "location", "organization", "writer", "literary genre", "award", "country", "poem", "book", "magazine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 1732, 11, 3813, 11, 7471, 11, 7061, 11, 32465, 17779, 11, 10292, 11, 3224, 11, 33894, 11, 2363, 11, 14756, 323, 507, 627, 85664, 25, 8442, 578, 74842, 17884, 6017, 555, 34221, 480, 2706, 276, 320, 220, 1049, 24, 883, 706, 2834, 2225, 279, 64373, 17867, 323, 279, 13890, 3778, 10292, 1174, 279, 1561, 31304, 17867, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "359", "dataset": "mit-restaurant", "split": "dev", "prediction": "find(O) me(O) a(O) cheap(B-Price) restaurant(O) with(O) a(O) no(B-Amenity) smoking(I-Amenity) area(I-Amenity)", "instance": {"id": "359", "words": ["find", "me", "a", "cheap", "restaurant", "with", "a", "no", "smoking", "area"], "labels": ["O", "O", "O", "B-Price", "O", "O", "O", "B-Amenity", "I-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Price, Hours, Amenity, Dish, Rating, Cuisine, Location and O.\nSentence: find me a cheap restaurant with a no smoking area", "prompt_labels": "find(O) me(O) a(O) cheap(B-Price) restaurant(O) with(O) a(O) no(B-Amenity) smoking(I-Amenity) area(I-Amenity)"}, "label_list": ["Restaurant Name", "Price", "Hours", "Amenity", "Dish", "Rating", "Cuisine", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 8650, 11, 30192, 11, 3383, 56685, 11, 49268, 11, 19767, 11, 81961, 11, 10067, 323, 507, 627, 85664, 25, 1505, 757, 264, 12136, 10960, 449, 264, 912, 20149, 3158, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "23", "dataset": "crossner_music", "split": "dev", "prediction": "She(O) rose(O) to(O) stardom(O) in(O) the(O) romantic(B-genre) comedy(I-genre) Roman(B-award) Holiday(I-award) ((O) 1953(O) )(O),(O) alongside(O) Gregory(B-actor) Peck(I-actor),(O) for(O) which(O) she(O) was(O) the(O) first(O) actress(O) to(O) win(O) an(O) Academy(O) Awards(O),(O) a(O) Golden(B-award) Globe(I-award) Awards(I-award),(O) and(O) a(O) British(B-award) Academy(I-award) Film(I-award) Awards(I-award) for(O) a(O) single(O) performance(O).(O)", "instance": {"id": "23", "words": ["She", "rose", "to", "stardom", "in", "the", "romantic", "comedy", "Roman", "Holiday", "(", "1953", ")", ",", "alongside", "Gregory", "Peck", ",", "for", "which", "she", "was", "the", "first", "actress", "to", "win", "an", "Academy", "Awards", ",", "a", "Golden", "Globe", "Awards", ",", "and", "a", "British", "Academy", "Film", "Awards", "for", "a", "single", "performance", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "O", "O", "B-award", "I-award", "I-award", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, location, album, song, band, country, award, organization, musical artist, event, musical instrument, music genre and O.\nSentence: She rose to stardom in the romantic comedy Roman Holiday ( 1953 ) , alongside Gregory Peck , for which she was the first actress to win an Academy Awards , a Golden Globe Awards , and a British Academy Film Awards for a single performance .", "prompt_labels": "She(O) rose(O) to(O) stardom(O) in(O) the(O) romantic(O) comedy(O) Roman(O) Holiday(O) ((O) 1953(O) )(O) ,(O) alongside(O) Gregory(B-person) Peck(I-person) ,(O) for(O) which(O) she(O) was(O) the(O) first(O) actress(O) to(O) win(O) an(O) Academy(B-award) Awards(I-award) ,(O) a(O) Golden(B-award) Globe(I-award) Awards(I-award) ,(O) and(O) a(O) British(B-award) Academy(I-award) Film(I-award) Awards(I-award) for(O) a(O) single(O) performance(O) .(O)"}, "label_list": ["person", "location", "album", "song", "band", "country", "award", "organization", "musical artist", "event", "musical instrument", "music genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 3813, 11, 8176, 11, 5609, 11, 7200, 11, 3224, 11, 10292, 11, 7471, 11, 18273, 10255, 11, 1567, 11, 18273, 14473, 11, 4731, 17779, 323, 507, 627, 85664, 25, 3005, 16392, 311, 357, 569, 316, 304, 279, 24364, 23160, 13041, 32769, 320, 220, 6280, 18, 883, 1174, 16662, 44069, 5250, 377, 1174, 369, 902, 1364, 574, 279, 1176, 24577, 311, 3243, 459, 16192, 23488, 1174, 264, 18288, 41910, 23488, 1174, 323, 264, 8013, 16192, 17042, 23488, 369, 264, 3254, 5178, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "29", "dataset": "crossner_music", "split": "dev", "prediction": "In(O) central(B-Location) Europe(I-Location),(O) Italo(B-music genre) disco(I-music genre) ((O) a.k.a.(O) 1980s(B-year) Euro(I-year) disco(I-year) )(O) and(O) Euro(B-music genre) house(I-music genre) were(O) the(O) predominant(O) attempts(O) by(O) young(O) musicians(O) to(O) have(O) a(O) hit(O) record(O) in(O) and(O) beyond(O) the(O) borders(O) of(O) their(O) own(O) country(O).(O)", "instance": {"id": "29", "words": ["In", "central", "Europe", ",", "Italo", "disco", "(", "a.k.a.", "1980s", "Euro", "disco", ")", "and", "Euro", "house", "were", "the", "predominant", "attempts", "by", "young", "musicians", "to", "have", "a", "hit", "record", "in", "and", "beyond", "the", "borders", "of", "their", "own", "country", "."], "labels": ["O", "B-location", "I-location", "O", "B-music genre", "I-music genre", "O", "O", "O", "B-music genre", "I-music genre", "O", "O", "B-music genre", "I-music genre", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, musical instrument, award, person, location, country, album, music genre, event, organization, band, song and O.\nSentence: In central Europe , Italo disco ( a.k.a. 1980s Euro disco ) and Euro house were the predominant attempts by young musicians to have a hit record in and beyond the borders of their own country .", "prompt_labels": "In(O) central(B-location) Europe(I-location) ,(O) Italo(B-music genre) disco(I-music genre) ((O) a.k.a.(O) 1980s(O) Euro(B-music genre) disco(I-music genre) )(O) and(O) Euro(B-music genre) house(I-music genre) were(O) the(O) predominant(O) attempts(O) by(O) young(O) musicians(O) to(O) have(O) a(O) hit(O) record(O) in(O) and(O) beyond(O) the(O) borders(O) of(O) their(O) own(O) country(O) .(O)"}, "label_list": ["musical artist", "musical instrument", "award", "person", "location", "country", "album", "music genre", "event", "organization", "band", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18273, 10255, 11, 18273, 14473, 11, 10292, 11, 1732, 11, 3813, 11, 3224, 11, 8176, 11, 4731, 17779, 11, 1567, 11, 7471, 11, 7200, 11, 5609, 323, 507, 627, 85664, 25, 763, 8792, 4606, 1174, 1102, 12812, 54969, 320, 264, 5314, 5973, 13, 220, 3753, 15, 82, 20026, 54969, 883, 323, 20026, 3838, 1051, 279, 96531, 13865, 555, 3995, 32629, 311, 617, 264, 4295, 3335, 304, 323, 7953, 279, 24743, 315, 872, 1866, 3224, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "95", "dataset": "mit-restaurant", "split": "dev", "prediction": "are(O) there(O) any(O) vegan(B-Cuisine) spots(O) that(O) are(O) open(B-Hours) after(I-Hours) 11(I-Hours) at(I-Hours) night(I-Hours)", "instance": {"id": "95", "words": ["are", "there", "any", "vegan", "spots", "that", "are", "open", "after", "11", "at", "night"], "labels": ["O", "O", "O", "B-Cuisine", "I-Cuisine", "O", "O", "B-Hours", "I-Hours", "I-Hours", "I-Hours", "I-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Dish, Hours, Cuisine, Price, Restaurant Name, Rating, Amenity and O.\nSentence: are there any vegan spots that are open after 11 at night", "prompt_labels": "are(O) there(O) any(O) vegan(B-Cuisine) spots(I-Cuisine) that(O) are(O) open(B-Hours) after(I-Hours) 11(I-Hours) at(I-Hours) night(I-Hours)"}, "label_list": ["Location", "Dish", "Hours", "Cuisine", "Price", "Restaurant Name", "Rating", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 49268, 11, 30192, 11, 81961, 11, 8650, 11, 26568, 4076, 11, 19767, 11, 3383, 56685, 323, 507, 627, 85664, 25, 527, 1070, 904, 30249, 19300, 430, 527, 1825, 1306, 220, 806, 520, 3814, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1773", "dataset": "mit-movie", "split": "dev", "prediction": "that(O) comedy(B-genre) was(O) so(O) funny(O) that(O) id(O) give(O) it(O) ten(B-average ratings) stars(I-average ratings)", "instance": {"id": "1773", "words": ["that", "comedy", "was", "so", "funny", "that", "id", "give", "it", "ten", "stars"], "labels": ["O", "O", "O", "O", "B-genre", "O", "O", "O", "O", "B-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, review, song, trailer, director, year, actor, average ratings, rating, plot, character, title and O.\nSentence: that comedy was so funny that id give it ten stars", "prompt_labels": "that(O) comedy(O) was(O) so(O) funny(B-genre) that(O) id(O) give(O) it(O) ten(B-average ratings) stars(I-average ratings)"}, "label_list": ["genre", "review", "song", "trailer", "director", "year", "actor", "average ratings", "rating", "plot", "character", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 3477, 11, 5609, 11, 19809, 11, 7690, 11, 1060, 11, 12360, 11, 5578, 18594, 11, 10959, 11, 7234, 11, 3752, 11, 2316, 323, 507, 627, 85664, 25, 430, 23160, 574, 779, 15526, 430, 887, 3041, 433, 5899, 9958, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "293", "dataset": "crossner_ai", "split": "dev", "prediction": "In(O) the(O) United(B-country) States(I-country) he(O) is(O) a(O) Member(O) of(O) the(O) National(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization),(O) the(O) American(B-organization) Academy(I-organization) of(I-organization) Arts(I-organization) and(I-organization) Sciences(I-organization),(O) the(O) Linguistic(B-organization) Society(I-organization) of(I-organization) America(I-organization),(O) the(O) American(B-organization) Philosophical(I-organization) Association(I-organization),(O) and(O) the(O) American(B-organization) Association(I-organization) for(I-organization) the(I-organization) Advancement(I-organization) of(I-organization) Science(I-organization).(O)", "instance": {"id": "293", "words": ["In", "the", "United", "States", "he", "is", "a", "Member", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "Linguistic", "Society", "of", "America", ",", "the", "American", "Philosophical", "Association", ",", "and", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "labels": ["O", "O", "B-country", "I-country", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, location, person, metric, algorithm, field, organization, product, researcher, country, conference, programming language, task and O.\nSentence: In the United States he is a Member of the National Academy of Sciences , the American Academy of Arts and Sciences , the Linguistic Society of America , the American Philosophical Association , and the American Association for the Advancement of Science .", "prompt_labels": "In(O) the(O) United(B-country) States(I-country) he(O) is(O) a(O) Member(O) of(O) the(O) National(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) ,(O) the(O) American(B-organization) Academy(I-organization) of(I-organization) Arts(I-organization) and(I-organization) Sciences(I-organization) ,(O) the(O) Linguistic(B-organization) Society(I-organization) of(I-organization) America(I-organization) ,(O) the(O) American(B-organization) Philosophical(I-organization) Association(I-organization) ,(O) and(O) the(O) American(B-organization) Association(I-organization) for(I-organization) the(I-organization) Advancement(I-organization) of(I-organization) Science(I-organization) .(O)"}, "label_list": ["university", "location", "person", "metric", "algorithm", "field", "organization", "product", "researcher", "country", "conference", "programming language", "task"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12374, 11, 3813, 11, 1732, 11, 18767, 11, 12384, 11, 2115, 11, 7471, 11, 2027, 11, 32185, 11, 3224, 11, 10017, 11, 15840, 4221, 11, 3465, 323, 507, 627, 85664, 25, 763, 279, 3723, 4273, 568, 374, 264, 12308, 315, 279, 5165, 16192, 315, 23199, 1174, 279, 3778, 16192, 315, 17979, 323, 23199, 1174, 279, 89333, 4633, 13581, 315, 5270, 1174, 279, 3778, 38356, 950, 10229, 1174, 323, 279, 3778, 10229, 369, 279, 12605, 16887, 315, 10170, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "639", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) want(O) something(O) full(O) of(O) grease(B-Dish)", "instance": {"id": "639", "words": ["i", "want", "something", "full", "of", "grease"], "labels": ["O", "O", "O", "O", "O", "B-Cuisine"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Rating, Dish, Hours, Location, Restaurant Name, Price, Amenity and O.\nSentence: i want something full of grease", "prompt_labels": "i(O) want(O) something(O) full(O) of(O) grease(B-Cuisine)"}, "label_list": ["Cuisine", "Rating", "Dish", "Hours", "Location", "Restaurant Name", "Price", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 19767, 11, 49268, 11, 30192, 11, 10067, 11, 26568, 4076, 11, 8650, 11, 3383, 56685, 323, 507, 627, 85664, 25, 602, 1390, 2555, 2539, 315, 63471, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1414", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) is(O) the(O) closest(B-Location) jimmie(B-Restaurant Name) johns(I-Restaurant Name)", "instance": {"id": "1414", "words": ["where", "is", "the", "closest", "jimmie", "johns"], "labels": ["O", "O", "O", "B-Location", "B-Restaurant Name", "I-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Rating, Dish, Restaurant Name, Location, Cuisine, Hours, Price and O.\nSentence: where is the closest jimmie johns", "prompt_labels": "where(O) is(O) the(O) closest(B-Location) jimmie(B-Restaurant Name) johns(I-Restaurant Name)"}, "label_list": ["Amenity", "Rating", "Dish", "Restaurant Name", "Location", "Cuisine", "Hours", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 19767, 11, 49268, 11, 26568, 4076, 11, 10067, 11, 81961, 11, 30192, 11, 8650, 323, 507, 627, 85664, 25, 1405, 374, 279, 18585, 503, 12828, 648, 40742, 82, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "194", "dataset": "crossner_music", "split": "dev", "prediction": "He(O) was(O) the(O) guitarist(O) for(O) the(O) 1980s(B-year) Hi-NRG(B-music genre),(O) Synth-pop(B-music genre) band(O),(O) Frankie(B-musical artist) Goes(I-musical artist) to(I-musical artist) Hollywood(I-musical artist).(O)", "instance": {"id": "194", "words": ["He", "was", "the", "guitarist", "for", "the", "1980s", "Hi-NRG", ",", "Synth-pop", "band", ",", "Frankie", "Goes", "to", "Hollywood", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-music genre", "O", "B-music genre", "O", "O", "B-band", "I-band", "I-band", "I-band", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, country, location, musical artist, album, song, event, award, band, person, musical instrument, music genre and O.\nSentence: He was the guitarist for the 1980s Hi-NRG , Synth-pop band , Frankie Goes to Hollywood .", "prompt_labels": "He(O) was(O) the(O) guitarist(O) for(O) the(O) 1980s(O) Hi-NRG(B-music genre) ,(O) Synth-pop(B-music genre) band(O) ,(O) Frankie(B-band) Goes(I-band) to(I-band) Hollywood(I-band) .(O)"}, "label_list": ["organization", "country", "location", "musical artist", "album", "song", "event", "award", "band", "person", "musical instrument", "music genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 3224, 11, 3813, 11, 18273, 10255, 11, 8176, 11, 5609, 11, 1567, 11, 10292, 11, 7200, 11, 1732, 11, 18273, 14473, 11, 4731, 17779, 323, 507, 627, 85664, 25, 1283, 574, 279, 62740, 369, 279, 220, 3753, 15, 82, 21694, 11500, 33460, 1174, 24028, 339, 41352, 7200, 1174, 94545, 61261, 311, 17681, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1442", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) robert(B-actor) de(I-actor) niro(I-actor) in(O) any(O) disaster(B-genre) movies(O)", "instance": {"id": "1442", "words": ["is", "robert", "de", "niro", "in", "any", "disaster", "movies"], "labels": ["O", "B-actor", "I-actor", "I-actor", "O", "O", "B-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, title, genre, review, average ratings, rating, character, actor, year, plot, director, song and O.\nSentence: is robert de niro in any disaster movies", "prompt_labels": "is(O) robert(B-actor) de(I-actor) niro(I-actor) in(O) any(O) disaster(B-genre) movies(O)"}, "label_list": ["trailer", "title", "genre", "review", "average ratings", "rating", "character", "actor", "year", "plot", "director", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 2316, 11, 17779, 11, 3477, 11, 5578, 18594, 11, 10959, 11, 3752, 11, 12360, 11, 1060, 11, 7234, 11, 7690, 11, 5609, 323, 507, 627, 85664, 25, 374, 89993, 409, 308, 8869, 304, 904, 21426, 9698, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "44", "dataset": "crossner_literature", "split": "dev", "prediction": "Hesser(B-person) lives(O) in(O) Brooklyn(B-location) Heights(I-location) with(O) her(O) husband(O),(O) Tad(B-writer) Friend(I-writer),(O) a(O) staff(O) writer(O) for(O) The(B-magazine) New(I-magazine) Yorker(I-magazine),(O) and(O) their(O) two(O) children(O).(O)", "instance": {"id": "44", "words": ["Hesser", "lives", "in", "Brooklyn", "Heights", "with", "her", "husband", ",", "Tad", "Friend", ",", "a", "staff", "writer", "for", "The", "New", "Yorker", ",", "and", "their", "two", "children", "."], "labels": ["B-writer", "O", "O", "B-location", "I-location", "O", "O", "O", "O", "B-writer", "I-writer", "O", "O", "O", "O", "O", "B-magazine", "I-magazine", "I-magazine", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, location, country, magazine, writer, poem, book, person, event, literary genre, organization and O.\nSentence: Hesser lives in Brooklyn Heights with her husband , Tad Friend , a staff writer for The New Yorker , and their two children .", "prompt_labels": "Hesser(B-writer) lives(O) in(O) Brooklyn(B-location) Heights(I-location) with(O) her(O) husband(O) ,(O) Tad(B-writer) Friend(I-writer) ,(O) a(O) staff(O) writer(O) for(O) The(B-magazine) New(I-magazine) Yorker(I-magazine) ,(O) and(O) their(O) two(O) children(O) .(O)"}, "label_list": ["award", "location", "country", "magazine", "writer", "poem", "book", "person", "event", "literary genre", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10292, 11, 3813, 11, 3224, 11, 14756, 11, 7061, 11, 33894, 11, 2363, 11, 1732, 11, 1567, 11, 32465, 17779, 11, 7471, 323, 507, 627, 85664, 25, 473, 37470, 6439, 304, 26832, 40503, 449, 1077, 10177, 1174, 350, 329, 11848, 1174, 264, 5687, 7061, 369, 578, 1561, 64874, 1174, 323, 872, 1403, 2911, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "115", "dataset": "crossner_literature", "split": "dev", "prediction": "He(O) particularly(O) revered(O) Johann(B-writer) Wolfgang(I-writer) von(I-writer) Goethe(I-writer),(O) Petrarch(B-writer),(O) Pedro(B-writer) Calder\u00f3n(I-writer) de(I-writer) la(I-writer) Barca(I-writer) and(O) William(B-writer) Shakespeare(I-writer).(O)", "instance": {"id": "115", "words": ["He", "particularly", "revered", "Johann", "Wolfgang", "von", "Goethe", ",", "Petrarch", ",", "Pedro", "Calder\u00f3n", "de", "la", "Barca", "and", "William", "Shakespeare", "."], "labels": ["O", "O", "O", "B-writer", "I-writer", "I-writer", "I-writer", "O", "B-writer", "O", "B-writer", "I-writer", "I-writer", "I-writer", "I-writer", "O", "B-writer", "I-writer", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, poem, organization, award, person, event, literary genre, book, location, magazine, writer and O.\nSentence: He particularly revered Johann Wolfgang von Goethe , Petrarch , Pedro Calder\u00f3n de la Barca and William Shakespeare .", "prompt_labels": "He(O) particularly(O) revered(O) Johann(B-writer) Wolfgang(I-writer) von(I-writer) Goethe(I-writer) ,(O) Petrarch(B-writer) ,(O) Pedro(B-writer) Calder\u00f3n(I-writer) de(I-writer) la(I-writer) Barca(I-writer) and(O) William(B-writer) Shakespeare(I-writer) .(O)"}, "label_list": ["country", "poem", "organization", "award", "person", "event", "literary genre", "book", "location", "magazine", "writer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 33894, 11, 7471, 11, 10292, 11, 1732, 11, 1567, 11, 32465, 17779, 11, 2363, 11, 3813, 11, 14756, 11, 7061, 323, 507, 627, 85664, 25, 1283, 8104, 85761, 88964, 87598, 6675, 6122, 19030, 1174, 96876, 1132, 1174, 43582, 76400, 3244, 409, 1208, 4821, 936, 323, 12656, 42482, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1127", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) bette(B-actor) davis(I-actor) ever(O) star(O) in(O) a(O) movie(O) directed(O) by(O) martin(B-director) scorsese(I-director)", "instance": {"id": "1127", "words": ["did", "bette", "davis", "ever", "star", "in", "a", "movie", "directed", "by", "martin", "scorsese"], "labels": ["O", "B-actor", "I-actor", "O", "O", "O", "O", "O", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, review, genre, character, title, plot, year, director, song, rating, trailer, actor and O.\nSentence: did bette davis ever star in a movie directed by martin scorsese", "prompt_labels": "did(O) bette(B-actor) davis(I-actor) ever(O) star(O) in(O) a(O) movie(O) directed(O) by(O) martin(B-director) scorsese(I-director)"}, "label_list": ["average ratings", "review", "genre", "character", "title", "plot", "year", "director", "song", "rating", "trailer", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 3477, 11, 17779, 11, 3752, 11, 2316, 11, 7234, 11, 1060, 11, 7690, 11, 5609, 11, 10959, 11, 19809, 11, 12360, 323, 507, 627, 85664, 25, 1550, 1297, 668, 294, 23156, 3596, 6917, 304, 264, 5818, 15910, 555, 96016, 1156, 1105, 2423, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "494", "dataset": "crossner_politics", "split": "dev", "prediction": "Once(O) the(O) Armistice(O) of(O) Mudanya(O) was(O) signed(O),(O) replacing(O) the(O) Armistice(O) of(O) Mundros(B-location) ((O) signed(O) by(O) the(O) Ottoman(O) Empire(O) in(O) 1918(O) at(O) the(O) end(O) of(O) World(O) War(O) I(O) )(O) and(O) ending(O) the(O) Turkish(O) War(O) of(O) Independence(O),(O) the(O) GNA(O) abolished(O) the(O) imperial(O) Sultanate(O),(O) which(O) was(O) accused(O) of(O) collaborating(O) with(O) the(O) Allies(O) of(O) World(O) War(O) I(O) during(O) the(O) occupation(O) of(O) Turkey(O).(O)", "instance": {"id": "494", "words": ["Once", "the", "Armistice", "of", "Mudanya", "was", "signed", ",", "replacing", "the", "Armistice", "of", "Mundros", "(", "signed", "by", "the", "Ottoman", "Empire", "in", "1918", "at", "the", "end", "of", "World", "War", "I", ")", "and", "ending", "the", "Turkish", "War", "of", "Independence", ",", "the", "GNA", "abolished", "the", "imperial", "Sultanate", ",", "which", "was", "accused", "of", "collaborating", "with", "the", "Allies", "of", "World", "War", "I", "during", "the", "occupation", "of", "Turkey", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-country", "I-country", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "O", "O", "O", "O", "B-event", "I-event", "I-event", "I-event", "O", "O", "B-organization", "O", "O", "O", "B-country", "O", "O", "O", "O", "O", "O", "O", "O", "B-country", "O", "B-event", "I-event", "I-event", "O", "O", "O", "O", "B-country", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, organization, location, person, political party, politician, election, country and O.\nSentence: Once the Armistice of Mudanya was signed , replacing the Armistice of Mundros ( signed by the Ottoman Empire in 1918 at the end of World War I ) and ending the Turkish War of Independence , the GNA abolished the imperial Sultanate , which was accused of collaborating with the Allies of World War I during the occupation of Turkey .", "prompt_labels": "Once(O) the(O) Armistice(O) of(O) Mudanya(O) was(O) signed(O) ,(O) replacing(O) the(O) Armistice(O) of(O) Mundros(O) ((O) signed(O) by(O) the(O) Ottoman(B-country) Empire(I-country) in(O) 1918(O) at(O) the(O) end(O) of(O) World(B-event) War(I-event) I(I-event) )(O) and(O) ending(O) the(O) Turkish(B-event) War(I-event) of(I-event) Independence(I-event) ,(O) the(O) GNA(B-organization) abolished(O) the(O) imperial(O) Sultanate(B-country) ,(O) which(O) was(O) accused(O) of(O) collaborating(O) with(O) the(O) Allies(B-country) of(O) World(B-event) War(I-event) I(I-event) during(O) the(O) occupation(O) of(O) Turkey(B-country) .(O)"}, "label_list": ["event", "organization", "location", "person", "political party", "politician", "election", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 7471, 11, 3813, 11, 1732, 11, 5054, 4717, 11, 37038, 11, 6355, 11, 3224, 323, 507, 627, 85664, 25, 9843, 279, 13287, 380, 560, 315, 69440, 25041, 574, 8667, 1174, 25935, 279, 13287, 380, 560, 315, 67661, 3714, 320, 8667, 555, 279, 70110, 21080, 304, 220, 7529, 23, 520, 279, 842, 315, 4435, 5111, 358, 883, 323, 13696, 279, 24666, 5111, 315, 44177, 1174, 279, 480, 7476, 81081, 279, 35379, 76086, 349, 1174, 902, 574, 13487, 315, 73301, 449, 279, 81774, 315, 4435, 5111, 358, 2391, 279, 30747, 315, 17442, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "111", "dataset": "crossner_music", "split": "dev", "prediction": "British(B-genre) genres(O) such(O) as(O) Lovers(B-music genre) rock(I-music genre),(O) Ragga(B-music genre) jungle(I-music genre) and(O) grime(B-music genre) are(O) also(O) influenced(O) by(O) Jamaican(B-music genre) music(O).(O)", "instance": {"id": "111", "words": ["British", "genres", "such", "as", "Lovers", "rock", ",", "Ragga", "jungle", "and", "grime", "are", "also", "influenced", "by", "Jamaican", "music", "."], "labels": ["O", "O", "O", "O", "B-music genre", "I-music genre", "O", "B-music genre", "I-music genre", "O", "B-music genre", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, person, music genre, location, band, country, award, event, album, song, organization, musical instrument and O.\nSentence: British genres such as Lovers rock , Ragga jungle and grime are also influenced by Jamaican music .", "prompt_labels": "British(O) genres(O) such(O) as(O) Lovers(B-music genre) rock(I-music genre) ,(O) Ragga(B-music genre) jungle(I-music genre) and(O) grime(B-music genre) are(O) also(O) influenced(O) by(O) Jamaican(O) music(O) .(O)"}, "label_list": ["musical artist", "person", "music genre", "location", "band", "country", "award", "event", "album", "song", "organization", "musical instrument"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18273, 10255, 11, 1732, 11, 4731, 17779, 11, 3813, 11, 7200, 11, 3224, 11, 10292, 11, 1567, 11, 8176, 11, 5609, 11, 7471, 11, 18273, 14473, 323, 507, 627, 85664, 25, 8013, 36744, 1778, 439, 445, 9146, 7091, 1174, 51359, 6885, 45520, 323, 1099, 547, 527, 1101, 28160, 555, 41259, 7210, 4731, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "340", "dataset": "crossner_science", "split": "dev", "prediction": "At(O) the(O) end(O) of(O) 2012(O) the(O) journal(O) was(O) split(O) into(O) three(O) independent(O) journals(O) :(O) Journal(O) of(O) Materials(O) Chemistry(O) A(O) ((O) energy(O) and(O) sustainability(O) )(O),(O) Journal(O) of(O) Materials(O) Chemistry(O) B(O) ((O) biology(O) and(O) medicine(O) )(O) and(O) Journal(O) of(O) Materials(O) Chemistry(O) C(O) ((O) optical(O),(O) magnetic(O) and(O) electronic(O) devices(O) )(O).(O)", "instance": {"id": "340", "words": ["At", "the", "end", "of", "2012", "the", "journal", "was", "split", "into", "three", "independent", "journals", ":", "Journal", "of", "Materials", "Chemistry", "A", "(", "energy", "and", "sustainability", ")", ",", "Journal", "of", "Materials", "Chemistry", "B", "(", "biology", "and", "medicine", ")", "and", "Journal", "of", "Materials", "Chemistry", "C", "(", "optical", ",", "magnetic", "and", "electronic", "devices", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O", "B-discipline", "I-discipline", "I-discipline", "O", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O", "B-discipline", "O", "B-discipline", "O", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, organization, country, academic journal, university, theory, protein, chemical element, event, location, enzyme, chemical compound, astronomical object, award, scientist, discipline and O.\nSentence: At the end of 2012 the journal was split into three independent journals : Journal of Materials Chemistry A ( energy and sustainability ) , Journal of Materials Chemistry B ( biology and medicine ) and Journal of Materials Chemistry C ( optical , magnetic and electronic devices ) .", "prompt_labels": "At(O) the(O) end(O) of(O) 2012(O) the(O) journal(O) was(O) split(O) into(O) three(O) independent(O) journals(O) :(O) Journal(B-academic journal) of(I-academic journal) Materials(I-academic journal) Chemistry(I-academic journal) A(I-academic journal) ((O) energy(B-discipline) and(I-discipline) sustainability(I-discipline) )(O) ,(O) Journal(B-academic journal) of(I-academic journal) Materials(I-academic journal) Chemistry(I-academic journal) B(I-academic journal) ((O) biology(B-discipline) and(O) medicine(B-discipline) )(O) and(O) Journal(B-academic journal) of(I-academic journal) Materials(I-academic journal) Chemistry(I-academic journal) C(I-academic journal) ((O) optical(O) ,(O) magnetic(O) and(O) electronic(O) devices(O) )(O) .(O)"}, "label_list": ["person", "organization", "country", "academic journal", "university", "theory", "protein", "chemical element", "event", "location", "enzyme", "chemical compound", "astronomical object", "award", "scientist", "discipline"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 7471, 11, 3224, 11, 14584, 8486, 11, 12374, 11, 10334, 11, 13128, 11, 11742, 2449, 11, 1567, 11, 3813, 11, 49242, 11, 11742, 24549, 11, 87283, 1665, 11, 10292, 11, 28568, 11, 26434, 323, 507, 627, 85664, 25, 2468, 279, 842, 315, 220, 679, 17, 279, 8486, 574, 6859, 1139, 2380, 9678, 42780, 551, 10139, 315, 32009, 42846, 362, 320, 4907, 323, 41329, 883, 1174, 10139, 315, 32009, 42846, 426, 320, 34458, 323, 16088, 883, 323, 10139, 315, 32009, 42846, 356, 320, 29393, 1174, 24924, 323, 14683, 7766, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "305", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movies(O) got(O) a(O) great(B-average ratings) review(I-average ratings) by(O) roger(B-review) ebert(I-review) in(O) 2011(B-year)", "instance": {"id": "305", "words": ["what", "movies", "got", "a", "great", "review", "by", "roger", "ebert", "in", "2011"], "labels": ["O", "O", "O", "O", "B-average ratings", "I-average ratings", "O", "O", "O", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, character, plot, rating, average ratings, year, song, genre, actor, title, trailer, director and O.\nSentence: what movies got a great review by roger ebert in 2011", "prompt_labels": "what(O) movies(O) got(O) a(O) great(B-average ratings) review(I-average ratings) by(O) roger(O) ebert(O) in(O) 2011(B-year)"}, "label_list": ["review", "character", "plot", "rating", "average ratings", "year", "song", "genre", "actor", "title", "trailer", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 3752, 11, 7234, 11, 10959, 11, 5578, 18594, 11, 1060, 11, 5609, 11, 17779, 11, 12360, 11, 2316, 11, 19809, 11, 7690, 323, 507, 627, 85664, 25, 1148, 9698, 2751, 264, 2294, 3477, 555, 938, 1414, 384, 9339, 304, 220, 679, 16, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2146", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movies(O) did(O) steve(B-actor) mcqueen(I-actor) have(O) a(O) role(O) in(O)", "instance": {"id": "2146", "words": ["what", "movies", "did", "steve", "mcqueen", "have", "a", "role", "in"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, plot, average ratings, review, director, actor, genre, year, rating, song, title, trailer and O.\nSentence: what movies did steve mcqueen have a role in", "prompt_labels": "what(O) movies(O) did(O) steve(B-actor) mcqueen(I-actor) have(O) a(O) role(O) in(O)"}, "label_list": ["character", "plot", "average ratings", "review", "director", "actor", "genre", "year", "rating", "song", "title", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 7234, 11, 5578, 18594, 11, 3477, 11, 7690, 11, 12360, 11, 17779, 11, 1060, 11, 10959, 11, 5609, 11, 2316, 11, 19809, 323, 507, 627, 85664, 25, 1148, 9698, 1550, 4179, 588, 19777, 94214, 617, 264, 3560, 304, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "279", "dataset": "mit-restaurant", "split": "dev", "prediction": "does(O) caribe(B-Restaurant Name) have(O) a(O) smoking(B-Amenity) area(I-Amenity)", "instance": {"id": "279", "words": ["does", "caribe", "have", "a", "smoking", "area"], "labels": ["O", "B-Restaurant Name", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Price, Rating, Location, Dish, Amenity, Restaurant Name, Hours and O.\nSentence: does caribe have a smoking area", "prompt_labels": "does(O) caribe(B-Restaurant Name) have(O) a(O) smoking(B-Amenity) area(I-Amenity)"}, "label_list": ["Cuisine", "Price", "Rating", "Location", "Dish", "Amenity", "Restaurant Name", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 8650, 11, 19767, 11, 10067, 11, 49268, 11, 3383, 56685, 11, 26568, 4076, 11, 30192, 323, 507, 627, 85664, 25, 1587, 1841, 24459, 617, 264, 20149, 3158, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "286", "dataset": "mit-restaurant", "split": "dev", "prediction": "does(O) jaimes(B-Restaurant Name) bakery(I-Restaurant Name) have(O) a(O) great(B-Amenity) decor(I-Amenity)", "instance": {"id": "286", "words": ["does", "jaimes", "bakery", "have", "a", "great", "decor"], "labels": ["O", "B-Restaurant Name", "I-Restaurant Name", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Amenity, Location, Hours, Rating, Price, Restaurant Name, Cuisine and O.\nSentence: does jaimes bakery have a great decor", "prompt_labels": "does(O) jaimes(B-Restaurant Name) bakery(I-Restaurant Name) have(O) a(O) great(B-Amenity) decor(I-Amenity)"}, "label_list": ["Dish", "Amenity", "Location", "Hours", "Rating", "Price", "Restaurant Name", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 3383, 56685, 11, 10067, 11, 30192, 11, 19767, 11, 8650, 11, 26568, 4076, 11, 81961, 323, 507, 627, 85664, 25, 1587, 12203, 1769, 66244, 617, 264, 2294, 10799, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "877", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) a(O) taco(B-Cuisine) joint(O) near(B-Location) the(I-Location) college(I-Location)", "instance": {"id": "877", "words": ["is", "there", "a", "taco", "joint", "near", "the", "college"], "labels": ["O", "O", "O", "B-Cuisine", "I-Cuisine", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Hours, Restaurant Name, Rating, Cuisine, Location, Amenity, Price and O.\nSentence: is there a taco joint near the college", "prompt_labels": "is(O) there(O) a(O) taco(B-Cuisine) joint(I-Cuisine) near(B-Location) the(I-Location) college(I-Location)"}, "label_list": ["Dish", "Hours", "Restaurant Name", "Rating", "Cuisine", "Location", "Amenity", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 30192, 11, 26568, 4076, 11, 19767, 11, 81961, 11, 10067, 11, 3383, 56685, 11, 8650, 323, 507, 627, 85664, 25, 374, 1070, 264, 91941, 10496, 3221, 279, 7926, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1120", "dataset": "mit-movie", "split": "dev", "prediction": "could(O) you(O) help(O) me(O) find(O) a(O) movie(O) starring(O) larenz(B-actor) tate(I-actor) that(O) was(O) made(O) in(O) the(O) past(B-year) eight(I-year) years(I-year) that(O) was(O) rated(B-average ratings) well(I-average ratings)", "instance": {"id": "1120", "words": ["could", "you", "help", "me", "find", "a", "movie", "starring", "larenz", "tate", "that", "was", "made", "in", "the", "past", "eight", "years", "that", "was", "rated", "well"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-actor", "I-actor", "O", "O", "O", "O", "O", "B-year", "I-year", "I-year", "O", "O", "B-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, title, song, average ratings, actor, genre, year, rating, character, plot, director, review and O.\nSentence: could you help me find a movie starring larenz tate that was made in the past eight years that was rated well", "prompt_labels": "could(O) you(O) help(O) me(O) find(O) a(O) movie(O) starring(O) larenz(B-actor) tate(I-actor) that(O) was(O) made(O) in(O) the(O) past(B-year) eight(I-year) years(I-year) that(O) was(O) rated(B-average ratings) well(I-average ratings)"}, "label_list": ["trailer", "title", "song", "average ratings", "actor", "genre", "year", "rating", "character", "plot", "director", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 2316, 11, 5609, 11, 5578, 18594, 11, 12360, 11, 17779, 11, 1060, 11, 10959, 11, 3752, 11, 7234, 11, 7690, 11, 3477, 323, 507, 627, 85664, 25, 1436, 499, 1520, 757, 1505, 264, 5818, 40500, 326, 9329, 89, 259, 349, 430, 574, 1903, 304, 279, 3347, 8223, 1667, 430, 574, 22359, 1664, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "759", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) a(O) movie(O) with(O) lots(B-plot) of(I-plot) sky(I-plot) diving(I-plot) in(O) it(O)", "instance": {"id": "759", "words": ["show", "me", "a", "movie", "with", "lots", "of", "sky", "diving", "in", "it"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-plot", "I-plot", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, review, song, character, title, average ratings, genre, year, rating, actor, director, trailer and O.\nSentence: show me a movie with lots of sky diving in it", "prompt_labels": "show(O) me(O) a(O) movie(O) with(O) lots(O) of(O) sky(B-plot) diving(I-plot) in(O) it(O)"}, "label_list": ["plot", "review", "song", "character", "title", "average ratings", "genre", "year", "rating", "actor", "director", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 3477, 11, 5609, 11, 3752, 11, 2316, 11, 5578, 18594, 11, 17779, 11, 1060, 11, 10959, 11, 12360, 11, 7690, 11, 19809, 323, 507, 627, 85664, 25, 1501, 757, 264, 5818, 449, 10283, 315, 13180, 43515, 304, 433, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "623", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) zombie(B-plot) movie(O) features(O) a(O) zombie(B-plot) tiger(I-plot)", "instance": {"id": "623", "words": ["what", "zombie", "movie", "features", "a", "zombie", "tiger"], "labels": ["O", "B-genre", "I-genre", "O", "O", "B-character", "I-character"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, character, title, song, trailer, rating, review, year, director, average ratings, plot, genre and O.\nSentence: what zombie movie features a zombie tiger", "prompt_labels": "what(O) zombie(B-genre) movie(I-genre) features(O) a(O) zombie(B-character) tiger(I-character)"}, "label_list": ["actor", "character", "title", "song", "trailer", "rating", "review", "year", "director", "average ratings", "plot", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 3752, 11, 2316, 11, 5609, 11, 19809, 11, 10959, 11, 3477, 11, 1060, 11, 7690, 11, 5578, 18594, 11, 7234, 11, 17779, 323, 507, 627, 85664, 25, 1148, 38836, 5818, 4519, 264, 38836, 52835, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1335", "dataset": "mit-movie", "split": "dev", "prediction": "i(O) would(O) like(O) a(O) war(B-genre) movie(O) directed(O) by(O) harry(B-director) elfont(I-director) from(O) last(B-year) year(I-year) rated(O) pg(B-rating) 13(I-rating)", "instance": {"id": "1335", "words": ["i", "would", "like", "a", "war", "movie", "directed", "by", "harry", "elfont", "from", "last", "year", "rated", "pg", "13"], "labels": ["O", "O", "O", "O", "B-plot", "O", "O", "O", "B-director", "I-director", "O", "B-year", "I-year", "O", "B-rating", "I-rating"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, average ratings, song, director, year, title, character, genre, rating, plot, trailer, actor and O.\nSentence: i would like a war movie directed by harry elfont from last year rated pg 13", "prompt_labels": "i(O) would(O) like(O) a(O) war(B-plot) movie(O) directed(O) by(O) harry(B-director) elfont(I-director) from(O) last(B-year) year(I-year) rated(O) pg(B-rating) 13(I-rating)"}, "label_list": ["review", "average ratings", "song", "director", "year", "title", "character", "genre", "rating", "plot", "trailer", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 5578, 18594, 11, 5609, 11, 7690, 11, 1060, 11, 2316, 11, 3752, 11, 17779, 11, 10959, 11, 7234, 11, 19809, 11, 12360, 323, 507, 627, 85664, 25, 602, 1053, 1093, 264, 4208, 5818, 15910, 555, 4960, 894, 41845, 546, 505, 1566, 1060, 22359, 17953, 220, 1032, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "313", "dataset": "crossner_ai", "split": "dev", "prediction": "They(O) presented(O) their(O) method(O) and(O) results(O) in(O) SIGGRAPH(B-conference) 2000(I-conference).(O)", "instance": {"id": "313", "words": ["They", "presented", "their", "method", "and", "results", "in", "SIGGRAPH", "2000", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-conference", "I-conference", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, programming language, university, product, researcher, task, location, organization, algorithm, field, conference, country, metric and O.\nSentence: They presented their method and results in SIGGRAPH 2000 .", "prompt_labels": "They(O) presented(O) their(O) method(O) and(O) results(O) in(O) SIGGRAPH(B-conference) 2000(I-conference) .(O)"}, "label_list": ["person", "programming language", "university", "product", "researcher", "task", "location", "organization", "algorithm", "field", "conference", "country", "metric"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 15840, 4221, 11, 12374, 11, 2027, 11, 32185, 11, 3465, 11, 3813, 11, 7471, 11, 12384, 11, 2115, 11, 10017, 11, 3224, 11, 18767, 323, 507, 627, 85664, 25, 2435, 10666, 872, 1749, 323, 3135, 304, 26093, 41084, 220, 1049, 15, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "47", "dataset": "mit-restaurant", "split": "dev", "prediction": "are(O) there(O) any(O) hamburger(B-Dish) restaurants(O) close(B-Location) by(I-Location)", "instance": {"id": "47", "words": ["are", "there", "any", "hamburger", "restaurants", "close", "by"], "labels": ["O", "O", "O", "B-Cuisine", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Price, Rating, Hours, Amenity, Cuisine, Dish, Location and O.\nSentence: are there any hamburger restaurants close by", "prompt_labels": "are(O) there(O) any(O) hamburger(B-Cuisine) restaurants(O) close(B-Location) by(I-Location)"}, "label_list": ["Restaurant Name", "Price", "Rating", "Hours", "Amenity", "Cuisine", "Dish", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 8650, 11, 19767, 11, 30192, 11, 3383, 56685, 11, 81961, 11, 49268, 11, 10067, 323, 507, 627, 85664, 25, 527, 1070, 904, 89847, 15926, 3345, 555, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2142", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movie(O) stared(O) terry(B-actor) farrell(I-actor) as(O) a(O) cowboy(B-plot) in(O) mexico(B-plot)", "instance": {"id": "2142", "words": ["what", "movie", "stared", "terry", "farrell", "as", "a", "cowboy", "in", "mexico"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O", "O", "B-genre", "O", "B-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, director, average ratings, genre, trailer, actor, plot, year, title, rating, character, song and O.\nSentence: what movie stared terry farrell as a cowboy in mexico", "prompt_labels": "what(O) movie(O) stared(O) terry(B-actor) farrell(I-actor) as(O) a(O) cowboy(B-genre) in(O) mexico(B-plot)"}, "label_list": ["review", "director", "average ratings", "genre", "trailer", "actor", "plot", "year", "title", "rating", "character", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 7690, 11, 5578, 18594, 11, 17779, 11, 19809, 11, 12360, 11, 7234, 11, 1060, 11, 2316, 11, 10959, 11, 3752, 11, 5609, 323, 507, 627, 85664, 25, 1148, 5818, 45135, 259, 5515, 3117, 16684, 439, 264, 81272, 304, 77476, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "216", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) directed(O) the(O) film(O) the(B-title) lorax(I-title)", "instance": {"id": "216", "words": ["who", "directed", "the", "film", "the", "lorax"], "labels": ["O", "O", "O", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, plot, actor, average ratings, genre, rating, title, director, year, character, song, trailer and O.\nSentence: who directed the film the lorax", "prompt_labels": "who(O) directed(O) the(O) film(O) the(B-title) lorax(I-title)"}, "label_list": ["review", "plot", "actor", "average ratings", "genre", "rating", "title", "director", "year", "character", "song", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 7234, 11, 12360, 11, 5578, 18594, 11, 17779, 11, 10959, 11, 2316, 11, 7690, 11, 1060, 11, 3752, 11, 5609, 11, 19809, 323, 507, 627, 85664, 25, 889, 15910, 279, 4632, 279, 67311, 710, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "554", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) am(O) looking(O) for(O) lunch(B-Hours) buffets(B-Amenity) within(B-Location) 15(I-Location) minutes(I-Location) driving(I-Location) distance(I-Location)", "instance": {"id": "554", "words": ["i", "am", "looking", "for", "lunch", "buffets", "within", "15", "minutes", "driving", "distance"], "labels": ["O", "O", "O", "O", "B-Hours", "B-Amenity", "B-Location", "I-Location", "I-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Rating, Cuisine, Location, Restaurant Name, Price, Hours, Dish and O.\nSentence: i am looking for lunch buffets within 15 minutes driving distance", "prompt_labels": "i(O) am(O) looking(O) for(O) lunch(B-Hours) buffets(B-Amenity) within(B-Location) 15(I-Location) minutes(I-Location) driving(I-Location) distance(I-Location)"}, "label_list": ["Amenity", "Rating", "Cuisine", "Location", "Restaurant Name", "Price", "Hours", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 19767, 11, 81961, 11, 10067, 11, 26568, 4076, 11, 8650, 11, 30192, 11, 49268, 323, 507, 627, 85664, 25, 602, 1097, 3411, 369, 16163, 11783, 1441, 2949, 220, 868, 4520, 10043, 6138, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "171", "dataset": "crossner_music", "split": "dev", "prediction": "Juliana(B-musical artist) Hatfield(I-musical artist) is(O) an(O) American(O) musician(O) and(O) singer-songwriter(O) from(O) the(O) Boston(B-Location) area(I-Location),(O) formerly(O) of(O) the(O) indie(B-music genre) rock(I-music genre) bands(O) Blake(B-band) Babies(I-band),(O) Some(B-band) Girls(I-band),(O) and(O) The(B-band) Lemonheads(I-band).(O)", "instance": {"id": "171", "words": ["Juliana", "Hatfield", "is", "an", "American", "musician", "and", "singer-songwriter", "from", "the", "Boston", "area", ",", "formerly", "of", "the", "indie", "rock", "bands", "Blake", "Babies", ",", "Some", "Girls", ",", "and", "The", "Lemonheads", "."], "labels": ["B-musical artist", "I-musical artist", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "O", "O", "O", "O", "O", "B-music genre", "O", "B-band", "I-band", "O", "B-band", "I-band", "O", "O", "B-band", "I-band", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, country, person, music genre, album, organization, musical artist, musical instrument, event, award, location, band and O.\nSentence: Juliana Hatfield is an American musician and singer-songwriter from the Boston area , formerly of the indie rock bands Blake Babies , Some Girls , and The Lemonheads .", "prompt_labels": "Juliana(B-musical artist) Hatfield(I-musical artist) is(O) an(O) American(O) musician(O) and(O) singer-songwriter(O) from(O) the(O) Boston(B-location) area(I-location) ,(O) formerly(O) of(O) the(O) indie(O) rock(B-music genre) bands(O) Blake(B-band) Babies(I-band) ,(O) Some(B-band) Girls(I-band) ,(O) and(O) The(B-band) Lemonheads(I-band) .(O)"}, "label_list": ["song", "country", "person", "music genre", "album", "organization", "musical artist", "musical instrument", "event", "award", "location", "band"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 3224, 11, 1732, 11, 4731, 17779, 11, 8176, 11, 7471, 11, 18273, 10255, 11, 18273, 14473, 11, 1567, 11, 10292, 11, 3813, 11, 7200, 323, 507, 627, 85664, 25, 10263, 12699, 22050, 2630, 374, 459, 3778, 39844, 323, 23597, 77740, 18688, 505, 279, 10406, 3158, 1174, 34833, 315, 279, 44578, 7091, 21562, 31994, 93792, 1174, 4427, 20666, 1174, 323, 578, 52310, 36910, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "164", "dataset": "crossner_politics", "split": "dev", "prediction": "The(O) Socialist(B-political party) Party(I-political party) of(I-political party) the(I-political party) United(I-political party) States(I-political party) ((O) SPUS(B-political party) )(O) -(O) its(O) name(O) inspired(O) by(O) co-thinkers(O) in(O) the(O) Socialist(B-political party) Party(I-political party) of(I-political party) Great(I-political party) Britain(I-political party) ((O) SPGB(B-political party) )(O) and(O) the(O) original(O) ((O) non-WSM(B-political party) )(O) Socialist(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) ((O) SPC(B-political party) )(O) -(O) was(O) established(O) on(O) July(O) 7(O),(O) 1916(O) by(O) 42(O) defecting(O) members(O) of(O) Local(O) Detroit(O) of(O) the(O) Socialist(B-political party) Party(I-political party) of(I-political party) America(I-political party) ((O) SPA(B-political party) )(O).(O)", "instance": {"id": "164", "words": ["The", "Socialist", "Party", "of", "the", "United", "States", "(", "SPUS", ")", "-", "its", "name", "inspired", "by", "co-thinkers", "in", "the", "Socialist", "Party", "of", "Great", "Britain", "(", "SPGB", ")", "and", "the", "original", "(", "non-WSM", ")", "Socialist", "Party", "of", "Canada", "(", "SPC", ")", "-", "was", "established", "on", "July", "7", ",", "1916", "by", "42", "defecting", "members", "of", "Local", "Detroit", "of", "the", "Socialist", "Party", "of", "America", "(", "SPA", ")", "."], "labels": ["O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "B-political party", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "B-political party", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "B-political party", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "B-political party", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, event, location, election, country, political party, person, politician and O.\nSentence: The Socialist Party of the United States ( SPUS ) - its name inspired by co-thinkers in the Socialist Party of Great Britain ( SPGB ) and the original ( non-WSM ) Socialist Party of Canada ( SPC ) - was established on July 7 , 1916 by 42 defecting members of Local Detroit of the Socialist Party of America ( SPA ) .", "prompt_labels": "The(O) Socialist(B-political party) Party(I-political party) of(I-political party) the(I-political party) United(I-political party) States(I-political party) ((O) SPUS(B-political party) )(O) -(O) its(O) name(O) inspired(O) by(O) co-thinkers(O) in(O) the(O) Socialist(B-political party) Party(I-political party) of(I-political party) Great(I-political party) Britain(I-political party) ((O) SPGB(B-political party) )(O) and(O) the(O) original(O) ((O) non-WSM(O) )(O) Socialist(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) ((O) SPC(B-political party) )(O) -(O) was(O) established(O) on(O) July(O) 7(O) ,(O) 1916(O) by(O) 42(O) defecting(O) members(O) of(O) Local(B-location) Detroit(I-location) of(O) the(O) Socialist(B-political party) Party(I-political party) of(I-political party) America(I-political party) ((O) SPA(B-political party) )(O) .(O)"}, "label_list": ["organization", "event", "location", "election", "country", "political party", "person", "politician"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 1567, 11, 3813, 11, 6355, 11, 3224, 11, 5054, 4717, 11, 1732, 11, 37038, 323, 507, 627, 85664, 25, 578, 57210, 8722, 315, 279, 3723, 4273, 320, 9440, 2078, 883, 482, 1202, 836, 14948, 555, 1080, 7716, 771, 388, 304, 279, 57210, 8722, 315, 8681, 13527, 320, 9440, 5494, 883, 323, 279, 4113, 320, 2536, 12, 7585, 44, 883, 57210, 8722, 315, 7008, 320, 328, 4977, 883, 482, 574, 9749, 389, 5887, 220, 22, 1174, 220, 7529, 21, 555, 220, 2983, 23011, 287, 3697, 315, 8949, 20344, 315, 279, 57210, 8722, 315, 5270, 320, 77508, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "289", "dataset": "mit-restaurant", "split": "dev", "prediction": "does(O) mcdonalds(B-Restaurant Name) serve(O) ice(B-Dish) cream(I-Dish) during(B-Hours) breakfast(I-Hours) hours(I-Hours)", "instance": {"id": "289", "words": ["does", "mcdonalds", "serve", "ice", "cream", "during", "breakfast", "hours"], "labels": ["O", "B-Restaurant Name", "O", "B-Dish", "I-Dish", "I-Dish", "B-Hours", "I-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Price, Location, Cuisine, Hours, Restaurant Name, Amenity, Dish and O.\nSentence: does mcdonalds serve ice cream during breakfast hours", "prompt_labels": "does(O) mcdonalds(B-Restaurant Name) serve(O) ice(B-Dish) cream(I-Dish) during(I-Dish) breakfast(B-Hours) hours(I-Hours)"}, "label_list": ["Rating", "Price", "Location", "Cuisine", "Hours", "Restaurant Name", "Amenity", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 8650, 11, 10067, 11, 81961, 11, 30192, 11, 26568, 4076, 11, 3383, 56685, 11, 49268, 323, 507, 627, 85664, 25, 1587, 296, 4484, 80794, 82, 8854, 10054, 12932, 2391, 17954, 4207, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1870", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) r(B-rating) rated(O) movie(O) was(O) released(O) this(O) year(O) about(O) the(O) 1960(B-year) s(I-year) that(O) has(O) an(O) eight(B-average ratings) star(I-average ratings) rating(O)", "instance": {"id": "1870", "words": ["what", "r", "rated", "movie", "was", "released", "this", "year", "about", "the", "1960", "s", "that", "has", "an", "eight", "star", "rating"], "labels": ["O", "B-rating", "O", "O", "O", "O", "B-year", "I-year", "O", "O", "B-plot", "I-plot", "O", "O", "O", "B-average ratings", "I-average ratings", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, title, director, rating, song, trailer, average ratings, actor, year, review, genre, character and O.\nSentence: what r rated movie was released this year about the 1960 s that has an eight star rating", "prompt_labels": "what(O) r(B-rating) rated(O) movie(O) was(O) released(O) this(B-year) year(I-year) about(O) the(O) 1960(B-plot) s(I-plot) that(O) has(O) an(O) eight(B-average ratings) star(I-average ratings) rating(O)"}, "label_list": ["plot", "title", "director", "rating", "song", "trailer", "average ratings", "actor", "year", "review", "genre", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 2316, 11, 7690, 11, 10959, 11, 5609, 11, 19809, 11, 5578, 18594, 11, 12360, 11, 1060, 11, 3477, 11, 17779, 11, 3752, 323, 507, 627, 85664, 25, 1148, 436, 22359, 5818, 574, 6004, 420, 1060, 922, 279, 220, 5162, 15, 274, 430, 706, 459, 8223, 6917, 10959, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1044", "dataset": "mit-restaurant", "split": "dev", "prediction": "red(B-Restaurant Name) robins(I-Restaurant Name) restaurant(O)", "instance": {"id": "1044", "words": ["red", "robins", "restaurant"], "labels": ["B-Restaurant Name", "I-Restaurant Name", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Location, Rating, Dish, Cuisine, Price, Amenity, Restaurant Name and O.\nSentence: red robins restaurant", "prompt_labels": "red(B-Restaurant Name) robins(I-Restaurant Name) restaurant(O)"}, "label_list": ["Hours", "Location", "Rating", "Dish", "Cuisine", "Price", "Amenity", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 10067, 11, 19767, 11, 49268, 11, 81961, 11, 8650, 11, 3383, 56685, 11, 26568, 4076, 323, 507, 627, 85664, 25, 2579, 10773, 1354, 10960, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "128", "dataset": "crossner_music", "split": "dev", "prediction": "They(O) restarted(O) to(O) perform(O) live(O) regularly(O),(O) touring(O) the(O) world(O) with(O) rapturous(O) feedbacks(O) :(O) they(O) brought(O) their(O) distinguishable(O) sound(O) in(O) great(O) venues(O) such(O) as(O) the(O) Kings(B-location) Place(I-location) in(O) London(O),(O) the(O) Soma(B-location) Festival(I-location) in(O) Belfast(B-location),(O) the(O) Bolshoi(B-location) Theatre(I-location) in(O) Moscow(B-location) and(O) the(O) Star(B-location) Pine(I-location)'s(I-location) cafe(I-location) in(O) Tokyo(B-location).(O)", "instance": {"id": "128", "words": ["They", "restarted", "to", "perform", "live", "regularly", ",", "touring", "the", "world", "with", "rapturous", "feedbacks", ":", "they", "brought", "their", "distinguishable", "sound", "in", "great", "venues", "such", "as", "the", "Kings", "Place", "in", "London", ",", "the", "Soma", "Festival", "in", "Belfast", ",", "the", "Bolshoi", "Theatre", "in", "Moscow", "and", "the", "Star", "Pine", "'s", "cafe", "in", "Tokyo", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "O", "B-location", "O", "O", "B-event", "I-event", "O", "B-location", "O", "O", "B-location", "I-location", "O", "B-location", "O", "O", "B-location", "I-location", "I-location", "I-location", "O", "B-location", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, musical artist, music genre, album, person, organization, award, musical instrument, event, location, song, band and O.\nSentence: They restarted to perform live regularly , touring the world with rapturous feedbacks : they brought their distinguishable sound in great venues such as the Kings Place in London , the Soma Festival in Belfast , the Bolshoi Theatre in Moscow and the Star Pine 's cafe in Tokyo .", "prompt_labels": "They(O) restarted(O) to(O) perform(O) live(O) regularly(O) ,(O) touring(O) the(O) world(O) with(O) rapturous(O) feedbacks(O) :(O) they(O) brought(O) their(O) distinguishable(O) sound(O) in(O) great(O) venues(O) such(O) as(O) the(O) Kings(B-location) Place(I-location) in(O) London(B-location) ,(O) the(O) Soma(B-event) Festival(I-event) in(O) Belfast(B-location) ,(O) the(O) Bolshoi(B-location) Theatre(I-location) in(O) Moscow(B-location) and(O) the(O) Star(B-location) Pine(I-location) 's(I-location) cafe(I-location) in(O) Tokyo(B-location) .(O)"}, "label_list": ["country", "musical artist", "music genre", "album", "person", "organization", "award", "musical instrument", "event", "location", "song", "band"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 18273, 10255, 11, 4731, 17779, 11, 8176, 11, 1732, 11, 7471, 11, 10292, 11, 18273, 14473, 11, 1567, 11, 3813, 11, 5609, 11, 7200, 323, 507, 627, 85664, 25, 2435, 81754, 311, 2804, 3974, 15870, 1174, 48551, 279, 1917, 449, 436, 2756, 55709, 11302, 82, 551, 814, 7263, 872, 33137, 481, 5222, 304, 2294, 37278, 1778, 439, 279, 24980, 11004, 304, 7295, 1174, 279, 328, 7942, 17772, 304, 55339, 1174, 279, 25007, 939, 6870, 27315, 304, 23223, 323, 279, 7834, 42609, 364, 82, 42030, 304, 27286, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "647", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) want(O) to(O) eat(O) hamburgers(B-Dish)", "instance": {"id": "647", "words": ["i", "want", "to", "eat", "hamburgers"], "labels": ["O", "O", "O", "O", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Dish, Price, Cuisine, Location, Hours, Restaurant Name, Rating and O.\nSentence: i want to eat hamburgers", "prompt_labels": "i(O) want(O) to(O) eat(O) hamburgers(B-Dish)"}, "label_list": ["Amenity", "Dish", "Price", "Cuisine", "Location", "Hours", "Restaurant Name", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 49268, 11, 8650, 11, 81961, 11, 10067, 11, 30192, 11, 26568, 4076, 11, 19767, 323, 507, 627, 85664, 25, 602, 1390, 311, 8343, 57947, 388, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "998", "dataset": "mit-restaurant", "split": "dev", "prediction": "may(O) i(O) have(O) the(O) business(O) hours(O) for(O) the(O) nearest(B-Location) red(B-Restaurant Name) lobster(I-Restaurant Name)", "instance": {"id": "998", "words": ["may", "i", "have", "the", "business", "hours", "for", "the", "nearest", "red", "lobster"], "labels": ["O", "O", "O", "O", "B-Hours", "O", "O", "O", "B-Location", "B-Restaurant Name", "I-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Price, Restaurant Name, Location, Rating, Cuisine, Amenity, Hours and O.\nSentence: may i have the business hours for the nearest red lobster", "prompt_labels": "may(O) i(O) have(O) the(O) business(B-Hours) hours(O) for(O) the(O) nearest(B-Location) red(B-Restaurant Name) lobster(I-Restaurant Name)"}, "label_list": ["Dish", "Price", "Restaurant Name", "Location", "Rating", "Cuisine", "Amenity", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 8650, 11, 26568, 4076, 11, 10067, 11, 19767, 11, 81961, 11, 3383, 56685, 11, 30192, 323, 507, 627, 85664, 25, 1253, 602, 617, 279, 2626, 4207, 369, 279, 24379, 2579, 80815, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "479", "dataset": "mit-restaurant", "split": "dev", "prediction": "help(O) me(O) find(O) a(O) good(B-Rating) place(O) to(O) eat(O)", "instance": {"id": "479", "words": ["help", "me", "find", "a", "good", "place", "to", "eat"], "labels": ["O", "O", "O", "O", "B-Rating", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Restaurant Name, Rating, Dish, Price, Amenity, Hours, Location and O.\nSentence: help me find a good place to eat", "prompt_labels": "help(O) me(O) find(O) a(O) good(B-Rating) place(O) to(O) eat(O)"}, "label_list": ["Cuisine", "Restaurant Name", "Rating", "Dish", "Price", "Amenity", "Hours", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 26568, 4076, 11, 19767, 11, 49268, 11, 8650, 11, 3383, 56685, 11, 30192, 11, 10067, 323, 507, 627, 85664, 25, 1520, 757, 1505, 264, 1695, 2035, 311, 8343, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "194", "dataset": "mit-movie", "split": "dev", "prediction": "when(O) did(O) runaway(B-title) jury(I-title) come(O) out(O)", "instance": {"id": "194", "words": ["when", "did", "runaway", "jury", "come", "out"], "labels": ["O", "O", "B-title", "I-title", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, title, average ratings, trailer, plot, genre, song, review, actor, character, director, year and O.\nSentence: when did runaway jury come out", "prompt_labels": "when(O) did(O) runaway(B-title) jury(I-title) come(O) out(O)"}, "label_list": ["rating", "title", "average ratings", "trailer", "plot", "genre", "song", "review", "actor", "character", "director", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 2316, 11, 5578, 18594, 11, 19809, 11, 7234, 11, 17779, 11, 5609, 11, 3477, 11, 12360, 11, 3752, 11, 7690, 11, 1060, 323, 507, 627, 85664, 25, 994, 1550, 91740, 21928, 2586, 704, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "77", "dataset": "crossner_politics", "split": "dev", "prediction": "In(O) recent(O) years(O),(O) the(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) of(I-political party) Canada(I-political party) has(O) had(O) the(O) most(O) success(O) in(O) the(O) city(O) :(O) its(O) members(O) were(O) elected(O) in(O) all(O) but(O) four(O) elections(O) since(O) 1953(O) :(O) 1974(B-election) Canadian(I-election) federal(I-election) election(I-election),(O) 1980(B-election) Canadian(I-election) federal(I-election) election(I-election),(O) 2004(B-election) Canadian(I-election) federal(I-election) election(I-election),(O) and(O) 2006(B-election) Canadian(I-election) federal(I-election) election(I-election).(O)", "instance": {"id": "77", "words": ["In", "recent", "years", ",", "the", "Progressive", "Conservative", "Party", "of", "Canada", "has", "had", "the", "most", "success", "in", "the", "city", ":", "its", "members", "were", "elected", "in", "all", "but", "four", "elections", "since", "1953", ":", "1974", "Canadian", "federal", "election", ",", "1980", "Canadian", "federal", "election", ",", "2004", "Canadian", "federal", "election", ",", "and", "2006", "Canadian", "federal", "election", "."], "labels": ["O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, country, organization, person, location, political party, election, event and O.\nSentence: In recent years , the Progressive Conservative Party of Canada has had the most success in the city : its members were elected in all but four elections since 1953 : 1974 Canadian federal election , 1980 Canadian federal election , 2004 Canadian federal election , and 2006 Canadian federal election .", "prompt_labels": "In(O) recent(O) years(O) ,(O) the(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) of(I-political party) Canada(I-political party) has(O) had(O) the(O) most(O) success(O) in(O) the(O) city(O) :(O) its(O) members(O) were(O) elected(O) in(O) all(O) but(O) four(O) elections(O) since(O) 1953(O) :(O) 1974(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) 1980(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) 2004(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) and(O) 2006(B-election) Canadian(I-election) federal(I-election) election(I-election) .(O)"}, "label_list": ["politician", "country", "organization", "person", "location", "political party", "election", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 37038, 11, 3224, 11, 7471, 11, 1732, 11, 3813, 11, 5054, 4717, 11, 6355, 11, 1567, 323, 507, 627, 85664, 25, 763, 3293, 1667, 1174, 279, 52870, 30071, 8722, 315, 7008, 706, 1047, 279, 1455, 2450, 304, 279, 3363, 551, 1202, 3697, 1051, 16689, 304, 682, 719, 3116, 16374, 2533, 220, 6280, 18, 551, 220, 4468, 19, 12152, 6918, 6355, 1174, 220, 3753, 15, 12152, 6918, 6355, 1174, 220, 1049, 19, 12152, 6918, 6355, 1174, 323, 220, 1049, 21, 12152, 6918, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "52", "dataset": "mit-restaurant", "split": "dev", "prediction": "are(O) there(O) any(O) japanese(B-Cuisine) restaurants(O) in(O) town(B-Location) that(O) do(O) discounts(B-Amenity) for(O) bulk(B-Amenity) orders(I-Amenity) of(O) sushi(B-Dish)", "instance": {"id": "52", "words": ["are", "there", "any", "japanese", "restaurants", "in", "town", "that", "do", "discounts", "for", "bulk", "orders", "of", "sushi"], "labels": ["O", "O", "O", "B-Cuisine", "O", "B-Location", "I-Location", "O", "O", "B-Amenity", "I-Amenity", "I-Amenity", "I-Amenity", "O", "B-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Dish, Location, Restaurant Name, Rating, Price, Hours, Amenity and O.\nSentence: are there any japanese restaurants in town that do discounts for bulk orders of sushi", "prompt_labels": "are(O) there(O) any(O) japanese(B-Cuisine) restaurants(O) in(B-Location) town(I-Location) that(O) do(O) discounts(B-Amenity) for(I-Amenity) bulk(I-Amenity) orders(I-Amenity) of(O) sushi(B-Amenity)"}, "label_list": ["Cuisine", "Dish", "Location", "Restaurant Name", "Rating", "Price", "Hours", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 49268, 11, 10067, 11, 26568, 4076, 11, 19767, 11, 8650, 11, 30192, 11, 3383, 56685, 323, 507, 627, 85664, 25, 527, 1070, 904, 54048, 15926, 304, 6424, 430, 656, 32162, 369, 20155, 10373, 315, 67322, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
