{"id": "82", "dataset": "crossner_ai", "split": "dev", "prediction": "Researchers(O) have(O) attempted(O) a(O) number(O) of(O) methods(O) such(O) as(O) optical(B-algorithm) flow(I-algorithm),(O) Kalman(B-algorithm) filtering(I-algorithm),(O) Hidden(B-algorithm) Markov(I-algorithm) model(I-algorithm) s(I-algorithm),(O) etc(O).(O)", "instance": {"id": "82", "words": ["Researchers", "have", "attempted", "a", "number", "of", "methods", "such", "as", "optical", "flow", ",", "Kalman", "filtering", ",", "Hidden", "Markov", "model", "s", ",", "etc", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-algorithm", "I-algorithm", "O", "B-algorithm", "I-algorithm", "O", "B-algorithm", "I-algorithm", "I-algorithm", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, field, task, researcher, location, country, product, programming language, metric, algorithm, conference, person, university and O.\nSentence: Researchers have attempted a number of methods such as optical flow , Kalman filtering , Hidden Markov model s , etc .", "prompt_labels": "Researchers(O) have(O) attempted(O) a(O) number(O) of(O) methods(O) such(O) as(O) optical(B-algorithm) flow(I-algorithm) ,(O) Kalman(B-algorithm) filtering(I-algorithm) ,(O) Hidden(B-algorithm) Markov(I-algorithm) model(I-algorithm) s(O) ,(O) etc(O) .(O)"}, "label_list": ["organization", "field", "task", "researcher", "location", "country", "product", "programming language", "metric", "algorithm", "conference", "person", "university"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 2115, 11, 3465, 11, 32185, 11, 3813, 11, 3224, 11, 2027, 11, 15840, 4221, 11, 18767, 11, 12384, 11, 10017, 11, 1732, 11, 12374, 323, 507, 627, 85664, 25, 59250, 617, 17644, 264, 1396, 315, 5528, 1778, 439, 29393, 6530, 1174, 27930, 1543, 30770, 1174, 35342, 4488, 869, 1646, 274, 1174, 5099, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "778", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) santa(B-Restaurant Name) ramen(I-Restaurant Name) in(O) san(B-Location) mateo(I-Location) busy(B-Amenity) on(B-Hours) thursday(I-Hours) nights(I-Hours)", "instance": {"id": "778", "words": ["is", "santa", "ramen", "in", "san", "mateo", "busy", "on", "thursday", "nights"], "labels": ["O", "B-Restaurant Name", "I-Restaurant Name", "O", "B-Location", "I-Location", "O", "O", "B-Hours", "I-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Dish, Amenity, Rating, Cuisine, Restaurant Name, Price, Location and O.\nSentence: is santa ramen in san mateo busy on thursday nights", "prompt_labels": "is(O) santa(B-Restaurant Name) ramen(I-Restaurant Name) in(O) san(B-Location) mateo(I-Location) busy(O) on(O) thursday(B-Hours) nights(I-Hours)"}, "label_list": ["Hours", "Dish", "Amenity", "Rating", "Cuisine", "Restaurant Name", "Price", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 49268, 11, 3383, 56685, 11, 19767, 11, 81961, 11, 26568, 4076, 11, 8650, 11, 10067, 323, 507, 627, 85664, 25, 374, 72851, 123537, 304, 8528, 30276, 78, 13326, 389, 270, 7329, 22178, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "264", "dataset": "crossner_literature", "split": "dev", "prediction": "Ireland(B-country)'s(O) 1990(B-event) FIFA(I-event) World(I-event) Cup(I-event) Group(I-event) F(I-event) opponents(I-event) in(O) Italy(B-country) '(O) 90(O) were(O) England(B-country),(O) Egypt(B-country) and(O) the(O) Netherlands(B-country).(O)", "instance": {"id": "264", "words": ["Ireland", "'s", "1990", "FIFA", "World", "Cup", "Group", "F", "opponents", "in", "Italy", "'", "90", "were", "England", ",", "Egypt", "and", "the", "Netherlands", "."], "labels": ["B-country", "O", "B-event", "I-event", "I-event", "I-event", "I-event", "I-event", "O", "O", "B-country", "O", "O", "O", "B-country", "O", "B-country", "O", "O", "B-country", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, book, country, event, poem, magazine, location, writer, award, person, organization and O.\nSentence: Ireland 's 1990 FIFA World Cup Group F opponents in Italy ' 90 were England , Egypt and the Netherlands .", "prompt_labels": "Ireland(B-country) 's(O) 1990(B-event) FIFA(I-event) World(I-event) Cup(I-event) Group(I-event) F(I-event) opponents(O) in(O) Italy(B-country) '(O) 90(O) were(O) England(B-country) ,(O) Egypt(B-country) and(O) the(O) Netherlands(B-country) .(O)"}, "label_list": ["literary genre", "book", "country", "event", "poem", "magazine", "location", "writer", "award", "person", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 32465, 17779, 11, 2363, 11, 3224, 11, 1567, 11, 33894, 11, 14756, 11, 3813, 11, 7061, 11, 10292, 11, 1732, 11, 7471, 323, 507, 627, 85664, 25, 14990, 364, 82, 220, 2550, 15, 44742, 4435, 11098, 5856, 435, 19949, 304, 15704, 364, 220, 1954, 1051, 9635, 1174, 15212, 323, 279, 26746, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1228", "dataset": "mit-movie", "split": "dev", "prediction": "does(O) julia(B-actor) roberts(I-actor) have(O) a(O) voice(O) in(O) wall(B-title) e(I-title)", "instance": {"id": "1228", "words": ["does", "julia", "roberts", "have", "a", "voice", "in", "wall", "e"], "labels": ["O", "B-actor", "I-actor", "O", "O", "O", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, average ratings, rating, genre, title, director, song, plot, actor, trailer, review, year and O.\nSentence: does julia roberts have a voice in wall e", "prompt_labels": "does(O) julia(B-actor) roberts(I-actor) have(O) a(O) voice(O) in(O) wall(B-title) e(I-title)"}, "label_list": ["character", "average ratings", "rating", "genre", "title", "director", "song", "plot", "actor", "trailer", "review", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 5578, 18594, 11, 10959, 11, 17779, 11, 2316, 11, 7690, 11, 5609, 11, 7234, 11, 12360, 11, 19809, 11, 3477, 11, 1060, 323, 507, 627, 85664, 25, 1587, 41638, 689, 89993, 82, 617, 264, 7899, 304, 7147, 384, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1605", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) a(O) chick(B-genre) film(O) in(O) the(O) past(B-year) ten(I-year) decades(I-year)", "instance": {"id": "1605", "words": ["list", "a", "chick", "film", "in", "the", "past", "ten", "decades"], "labels": ["O", "O", "B-genre", "O", "O", "O", "B-year", "I-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, rating, song, review, title, plot, genre, year, trailer, average ratings, director, character and O.\nSentence: list a chick film in the past ten decades", "prompt_labels": "list(O) a(O) chick(B-genre) film(O) in(O) the(O) past(B-year) ten(I-year) decades(I-year)"}, "label_list": ["actor", "rating", "song", "review", "title", "plot", "genre", "year", "trailer", "average ratings", "director", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 10959, 11, 5609, 11, 3477, 11, 2316, 11, 7234, 11, 17779, 11, 1060, 11, 19809, 11, 5578, 18594, 11, 7690, 11, 3752, 323, 507, 627, 85664, 25, 1160, 264, 31863, 4632, 304, 279, 3347, 5899, 11026, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "872", "dataset": "mit-movie", "split": "dev", "prediction": "are(O) there(O) any(O) movies(O) about(O) the(O) korean(B-plot) war(I-plot)", "instance": {"id": "872", "words": ["are", "there", "any", "movies", "about", "the", "korean", "war"], "labels": ["O", "O", "O", "O", "O", "O", "B-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, director, trailer, year, actor, rating, title, song, genre, character, average ratings, plot and O.\nSentence: are there any movies about the korean war", "prompt_labels": "are(O) there(O) any(O) movies(O) about(O) the(O) korean(B-plot) war(I-plot)"}, "label_list": ["review", "director", "trailer", "year", "actor", "rating", "title", "song", "genre", "character", "average ratings", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 7690, 11, 19809, 11, 1060, 11, 12360, 11, 10959, 11, 2316, 11, 5609, 11, 17779, 11, 3752, 11, 5578, 18594, 11, 7234, 323, 507, 627, 85664, 25, 527, 1070, 904, 9698, 922, 279, 597, 46295, 4208, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2140", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movie(O) is(O) known(O) as(O) oliver(B-director) stones(I-director) best(O) work(O)", "instance": {"id": "2140", "words": ["what", "movie", "is", "known", "as", "oliver", "stones", "best", "work"], "labels": ["O", "O", "O", "O", "O", "B-director", "I-director", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, rating, review, year, song, title, average ratings, actor, genre, director, trailer, plot and O.\nSentence: what movie is known as oliver stones best work", "prompt_labels": "what(O) movie(O) is(O) known(O) as(O) oliver(B-director) stones(I-director) best(O) work(O)"}, "label_list": ["character", "rating", "review", "year", "song", "title", "average ratings", "actor", "genre", "director", "trailer", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 10959, 11, 3477, 11, 1060, 11, 5609, 11, 2316, 11, 5578, 18594, 11, 12360, 11, 17779, 11, 7690, 11, 19809, 11, 7234, 323, 507, 627, 85664, 25, 1148, 5818, 374, 3967, 439, 8492, 1553, 27302, 1888, 990, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "199", "dataset": "crossner_ai", "split": "dev", "prediction": "The(O) term(O) Semantic(B-field) Web(I-field) was(O) coined(O) by(O) Tim(B-researcher) Berners-Lee(I-researcher),(O) the(O) inventor(O) of(O) the(O) World(B-product) Wide(I-product) Web(I-product) and(O) director(O) of(O) the(O) World(B-organization) Wide(I-organization) Web(I-organization) Consortium(I-organization) ((O) W3C(B-organization) )(O),(O) which(O) oversees(O) the(O) development(O) of(O) proposed(O) Semantic(B-metric) Web(I-metric) standards(O).(O)", "instance": {"id": "199", "words": ["The", "term", "Semantic", "Web", "was", "coined", "by", "Tim", "Berners-Lee", ",", "the", "inventor", "of", "the", "World", "Wide", "Web", "and", "director", "of", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "which", "oversees", "the", "development", "of", "proposed", "Semantic", "Web", "standards", "."], "labels": ["O", "O", "B-product", "I-product", "O", "O", "O", "B-researcher", "I-researcher", "O", "O", "O", "O", "O", "B-product", "I-product", "I-product", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "O", "O", "O", "O", "O", "O", "O", "O", "B-product", "I-product", "I-product", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, task, conference, location, university, metric, person, field, country, organization, algorithm, researcher, product and O.\nSentence: The term Semantic Web was coined by Tim Berners-Lee , the inventor of the World Wide Web and director of the World Wide Web Consortium ( W3C ) , which oversees the development of proposed Semantic Web standards .", "prompt_labels": "The(O) term(O) Semantic(B-product) Web(I-product) was(O) coined(O) by(O) Tim(B-researcher) Berners-Lee(I-researcher) ,(O) the(O) inventor(O) of(O) the(O) World(B-product) Wide(I-product) Web(I-product) and(O) director(O) of(O) the(O) World(B-organization) Wide(I-organization) Web(I-organization) Consortium(I-organization) ((O) W3C(B-organization) )(O) ,(O) which(O) oversees(O) the(O) development(O) of(O) proposed(O) Semantic(B-product) Web(I-product) standards(I-product) .(O)"}, "label_list": ["programming language", "task", "conference", "location", "university", "metric", "person", "field", "country", "organization", "algorithm", "researcher", "product"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 15840, 4221, 11, 3465, 11, 10017, 11, 3813, 11, 12374, 11, 18767, 11, 1732, 11, 2115, 11, 3224, 11, 7471, 11, 12384, 11, 32185, 11, 2027, 323, 507, 627, 85664, 25, 578, 4751, 75433, 5000, 574, 78718, 555, 9538, 14502, 388, 8288, 2176, 1174, 279, 72001, 315, 279, 4435, 33845, 5000, 323, 7690, 315, 279, 4435, 33845, 5000, 73547, 320, 468, 18, 34, 883, 1174, 902, 71945, 279, 4500, 315, 11223, 75433, 5000, 10886, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "329", "dataset": "crossner_politics", "split": "dev", "prediction": "Alex(B-politician) T.(I-politician) Atamanenko(I-politician) MP(O) ((O) born(O) January(O) 24(O),(O) 1945(O) )(O) is(O) a(O) Canadian(O) politician(O),(O) who(O) was(O) elected(O) to(O) the(O) House(B-location) of(I-location) Commons(I-location) in(O) 2006(O),(O) winning(O) the(O) riding(O) of(O) British(B-location) Columbia(I-location) Southern(I-location) Interior(I-location) for(O) the(O) New(B-political party) Democratic(I-political party) Party(I-political party) in(O) the(O) 2006(B-election) Canadian(I-election) federal(I-election) election(I-election),(O) and(O) served(O) in(O) parliament(O) until(O) his(O) retirement(O) at(O) the(O) 2015(B-election) Canadian(I-election) federal(I-election) election(I-election).(O)", "instance": {"id": "329", "words": ["Alex", "T.", "Atamanenko", "MP", "(", "born", "January", "24", ",", "1945", ")", "is", "a", "Canadian", "politician", ",", "who", "was", "elected", "to", "the", "House", "of", "Commons", "in", "2006", ",", "winning", "the", "riding", "of", "British", "Columbia", "Southern", "Interior", "for", "the", "New", "Democratic", "Party", "in", "the", "2006", "Canadian", "federal", "election", ",", "and", "served", "in", "parliament", "until", "his", "retirement", "at", "the", "2015", "Canadian", "federal", "election", "."], "labels": ["B-politician", "I-politician", "I-politician", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-political party", "I-political party", "I-political party", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, politician, person, country, location, organization, political party, event and O.\nSentence: Alex T. Atamanenko MP ( born January 24 , 1945 ) is a Canadian politician , who was elected to the House of Commons in 2006 , winning the riding of British Columbia Southern Interior for the New Democratic Party in the 2006 Canadian federal election , and served in parliament until his retirement at the 2015 Canadian federal election .", "prompt_labels": "Alex(B-politician) T.(I-politician) Atamanenko(I-politician) MP(O) ((O) born(O) January(O) 24(O) ,(O) 1945(O) )(O) is(O) a(O) Canadian(O) politician(O) ,(O) who(O) was(O) elected(O) to(O) the(O) House(B-organization) of(I-organization) Commons(I-organization) in(O) 2006(O) ,(O) winning(O) the(O) riding(O) of(O) British(B-organization) Columbia(I-organization) Southern(I-organization) Interior(I-organization) for(O) the(O) New(B-political party) Democratic(I-political party) Party(I-political party) in(O) the(O) 2006(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) and(O) served(O) in(O) parliament(O) until(O) his(O) retirement(O) at(O) the(O) 2015(B-election) Canadian(I-election) federal(I-election) election(I-election) .(O)"}, "label_list": ["election", "politician", "person", "country", "location", "organization", "political party", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 6355, 11, 37038, 11, 1732, 11, 3224, 11, 3813, 11, 7471, 11, 5054, 4717, 11, 1567, 323, 507, 627, 85664, 25, 8683, 350, 13, 2468, 13005, 56155, 9599, 320, 9405, 6186, 220, 1187, 1174, 220, 6393, 20, 883, 374, 264, 12152, 37038, 1174, 889, 574, 16689, 311, 279, 4783, 315, 26667, 304, 220, 1049, 21, 1174, 11230, 279, 20427, 315, 8013, 19326, 16642, 29958, 369, 279, 1561, 11650, 8722, 304, 279, 220, 1049, 21, 12152, 6918, 6355, 1174, 323, 10434, 304, 21814, 3156, 813, 21624, 520, 279, 220, 679, 20, 12152, 6918, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "257", "dataset": "crossner_ai", "split": "dev", "prediction": "Sub-domains(O) of(O) computer(B-field) vision(I-field) include(O) scene(B-field) reconstruction(I-field),(O) event(B-field) detection(I-field),(O) video(B-field) tracking(I-field),(O) object(B-field) recognition(I-field),(O) 3D(B-field) pose(I-field) estimation(I-field),(O) learning(B-field),(O) indexing(B-field),(O) motion(B-field) estimation(I-field),(O) visual(B-field) servoing(I-field),(O) 3D(I-field) scene(I-field) modeling(I-field),(O) and(O) image(B-field) restoration(I-field).(O)", "instance": {"id": "257", "words": ["Sub-domains", "of", "computer", "vision", "include", "scene", "reconstruction", ",", "event", "detection", ",", "video", "tracking", ",", "object", "recognition", ",", "3D", "pose", "estimation", ",", "learning", ",", "indexing", ",", "motion", "estimation", ",", "visual", "servoing", ",", "3D", "scene", "modeling", ",", "and", "image", "restoration", "."], "labels": ["O", "O", "B-field", "I-field", "O", "B-task", "I-task", "O", "B-task", "I-task", "O", "B-task", "I-task", "O", "B-task", "I-task", "O", "B-task", "I-task", "I-task", "O", "B-task", "O", "B-task", "O", "B-task", "I-task", "O", "B-task", "I-task", "O", "B-task", "I-task", "I-task", "O", "O", "B-task", "I-task", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, task, country, field, programming language, conference, product, metric, organization, researcher, university, algorithm, person and O.\nSentence: Sub-domains of computer vision include scene reconstruction , event detection , video tracking , object recognition , 3D pose estimation , learning , indexing , motion estimation , visual servoing , 3D scene modeling , and image restoration .", "prompt_labels": "Sub-domains(O) of(O) computer(B-field) vision(I-field) include(O) scene(B-task) reconstruction(I-task) ,(O) event(B-task) detection(I-task) ,(O) video(B-task) tracking(I-task) ,(O) object(B-task) recognition(I-task) ,(O) 3D(B-task) pose(I-task) estimation(I-task) ,(O) learning(B-task) ,(O) indexing(B-task) ,(O) motion(B-task) estimation(I-task) ,(O) visual(B-task) servoing(I-task) ,(O) 3D(B-task) scene(I-task) modeling(I-task) ,(O) and(O) image(B-task) restoration(I-task) .(O)"}, "label_list": ["location", "task", "country", "field", "programming language", "conference", "product", "metric", "organization", "researcher", "university", "algorithm", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 3465, 11, 3224, 11, 2115, 11, 15840, 4221, 11, 10017, 11, 2027, 11, 18767, 11, 7471, 11, 32185, 11, 12374, 11, 12384, 11, 1732, 323, 507, 627, 85664, 25, 3804, 14766, 1771, 315, 6500, 11376, 2997, 6237, 43738, 1174, 1567, 18468, 1174, 2835, 15194, 1174, 1665, 18324, 1174, 220, 18, 35, 17477, 42304, 1174, 6975, 1174, 53080, 1174, 11633, 42304, 1174, 9302, 59412, 287, 1174, 220, 18, 35, 6237, 34579, 1174, 323, 2217, 35093, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "884", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) a(O) white(B-Restaurant Name) castle(I-Restaurant Name) on(O) berkeley(B-Location) avenue(I-Location)", "instance": {"id": "884", "words": ["is", "there", "a", "white", "castle", "on", "berkeley", "avenue"], "labels": ["O", "O", "O", "B-Restaurant Name", "I-Restaurant Name", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Location, Cuisine, Rating, Amenity, Restaurant Name, Hours, Dish and O.\nSentence: is there a white castle on berkeley avenue", "prompt_labels": "is(O) there(O) a(O) white(B-Restaurant Name) castle(I-Restaurant Name) on(O) berkeley(B-Location) avenue(I-Location)"}, "label_list": ["Price", "Location", "Cuisine", "Rating", "Amenity", "Restaurant Name", "Hours", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 10067, 11, 81961, 11, 19767, 11, 3383, 56685, 11, 26568, 4076, 11, 30192, 11, 49268, 323, 507, 627, 85664, 25, 374, 1070, 264, 4251, 33684, 389, 10418, 28399, 62803, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "107", "dataset": "crossner_politics", "split": "dev", "prediction": "The(O) following(O) parties(O) have(O) won(O) the(O) special(O) seats(O) reserved(O) for(O) national(O) minority(O) representatives(O) ((O) also(O) in(O) alphabetical(O) order(O) )(O) :(O) the(O) Bosnian(B-political party) Democratic(I-political party) Party(I-political party) of(I-political party) Croatia(I-political party),(O) the(O) Democratic(B-political party) Union(I-political party) of(I-political party) Hungarians(I-political party) of(I-political party) Croatia(I-political party),(O) the(O) German(B-political party) People(I-political party)'s(I-political party) Union(I-political party) -(I-political party) National(I-political party) Association(I-political party) of(I-political party) Danube(I-political party) Swabians(I-political party) in(O) Croatia(B-location),(O) the(O) Independent(B-political party) Democratic(I-political party) Serb(I-political party) Party(I-political party),(O) the(O) Party(B-political party) of(I-political party) Democratic(I-political party) Action(I-political party) of(I-political party) Croatia(I-political party) and(O) the(O) Serb(B-political party) People(I-political party)'s(I-political party) Party(I-political party).(O)", "instance": {"id": "107", "words": ["The", "following", "parties", "have", "won", "the", "special", "seats", "reserved", "for", "national", "minority", "representatives", "(", "also", "in", "alphabetical", "order", ")", ":", "the", "Bosnian", "Democratic", "Party", "of", "Croatia", ",", "the", "Democratic", "Union", "of", "Hungarians", "of", "Croatia", ",", "the", "German", "People", "'s", "Union", "-", "National", "Association", "of", "Danube", "Swabians", "in", "Croatia", ",", "the", "Independent", "Democratic", "Serb", "Party", ",", "the", "Party", "of", "Democratic", "Action", "of", "Croatia", "and", "the", "Serb", "People", "'s", "Party", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, politician, location, organization, election, country, event, person and O.\nSentence: The following parties have won the special seats reserved for national minority representatives ( also in alphabetical order ) : the Bosnian Democratic Party of Croatia , the Democratic Union of Hungarians of Croatia , the German People 's Union - National Association of Danube Swabians in Croatia , the Independent Democratic Serb Party , the Party of Democratic Action of Croatia and the Serb People 's Party .", "prompt_labels": "The(O) following(O) parties(O) have(O) won(O) the(O) special(O) seats(O) reserved(O) for(O) national(O) minority(O) representatives(O) ((O) also(O) in(O) alphabetical(O) order(O) )(O) :(O) the(O) Bosnian(B-political party) Democratic(I-political party) Party(I-political party) of(I-political party) Croatia(I-political party) ,(O) the(O) Democratic(B-political party) Union(I-political party) of(I-political party) Hungarians(I-political party) of(I-political party) Croatia(I-political party) ,(O) the(O) German(B-political party) People(I-political party) 's(I-political party) Union(I-political party) -(I-political party) National(I-political party) Association(I-political party) of(I-political party) Danube(I-political party) Swabians(I-political party) in(I-political party) Croatia(I-political party) ,(O) the(O) Independent(B-political party) Democratic(I-political party) Serb(I-political party) Party(I-political party) ,(O) the(O) Party(B-political party) of(I-political party) Democratic(I-political party) Action(I-political party) of(I-political party) Croatia(I-political party) and(O) the(O) Serb(B-political party) People(I-political party) 's(I-political party) Party(I-political party) .(O)"}, "label_list": ["political party", "politician", "location", "organization", "election", "country", "event", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5054, 4717, 11, 37038, 11, 3813, 11, 7471, 11, 6355, 11, 3224, 11, 1567, 11, 1732, 323, 507, 627, 85664, 25, 578, 2768, 9875, 617, 2834, 279, 3361, 16712, 4694, 369, 5426, 23413, 24005, 320, 1101, 304, 84398, 2015, 883, 551, 279, 29071, 77, 1122, 11650, 8722, 315, 58311, 1174, 279, 11650, 9323, 315, 26604, 30627, 315, 58311, 1174, 279, 6063, 9029, 364, 82, 9323, 482, 5165, 10229, 315, 11824, 3845, 4593, 370, 5493, 304, 58311, 1174, 279, 22765, 11650, 8409, 65, 8722, 1174, 279, 8722, 315, 11650, 5703, 315, 58311, 323, 279, 8409, 65, 9029, 364, 82, 8722, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "281", "dataset": "crossner_literature", "split": "dev", "prediction": "Meanwhile(O),(O) Housman(B-writer) pursued(O) his(O) classical(O) studies(O) independently(O),(O) and(O) published(O) scholarly(O) articles(O) on(O) Horace(B-writer),(O) Propertius(B-writer),(O) Ovid(B-writer),(O) Aeschylus(B-writer),(O) Euripides(B-writer) and(O) Sophocles(B-writer).ref(O) Name(O) =(O) Poets(O) /(O) He(O) also(O) completed(O) an(O) edition(O) of(O) Propertius(B-writer),(O) which(O) however(O) was(O) rejected(O) by(O) both(O) Oxford(B-organization) University(I-organization) Press(I-organization) and(O) Macmillan(B-organization) in(O) 1885(O),(O) and(O) was(O) destroyed(O) after(O) his(O) death(O).(O)", "instance": {"id": "281", "words": ["Meanwhile", ",", "Housman", "pursued", "his", "classical", "studies", "independently", ",", "and", "published", "scholarly", "articles", "on", "Horace", ",", "Propertius", ",", "Ovid", ",", "Aeschylus", ",", "Euripides", "and", "Sophocles", ".ref", "Name", "=", "Poets", "/", "He", "also", "completed", "an", "edition", "of", "Propertius", ",", "which", "however", "was", "rejected", "by", "both", "Oxford", "University", "Press", "and", "Macmillan", "in", "1885", ",", "and", "was", "destroyed", "after", "his", "death", "."], "labels": ["O", "O", "B-writer", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-writer", "O", "B-writer", "O", "B-writer", "O", "B-writer", "O", "B-writer", "O", "B-writer", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-writer", "O", "O", "O", "O", "O", "O", "O", "B-magazine", "I-magazine", "I-magazine", "O", "B-magazine", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, book, award, country, writer, literary genre, poem, magazine, location, organization, event and O.\nSentence: Meanwhile , Housman pursued his classical studies independently , and published scholarly articles on Horace , Propertius , Ovid , Aeschylus , Euripides and Sophocles .ref Name = Poets / He also completed an edition of Propertius , which however was rejected by both Oxford University Press and Macmillan in 1885 , and was destroyed after his death .", "prompt_labels": "Meanwhile(O) ,(O) Housman(B-writer) pursued(O) his(O) classical(O) studies(O) independently(O) ,(O) and(O) published(O) scholarly(O) articles(O) on(O) Horace(B-writer) ,(O) Propertius(B-writer) ,(O) Ovid(B-writer) ,(O) Aeschylus(B-writer) ,(O) Euripides(B-writer) and(O) Sophocles(B-writer) .ref(O) Name(O) =(O) Poets(O) /(O) He(O) also(O) completed(O) an(O) edition(O) of(O) Propertius(B-writer) ,(O) which(O) however(O) was(O) rejected(O) by(O) both(O) Oxford(B-magazine) University(I-magazine) Press(I-magazine) and(O) Macmillan(B-magazine) in(O) 1885(O) ,(O) and(O) was(O) destroyed(O) after(O) his(O) death(O) .(O)"}, "label_list": ["person", "book", "award", "country", "writer", "literary genre", "poem", "magazine", "location", "organization", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 2363, 11, 10292, 11, 3224, 11, 7061, 11, 32465, 17779, 11, 33894, 11, 14756, 11, 3813, 11, 7471, 11, 1567, 323, 507, 627, 85664, 25, 26982, 1174, 473, 788, 1543, 46531, 813, 29924, 7978, 29235, 1174, 323, 4756, 63681, 9908, 389, 15083, 580, 1174, 3998, 531, 9334, 1174, 507, 1325, 1174, 362, 60478, 4010, 355, 1174, 85477, 575, 3422, 323, 34940, 511, 645, 662, 1116, 4076, 284, 14128, 1441, 611, 1283, 1101, 8308, 459, 14002, 315, 3998, 531, 9334, 1174, 902, 4869, 574, 18010, 555, 2225, 26275, 3907, 8612, 323, 7553, 26064, 276, 304, 220, 9367, 20, 1174, 323, 574, 14763, 1306, 813, 4648, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "231", "dataset": "crossner_music", "split": "dev", "prediction": "Soca(B-music genre) is(O) an(O) offshoot(O) of(O) kaiso(B-music genre) /(O) Calypso(B-music genre) music(O),(O) with(O) influences(O) from(O) Music(O) of(O) Latin(B-music genre) America(I-music genre),(O) Cadence(B-music genre) rampa(I-music genre),(O) funk(B-music genre) and(O) Soul(B-music genre) music(O).(O)", "instance": {"id": "231", "words": ["Soca", "is", "an", "offshoot", "of", "kaiso", "/", "Calypso", "music", ",", "with", "influences", "from", "Music", "of", "Latin", "America", ",", "Cadence", "rampa", ",", "funk", "and", "Soul", "music", "."], "labels": ["B-music genre", "O", "O", "O", "O", "B-music genre", "O", "B-music genre", "I-music genre", "O", "O", "O", "O", "B-music genre", "I-music genre", "I-music genre", "I-music genre", "O", "B-music genre", "I-music genre", "O", "B-music genre", "O", "B-music genre", "I-music genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, album, musical artist, award, event, person, song, band, location, country, organization, musical instrument and O.\nSentence: Soca is an offshoot of kaiso / Calypso music , with influences from Music of Latin America , Cadence rampa , funk and Soul music .", "prompt_labels": "Soca(B-music genre) is(O) an(O) offshoot(O) of(O) kaiso(B-music genre) /(O) Calypso(B-music genre) music(I-music genre) ,(O) with(O) influences(O) from(O) Music(B-music genre) of(I-music genre) Latin(I-music genre) America(I-music genre) ,(O) Cadence(B-music genre) rampa(I-music genre) ,(O) funk(B-music genre) and(O) Soul(B-music genre) music(I-music genre) .(O)"}, "label_list": ["music genre", "album", "musical artist", "award", "event", "person", "song", "band", "location", "country", "organization", "musical instrument"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 4731, 17779, 11, 8176, 11, 18273, 10255, 11, 10292, 11, 1567, 11, 1732, 11, 5609, 11, 7200, 11, 3813, 11, 3224, 11, 7471, 11, 18273, 14473, 323, 507, 627, 85664, 25, 328, 17270, 374, 459, 1022, 68392, 315, 597, 2852, 78, 611, 3400, 1100, 708, 4731, 1174, 449, 34453, 505, 10948, 315, 20023, 5270, 1174, 33160, 768, 23091, 64, 1174, 69392, 323, 30242, 4731, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1382", "dataset": "mit-movie", "split": "dev", "prediction": "im(O) looking(O) for(O) the(O) 1950(B-year) g(B-rating) rated(O) psychological(B-genre) movie(O) about(O) a(O) missing(B-plot) prisoner(I-plot) directed(O) by(O) michael(B-director) staininger(I-director)", "instance": {"id": "1382", "words": ["im", "looking", "for", "the", "1950", "g", "rated", "psychological", "movie", "about", "a", "missing", "prisoner", "directed", "by", "michael", "staininger"], "labels": ["O", "O", "O", "O", "B-year", "B-rating", "O", "B-genre", "O", "O", "O", "B-plot", "I-plot", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, average ratings, trailer, character, year, song, rating, plot, director, title, review, actor and O.\nSentence: im looking for the 1950 g rated psychological movie about a missing prisoner directed by michael staininger", "prompt_labels": "im(O) looking(O) for(O) the(O) 1950(B-year) g(B-rating) rated(O) psychological(B-genre) movie(O) about(O) a(O) missing(B-plot) prisoner(I-plot) directed(O) by(O) michael(B-director) staininger(I-director)"}, "label_list": ["genre", "average ratings", "trailer", "character", "year", "song", "rating", "plot", "director", "title", "review", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 5578, 18594, 11, 19809, 11, 3752, 11, 1060, 11, 5609, 11, 10959, 11, 7234, 11, 7690, 11, 2316, 11, 3477, 11, 12360, 323, 507, 627, 85664, 25, 737, 3411, 369, 279, 220, 6280, 15, 342, 22359, 24064, 5818, 922, 264, 7554, 42950, 15910, 555, 89006, 88896, 261, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "549", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movie(O) had(O) jim(B-actor) carrey(I-actor) as(O) a(O) dr(B-character) seuss(I-character) character(O)", "instance": {"id": "549", "words": ["what", "movie", "had", "jim", "carrey", "as", "a", "dr", "seuss", "character"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O", "O", "B-character", "I-character", "I-character"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, character, song, year, rating, director, trailer, plot, genre, average ratings, title, review and O.\nSentence: what movie had jim carrey as a dr seuss character", "prompt_labels": "what(O) movie(O) had(O) jim(B-actor) carrey(I-actor) as(O) a(O) dr(B-character) seuss(I-character) character(I-character)"}, "label_list": ["actor", "character", "song", "year", "rating", "director", "trailer", "plot", "genre", "average ratings", "title", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 3752, 11, 5609, 11, 1060, 11, 10959, 11, 7690, 11, 19809, 11, 7234, 11, 17779, 11, 5578, 18594, 11, 2316, 11, 3477, 323, 507, 627, 85664, 25, 1148, 5818, 1047, 96544, 1841, 8233, 439, 264, 1377, 513, 1892, 3752, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "83", "dataset": "mit-movie", "split": "dev", "prediction": "find(O) action(B-genre) movies(O) featuring(O) comic(B-plot) book(I-plot) characters(O)", "instance": {"id": "83", "words": ["find", "action", "movies", "featuring", "comic", "book", "characters"], "labels": ["O", "B-genre", "O", "O", "B-plot", "I-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, plot, genre, title, character, director, average ratings, trailer, review, rating, song, actor and O.\nSentence: find action movies featuring comic book characters", "prompt_labels": "find(O) action(B-genre) movies(O) featuring(O) comic(B-plot) book(I-plot) characters(I-plot)"}, "label_list": ["year", "plot", "genre", "title", "character", "director", "average ratings", "trailer", "review", "rating", "song", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 7234, 11, 17779, 11, 2316, 11, 3752, 11, 7690, 11, 5578, 18594, 11, 19809, 11, 3477, 11, 10959, 11, 5609, 11, 12360, 323, 507, 627, 85664, 25, 1505, 1957, 9698, 16850, 20303, 2363, 5885, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "289", "dataset": "crossner_music", "split": "dev", "prediction": "The(O) success(O) of(O) this(O) performance(O) lead(O) to(O) them(O) embarking(O) on(O) a(O) string(O) of(O) other(O) live(O) performances(O) in(O) 2009(O) and(O) 2010(O),(O) selling(O) out(O) prestigious(O) venues(O),(O) such(O) as(O) the(O) Queen(B-location) Elizabeth(I-location) Hall(I-location) in(O) London(B-location),(O) Volksb\u00fchne(B-location) in(O) Berlin(B-location) and(O) La(B-location) Cigale(I-location) in(O) Paris(B-location) before(O) they(O) returned(O) to(O) their(O) homeland(O) for(O) their(O) performance(O) at(O) The(O) Norwegian(B-location) Opera(I-location) House(I-location).(O)", "instance": {"id": "289", "words": ["The", "success", "of", "this", "performance", "lead", "to", "them", "embarking", "on", "a", "string", "of", "other", "live", "performances", "in", "2009", "and", "2010", ",", "selling", "out", "prestigious", "venues", ",", "such", "as", "the", "Queen", "Elizabeth", "Hall", "in", "London", ",", "Volksb\u00fchne", "in", "Berlin", "and", "La", "Cigale", "in", "Paris", "before", "they", "returned", "to", "their", "homeland", "for", "their", "performance", "at", "The", "Norwegian", "Opera", "House", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "I-location", "O", "B-location", "O", "B-location", "O", "B-band", "O", "B-location", "I-location", "O", "B-location", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "I-location", "I-location", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, song, musical artist, location, organization, person, album, band, country, award, music genre, event and O.\nSentence: The success of this performance lead to them embarking on a string of other live performances in 2009 and 2010 , selling out prestigious venues , such as the Queen Elizabeth Hall in London , Volksb\u00fchne in Berlin and La Cigale in Paris before they returned to their homeland for their performance at The Norwegian Opera House .", "prompt_labels": "The(O) success(O) of(O) this(O) performance(O) lead(O) to(O) them(O) embarking(O) on(O) a(O) string(O) of(O) other(O) live(O) performances(O) in(O) 2009(O) and(O) 2010(O) ,(O) selling(O) out(O) prestigious(O) venues(O) ,(O) such(O) as(O) the(O) Queen(B-location) Elizabeth(I-location) Hall(I-location) in(O) London(B-location) ,(O) Volksb\u00fchne(B-location) in(O) Berlin(B-band) and(O) La(B-location) Cigale(I-location) in(O) Paris(B-location) before(O) they(O) returned(O) to(O) their(O) homeland(O) for(O) their(O) performance(O) at(O) The(B-location) Norwegian(I-location) Opera(I-location) House(I-location) .(O)"}, "label_list": ["musical instrument", "song", "musical artist", "location", "organization", "person", "album", "band", "country", "award", "music genre", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18273, 14473, 11, 5609, 11, 18273, 10255, 11, 3813, 11, 7471, 11, 1732, 11, 8176, 11, 7200, 11, 3224, 11, 10292, 11, 4731, 17779, 11, 1567, 323, 507, 627, 85664, 25, 578, 2450, 315, 420, 5178, 3063, 311, 1124, 8126, 34552, 389, 264, 925, 315, 1023, 3974, 24601, 304, 220, 1049, 24, 323, 220, 679, 15, 1174, 11486, 704, 41385, 37278, 1174, 1778, 439, 279, 16657, 21393, 11166, 304, 7295, 1174, 11119, 2857, 65, 22284, 818, 304, 20437, 323, 5034, 356, 343, 1604, 304, 12366, 1603, 814, 6052, 311, 872, 56336, 369, 872, 5178, 520, 578, 45721, 39679, 4783, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "761", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) animated(B-genre) movies(O) were(O) nominated(B-review) for(O) oscars(B-review)", "instance": {"id": "761", "words": ["what", "animated", "movies", "were", "nominated", "for", "oscars"], "labels": ["O", "B-genre", "O", "O", "B-average ratings", "I-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, rating, plot, director, trailer, actor, character, average ratings, genre, song, title, review and O.\nSentence: what animated movies were nominated for oscars", "prompt_labels": "what(O) animated(B-genre) movies(O) were(O) nominated(B-average ratings) for(I-average ratings) oscars(I-average ratings)"}, "label_list": ["year", "rating", "plot", "director", "trailer", "actor", "character", "average ratings", "genre", "song", "title", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 10959, 11, 7234, 11, 7690, 11, 19809, 11, 12360, 11, 3752, 11, 5578, 18594, 11, 17779, 11, 5609, 11, 2316, 11, 3477, 323, 507, 627, 85664, 25, 1148, 11625, 9698, 1051, 39048, 369, 32047, 1590, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1104", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) asian(B-Cuisine) restaurants(O) offer(O) carry(B-Amenity) out(I-Amenity)", "instance": {"id": "1104", "words": ["what", "asian", "restaurants", "offer", "carry", "out"], "labels": ["O", "B-Cuisine", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Amenity, Dish, Restaurant Name, Location, Hours, Price, Cuisine and O.\nSentence: what asian restaurants offer carry out", "prompt_labels": "what(O) asian(B-Cuisine) restaurants(O) offer(O) carry(B-Amenity) out(I-Amenity)"}, "label_list": ["Rating", "Amenity", "Dish", "Restaurant Name", "Location", "Hours", "Price", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 3383, 56685, 11, 49268, 11, 26568, 4076, 11, 10067, 11, 30192, 11, 8650, 11, 81961, 323, 507, 627, 85664, 25, 1148, 36725, 15926, 3085, 6920, 704, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2353", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) anthony(B-actor) hopkins(I-actor) in(O) a(O) musical(B-genre)", "instance": {"id": "2353", "words": ["is", "anthony", "hopkins", "in", "a", "musical"], "labels": ["O", "B-actor", "I-actor", "O", "O", "B-genre"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, plot, character, song, year, average ratings, actor, genre, review, rating, trailer, director and O.\nSentence: is anthony hopkins in a musical", "prompt_labels": "is(O) anthony(B-actor) hopkins(I-actor) in(O) a(O) musical(B-genre)"}, "label_list": ["title", "plot", "character", "song", "year", "average ratings", "actor", "genre", "review", "rating", "trailer", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 7234, 11, 3752, 11, 5609, 11, 1060, 11, 5578, 18594, 11, 12360, 11, 17779, 11, 3477, 11, 10959, 11, 19809, 11, 7690, 323, 507, 627, 85664, 25, 374, 23064, 3633, 7598, 11966, 304, 264, 18273, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "144", "dataset": "mit-restaurant", "split": "dev", "prediction": "can(O) you(O) find(O) a(O) site(O) where(O) i(O) can(O) see(O) reviews(B-Rating) on(O) restaurant(O) downtown(B-Location)", "instance": {"id": "144", "words": ["can", "you", "find", "a", "site", "where", "i", "can", "see", "reviews", "on", "restaurant", "downtown"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Hours, Cuisine, Restaurant Name, Price, Rating, Location, Amenity and O.\nSentence: can you find a site where i can see reviews on restaurant downtown", "prompt_labels": "can(O) you(O) find(O) a(O) site(O) where(O) i(O) can(O) see(O) reviews(O) on(O) restaurant(O) downtown(B-Location)"}, "label_list": ["Dish", "Hours", "Cuisine", "Restaurant Name", "Price", "Rating", "Location", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 30192, 11, 81961, 11, 26568, 4076, 11, 8650, 11, 19767, 11, 10067, 11, 3383, 56685, 323, 507, 627, 85664, 25, 649, 499, 1505, 264, 2816, 1405, 602, 649, 1518, 8544, 389, 10960, 19441, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "446", "dataset": "mit-restaurant", "split": "dev", "prediction": "find(O) restaurants(O) within(B-Location) 5(I-Location) miles(I-Location) with(O) entrees(B-Price) under(I-Price) 15(I-Price)", "instance": {"id": "446", "words": ["find", "restaurants", "within", "5", "miles", "with", "entrees", "under", "15"], "labels": ["O", "O", "B-Location", "I-Location", "I-Location", "O", "B-Price", "I-Price", "I-Price"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Dish, Location, Hours, Restaurant Name, Price, Cuisine, Rating and O.\nSentence: find restaurants within 5 miles with entrees under 15", "prompt_labels": "find(O) restaurants(O) within(B-Location) 5(I-Location) miles(I-Location) with(O) entrees(B-Price) under(I-Price) 15(I-Price)"}, "label_list": ["Amenity", "Dish", "Location", "Hours", "Restaurant Name", "Price", "Cuisine", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 49268, 11, 10067, 11, 30192, 11, 26568, 4076, 11, 8650, 11, 81961, 11, 19767, 323, 507, 627, 85664, 25, 1505, 15926, 2949, 220, 20, 8931, 449, 1218, 8016, 1234, 220, 868, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "409", "dataset": "crossner_science", "split": "dev", "prediction": "He(O) won(O) silver(B-award) medals(I-award) at(O) the(O) 1989(B-event) Southeast(I-event) Asian(I-event) Games(I-event),(O) 1991(B-event) Southeast(I-event) Asian(I-event) Games(I-event),(O) and(O) 1993(B-event) Southeast(I-event) Asian(I-event) Games(I-event).(O)", "instance": {"id": "409", "words": ["He", "won", "silver", "medals", "at", "the", "1989", "Southeast", "Asian", "Games", ",", "1991", "Southeast", "Asian", "Games", ",", "and", "1993", "Southeast", "Asian", "Games", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "I-event", "O", "B-event", "I-event", "I-event", "I-event", "O", "O", "B-event", "I-event", "I-event", "I-event", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, person, scientist, protein, academic journal, organization, award, university, theory, location, chemical element, astronomical object, discipline, chemical compound, country, enzyme and O.\nSentence: He won silver medals at the 1989 Southeast Asian Games , 1991 Southeast Asian Games , and 1993 Southeast Asian Games .", "prompt_labels": "He(O) won(O) silver(O) medals(O) at(O) the(O) 1989(B-event) Southeast(I-event) Asian(I-event) Games(I-event) ,(O) 1991(B-event) Southeast(I-event) Asian(I-event) Games(I-event) ,(O) and(O) 1993(B-event) Southeast(I-event) Asian(I-event) Games(I-event) .(O)"}, "label_list": ["event", "person", "scientist", "protein", "academic journal", "organization", "award", "university", "theory", "location", "chemical element", "astronomical object", "discipline", "chemical compound", "country", "enzyme"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 1732, 11, 28568, 11, 13128, 11, 14584, 8486, 11, 7471, 11, 10292, 11, 12374, 11, 10334, 11, 3813, 11, 11742, 2449, 11, 87283, 1665, 11, 26434, 11, 11742, 24549, 11, 3224, 11, 49242, 323, 507, 627, 85664, 25, 1283, 2834, 15310, 60082, 520, 279, 220, 3753, 24, 36664, 14875, 11871, 1174, 220, 2550, 16, 36664, 14875, 11871, 1174, 323, 220, 2550, 18, 36664, 14875, 11871, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1238", "dataset": "mit-restaurant", "split": "dev", "prediction": "whats(O) the(O) closest(B-Location) restaurant(O) with(O) a(O) full(B-Amenity) salad(I-Amenity) bar(I-Amenity)", "instance": {"id": "1238", "words": ["whats", "the", "closest", "restaurant", "with", "a", "full", "salad", "bar"], "labels": ["O", "O", "B-Location", "O", "O", "O", "B-Cuisine", "I-Cuisine", "I-Cuisine"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Amenity, Price, Cuisine, Hours, Dish, Rating, Restaurant Name and O.\nSentence: whats the closest restaurant with a full salad bar", "prompt_labels": "whats(O) the(O) closest(B-Location) restaurant(O) with(O) a(O) full(B-Cuisine) salad(I-Cuisine) bar(I-Cuisine)"}, "label_list": ["Location", "Amenity", "Price", "Cuisine", "Hours", "Dish", "Rating", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 3383, 56685, 11, 8650, 11, 81961, 11, 30192, 11, 49268, 11, 19767, 11, 26568, 4076, 323, 507, 627, 85664, 25, 41209, 279, 18585, 10960, 449, 264, 2539, 33566, 3703, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "202", "dataset": "crossner_politics", "split": "dev", "prediction": "She(O) was(O) re-elected(O) to(O) additional(O) terms(O) in(O) 1974(B-election) Australian(I-election) federal(I-election) election(I-election),(O) 1975(B-election) Australian(I-election) federal(I-election) election(I-election),(O) and(O) 1980(B-election) Australian(I-election) federal(I-election) election(I-election),(O) retiring(O) on(O) 5(O) June(O) 1987(O) at(O) the(O) end(O) of(O) her(O) final(O) term(O).(O)", "instance": {"id": "202", "words": ["She", "was", "re-elected", "to", "additional", "terms", "in", "1974", "Australian", "federal", "election", ",", "1975", "Australian", "federal", "election", ",", "and", "1980", "Australian", "federal", "election", ",", "retiring", "on", "5", "June", "1987", "at", "the", "end", "of", "her", "final", "term", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, politician, election, organization, event, political party, location, country and O.\nSentence: She was re-elected to additional terms in 1974 Australian federal election , 1975 Australian federal election , and 1980 Australian federal election , retiring on 5 June 1987 at the end of her final term .", "prompt_labels": "She(O) was(O) re-elected(O) to(O) additional(O) terms(O) in(O) 1974(B-election) Australian(I-election) federal(I-election) election(I-election) ,(O) 1975(B-election) Australian(I-election) federal(I-election) election(I-election) ,(O) and(O) 1980(B-election) Australian(I-election) federal(I-election) election(I-election) ,(O) retiring(O) on(O) 5(O) June(O) 1987(O) at(O) the(O) end(O) of(O) her(O) final(O) term(O) .(O)"}, "label_list": ["person", "politician", "election", "organization", "event", "political party", "location", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 37038, 11, 6355, 11, 7471, 11, 1567, 11, 5054, 4717, 11, 3813, 11, 3224, 323, 507, 627, 85664, 25, 3005, 574, 312, 96805, 311, 5217, 3878, 304, 220, 4468, 19, 13673, 6918, 6355, 1174, 220, 4468, 20, 13673, 6918, 6355, 1174, 323, 220, 3753, 15, 13673, 6918, 6355, 1174, 60873, 389, 220, 20, 5651, 220, 3753, 22, 520, 279, 842, 315, 1077, 1620, 4751, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "971", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) scariest(B-review) horror(B-genre) movie(O) from(O) the(O) 90s(B-year)", "instance": {"id": "971", "words": ["what", "is", "the", "scariest", "horror", "movie", "from", "the", "90s"], "labels": ["O", "O", "O", "B-genre", "I-genre", "O", "O", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, song, plot, director, trailer, actor, review, title, rating, character, year, average ratings and O.\nSentence: what is the scariest horror movie from the 90s", "prompt_labels": "what(O) is(O) the(O) scariest(B-genre) horror(I-genre) movie(O) from(O) the(O) 90s(B-year)"}, "label_list": ["genre", "song", "plot", "director", "trailer", "actor", "review", "title", "rating", "character", "year", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 5609, 11, 7234, 11, 7690, 11, 19809, 11, 12360, 11, 3477, 11, 2316, 11, 10959, 11, 3752, 11, 1060, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1148, 374, 279, 1156, 2850, 478, 22169, 5818, 505, 279, 220, 1954, 82, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "272", "dataset": "mit-restaurant", "split": "dev", "prediction": "do(O) you(O) think(O) tin(B-Restaurant Name) whistle(I-Restaurant Name) has(O) fabulous(B-Amenity) service(I-Amenity)", "instance": {"id": "272", "words": ["do", "you", "think", "tin", "whistle", "has", "fabulous", "service"], "labels": ["O", "O", "O", "B-Restaurant Name", "I-Restaurant Name", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Dish, Price, Rating, Restaurant Name, Hours, Amenity, Location and O.\nSentence: do you think tin whistle has fabulous service", "prompt_labels": "do(O) you(O) think(O) tin(B-Restaurant Name) whistle(I-Restaurant Name) has(O) fabulous(B-Amenity) service(I-Amenity)"}, "label_list": ["Cuisine", "Dish", "Price", "Rating", "Restaurant Name", "Hours", "Amenity", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 49268, 11, 8650, 11, 19767, 11, 26568, 4076, 11, 30192, 11, 3383, 56685, 11, 10067, 323, 507, 627, 85664, 25, 656, 499, 1781, 25826, 40649, 706, 35631, 2532, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "782", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) the(O) chateau(B-Restaurant Name) restaurant(O) affordable(B-Price)", "instance": {"id": "782", "words": ["is", "the", "chateau", "restaurant", "affordable"], "labels": ["O", "O", "B-Restaurant Name", "I-Restaurant Name", "B-Price"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Hours, Dish, Cuisine, Rating, Location, Restaurant Name, Price and O.\nSentence: is the chateau restaurant affordable", "prompt_labels": "is(O) the(O) chateau(B-Restaurant Name) restaurant(I-Restaurant Name) affordable(B-Price)"}, "label_list": ["Amenity", "Hours", "Dish", "Cuisine", "Rating", "Location", "Restaurant Name", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 30192, 11, 49268, 11, 81961, 11, 19767, 11, 10067, 11, 26568, 4076, 11, 8650, 323, 507, 627, 85664, 25, 374, 279, 523, 77725, 10960, 17049, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "329", "dataset": "crossner_music", "split": "dev", "prediction": "Jimmie(B-musical artist) Rodgers(I-musical artist),(O) Moon(B-musical artist) Mullican(I-musical artist),(O) Bob(B-musical artist) Wills(I-musical artist),(O) Bill(B-musical artist) Monroe(I-musical artist) and(O) Hank(B-musical artist) Williams(I-musical artist) have(O) all(O) described(O) themselves(O) as(O) blues(B-music genre) singers(O) and(O) their(O) music(O) has(O) a(O) blues(B-music genre) feel(O) that(O) is(O) different(O),(O) at(O) first(O) glance(O) at(O) least(O),(O) from(O) the(O) later(O) country(B-music genre) pop(I-music genre) of(O) artists(O) like(O) Eddy(B-musical artist) Arnold(I-musical artist).(O)", "instance": {"id": "329", "words": ["Jimmie", "Rodgers", ",", "Moon", "Mullican", ",", "Bob", "Wills", ",", "Bill", "Monroe", "and", "Hank", "Williams", "have", "all", "described", "themselves", "as", "blues", "singers", "and", "their", "music", "has", "a", "blues", "feel", "that", "is", "different", ",", "at", "first", "glance", "at", "least", ",", "from", "the", "later", "country", "pop", "of", "artists", "like", "Eddy", "Arnold", "."], "labels": ["B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "O", "O", "O", "O", "B-music genre", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-music genre", "I-music genre", "O", "O", "O", "B-musical artist", "I-musical artist", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, band, location, person, event, organization, country, musical instrument, album, musical artist, music genre, award and O.\nSentence: Jimmie Rodgers , Moon Mullican , Bob Wills , Bill Monroe and Hank Williams have all described themselves as blues singers and their music has a blues feel that is different , at first glance at least , from the later country pop of artists like Eddy Arnold .", "prompt_labels": "Jimmie(B-musical artist) Rodgers(I-musical artist) ,(O) Moon(B-musical artist) Mullican(I-musical artist) ,(O) Bob(B-musical artist) Wills(I-musical artist) ,(O) Bill(B-musical artist) Monroe(I-musical artist) and(O) Hank(B-musical artist) Williams(I-musical artist) have(O) all(O) described(O) themselves(O) as(O) blues(B-music genre) singers(O) and(O) their(O) music(O) has(O) a(O) blues(O) feel(O) that(O) is(O) different(O) ,(O) at(O) first(O) glance(O) at(O) least(O) ,(O) from(O) the(O) later(O) country(B-music genre) pop(I-music genre) of(O) artists(O) like(O) Eddy(B-musical artist) Arnold(I-musical artist) .(O)"}, "label_list": ["song", "band", "location", "person", "event", "organization", "country", "musical instrument", "album", "musical artist", "music genre", "award"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 7200, 11, 3813, 11, 1732, 11, 1567, 11, 7471, 11, 3224, 11, 18273, 14473, 11, 8176, 11, 18273, 10255, 11, 4731, 17779, 11, 10292, 323, 507, 627, 85664, 25, 11641, 74696, 50117, 1174, 17781, 30451, 416, 276, 1174, 14596, 468, 3385, 1174, 8766, 50887, 323, 55761, 13926, 617, 682, 7633, 5694, 439, 44695, 68141, 323, 872, 4731, 706, 264, 44695, 2733, 430, 374, 2204, 1174, 520, 1176, 34522, 520, 3325, 1174, 505, 279, 3010, 3224, 2477, 315, 13820, 1093, 469, 54610, 44312, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "98", "dataset": "crossner_politics", "split": "dev", "prediction": "Hugo(B-politician) Ch\u00e1vez(I-politician),(O) the(O) central(O) figure(O) of(O) the(O) Venezuelan(O) political(O) landscape(O) since(O) 1998(O) Venezuelan(O) presidential(O) election(O) as(O) a(O) political(O) outsider(O),(O) died(O) in(O) office(O) in(O) early(O) 2013(O),(O) and(O) was(O) succeeded(O) by(O) Nicol\u00e1s(B-politician) Maduro(I-politician),(O) initially(O) as(O) interim(O) President(O),(O) before(O) winning(O) 2013(O) Venezuelan(O) presidential(O) election(O) and(O) re-election(O) in(O) 2018(O) Venezuelan(O) presidential(O) election(O).(O)", "instance": {"id": "98", "words": ["Hugo", "Ch\u00e1vez", ",", "the", "central", "figure", "of", "the", "Venezuelan", "political", "landscape", "since", "1998", "Venezuelan", "presidential", "election", "as", "a", "political", "outsider", ",", "died", "in", "office", "in", "early", "2013", ",", "and", "was", "succeeded", "by", "Nicol\u00e1s", "Maduro", ",", "initially", "as", "interim", "President", ",", "before", "winning", "2013", "Venezuelan", "presidential", "election", "and", "re-election", "in", "2018", "Venezuelan", "presidential", "election", "."], "labels": ["B-politician", "I-politician", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-politician", "I-politician", "O", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, election, country, political party, event, person, location, politician and O.\nSentence: Hugo Ch\u00e1vez , the central figure of the Venezuelan political landscape since 1998 Venezuelan presidential election as a political outsider , died in office in early 2013 , and was succeeded by Nicol\u00e1s Maduro , initially as interim President , before winning 2013 Venezuelan presidential election and re-election in 2018 Venezuelan presidential election .", "prompt_labels": "Hugo(B-politician) Ch\u00e1vez(I-politician) ,(O) the(O) central(O) figure(O) of(O) the(O) Venezuelan(O) political(O) landscape(O) since(O) 1998(B-election) Venezuelan(I-election) presidential(I-election) election(I-election) as(O) a(O) political(O) outsider(O) ,(O) died(O) in(O) office(O) in(O) early(O) 2013(O) ,(O) and(O) was(O) succeeded(O) by(O) Nicol\u00e1s(B-politician) Maduro(I-politician) ,(O) initially(O) as(O) interim(O) President(O) ,(O) before(O) winning(O) 2013(B-election) Venezuelan(I-election) presidential(I-election) election(I-election) and(O) re-election(O) in(O) 2018(B-election) Venezuelan(I-election) presidential(I-election) election(I-election) .(O)"}, "label_list": ["organization", "election", "country", "political party", "event", "person", "location", "politician"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 6355, 11, 3224, 11, 5054, 4717, 11, 1567, 11, 1732, 11, 3813, 11, 37038, 323, 507, 627, 85664, 25, 52194, 921, 1995, 19610, 1174, 279, 8792, 7216, 315, 279, 83749, 5054, 18921, 2533, 220, 2550, 23, 83749, 13621, 6355, 439, 264, 5054, 75683, 1174, 8636, 304, 5274, 304, 4216, 220, 679, 18, 1174, 323, 574, 26399, 555, 83440, 7206, 78802, 1174, 15453, 439, 41653, 4900, 1174, 1603, 11230, 220, 679, 18, 83749, 13621, 6355, 323, 312, 43733, 304, 220, 679, 23, 83749, 13621, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "204", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) people(O) like(O) or(O) hate(O) the(O) last(O) twilight(B-title) movie(O)", "instance": {"id": "204", "words": ["did", "people", "like", "or", "hate", "the", "last", "twilight", "movie"], "labels": ["O", "O", "B-review", "O", "B-review", "O", "O", "B-title", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, actor, year, average ratings, character, song, review, title, rating, trailer, genre, plot and O.\nSentence: did people like or hate the last twilight movie", "prompt_labels": "did(O) people(O) like(B-review) or(O) hate(B-review) the(O) last(O) twilight(B-title) movie(O)"}, "label_list": ["director", "actor", "year", "average ratings", "character", "song", "review", "title", "rating", "trailer", "genre", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 12360, 11, 1060, 11, 5578, 18594, 11, 3752, 11, 5609, 11, 3477, 11, 2316, 11, 10959, 11, 19809, 11, 17779, 11, 7234, 323, 507, 627, 85664, 25, 1550, 1274, 1093, 477, 12491, 279, 1566, 93722, 5818, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1017", "dataset": "mit-restaurant", "split": "dev", "prediction": "please(O) find(O) a(O) japanese(B-Cuisine) place(O) that(O) near(B-Location) an(O) indian(B-Cuisine) restaurant(O)", "instance": {"id": "1017", "words": ["please", "find", "a", "japanese", "place", "that", "near", "an", "indian", "restaurant"], "labels": ["O", "O", "O", "B-Cuisine", "O", "O", "B-Location", "O", "B-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Restaurant Name, Cuisine, Hours, Location, Amenity, Rating, Dish and O.\nSentence: please find a japanese place that near an indian restaurant", "prompt_labels": "please(O) find(O) a(O) japanese(B-Cuisine) place(O) that(O) near(B-Location) an(O) indian(B-Cuisine) restaurant(O)"}, "label_list": ["Price", "Restaurant Name", "Cuisine", "Hours", "Location", "Amenity", "Rating", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 26568, 4076, 11, 81961, 11, 30192, 11, 10067, 11, 3383, 56685, 11, 19767, 11, 49268, 323, 507, 627, 85664, 25, 4587, 1505, 264, 54048, 2035, 430, 3221, 459, 43325, 10960, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1146", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) jacob(B-actor) ransom(I-actor) have(O) a(O) movie(O) about(O) fear(B-plot) of(I-plot) marriage(I-plot) that(O) was(O) rated(O) seven(B-average ratings) in(O) the(O) last(B-year) five(I-year) decades(I-year)", "instance": {"id": "1146", "words": ["did", "jacob", "ransom", "have", "a", "movie", "about", "fear", "of", "marriage", "that", "was", "rated", "seven", "in", "the", "last", "five", "decades"], "labels": ["O", "B-director", "I-director", "O", "O", "O", "O", "B-plot", "I-plot", "I-plot", "O", "O", "O", "B-average ratings", "O", "O", "B-year", "I-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, title, plot, trailer, rating, genre, average ratings, character, director, year, actor, review and O.\nSentence: did jacob ransom have a movie about fear of marriage that was rated seven in the last five decades", "prompt_labels": "did(O) jacob(B-director) ransom(I-director) have(O) a(O) movie(O) about(O) fear(B-plot) of(I-plot) marriage(I-plot) that(O) was(O) rated(O) seven(B-average ratings) in(O) the(O) last(B-year) five(I-year) decades(I-year)"}, "label_list": ["song", "title", "plot", "trailer", "rating", "genre", "average ratings", "character", "director", "year", "actor", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 2316, 11, 7234, 11, 19809, 11, 10959, 11, 17779, 11, 5578, 18594, 11, 3752, 11, 7690, 11, 1060, 11, 12360, 11, 3477, 323, 507, 627, 85664, 25, 1550, 503, 40051, 58686, 617, 264, 5818, 922, 8850, 315, 11103, 430, 574, 22359, 8254, 304, 279, 1566, 4330, 11026, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "246", "dataset": "crossner_literature", "split": "dev", "prediction": "He(O) also(O) led(O) the(O) trend(O) for(O) pastoral(B-literary genre) poetry(I-literary genre) and(O) his(O) pastoral(B-literary genre) opera(I-literary genre) The(B-title) Gentle(I-title) Shepherd(I-title) was(O) one(O) of(O) the(O) most(O) influential(O) works(O) of(O) the(O) era(O).(O)", "instance": {"id": "246", "words": ["He", "also", "led", "the", "trend", "for", "pastoral", "poetry", "and", "his", "pastoral", "opera", "The", "Gentle", "Shepherd", "was", "one", "of", "the", "most", "influential", "works", "of", "the", "era", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-literary genre", "I-literary genre", "O", "O", "B-literary genre", "I-literary genre", "B-poem", "I-poem", "I-poem", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, award, person, country, event, magazine, writer, organization, location, book, poem and O.\nSentence: He also led the trend for pastoral poetry and his pastoral opera The Gentle Shepherd was one of the most influential works of the era .", "prompt_labels": "He(O) also(O) led(O) the(O) trend(O) for(O) pastoral(B-literary genre) poetry(I-literary genre) and(O) his(O) pastoral(B-literary genre) opera(I-literary genre) The(B-poem) Gentle(I-poem) Shepherd(I-poem) was(O) one(O) of(O) the(O) most(O) influential(O) works(O) of(O) the(O) era(O) .(O)"}, "label_list": ["literary genre", "award", "person", "country", "event", "magazine", "writer", "organization", "location", "book", "poem"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 32465, 17779, 11, 10292, 11, 1732, 11, 3224, 11, 1567, 11, 14756, 11, 7061, 11, 7471, 11, 3813, 11, 2363, 11, 33894, 323, 507, 627, 85664, 25, 1283, 1101, 6197, 279, 9327, 369, 90371, 32349, 323, 813, 90371, 43516, 578, 74569, 59646, 574, 832, 315, 279, 1455, 32549, 4375, 315, 279, 11639, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "79", "dataset": "crossner_politics", "split": "dev", "prediction": "He(O) was(O) the(O) American(B-political party) Independent(I-political party) Party(I-political party) vice(O) presidential(O) nominee(O) under(O) John(B-politician) G.(I-politician) Schmitz(I-politician) in(O) 1972(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) and(O) the(O) American(B-political party) Party(I-political party) presidential(O) nominee(O) in(O) 1976(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election).(O)", "instance": {"id": "79", "words": ["He", "was", "the", "American", "Independent", "Party", "vice", "presidential", "nominee", "under", "John", "G.", "Schmitz", "in", "1972", "United", "States", "presidential", "election", "and", "the", "American", "Party", "presidential", "nominee", "in", "1976", "United", "States", "presidential", "election", "."], "labels": ["O", "O", "O", "B-political party", "I-political party", "I-political party", "O", "O", "O", "O", "B-politician", "I-politician", "I-politician", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, event, location, organization, political party, election, politician, country and O.\nSentence: He was the American Independent Party vice presidential nominee under John G. Schmitz in 1972 United States presidential election and the American Party presidential nominee in 1976 United States presidential election .", "prompt_labels": "He(O) was(O) the(O) American(B-political party) Independent(I-political party) Party(I-political party) vice(O) presidential(O) nominee(O) under(O) John(B-politician) G.(I-politician) Schmitz(I-politician) in(O) 1972(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) and(O) the(O) American(O) Party(O) presidential(O) nominee(O) in(O) 1976(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) .(O)"}, "label_list": ["person", "event", "location", "organization", "political party", "election", "politician", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 1567, 11, 3813, 11, 7471, 11, 5054, 4717, 11, 6355, 11, 37038, 11, 3224, 323, 507, 627, 85664, 25, 1283, 574, 279, 3778, 22765, 8722, 17192, 13621, 29311, 1234, 3842, 480, 13, 5124, 1800, 89, 304, 220, 4468, 17, 3723, 4273, 13621, 6355, 323, 279, 3778, 8722, 13621, 29311, 304, 220, 4468, 21, 3723, 4273, 13621, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "223", "dataset": "crossner_politics", "split": "dev", "prediction": "In(O) 1966(O),(O) he(O) used(O) some(O) of(O) his(O) wealth(O) to(O) form(O) the(O) Liberal(B-political party) Reform(I-political party) Group(I-political party),(O) a(O) splinter(O) group(O) of(O) members(O) of(O) the(O) Liberal(B-political party) Party(I-political party) of(I-political party) Australia(I-political party) disenchanted(O) with(O) their(O) party(O)'s(O) support(O) for(O) the(O) Vietnam(B-event) War(I-event) ;(O) this(O) became(O) the(O) Australian(B-political party) Reform(I-political party) Movement(I-political party) and(O) then(O) the(O) Australia(B-political party) Party(I-political party),(O) the(O) precursor(O) of(O) the(O) Australian(B-political party) Democrats(I-political party).(O)", "instance": {"id": "223", "words": ["In", "1966", ",", "he", "used", "some", "of", "his", "wealth", "to", "form", "the", "Liberal", "Reform", "Group", ",", "a", "splinter", "group", "of", "members", "of", "the", "Liberal", "Party", "of", "Australia", "disenchanted", "with", "their", "party", "'s", "support", "for", "the", "Vietnam", "War", ";", "this", "became", "the", "Australian", "Reform", "Movement", "and", "then", "the", "Australia", "Party", ",", "the", "precursor", "of", "the", "Australian", "Democrats", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "O", "O", "O", "B-political party", "I-political party", "O", "O", "O", "O", "O", "B-political party", "I-political party", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, country, political party, organization, location, politician, person, event and O.\nSentence: In 1966 , he used some of his wealth to form the Liberal Reform Group , a splinter group of members of the Liberal Party of Australia disenchanted with their party 's support for the Vietnam War ; this became the Australian Reform Movement and then the Australia Party , the precursor of the Australian Democrats .", "prompt_labels": "In(O) 1966(O) ,(O) he(O) used(O) some(O) of(O) his(O) wealth(O) to(O) form(O) the(O) Liberal(B-political party) Reform(I-political party) Group(I-political party) ,(O) a(O) splinter(O) group(O) of(O) members(O) of(O) the(O) Liberal(B-political party) Party(I-political party) of(I-political party) Australia(I-political party) disenchanted(O) with(O) their(O) party(O) 's(O) support(O) for(O) the(O) Vietnam(B-event) War(I-event) ;(O) this(O) became(O) the(O) Australian(B-political party) Reform(I-political party) Movement(I-political party) and(O) then(O) the(O) Australia(B-political party) Party(I-political party) ,(O) the(O) precursor(O) of(O) the(O) Australian(B-political party) Democrats(I-political party) .(O)"}, "label_list": ["election", "country", "political party", "organization", "location", "politician", "person", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 6355, 11, 3224, 11, 5054, 4717, 11, 7471, 11, 3813, 11, 37038, 11, 1732, 11, 1567, 323, 507, 627, 85664, 25, 763, 220, 5162, 21, 1174, 568, 1511, 1063, 315, 813, 12205, 311, 1376, 279, 31158, 40365, 5856, 1174, 264, 12786, 2295, 1912, 315, 3697, 315, 279, 31158, 8722, 315, 8494, 834, 20345, 7719, 449, 872, 4717, 364, 82, 1862, 369, 279, 23315, 5111, 2652, 420, 6244, 279, 13673, 40365, 29098, 323, 1243, 279, 8494, 8722, 1174, 279, 71261, 315, 279, 13673, 12643, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "188", "dataset": "crossner_music", "split": "dev", "prediction": "They(O) were(O) inducted(O) by(O) Chuck(B-person) D(I-person) and(O) LL(B-person) Cool(I-person) J(I-person) on(O) April(O) 14(O),(O) 2012(O) therefore(O) the(O) group(O) didn(O) '(O) t(O) perform(O) ;(O) instead(O) Black(B-musical artist) Thought(I-musical artist),(O) Travie(B-musical artist) from(O) Gym(B-band) Class(I-band) Heroes(I-band) and(O) Kid(B-musical artist) Rock(I-musical artist) performed(O) a(O) medley(O) of(O) their(O) songs(O).(O)", "instance": {"id": "188", "words": ["They", "were", "inducted", "by", "Chuck", "D", "and", "LL", "Cool", "J", "on", "April", "14", ",", "2012", "therefore", "the", "group", "didn", "'t", "perform", ";", "instead", "Black", "Thought", ",", "Travie", "from", "Gym", "Class", "Heroes", "and", "Kid", "Rock", "performed", "a", "medley", "of", "their", "songs", "."], "labels": ["O", "O", "O", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "I-musical artist", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "O", "B-band", "I-band", "I-band", "O", "B-musical artist", "I-musical artist", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, song, music genre, event, musical artist, award, band, organization, person, location, musical instrument, country and O.\nSentence: They were inducted by Chuck D and LL Cool J on April 14 , 2012 therefore the group didn 't perform ; instead Black Thought , Travie from Gym Class Heroes and Kid Rock performed a medley of their songs .", "prompt_labels": "They(O) were(O) inducted(O) by(O) Chuck(B-musical artist) D(I-musical artist) and(O) LL(B-musical artist) Cool(I-musical artist) J(I-musical artist) on(O) April(O) 14(O) ,(O) 2012(O) therefore(O) the(O) group(O) didn(O) 't(O) perform(O) ;(O) instead(O) Black(B-musical artist) Thought(I-musical artist) ,(O) Travie(B-musical artist) from(O) Gym(B-band) Class(I-band) Heroes(I-band) and(O) Kid(B-musical artist) Rock(I-musical artist) performed(O) a(O) medley(O) of(O) their(O) songs(O) .(O)"}, "label_list": ["album", "song", "music genre", "event", "musical artist", "award", "band", "organization", "person", "location", "musical instrument", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8176, 11, 5609, 11, 4731, 17779, 11, 1567, 11, 18273, 10255, 11, 10292, 11, 7200, 11, 7471, 11, 1732, 11, 3813, 11, 18273, 14473, 11, 3224, 323, 507, 627, 85664, 25, 2435, 1051, 304, 55015, 555, 34349, 423, 323, 20072, 24882, 622, 389, 5936, 220, 975, 1174, 220, 679, 17, 9093, 279, 1912, 3287, 364, 83, 2804, 2652, 4619, 5348, 36287, 1174, 43359, 648, 505, 46631, 3308, 38099, 323, 32666, 9305, 10887, 264, 1812, 3258, 315, 872, 11936, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "270", "dataset": "crossner_music", "split": "dev", "prediction": "In(O) 1974(O) he(O) returned(O) to(O) the(O) No.(O) 1(O) spot(O) on(O) the(O) R(B-album) &(I-album) B(I-album) charts(O) with(O) The(B-song) Payback(I-song),(O) with(O) the(O) The(B-song) Payback(I-song) reaching(O) the(O) same(O) spot(O) on(O) the(O) album(O) charts(O) ;(O) he(O) would(O) reach(O) No.(O) 1(O) two(O) more(O) times(O) in(O) 1974(O),(O) with(O) My(B-song) Thang(I-song) and(O) Papa(B-song) Don(I-song) 't(I-song) Take(I-song) No(I-song) Mess(I-song).(O)", "instance": {"id": "270", "words": ["In", "1974", "he", "returned", "to", "the", "No.", "1", "spot", "on", "the", "R", "&", "B", "charts", "with", "The", "Payback", ",", "with", "the", "The", "Payback", "reaching", "the", "same", "spot", "on", "the", "album", "charts", ";", "he", "would", "reach", "No.", "1", "two", "more", "times", "in", "1974", ",", "with", "My", "Thang", "and", "Papa", "Don", "'t", "Take", "No", "Mess", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-music genre", "I-music genre", "I-music genre", "O", "O", "B-album", "I-album", "O", "O", "O", "B-album", "I-album", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-song", "I-song", "O", "B-song", "I-song", "I-song", "I-song", "I-song", "I-song", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, music genre, album, organization, band, musical artist, musical instrument, person, country, event, location, song and O.\nSentence: In 1974 he returned to the No. 1 spot on the R & B charts with The Payback , with the The Payback reaching the same spot on the album charts ; he would reach No. 1 two more times in 1974 , with My Thang and Papa Don 't Take No Mess .", "prompt_labels": "In(O) 1974(O) he(O) returned(O) to(O) the(O) No.(O) 1(O) spot(O) on(O) the(O) R(B-music genre) &(I-music genre) B(I-music genre) charts(O) with(O) The(B-album) Payback(I-album) ,(O) with(O) the(O) The(B-album) Payback(I-album) reaching(O) the(O) same(O) spot(O) on(O) the(O) album(O) charts(O) ;(O) he(O) would(O) reach(O) No.(O) 1(O) two(O) more(O) times(O) in(O) 1974(O) ,(O) with(O) My(B-song) Thang(I-song) and(O) Papa(B-song) Don(I-song) 't(I-song) Take(I-song) No(I-song) Mess(I-song) .(O)"}, "label_list": ["award", "music genre", "album", "organization", "band", "musical artist", "musical instrument", "person", "country", "event", "location", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10292, 11, 4731, 17779, 11, 8176, 11, 7471, 11, 7200, 11, 18273, 10255, 11, 18273, 14473, 11, 1732, 11, 3224, 11, 1567, 11, 3813, 11, 5609, 323, 507, 627, 85664, 25, 763, 220, 4468, 19, 568, 6052, 311, 279, 2360, 13, 220, 16, 7858, 389, 279, 432, 612, 426, 27223, 449, 578, 11728, 1445, 1174, 449, 279, 578, 11728, 1445, 19261, 279, 1890, 7858, 389, 279, 8176, 27223, 2652, 568, 1053, 5662, 2360, 13, 220, 16, 1403, 810, 3115, 304, 220, 4468, 19, 1174, 449, 3092, 666, 526, 323, 65673, 4418, 364, 83, 12040, 2360, 19234, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "8", "dataset": "crossner_music", "split": "dev", "prediction": "The(O) album(O) was(O) certified(O) seven-times(O) platinum(O) in(O) Australia(O) by(O) the(O) Australian(B-organization) Recording(I-organization) Industry(I-organization) Association(I-organization) of(I-organization) America(I-organization) ((O) RIAA(B-organization) )(O).(O)", "instance": {"id": "8", "words": ["The", "album", "was", "certified", "seven-times", "platinum", "in", "Australia", "by", "the", "Australian", "Recording", "Industry", "Association", "(", "ARIA", ")", ",", "five-times", "platinum", "in", "the", "UK", "by", "the", "British", "Phonographic", "Industry", "(", "BPI", ")", ",", "and", "platinum", "in", "the", "US", "by", "the", "Recording", "Industry", "Association", "of", "America", "(", "RIAA", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-country", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "O", "O", "O", "O", "O", "O", "B-country", "O", "O", "B-organization", "I-organization", "I-organization", "O", "B-organization", "O", "O", "O", "O", "O", "O", "B-country", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, organization, location, country, album, music genre, musical instrument, song, musical artist, award, person, event and O.\nSentence: The album was certified seven-times platinum in Australia by the Australian Recording Industry Association ( ARIA ) , five-times platinum in the UK by the British Phonographic Industry ( BPI ) , and platinum in the US by the Recording Industry Association of America ( RIAA ) .", "prompt_labels": "The(O) album(O) was(O) certified(O) seven-times(O) platinum(O) in(O) Australia(B-country) by(O) the(O) Australian(B-organization) Recording(I-organization) Industry(I-organization) Association(I-organization) ((O) ARIA(B-organization) )(O) ,(O) five-times(O) platinum(O) in(O) the(O) UK(B-country) by(O) the(O) British(B-organization) Phonographic(I-organization) Industry(I-organization) ((O) BPI(B-organization) )(O) ,(O) and(O) platinum(O) in(O) the(O) US(B-country) by(O) the(O) Recording(B-organization) Industry(I-organization) Association(I-organization) of(I-organization) America(I-organization) ((O) RIAA(B-organization) )(O) .(O)"}, "label_list": ["band", "organization", "location", "country", "album", "music genre", "musical instrument", "song", "musical artist", "award", "person", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7200, 11, 7471, 11, 3813, 11, 3224, 11, 8176, 11, 4731, 17779, 11, 18273, 14473, 11, 5609, 11, 18273, 10255, 11, 10292, 11, 1732, 11, 1567, 323, 507, 627, 85664, 25, 578, 8176, 574, 23759, 8254, 45548, 63327, 304, 8494, 555, 279, 13673, 61647, 24780, 10229, 320, 362, 79363, 883, 1174, 4330, 45548, 63327, 304, 279, 6560, 555, 279, 8013, 71424, 12968, 24780, 320, 426, 1932, 883, 1174, 323, 63327, 304, 279, 2326, 555, 279, 61647, 24780, 10229, 315, 5270, 320, 432, 5987, 32, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "696", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) would(O) like(O) to(O) find(O) a(O) vegeterian(B-Cuisine) restaurant(O)", "instance": {"id": "696", "words": ["i", "would", "like", "to", "find", "a", "vegeterian", "restaurant"], "labels": ["O", "O", "O", "O", "O", "O", "B-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Rating, Hours, Location, Cuisine, Price, Amenity, Dish and O.\nSentence: i would like to find a vegeterian restaurant", "prompt_labels": "i(O) would(O) like(O) to(O) find(O) a(O) vegeterian(B-Cuisine) restaurant(O)"}, "label_list": ["Restaurant Name", "Rating", "Hours", "Location", "Cuisine", "Price", "Amenity", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 19767, 11, 30192, 11, 10067, 11, 81961, 11, 8650, 11, 3383, 56685, 11, 49268, 323, 507, 627, 85664, 25, 602, 1053, 1093, 311, 1505, 264, 13294, 261, 1122, 10960, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1462", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) there(O) a(O) restaurant(O) located(O) within(B-Location) 1(I-Location) mile(I-Location) from(I-Location) here(I-Location)", "instance": {"id": "1462", "words": ["where", "there", "a", "restaurant", "located", "within", "1", "mile", "from", "here"], "labels": ["O", "O", "O", "O", "O", "B-Location", "I-Location", "I-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Price, Rating, Restaurant Name, Hours, Location, Cuisine, Dish and O.\nSentence: where there a restaurant located within 1 mile from here", "prompt_labels": "where(O) there(O) a(O) restaurant(O) located(O) within(B-Location) 1(I-Location) mile(I-Location) from(I-Location) here(I-Location)"}, "label_list": ["Amenity", "Price", "Rating", "Restaurant Name", "Hours", "Location", "Cuisine", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 8650, 11, 19767, 11, 26568, 4076, 11, 30192, 11, 10067, 11, 81961, 11, 49268, 323, 507, 627, 85664, 25, 1405, 1070, 264, 10960, 7559, 2949, 220, 16, 14929, 505, 1618, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "516", "dataset": "mit-restaurant", "split": "dev", "prediction": "how(O) far(O) is(O) the(O) english(B-Cuisine) pub(I-Cuisine) that(O) serves(O) a(O) fry(B-Dish) up(I-Dish)", "instance": {"id": "516", "words": ["how", "far", "is", "the", "english", "pub", "that", "serves", "a", "fry", "up"], "labels": ["O", "O", "O", "O", "B-Amenity", "I-Amenity", "O", "O", "O", "B-Dish", "I-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Cuisine, Restaurant Name, Rating, Amenity, Location, Price, Dish and O.\nSentence: how far is the english pub that serves a fry up", "prompt_labels": "how(O) far(O) is(O) the(O) english(B-Amenity) pub(I-Amenity) that(O) serves(O) a(O) fry(B-Dish) up(I-Dish)"}, "label_list": ["Hours", "Cuisine", "Restaurant Name", "Rating", "Amenity", "Location", "Price", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 81961, 11, 26568, 4076, 11, 19767, 11, 3383, 56685, 11, 10067, 11, 8650, 11, 49268, 323, 507, 627, 85664, 25, 1268, 3117, 374, 279, 30063, 6814, 430, 17482, 264, 53646, 709, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2394", "dataset": "mit-movie", "split": "dev", "prediction": "could(O) you(O) send(O) me(O) to(O) a(O) website(O) with(O) user(B-review) reviews(O) of(O) willy(B-title) wonka(I-title) the(I-title) chocolate(I-title) factory(I-title)", "instance": {"id": "2394", "words": ["could", "you", "send", "me", "to", "a", "website", "with", "user", "reviews", "of", "willy", "wonka", "the", "chocolate", "factory"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-review", "O", "B-title", "I-title", "I-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, review, rating, title, trailer, year, average ratings, plot, actor, character, genre, song and O.\nSentence: could you send me to a website with user reviews of willy wonka the chocolate factory", "prompt_labels": "could(O) you(O) send(O) me(O) to(O) a(O) website(O) with(O) user(O) reviews(B-review) of(O) willy(B-title) wonka(I-title) the(I-title) chocolate(I-title) factory(I-title)"}, "label_list": ["director", "review", "rating", "title", "trailer", "year", "average ratings", "plot", "actor", "character", "genre", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 3477, 11, 10959, 11, 2316, 11, 19809, 11, 1060, 11, 5578, 18594, 11, 7234, 11, 12360, 11, 3752, 11, 17779, 11, 5609, 323, 507, 627, 85664, 25, 1436, 499, 3708, 757, 311, 264, 3997, 449, 1217, 8544, 315, 289, 14722, 2834, 4657, 279, 18414, 8803, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "86", "dataset": "mit-restaurant", "split": "dev", "prediction": "are(O) there(O) any(O) restaurants(O) within(B-Location) 5(I-Location) miles(I-Location) that(O) accept(B-Amenity) travelers(I-Amenity) checks(I-Amenity)", "instance": {"id": "86", "words": ["are", "there", "any", "restaurants", "within", "5", "miles", "that", "accept", "travelers", "checks"], "labels": ["O", "O", "O", "O", "B-Location", "I-Location", "I-Location", "O", "B-Amenity", "I-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Restaurant Name, Amenity, Dish, Price, Hours, Rating, Cuisine and O.\nSentence: are there any restaurants within 5 miles that accept travelers checks", "prompt_labels": "are(O) there(O) any(O) restaurants(O) within(B-Location) 5(I-Location) miles(I-Location) that(O) accept(B-Amenity) travelers(I-Amenity) checks(I-Amenity)"}, "label_list": ["Location", "Restaurant Name", "Amenity", "Dish", "Price", "Hours", "Rating", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 26568, 4076, 11, 3383, 56685, 11, 49268, 11, 8650, 11, 30192, 11, 19767, 11, 81961, 323, 507, 627, 85664, 25, 527, 1070, 904, 15926, 2949, 220, 20, 8931, 430, 4287, 40386, 12621, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1498", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) there(O) a(O) good(O) thriller(B-genre) that(O) is(O) rated(O) pg(B-rating) 13(I-rating) that(O) came(O) out(O) in(O) the(O) 2010(B-year) s(I-year)", "instance": {"id": "1498", "words": ["is", "there", "a", "good", "thriller", "that", "is", "rated", "pg", "13", "that", "came", "out", "in", "the", "2010", "s"], "labels": ["O", "O", "O", "O", "B-genre", "O", "O", "O", "B-rating", "I-rating", "O", "O", "O", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, trailer, plot, song, title, character, average ratings, actor, rating, director, review, year and O.\nSentence: is there a good thriller that is rated pg 13 that came out in the 2010 s", "prompt_labels": "is(O) there(O) a(O) good(O) thriller(B-genre) that(O) is(O) rated(O) pg(B-rating) 13(I-rating) that(O) came(O) out(O) in(O) the(O) 2010(B-year) s(I-year)"}, "label_list": ["genre", "trailer", "plot", "song", "title", "character", "average ratings", "actor", "rating", "director", "review", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 19809, 11, 7234, 11, 5609, 11, 2316, 11, 3752, 11, 5578, 18594, 11, 12360, 11, 10959, 11, 7690, 11, 3477, 11, 1060, 323, 507, 627, 85664, 25, 374, 1070, 264, 1695, 54461, 430, 374, 22359, 17953, 220, 1032, 430, 3782, 704, 304, 279, 220, 679, 15, 274, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "255", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) any(O) action(B-genre) movies(O) that(O) are(O) in(O) theatres(O) right(B-year) now(I-year)", "instance": {"id": "255", "words": ["show", "me", "any", "action", "movies", "that", "are", "in", "theatres", "right", "now"], "labels": ["O", "O", "O", "B-genre", "O", "O", "O", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, title, average ratings, trailer, song, year, genre, character, director, rating, plot, actor and O.\nSentence: show me any action movies that are in theatres right now", "prompt_labels": "show(O) me(O) any(O) action(B-genre) movies(O) that(O) are(O) in(O) theatres(O) right(B-year) now(I-year)"}, "label_list": ["review", "title", "average ratings", "trailer", "song", "year", "genre", "character", "director", "rating", "plot", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 2316, 11, 5578, 18594, 11, 19809, 11, 5609, 11, 1060, 11, 17779, 11, 3752, 11, 7690, 11, 10959, 11, 7234, 11, 12360, 323, 507, 627, 85664, 25, 1501, 757, 904, 1957, 9698, 430, 527, 304, 47213, 417, 1314, 1457, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "876", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) a(O) list(O) of(O) r(B-rating) rated(O) movies(O) about(O) aliens(B-plot)", "instance": {"id": "876", "words": ["show", "me", "a", "list", "of", "r", "rated", "movies", "about", "aliens"], "labels": ["O", "O", "O", "O", "O", "B-rating", "I-rating", "O", "O", "B-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, year, plot, rating, title, average ratings, song, character, review, genre, trailer, director and O.\nSentence: show me a list of r rated movies about aliens", "prompt_labels": "show(O) me(O) a(O) list(O) of(O) r(B-rating) rated(I-rating) movies(O) about(O) aliens(B-plot)"}, "label_list": ["actor", "year", "plot", "rating", "title", "average ratings", "song", "character", "review", "genre", "trailer", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 1060, 11, 7234, 11, 10959, 11, 2316, 11, 5578, 18594, 11, 5609, 11, 3752, 11, 3477, 11, 17779, 11, 19809, 11, 7690, 323, 507, 627, 85664, 25, 1501, 757, 264, 1160, 315, 436, 22359, 9698, 922, 37219, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "258", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) a(O) good(O) romance(B-genre) movie(O) with(O) jennifer(B-actor) aniston(I-actor)", "instance": {"id": "258", "words": ["what", "is", "a", "good", "romance", "movie", "with", "jennifer", "aniston"], "labels": ["O", "O", "O", "B-review", "B-genre", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, average ratings, trailer, plot, year, genre, character, song, actor, director, title, review and O.\nSentence: what is a good romance movie with jennifer aniston", "prompt_labels": "what(O) is(O) a(O) good(B-review) romance(B-genre) movie(O) with(O) jennifer(B-actor) aniston(I-actor)"}, "label_list": ["rating", "average ratings", "trailer", "plot", "year", "genre", "character", "song", "actor", "director", "title", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 5578, 18594, 11, 19809, 11, 7234, 11, 1060, 11, 17779, 11, 3752, 11, 5609, 11, 12360, 11, 7690, 11, 2316, 11, 3477, 323, 507, 627, 85664, 25, 1148, 374, 264, 1695, 30363, 5818, 449, 503, 60070, 459, 59919, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "393", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) stared(O) in(O) the(O) movie(O) the(B-title) bank(I-title) job(I-title)", "instance": {"id": "393", "words": ["who", "stared", "in", "the", "movie", "the", "bank", "job"], "labels": ["O", "O", "O", "O", "O", "B-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, title, genre, plot, actor, character, trailer, rating, average ratings, director, song, review and O.\nSentence: who stared in the movie the bank job", "prompt_labels": "who(O) stared(O) in(O) the(O) movie(O) the(B-title) bank(I-title) job(I-title)"}, "label_list": ["year", "title", "genre", "plot", "actor", "character", "trailer", "rating", "average ratings", "director", "song", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 2316, 11, 17779, 11, 7234, 11, 12360, 11, 3752, 11, 19809, 11, 10959, 11, 5578, 18594, 11, 7690, 11, 5609, 11, 3477, 323, 507, 627, 85664, 25, 889, 45135, 304, 279, 5818, 279, 6201, 2683, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "159", "dataset": "crossner_science", "split": "dev", "prediction": "Bennett(B-person) was(O) the(O) flight(O) safety(O) manager(O) for(O) the(O) radioisotope(O) power(O) sources(O) currently(O) in(O) use(O) on(O) the(O) Voyager(B-astronomical object) 1(I-astronomical object) and(O) Voyager(B-astronomical object) 2(I-astronomical object) spacecraft(O) ((O) which(O) went(O) to(O) Jupiter(B-astronomical object),(O) Saturn(B-astronomical object),(O) Uranus(B-astronomical object),(O) Neptune(B-astronomical object) and(O) beyond(O) )(O) and(O) on(O) Lincoln(B-organization) Laboratory(I-organization) '(O) s(O) LES(B-organization) 8(I-organization) and(O) LES(B-organization) 9(I-organization) communications(O) satellites(O).(O)", "instance": {"id": "159", "words": ["Bennett", "was", "the", "flight", "safety", "manager", "for", "the", "radioisotope", "power", "sources", "currently", "in", "use", "on", "the", "Voyager", "1", "and", "Voyager", "2", "spacecraft", "(", "which", "went", "to", "Jupiter", ",", "Saturn", ",", "Uranus", ",", "Neptune", "and", "beyond", ")", "and", "on", "Lincoln", "Laboratory", "'", "s", "LES", "8", "and", "LES", "9", "communications", "satellites", "."], "labels": ["B-person", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-astronomical object", "O", "B-astronomical object", "O", "B-astronomical object", "O", "B-astronomical object", "O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: astronomical object, chemical compound, theory, chemical element, academic journal, enzyme, country, discipline, scientist, location, university, person, event, award, organization, protein and O.\nSentence: Bennett was the flight safety manager for the radioisotope power sources currently in use on the Voyager 1 and Voyager 2 spacecraft ( which went to Jupiter , Saturn , Uranus , Neptune and beyond ) and on Lincoln Laboratory ' s LES 8 and LES 9 communications satellites .", "prompt_labels": "Bennett(B-person) was(O) the(O) flight(O) safety(O) manager(O) for(O) the(O) radioisotope(O) power(O) sources(O) currently(O) in(O) use(O) on(O) the(O) Voyager(O) 1(O) and(O) Voyager(O) 2(O) spacecraft(O) ((O) which(O) went(O) to(O) Jupiter(B-astronomical object) ,(O) Saturn(B-astronomical object) ,(O) Uranus(B-astronomical object) ,(O) Neptune(B-astronomical object) and(O) beyond(O) )(O) and(O) on(O) Lincoln(B-organization) Laboratory(I-organization) '(O) s(O) LES(O) 8(O) and(O) LES(O) 9(O) communications(O) satellites(O) .(O)"}, "label_list": ["astronomical object", "chemical compound", "theory", "chemical element", "academic journal", "enzyme", "country", "discipline", "scientist", "location", "university", "person", "event", "award", "organization", "protein"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 87283, 1665, 11, 11742, 24549, 11, 10334, 11, 11742, 2449, 11, 14584, 8486, 11, 49242, 11, 3224, 11, 26434, 11, 28568, 11, 3813, 11, 12374, 11, 1732, 11, 1567, 11, 10292, 11, 7471, 11, 13128, 323, 507, 627, 85664, 25, 39386, 574, 279, 11213, 7296, 6783, 369, 279, 9063, 285, 51782, 2410, 8336, 5131, 304, 1005, 389, 279, 86260, 220, 16, 323, 86260, 220, 17, 42640, 320, 902, 4024, 311, 50789, 1174, 50253, 1174, 80770, 355, 1174, 80724, 323, 7953, 883, 323, 389, 25379, 32184, 364, 274, 97529, 220, 23, 323, 97529, 220, 24, 17320, 47710, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "223", "dataset": "crossner_ai", "split": "dev", "prediction": "Time(B-task) series(I-task) are(O) used(O) in(O) statistics(B-field),(O) signal(B-field) processing(I-field),(O) pattern(B-field) recognition(I-field),(O) econometrics(B-field),(O) mathematical(B-field) finance(I-field),(O) weather(B-field) forecasting(I-field),(O) earthquake(B-field) prediction(I-field),(O) electroencephalography(B-field),(O) control(B-field) engineering(I-field),(O) astronomy(B-field),(O) communications(B-field) engineering(I-field),(O) and(O) largely(O) in(O) any(O) domain(O) of(O) applied(O) science(O) and(O) engineering(O) which(O) involves(O) temporal(O) measurements(O).(O)", "instance": {"id": "223", "words": ["Time", "series", "are", "used", "in", "statistics", ",", "signal", "processing", ",", "pattern", "recognition", ",", "econometrics", ",", "mathematical", "finance", ",", "weather", "forecasting", ",", "earthquake", "prediction", ",", "electroencephalography", ",", "control", "engineering", ",", "astronomy", ",", "communications", "engineering", ",", "and", "largely", "in", "any", "domain", "of", "applied", "science", "and", "engineering", "which", "involves", "temporal", "measurements", "."], "labels": ["O", "O", "O", "O", "O", "B-field", "O", "B-field", "I-field", "O", "B-field", "I-field", "O", "B-field", "O", "B-field", "I-field", "O", "B-field", "I-field", "O", "B-field", "I-field", "O", "B-field", "O", "B-field", "I-field", "O", "B-field", "O", "B-field", "I-field", "O", "O", "O", "O", "O", "O", "O", "B-field", "I-field", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, metric, country, programming language, university, algorithm, organization, product, researcher, task, conference, location, field and O.\nSentence: Time series are used in statistics , signal processing , pattern recognition , econometrics , mathematical finance , weather forecasting , earthquake prediction , electroencephalography , control engineering , astronomy , communications engineering , and largely in any domain of applied science and engineering which involves temporal measurements .", "prompt_labels": "Time(O) series(O) are(O) used(O) in(O) statistics(B-field) ,(O) signal(B-field) processing(I-field) ,(O) pattern(B-field) recognition(I-field) ,(O) econometrics(B-field) ,(O) mathematical(B-field) finance(I-field) ,(O) weather(B-field) forecasting(I-field) ,(O) earthquake(B-field) prediction(I-field) ,(O) electroencephalography(B-field) ,(O) control(B-field) engineering(I-field) ,(O) astronomy(B-field) ,(O) communications(B-field) engineering(I-field) ,(O) and(O) largely(O) in(O) any(O) domain(O) of(O) applied(B-field) science(I-field) and(O) engineering(O) which(O) involves(O) temporal(O) measurements(O) .(O)"}, "label_list": ["person", "metric", "country", "programming language", "university", "algorithm", "organization", "product", "researcher", "task", "conference", "location", "field"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 18767, 11, 3224, 11, 15840, 4221, 11, 12374, 11, 12384, 11, 7471, 11, 2027, 11, 32185, 11, 3465, 11, 10017, 11, 3813, 11, 2115, 323, 507, 627, 85664, 25, 4212, 4101, 527, 1511, 304, 13443, 1174, 8450, 8863, 1174, 5497, 18324, 1174, 3898, 92891, 1174, 37072, 17452, 1174, 9282, 79482, 1174, 38413, 20212, 1174, 25396, 768, 764, 278, 5814, 1174, 2585, 15009, 1174, 82213, 1174, 17320, 15009, 1174, 323, 14090, 304, 904, 8106, 315, 9435, 8198, 323, 15009, 902, 18065, 37015, 22323, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "375", "dataset": "mit-restaurant", "split": "dev", "prediction": "find(O) me(O) a(O) good(B-Rating) pub(B-Cuisine) that(O) has(O) a(O) dance(B-Amenity) floor(I-Amenity)", "instance": {"id": "375", "words": ["find", "me", "a", "good", "pub", "that", "has", "a", "dance", "floor"], "labels": ["O", "O", "O", "B-Rating", "B-Cuisine", "O", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Price, Hours, Location, Amenity, Cuisine, Rating, Restaurant Name and O.\nSentence: find me a good pub that has a dance floor", "prompt_labels": "find(O) me(O) a(O) good(B-Rating) pub(B-Cuisine) that(O) has(O) a(O) dance(B-Amenity) floor(I-Amenity)"}, "label_list": ["Dish", "Price", "Hours", "Location", "Amenity", "Cuisine", "Rating", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 8650, 11, 30192, 11, 10067, 11, 3383, 56685, 11, 81961, 11, 19767, 11, 26568, 4076, 323, 507, 627, 85664, 25, 1505, 757, 264, 1695, 6814, 430, 706, 264, 15612, 6558, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "739", "dataset": "mit-restaurant", "split": "dev", "prediction": "im(O) looking(O) for(O) a(O) romantic(B-Amenity) restaurant(O) where(O) are(O) some(O) near(B-Location) me(I-Location)", "instance": {"id": "739", "words": ["im", "looking", "for", "a", "romantic", "restaurant", "where", "are", "some", "near", "me"], "labels": ["O", "O", "O", "O", "B-Amenity", "O", "O", "O", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Dish, Hours, Location, Cuisine, Amenity, Restaurant Name, Rating and O.\nSentence: im looking for a romantic restaurant where are some near me", "prompt_labels": "im(O) looking(O) for(O) a(O) romantic(B-Amenity) restaurant(O) where(O) are(O) some(O) near(B-Location) me(I-Location)"}, "label_list": ["Price", "Dish", "Hours", "Location", "Cuisine", "Amenity", "Restaurant Name", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 49268, 11, 30192, 11, 10067, 11, 81961, 11, 3383, 56685, 11, 26568, 4076, 11, 19767, 323, 507, 627, 85664, 25, 737, 3411, 369, 264, 24364, 10960, 1405, 527, 1063, 3221, 757, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1207", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) time(O) does(O) on(B-Restaurant Name) the(I-Restaurant Name) rocks(I-Restaurant Name) on(O) seminary(B-Location) stop(O) serving(O) food(O)", "instance": {"id": "1207", "words": ["what", "time", "does", "on", "the", "rocks", "on", "seminary", "stop", "serving", "food"], "labels": ["O", "B-Hours", "O", "B-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name", "O", "B-Location", "B-Hours", "I-Hours", "I-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Rating, Amenity, Location, Hours, Dish, Restaurant Name, Price and O.\nSentence: what time does on the rocks on seminary stop serving food", "prompt_labels": "what(O) time(B-Hours) does(O) on(B-Restaurant Name) the(I-Restaurant Name) rocks(I-Restaurant Name) on(O) seminary(B-Location) stop(B-Hours) serving(I-Hours) food(I-Hours)"}, "label_list": ["Cuisine", "Rating", "Amenity", "Location", "Hours", "Dish", "Restaurant Name", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 19767, 11, 3383, 56685, 11, 10067, 11, 30192, 11, 49268, 11, 26568, 4076, 11, 8650, 323, 507, 627, 85664, 25, 1148, 892, 1587, 389, 279, 23902, 389, 5347, 3367, 3009, 13788, 3691, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "33", "dataset": "crossner_literature", "split": "dev", "prediction": "The(O) poem(O) is(O) quoted(O) by(O) Sue(B-writer) Bridehead(I-writer) in(O) Thomas(B-writer) Hardy(I-writer) '(O) s(O) 1895(O) novel(O),(O) Jude(B-book) the(I-book) Obscure(I-book) and(O) also(O) by(O) Edward(B-writer) Ashburnham(I-writer) in(O) Ford(B-writer) Madox(I-writer).(O) Ford(B-writer) '(O) s(O) The(O) Good(B-book) Soldier(I-book).(O)", "instance": {"id": "33", "words": ["The", "poem", "is", "quoted", "by", "Sue", "Bridehead", "in", "Thomas", "Hardy", "'", "s", "1895", "novel", ",", "Jude", "the", "Obscure", "and", "also", "by", "Edward", "Ashburnham", "in", "Ford", "Madox", ".", "Ford", "'", "s", "The", "Good", "Soldier", "."], "labels": ["O", "B-literary genre", "O", "O", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "O", "O", "B-literary genre", "O", "B-book", "I-book", "I-book", "O", "O", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "B-writer", "O", "O", "B-book", "I-book", "I-book", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, magazine, award, book, literary genre, poem, country, organization, event, writer, location and O.\nSentence: The poem is quoted by Sue Bridehead in Thomas Hardy ' s 1895 novel , Jude the Obscure and also by Edward Ashburnham in Ford Madox . Ford ' s The Good Soldier .", "prompt_labels": "The(O) poem(B-literary genre) is(O) quoted(O) by(O) Sue(B-writer) Bridehead(I-writer) in(O) Thomas(B-writer) Hardy(I-writer) '(O) s(O) 1895(O) novel(B-literary genre) ,(O) Jude(B-book) the(I-book) Obscure(I-book) and(O) also(O) by(O) Edward(B-writer) Ashburnham(I-writer) in(O) Ford(B-writer) Madox(I-writer) .(O) Ford(B-writer) '(O) s(O) The(B-book) Good(I-book) Soldier(I-book) .(O)"}, "label_list": ["person", "magazine", "award", "book", "literary genre", "poem", "country", "organization", "event", "writer", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 14756, 11, 10292, 11, 2363, 11, 32465, 17779, 11, 33894, 11, 3224, 11, 7471, 11, 1567, 11, 7061, 11, 3813, 323, 507, 627, 85664, 25, 578, 33894, 374, 24116, 555, 48749, 78160, 2025, 304, 11355, 58374, 364, 274, 220, 9378, 20, 11775, 1174, 62734, 279, 51541, 66, 554, 323, 1101, 555, 22653, 14937, 22464, 5721, 304, 14337, 386, 40197, 662, 14337, 364, 274, 578, 7839, 53529, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "98", "dataset": "crossner_science", "split": "dev", "prediction": "It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O),(O) by(O) Ingrid(B-scientist) van(I-scientist) Houten-Groeneveld(I-scientist) and(O) Cornelis(B-scientist) van(I-scientist) Houten(I-scientist) at(O) Leiden(B-location),(O) and(O) Tom(B-scientist) Gehrels(I-scientist) at(O) Palomar(B-location) Observatory(I-location) in(O) California(B-location).(O)", "instance": {"id": "98", "words": ["It", "was", "discovered", "on", "24", "September", "1960", ",", "by", "Ingrid", "van", "Houten-Groeneveld", "and", "Cornelis", "van", "Houten", "at", "Leiden", ",", "and", "Tom", "Gehrels", "at", "Palomar", "Observatory", "in", "California", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-scientist", "I-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "I-scientist", "O", "B-location", "O", "O", "B-scientist", "I-scientist", "O", "B-location", "I-location", "O", "B-location", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, enzyme, discipline, astronomical object, scientist, academic journal, chemical compound, chemical element, person, location, theory, country, event, university, award, protein and O.\nSentence: It was discovered on 24 September 1960 , by Ingrid van Houten-Groeneveld and Cornelis van Houten at Leiden , and Tom Gehrels at Palomar Observatory in California .", "prompt_labels": "It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O) ,(O) by(O) Ingrid(B-scientist) van(I-scientist) Houten-Groeneveld(I-scientist) and(O) Cornelis(B-scientist) van(I-scientist) Houten(I-scientist) at(O) Leiden(B-location) ,(O) and(O) Tom(B-scientist) Gehrels(I-scientist) at(O) Palomar(B-location) Observatory(I-location) in(O) California(B-location) .(O)"}, "label_list": ["organization", "enzyme", "discipline", "astronomical object", "scientist", "academic journal", "chemical compound", "chemical element", "person", "location", "theory", "country", "event", "university", "award", "protein"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 49242, 11, 26434, 11, 87283, 1665, 11, 28568, 11, 14584, 8486, 11, 11742, 24549, 11, 11742, 2449, 11, 1732, 11, 3813, 11, 10334, 11, 3224, 11, 1567, 11, 12374, 11, 10292, 11, 13128, 323, 507, 627, 85664, 25, 1102, 574, 11352, 389, 220, 1187, 6250, 220, 5162, 15, 1174, 555, 763, 4297, 5355, 473, 412, 268, 12279, 299, 1994, 85, 789, 323, 99045, 285, 5355, 473, 412, 268, 520, 2009, 12770, 1174, 323, 8529, 74680, 54883, 520, 11165, 316, 277, 58974, 304, 7188, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "186", "dataset": "crossner_science", "split": "dev", "prediction": "He(O) was(O) awarded(O) honorary(O) doctorate(O) degrees(O) by(O) Princeton(B-university) University(I-university) ((O) 1958(O) )(O),(O) Moscow(B-university) State(I-university) University(I-university) ((O) 1992(O) )(O),(O) and(O) the(O) Chinese(B-university) University(I-university) of(I-university) Hong(I-university) Kong(I-university) ((O) 1997(O) )(O).(O)", "instance": {"id": "186", "words": ["He", "was", "awarded", "honorary", "doctorate", "degrees", "by", "Princeton", "University", "(", "1958", ")", ",", "Moscow", "State", "University", "(", "1992", ")", ",", "and", "the", "Chinese", "University", "of", "Hong", "Kong", "(", "1997", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-university", "I-university", "O", "O", "O", "O", "B-university", "I-university", "I-university", "O", "O", "O", "O", "O", "O", "B-university", "I-university", "I-university", "I-university", "I-university", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: protein, university, enzyme, event, astronomical object, chemical compound, country, academic journal, discipline, person, award, scientist, location, chemical element, organization, theory and O.\nSentence: He was awarded honorary doctorate degrees by Princeton University ( 1958 ) , Moscow State University ( 1992 ) , and the Chinese University of Hong Kong ( 1997 ) .", "prompt_labels": "He(O) was(O) awarded(O) honorary(O) doctorate(O) degrees(O) by(O) Princeton(B-university) University(I-university) ((O) 1958(O) )(O) ,(O) Moscow(B-university) State(I-university) University(I-university) ((O) 1992(O) )(O) ,(O) and(O) the(O) Chinese(B-university) University(I-university) of(I-university) Hong(I-university) Kong(I-university) ((O) 1997(O) )(O) .(O)"}, "label_list": ["protein", "university", "enzyme", "event", "astronomical object", "chemical compound", "country", "academic journal", "discipline", "person", "award", "scientist", "location", "chemical element", "organization", "theory"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 13128, 11, 12374, 11, 49242, 11, 1567, 11, 87283, 1665, 11, 11742, 24549, 11, 3224, 11, 14584, 8486, 11, 26434, 11, 1732, 11, 10292, 11, 28568, 11, 3813, 11, 11742, 2449, 11, 7471, 11, 10334, 323, 507, 627, 85664, 25, 1283, 574, 22034, 99119, 10896, 349, 12628, 555, 50421, 3907, 320, 220, 6280, 23, 883, 1174, 23223, 3314, 3907, 320, 220, 2550, 17, 883, 1174, 323, 279, 8620, 3907, 315, 19730, 18711, 320, 220, 2550, 22, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "7", "dataset": "mit-movie", "split": "dev", "prediction": "can(O) you(O) get(O) a(O) soundtrac(B-title) for(O) the(O) harry(B-title) potter(I-title) films(O)", "instance": {"id": "7", "words": ["can", "you", "get", "a", "soundtrac", "for", "the", "harry", "potter", "films"], "labels": ["O", "O", "O", "O", "B-song", "O", "O", "B-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, director, average ratings, genre, year, song, rating, title, review, plot, trailer, actor and O.\nSentence: can you get a soundtrac for the harry potter films", "prompt_labels": "can(O) you(O) get(O) a(O) soundtrac(B-song) for(O) the(O) harry(B-title) potter(I-title) films(I-title)"}, "label_list": ["character", "director", "average ratings", "genre", "year", "song", "rating", "title", "review", "plot", "trailer", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 7690, 11, 5578, 18594, 11, 17779, 11, 1060, 11, 5609, 11, 10959, 11, 2316, 11, 3477, 11, 7234, 11, 19809, 11, 12360, 323, 507, 627, 85664, 25, 649, 499, 636, 264, 5222, 376, 582, 369, 279, 4960, 894, 3419, 466, 12631, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "425", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) said(O) asta(B-title) la(I-title) vista(I-title) baby(I-title)", "instance": {"id": "425", "words": ["who", "said", "asta", "la", "vista", "baby"], "labels": ["O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, review, director, year, trailer, genre, character, plot, average ratings, title, rating, song and O.\nSentence: who said asta la vista baby", "prompt_labels": "who(O) said(O) asta(O) la(O) vista(O) baby(O)"}, "label_list": ["actor", "review", "director", "year", "trailer", "genre", "character", "plot", "average ratings", "title", "rating", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 3477, 11, 7690, 11, 1060, 11, 19809, 11, 17779, 11, 3752, 11, 7234, 11, 5578, 18594, 11, 2316, 11, 10959, 11, 5609, 323, 507, 627, 85664, 25, 889, 1071, 12025, 64, 1208, 40136, 8945, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "64", "dataset": "crossner_literature", "split": "dev", "prediction": "Among(O) his(O) childhood(O) favorites(O) were(O) Charles(B-writer) Dickens(I-writer),(O) Tobias(B-writer) Smollett(I-writer),(O) Mark(B-writer) Twain(I-writer),(O) Booth(B-writer) Tarkington(I-writer),(O) and(O) later(O),(O) Robert(B-writer) Benchley(I-writer) and(O) S.(B-writer) J.(I-writer) Perelman(I-writer).(O)", "instance": {"id": "64", "words": ["Among", "his", "childhood", "favorites", "were", "Charles", "Dickens", ",", "Tobias", "Smollett", ",", "Mark", "Twain", ",", "Booth", "Tarkington", ",", "and", "later", ",", "Robert", "Benchley", "and", "S.", "J.", "Perelman", "."], "labels": ["O", "O", "O", "O", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "O", "O", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "I-writer", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: poem, event, literary genre, country, organization, location, writer, magazine, person, book, award and O.\nSentence: Among his childhood favorites were Charles Dickens , Tobias Smollett , Mark Twain , Booth Tarkington , and later , Robert Benchley and S. J. Perelman .", "prompt_labels": "Among(O) his(O) childhood(O) favorites(O) were(O) Charles(B-writer) Dickens(I-writer) ,(O) Tobias(B-writer) Smollett(I-writer) ,(O) Mark(B-writer) Twain(I-writer) ,(O) Booth(B-writer) Tarkington(I-writer) ,(O) and(O) later(O) ,(O) Robert(B-writer) Benchley(I-writer) and(O) S.(B-writer) J.(I-writer) Perelman(I-writer) .(O)"}, "label_list": ["poem", "event", "literary genre", "country", "organization", "location", "writer", "magazine", "person", "book", "award"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 33894, 11, 1567, 11, 32465, 17779, 11, 3224, 11, 7471, 11, 3813, 11, 7061, 11, 14756, 11, 1732, 11, 2363, 11, 10292, 323, 507, 627, 85664, 25, 22395, 813, 20587, 27672, 1051, 15274, 93999, 1174, 80102, 4487, 337, 28163, 1174, 4488, 12015, 467, 1174, 64370, 350, 847, 4910, 1174, 323, 3010, 1174, 8563, 36358, 3258, 323, 328, 13, 622, 13, 3700, 64641, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "853", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) a(O) rancho(B-Restaurant Name) veo(I-Restaurant Name) restaurant(O) in(O) north(B-Location) memphis(I-Location)", "instance": {"id": "853", "words": ["is", "there", "a", "rancho", "veo", "restaurant", "in", "north", "memphis"], "labels": ["O", "O", "O", "B-Restaurant Name", "I-Restaurant Name", "O", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Location, Price, Restaurant Name, Rating, Amenity, Dish, Cuisine and O.\nSentence: is there a rancho veo restaurant in north memphis", "prompt_labels": "is(O) there(O) a(O) rancho(B-Restaurant Name) veo(I-Restaurant Name) restaurant(O) in(O) north(B-Location) memphis(I-Location)"}, "label_list": ["Hours", "Location", "Price", "Restaurant Name", "Rating", "Amenity", "Dish", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 10067, 11, 8650, 11, 26568, 4076, 11, 19767, 11, 3383, 56685, 11, 49268, 11, 81961, 323, 507, 627, 85664, 25, 374, 1070, 264, 10837, 971, 5320, 78, 10960, 304, 10411, 1871, 37889, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "169", "dataset": "crossner_literature", "split": "dev", "prediction": "It(O) is(O) based(O) on(O) H.(B-writer) P.(I-writer) Lovecraft(I-writer) '(O) s(O) Cthulhu(B-poem) Mythos(I-poem),(O) particularly(O) At(B-book) the(I-book) Mountains(I-book) of(I-book) Madness(I-book),(O) and(O) is(O) a(O) follow-up(O) to(O) Infogrames(O) '(O) earlier(O) Shadow(B-book) of(I-book) the(I-book) Comet(I-book).(O)", "instance": {"id": "169", "words": ["It", "is", "based", "on", "H.", "P.", "Lovecraft", "'", "s", "Cthulhu", "Mythos", ",", "particularly", "At", "the", "Mountains", "of", "Madness", ",", "and", "is", "a", "follow-up", "to", "Infogrames", "'", "earlier", "Shadow", "of", "the", "Comet", "."], "labels": ["O", "O", "O", "O", "B-writer", "I-writer", "I-writer", "O", "O", "O", "O", "O", "O", "B-book", "I-book", "I-book", "I-book", "I-book", "O", "O", "O", "O", "O", "O", "B-organization", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: writer, location, book, poem, literary genre, person, organization, country, award, event, magazine and O.\nSentence: It is based on H. P. Lovecraft ' s Cthulhu Mythos , particularly At the Mountains of Madness , and is a follow-up to Infogrames ' earlier Shadow of the Comet .", "prompt_labels": "It(O) is(O) based(O) on(O) H.(B-writer) P.(I-writer) Lovecraft(I-writer) '(O) s(O) Cthulhu(O) Mythos(O) ,(O) particularly(O) At(B-book) the(I-book) Mountains(I-book) of(I-book) Madness(I-book) ,(O) and(O) is(O) a(O) follow-up(O) to(O) Infogrames(B-organization) '(O) earlier(O) Shadow(O) of(O) the(O) Comet(O) .(O)"}, "label_list": ["writer", "location", "book", "poem", "literary genre", "person", "organization", "country", "award", "event", "magazine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7061, 11, 3813, 11, 2363, 11, 33894, 11, 32465, 17779, 11, 1732, 11, 7471, 11, 3224, 11, 10292, 11, 1567, 11, 14756, 323, 507, 627, 85664, 25, 1102, 374, 3196, 389, 473, 13, 393, 13, 10919, 7868, 364, 274, 356, 339, 360, 17156, 47595, 437, 1174, 8104, 2468, 279, 41114, 315, 71428, 1174, 323, 374, 264, 1833, 5352, 311, 15268, 540, 15988, 364, 6931, 25284, 315, 279, 99198, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "301", "dataset": "crossner_music", "split": "dev", "prediction": "He(O) was(O) the(O) direct(O) inspiration(O) for(O) three(O) Beatles(B-musical artist)'songs(O) :(O) Lucy(B-song) in(I-song) the(I-song) Sky(I-song) with(I-song) Diamonds(I-song) ((O) 1967(O) )(O),(O) Hey(B-song) Jude(I-song) ((O) 1968(O) )(O),(O) and(O) Good(B-song) Night(I-song) ((O) 1968(O) )(O).(O)", "instance": {"id": "301", "words": ["He", "was", "the", "direct", "inspiration", "for", "three", "Beatles", "'", "songs", ":", "Lucy", "in", "the", "Sky", "with", "Diamonds", "(", "1967", ")", ",", "Hey", "Jude", "(", "1968", ")", ",", "and", "Good", "Night", "(", "1968", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-band", "O", "O", "O", "B-song", "I-song", "I-song", "I-song", "I-song", "I-song", "O", "O", "O", "O", "B-song", "I-song", "O", "O", "O", "O", "O", "B-song", "I-song", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, person, award, album, musical artist, location, event, country, band, song, music genre, musical instrument and O.\nSentence: He was the direct inspiration for three Beatles ' songs : Lucy in the Sky with Diamonds ( 1967 ) , Hey Jude ( 1968 ) , and Good Night ( 1968 ) .", "prompt_labels": "He(O) was(O) the(O) direct(O) inspiration(O) for(O) three(O) Beatles(B-band) '(O) songs(O) :(O) Lucy(B-song) in(I-song) the(I-song) Sky(I-song) with(I-song) Diamonds(I-song) ((O) 1967(O) )(O) ,(O) Hey(B-song) Jude(I-song) ((O) 1968(O) )(O) ,(O) and(O) Good(B-song) Night(I-song) ((O) 1968(O) )(O) .(O)"}, "label_list": ["organization", "person", "award", "album", "musical artist", "location", "event", "country", "band", "song", "music genre", "musical instrument"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 1732, 11, 10292, 11, 8176, 11, 18273, 10255, 11, 3813, 11, 1567, 11, 3224, 11, 7200, 11, 5609, 11, 4731, 17779, 11, 18273, 14473, 323, 507, 627, 85664, 25, 1283, 574, 279, 2167, 20343, 369, 2380, 55957, 364, 11936, 551, 45170, 304, 279, 15064, 449, 91210, 320, 220, 5162, 22, 883, 1174, 28653, 62734, 320, 220, 5162, 23, 883, 1174, 323, 7839, 13120, 320, 220, 5162, 23, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "80", "dataset": "crossner_politics", "split": "dev", "prediction": "In(O) 1997(B-election) Canadian(I-election) federal(I-election) election(I-election) and(O) again(O) in(O) 2000(B-election) Canadian(I-election) federal(I-election) election(I-election) Timbrell(B-politician) campaigned(O) for(O) a(O) seat(O) in(O) the(O) House(B-organization) of(I-organization) Commons(I-organization) of(I-organization) Canada(I-organization) as(O) the(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) of(I-political party) Canada(I-political party) candidate(O) in(O) the(O) eastern(B-location) Ontario(I-location) riding(O) of(O) Prince(B-location) Edward(I-location) -I-location) Hastings(I-location) In(O) the(O) 1997(B-election) federal(I-election) election(I-election),(O) Timbrell(B-politician) placed(O) second(O) to(O) Liberal(O) Lyle(B-politician) Vanclief(I-politician),(O) with(O) 21.5(O) %(O) of(O) the(O) vote(O).(O)", "instance": {"id": "80", "words": ["In", "1997", "Canadian", "federal", "election", "and", "again", "in", "2000", "Canadian", "federal", "election", "Timbrell", "campaigned", "for", "a", "seat", "in", "the", "House", "of", "Commons", "of", "Canada", "as", "the", "Progressive", "Conservative", "Party", "of", "Canada", "candidate", "in", "the", "eastern", "Ontario", "riding", "of", "Prince", "Edward", "-", "Hastings", "In", "the", "1997", "federal", "election", ",", "Timbrell", "placed", "second", "to", "Liberal", "Lyle", "Vanclief", ",", "with", "21.5", "%", "of", "the", "vote", "."], "labels": ["O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "B-politician", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "I-location", "I-location", "O", "O", "O", "O", "O", "O", "B-politician", "O", "O", "O", "O", "B-politician", "I-politician", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, country, political party, politician, person, location, event, election and O.\nSentence: In 1997 Canadian federal election and again in 2000 Canadian federal election Timbrell campaigned for a seat in the House of Commons of Canada as the Progressive Conservative Party of Canada candidate in the eastern Ontario riding of Prince Edward - Hastings In the 1997 federal election , Timbrell placed second to Liberal Lyle Vanclief , with 21.5 % of the vote .", "prompt_labels": "In(O) 1997(B-election) Canadian(I-election) federal(I-election) election(I-election) and(O) again(O) in(O) 2000(B-election) Canadian(I-election) federal(I-election) election(I-election) Timbrell(B-politician) campaigned(O) for(O) a(O) seat(O) in(O) the(O) House(B-organization) of(I-organization) Commons(I-organization) of(I-organization) Canada(I-organization) as(O) the(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) of(I-political party) Canada(I-political party) candidate(O) in(O) the(O) eastern(O) Ontario(O) riding(O) of(O) Prince(B-location) Edward(I-location) -(I-location) Hastings(I-location) In(O) the(O) 1997(O) federal(O) election(O) ,(O) Timbrell(B-politician) placed(O) second(O) to(O) Liberal(O) Lyle(B-politician) Vanclief(I-politician) ,(O) with(O) 21.5(O) %(O) of(O) the(O) vote(O) .(O)"}, "label_list": ["organization", "country", "political party", "politician", "person", "location", "event", "election"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 3224, 11, 5054, 4717, 11, 37038, 11, 1732, 11, 3813, 11, 1567, 11, 6355, 323, 507, 627, 85664, 25, 763, 220, 2550, 22, 12152, 6918, 6355, 323, 1578, 304, 220, 1049, 15, 12152, 6918, 6355, 9538, 65, 16684, 87296, 369, 264, 10954, 304, 279, 4783, 315, 26667, 315, 7008, 439, 279, 52870, 30071, 8722, 315, 7008, 9322, 304, 279, 24024, 21193, 20427, 315, 19912, 22653, 482, 79844, 763, 279, 220, 2550, 22, 6918, 6355, 1174, 9538, 65, 16684, 9277, 2132, 311, 31158, 445, 982, 13000, 566, 4843, 1174, 449, 220, 1691, 13, 20, 1034, 315, 279, 7055, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "254", "dataset": "crossner_music", "split": "dev", "prediction": "He(O) is(O) the(O) only(O) person(O) ever(O) to(O) have(O) won(O) Academy(B-award) Awards(I-award),(O) Emmy(B-award) Award(I-award),(O) and(O) Tony(B-award) Award(I-award) awards(O) in(O) the(O) same(O) year(O) ((O) 1973(O) )(O).(O)", "instance": {"id": "254", "words": ["He", "is", "the", "only", "person", "ever", "to", "have", "won", "Academy", "Awards", ",", "Emmy", "Award", ",", "and", "Tony", "Award", "awards", "in", "the", "same", "year", "(", "1973", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "O", "B-award", "I-award", "O", "O", "B-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, music genre, album, person, musical artist, band, location, country, event, organization, award, musical instrument and O.\nSentence: He is the only person ever to have won Academy Awards , Emmy Award , and Tony Award awards in the same year ( 1973 ) .", "prompt_labels": "He(O) is(O) the(O) only(O) person(O) ever(O) to(O) have(O) won(O) Academy(B-award) Awards(I-award) ,(O) Emmy(B-award) Award(I-award) ,(O) and(O) Tony(B-award) Award(I-award) awards(O) in(O) the(O) same(O) year(O) ((O) 1973(O) )(O) .(O)"}, "label_list": ["song", "music genre", "album", "person", "musical artist", "band", "location", "country", "event", "organization", "award", "musical instrument"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 4731, 17779, 11, 8176, 11, 1732, 11, 18273, 10255, 11, 7200, 11, 3813, 11, 3224, 11, 1567, 11, 7471, 11, 10292, 11, 18273, 14473, 323, 507, 627, 85664, 25, 1283, 374, 279, 1193, 1732, 3596, 311, 617, 2834, 16192, 23488, 1174, 67112, 17768, 1174, 323, 19036, 17768, 23146, 304, 279, 1890, 1060, 320, 220, 4468, 18, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "10", "dataset": "crossner_science", "split": "dev", "prediction": "He(O) is(O) currently(O) Director(O) of(O) the(O) Yale(B-organization) Center(I-organization) for(I-organization) the(I-organization) Study(I-organization) of(I-organization) Globalization(I-organization) at(O) Yale(B-university) University(I-university),(O) is(O) the(O) Latin(B-discipline) American(I-discipline) co-chair(O) of(O) the(O) Inter-American(B-organization) Dialogue(I-organization),(O) and(O) is(O) on(O) the(O) board(O) of(O) directors(O) of(O) Citigroup(B-organization).(O)", "instance": {"id": "10", "words": ["He", "is", "currently", "Director", "of", "the", "Yale", "Center", "for", "the", "Study", "of", "Globalization", "at", "Yale", "University", ",", "is", "the", "Latin", "American", "co-chair", "of", "the", "Inter-American", "Dialogue", ",", "and", "is", "on", "the", "board", "of", "directors", "of", "Citigroup", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "B-university", "I-university", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, location, protein, event, organization, theory, country, scientist, award, enzyme, discipline, chemical element, person, university, academic journal, astronomical object and O.\nSentence: He is currently Director of the Yale Center for the Study of Globalization at Yale University , is the Latin American co-chair of the Inter-American Dialogue , and is on the board of directors of Citigroup .", "prompt_labels": "He(O) is(O) currently(O) Director(O) of(O) the(O) Yale(B-organization) Center(I-organization) for(I-organization) the(I-organization) Study(I-organization) of(I-organization) Globalization(I-organization) at(O) Yale(B-university) University(I-university) ,(O) is(O) the(O) Latin(O) American(O) co-chair(O) of(O) the(O) Inter-American(B-organization) Dialogue(I-organization) ,(O) and(O) is(O) on(O) the(O) board(O) of(O) directors(O) of(O) Citigroup(B-organization) .(O)"}, "label_list": ["chemical compound", "location", "protein", "event", "organization", "theory", "country", "scientist", "award", "enzyme", "discipline", "chemical element", "person", "university", "academic journal", "astronomical object"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 11742, 24549, 11, 3813, 11, 13128, 11, 1567, 11, 7471, 11, 10334, 11, 3224, 11, 28568, 11, 10292, 11, 49242, 11, 26434, 11, 11742, 2449, 11, 1732, 11, 12374, 11, 14584, 8486, 11, 87283, 1665, 323, 507, 627, 85664, 25, 1283, 374, 5131, 10783, 315, 279, 44552, 5955, 369, 279, 19723, 315, 8121, 2065, 520, 44552, 3907, 1174, 374, 279, 20023, 3778, 1080, 79781, 315, 279, 5783, 24145, 70589, 1174, 323, 374, 389, 279, 4580, 315, 28454, 315, 18002, 75758, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2136", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movie(O) does(O) kenneth(B-actor) branagh(I-actor) star(O) in(O) that(O) was(O) made(O) in(O) the(O) 1940(B-year) s(I-year) with(O) a(O) megacorporation(B-plot) plot(O) that(O) was(O) liked(B-average ratings) by(I-average ratings) many(I-average ratings)", "instance": {"id": "2136", "words": ["what", "movie", "does", "kenneth", "branagh", "star", "in", "that", "was", "made", "in", "the", "1940", "s", "with", "a", "megacorporation", "plot", "that", "was", "liked", "by", "many"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O", "O", "O", "O", "O", "O", "O", "B-year", "I-year", "O", "O", "B-plot", "O", "O", "O", "B-average ratings", "I-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, trailer, character, year, actor, review, average ratings, plot, song, title, genre, director and O.\nSentence: what movie does kenneth branagh star in that was made in the 1940 s with a megacorporation plot that was liked by many", "prompt_labels": "what(O) movie(O) does(O) kenneth(B-actor) branagh(I-actor) star(O) in(O) that(O) was(O) made(O) in(O) the(O) 1940(B-year) s(I-year) with(O) a(O) megacorporation(B-plot) plot(O) that(O) was(O) liked(B-average ratings) by(I-average ratings) many(I-average ratings)"}, "label_list": ["rating", "trailer", "character", "year", "actor", "review", "average ratings", "plot", "song", "title", "genre", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 19809, 11, 3752, 11, 1060, 11, 12360, 11, 3477, 11, 5578, 18594, 11, 7234, 11, 5609, 11, 2316, 11, 17779, 11, 7690, 323, 507, 627, 85664, 25, 1148, 5818, 1587, 75361, 774, 53358, 34856, 6917, 304, 430, 574, 1903, 304, 279, 220, 6393, 15, 274, 449, 264, 19262, 582, 39382, 367, 7234, 430, 574, 15262, 555, 1690, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1987", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) wall(B-title) e(I-title) about(O)", "instance": {"id": "1987", "words": ["what", "is", "wall", "e", "about"], "labels": ["O", "O", "B-title", "I-title", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, average ratings, plot, character, review, director, genre, actor, year, rating, title, trailer and O.\nSentence: what is wall e about", "prompt_labels": "what(O) is(O) wall(B-title) e(I-title) about(O)"}, "label_list": ["song", "average ratings", "plot", "character", "review", "director", "genre", "actor", "year", "rating", "title", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 5578, 18594, 11, 7234, 11, 3752, 11, 3477, 11, 7690, 11, 17779, 11, 12360, 11, 1060, 11, 10959, 11, 2316, 11, 19809, 323, 507, 627, 85664, 25, 1148, 374, 7147, 384, 922, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "34", "dataset": "crossner_science", "split": "dev", "prediction": "Helicase(O) s(O) unwind(O) the(O) strands(O) to(O) facilitate(O) the(O) advance(O) of(O) sequence-reading(O) enzymes(O) such(O) as(O) DNA(B-enzyme) polymerase(I-enzyme).(O)", "instance": {"id": "34", "words": ["Helicase", "s", "unwind", "the", "strands", "to", "facilitate", "the", "advance", "of", "sequence-reading", "enzymes", "such", "as", "DNA", "polymerase", "."], "labels": ["B-enzyme", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-enzyme", "I-enzyme", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, country, event, person, scientist, organization, location, academic journal, discipline, university, theory, protein, astronomical object, chemical element, enzyme, award and O.\nSentence: Helicase s unwind the strands to facilitate the advance of sequence-reading enzymes such as DNA polymerase .", "prompt_labels": "Helicase(B-enzyme) s(O) unwind(O) the(O) strands(O) to(O) facilitate(O) the(O) advance(O) of(O) sequence-reading(O) enzymes(O) such(O) as(O) DNA(B-enzyme) polymerase(I-enzyme) .(O)"}, "label_list": ["chemical compound", "country", "event", "person", "scientist", "organization", "location", "academic journal", "discipline", "university", "theory", "protein", "astronomical object", "chemical element", "enzyme", "award"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 11742, 24549, 11, 3224, 11, 1567, 11, 1732, 11, 28568, 11, 7471, 11, 3813, 11, 14584, 8486, 11, 26434, 11, 12374, 11, 10334, 11, 13128, 11, 87283, 1665, 11, 11742, 2449, 11, 49242, 11, 10292, 323, 507, 627, 85664, 25, 16183, 292, 521, 274, 82610, 279, 69864, 311, 28696, 279, 12178, 315, 8668, 12, 6285, 56067, 1778, 439, 15922, 47393, 521, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "76", "dataset": "crossner_music", "split": "dev", "prediction": "It(O) comprises(O) the(O) music(O) of(O) Bosnia(B-country) and(I-country) Herzegovina(I-country),(O) Bulgaria(B-country),(O) Croatia(B-country),(O) Music(B-music genre) of(I-music genre) Greece(I-music genre),(O) Montenegro(B-country),(O) Serbia(B-country),(O) Romania(B-country),(O) Republic(I-country) of(I-country) Macedonia(I-country),(O) Albania(B-country),(O) some(O) of(O) the(O) historical(O) states(O) of(O) Yugoslavia(B-country) or(O) the(O) State(B-country) Union(I-country) of(I-country) Serbia(I-country) and(I-country) Montenegro(I-country) and(O) geographical(O) regions(O) such(O) as(O) Thrace(B-location).(O)", "instance": {"id": "76", "words": ["It", "comprises", "the", "music", "of", "Bosnia", "and", "Herzegovina", ",", "Bulgaria", ",", "Croatia", ",", "Music", "of", "Greece", ",", "Montenegro", ",", "Serbia", ",", "Romania", ",", "Republic", "of", "Macedonia", ",", "Albania", ",", "some", "of", "the", "historical", "states", "of", "Yugoslavia", "or", "the", "State", "Union", "of", "Serbia", "and", "Montenegro", "and", "geographical", "regions", "such", "as", "Thrace", "."], "labels": ["O", "O", "O", "B-music genre", "I-music genre", "I-music genre", "I-music genre", "I-music genre", "O", "B-country", "O", "B-country", "O", "B-music genre", "I-music genre", "I-music genre", "O", "B-country", "O", "B-country", "O", "B-country", "O", "B-country", "I-country", "I-country", "O", "B-country", "O", "O", "O", "O", "O", "O", "O", "B-country", "O", "O", "B-country", "I-country", "I-country", "I-country", "I-country", "I-country", "O", "O", "O", "O", "O", "B-location", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, award, country, organization, musical artist, song, musical instrument, album, music genre, location, band, person and O.\nSentence: It comprises the music of Bosnia and Herzegovina , Bulgaria , Croatia , Music of Greece , Montenegro , Serbia , Romania , Republic of Macedonia , Albania , some of the historical states of Yugoslavia or the State Union of Serbia and Montenegro and geographical regions such as Thrace .", "prompt_labels": "It(O) comprises(O) the(O) music(B-music genre) of(I-music genre) Bosnia(I-music genre) and(I-music genre) Herzegovina(I-music genre) ,(O) Bulgaria(B-country) ,(O) Croatia(B-country) ,(O) Music(B-music genre) of(I-music genre) Greece(I-music genre) ,(O) Montenegro(B-country) ,(O) Serbia(B-country) ,(O) Romania(B-country) ,(O) Republic(B-country) of(I-country) Macedonia(I-country) ,(O) Albania(B-country) ,(O) some(O) of(O) the(O) historical(O) states(O) of(O) Yugoslavia(B-country) or(O) the(O) State(B-country) Union(I-country) of(I-country) Serbia(I-country) and(I-country) Montenegro(I-country) and(O) geographical(O) regions(O) such(O) as(O) Thrace(B-location) .(O)"}, "label_list": ["event", "award", "country", "organization", "musical artist", "song", "musical instrument", "album", "music genre", "location", "band", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 10292, 11, 3224, 11, 7471, 11, 18273, 10255, 11, 5609, 11, 18273, 14473, 11, 8176, 11, 4731, 17779, 11, 3813, 11, 7200, 11, 1732, 323, 507, 627, 85664, 25, 1102, 41095, 279, 4731, 315, 77428, 323, 53739, 75287, 2259, 1174, 59819, 1174, 58311, 1174, 10948, 315, 25431, 1174, 9995, 88921, 1174, 59814, 1174, 47149, 1174, 5545, 315, 77509, 1174, 95733, 1174, 1063, 315, 279, 13970, 5415, 315, 97877, 477, 279, 3314, 9323, 315, 59814, 323, 9995, 88921, 323, 54001, 13918, 1778, 439, 30665, 580, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "298", "dataset": "crossner_literature", "split": "dev", "prediction": "In(O) Vertigo(B-title) ((O) 1958(O) )(O) and(O) North(B-title) by(I-title) Northwest(I-title) ((O) 1959(O) )(O) respectively(O),(O) Kim(B-person) Novak(I-person) and(O) Eva(B-person) Marie(I-person) Saint(I-person) play(O) the(O) blonde(O) heroines(O).(O)", "instance": {"id": "298", "words": ["In", "Vertigo", "(", "1958", ")", "and", "North", "by", "Northwest", "(", "1959", ")", "respectively", ",", "Kim", "Novak", "and", "Eva", "Marie", "Saint", "play", "the", "blonde", "heroines", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "B-person", "I-person", "I-person", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, person, magazine, country, poem, writer, organization, book, event, location, award and O.\nSentence: In Vertigo ( 1958 ) and North by Northwest ( 1959 ) respectively , Kim Novak and Eva Marie Saint play the blonde heroines .", "prompt_labels": "In(O) Vertigo(O) ((O) 1958(O) )(O) and(O) North(O) by(O) Northwest(O) ((O) 1959(O) )(O) respectively(O) ,(O) Kim(B-person) Novak(I-person) and(O) Eva(B-person) Marie(I-person) Saint(I-person) play(O) the(O) blonde(O) heroines(O) .(O)"}, "label_list": ["literary genre", "person", "magazine", "country", "poem", "writer", "organization", "book", "event", "location", "award"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 32465, 17779, 11, 1732, 11, 14756, 11, 3224, 11, 33894, 11, 7061, 11, 7471, 11, 2363, 11, 1567, 11, 3813, 11, 10292, 323, 507, 627, 85664, 25, 763, 15408, 7992, 320, 220, 6280, 23, 883, 323, 4892, 555, 40505, 320, 220, 6280, 24, 883, 15947, 1174, 13818, 4723, 587, 323, 55492, 33116, 14539, 1514, 279, 27117, 12084, 1572, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2112", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) rated(O) r(B-rating) movie(O) that(O) marleen(B-director) gorris(I-director) directed(O) with(O) the(O) emotional(B-genre) decision(O) aspect(O) to(O) it(O) receiving(O) an(O) average(B-average ratings) rating(O)", "instance": {"id": "2112", "words": ["what", "is", "the", "rated", "r", "movie", "that", "marleen", "gorris", "directed", "with", "the", "emotional", "decision", "aspect", "to", "it", "receiving", "an", "average", "rating"], "labels": ["O", "O", "O", "O", "B-rating", "O", "O", "B-director", "I-director", "O", "O", "O", "B-genre", "B-plot", "O", "O", "O", "O", "O", "B-average ratings", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, genre, character, actor, year, song, plot, review, title, director, rating, average ratings and O.\nSentence: what is the rated r movie that marleen gorris directed with the emotional decision aspect to it receiving an average rating", "prompt_labels": "what(O) is(O) the(O) rated(O) r(B-rating) movie(O) that(O) marleen(B-director) gorris(I-director) directed(O) with(O) the(O) emotional(B-genre) decision(B-plot) aspect(O) to(O) it(O) receiving(O) an(O) average(B-average ratings) rating(O)"}, "label_list": ["trailer", "genre", "character", "actor", "year", "song", "plot", "review", "title", "director", "rating", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 17779, 11, 3752, 11, 12360, 11, 1060, 11, 5609, 11, 7234, 11, 3477, 11, 2316, 11, 7690, 11, 10959, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1148, 374, 279, 22359, 436, 5818, 430, 3678, 40762, 46298, 6091, 15910, 449, 279, 14604, 5597, 13189, 311, 433, 12588, 459, 5578, 10959, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "47", "dataset": "crossner_literature", "split": "dev", "prediction": "In(O) March(O) 2020(O),(O) a(O) third(O) season(O) of(O) Cosmos(B-title) named(O) Cosmos(B-title) :(O) Possible(B-title) Worlds(I-title),(O) for(O) which(O) Druyan(B-person) was(O) executive(O) producer(O),(O) writer(O),(O) and(O) director(O) premiered(O) on(O) National(B-title) Geographic(I-title).(O)", "instance": {"id": "47", "words": ["In", "March", "2020", ",", "a", "third", "season", "of", "Cosmos", "named", "Cosmos", ":", "Possible", "Worlds", ",", "for", "which", "Druyan", "was", "executive", "producer", ",", "writer", ",", "and", "director", "premiered", "on", "National", "Geographic", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-writer", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-magazine", "I-magazine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: book, person, location, organization, magazine, award, literary genre, country, writer, poem, event and O.\nSentence: In March 2020 , a third season of Cosmos named Cosmos : Possible Worlds , for which Druyan was executive producer , writer , and director premiered on National Geographic .", "prompt_labels": "In(O) March(O) 2020(O) ,(O) a(O) third(O) season(O) of(O) Cosmos(O) named(O) Cosmos(O) :(O) Possible(O) Worlds(O) ,(O) for(O) which(O) Druyan(B-writer) was(O) executive(O) producer(O) ,(O) writer(O) ,(O) and(O) director(O) premiered(O) on(O) National(B-magazine) Geographic(I-magazine) .(O)"}, "label_list": ["book", "person", "location", "organization", "magazine", "award", "literary genre", "country", "writer", "poem", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2363, 11, 1732, 11, 3813, 11, 7471, 11, 14756, 11, 10292, 11, 32465, 17779, 11, 3224, 11, 7061, 11, 33894, 11, 1567, 323, 507, 627, 85664, 25, 763, 5587, 220, 2366, 15, 1174, 264, 4948, 3280, 315, 84524, 7086, 84524, 551, 37207, 52947, 1174, 369, 902, 423, 2739, 8503, 574, 11145, 17276, 1174, 7061, 1174, 323, 7690, 85170, 389, 5165, 66542, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1469", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) there(O) a(O) animation(B-genre) pg(B-rating) 13(I-rating) movie(O) with(O) trisha(B-plot) romance(I-plot)", "instance": {"id": "1469", "words": ["is", "there", "a", "animation", "pg", "13", "movie", "with", "trisha", "romance"], "labels": ["O", "O", "O", "B-genre", "B-rating", "I-rating", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, title, rating, director, character, year, review, average ratings, actor, plot, genre, song and O.\nSentence: is there a animation pg 13 movie with trisha romance", "prompt_labels": "is(O) there(O) a(O) animation(B-genre) pg(B-rating) 13(I-rating) movie(O) with(O) trisha(B-actor) romance(I-actor)"}, "label_list": ["trailer", "title", "rating", "director", "character", "year", "review", "average ratings", "actor", "plot", "genre", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 2316, 11, 10959, 11, 7690, 11, 3752, 11, 1060, 11, 3477, 11, 5578, 18594, 11, 12360, 11, 7234, 11, 17779, 11, 5609, 323, 507, 627, 85664, 25, 374, 1070, 264, 10571, 17953, 220, 1032, 5818, 449, 490, 36040, 30363, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "208", "dataset": "crossner_music", "split": "dev", "prediction": "The(O) song(O)'s(O) popularity(O) resulted(O) in(O) its(O) being(O) covered(O) by(O) other(O) musicians(O),(O) such(O) as(O) The(O) Disposable(B-band) Heroes(I-band) of(I-band) Hiphoprisy(I-band) ((O) who(O) rewrote(O) the(O) lyrics(O) to(O) parody(O) Pete(B-musical artist) Wilson(I-musical artist) )(O),(O) John(B-musical artist) Linnell(I-musical artist) of(O) They(B-band) Might(I-band) Be(I-band) Giants(I-band) and(O) Six(B-band) Feet(I-band) Under(I-band) on(O) their(O) Graveyard(B-album) Classics(I-album) album(O) of(O) cover(O) versions(O).(O)", "instance": {"id": "208", "words": ["The", "song", "'s", "popularity", "resulted", "in", "its", "being", "covered", "by", "other", "musicians", ",", "such", "as", "The", "Disposable", "Heroes", "of", "Hiphoprisy", "(", "who", "rewrote", "the", "lyrics", "to", "parody", "Pete", "Wilson", ")", ",", "John", "Linnell", "of", "They", "Might", "Be", "Giants", "and", "Six", "Feet", "Under", "on", "their", "Graveyard", "Classics", "album", "of", "cover", "versions", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-band", "I-band", "I-band", "I-band", "I-band", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "O", "B-musical artist", "I-musical artist", "O", "B-band", "I-band", "I-band", "I-band", "O", "B-band", "I-band", "I-band", "O", "O", "B-album", "I-album", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, country, event, person, musical instrument, location, band, musical artist, award, music genre, album, organization and O.\nSentence: The song 's popularity resulted in its being covered by other musicians , such as The Disposable Heroes of Hiphoprisy ( who rewrote the lyrics to parody Pete Wilson ) , John Linnell of They Might Be Giants and Six Feet Under on their Graveyard Classics album of cover versions .", "prompt_labels": "The(O) song(O) 's(O) popularity(O) resulted(O) in(O) its(O) being(O) covered(O) by(O) other(O) musicians(O) ,(O) such(O) as(O) The(B-band) Disposable(I-band) Heroes(I-band) of(I-band) Hiphoprisy(I-band) ((O) who(O) rewrote(O) the(O) lyrics(O) to(O) parody(O) Pete(B-person) Wilson(I-person) )(O) ,(O) John(B-musical artist) Linnell(I-musical artist) of(O) They(B-band) Might(I-band) Be(I-band) Giants(I-band) and(O) Six(B-band) Feet(I-band) Under(I-band) on(O) their(O) Graveyard(B-album) Classics(I-album) album(O) of(O) cover(O) versions(O) .(O)"}, "label_list": ["song", "country", "event", "person", "musical instrument", "location", "band", "musical artist", "award", "music genre", "album", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 3224, 11, 1567, 11, 1732, 11, 18273, 14473, 11, 3813, 11, 7200, 11, 18273, 10255, 11, 10292, 11, 4731, 17779, 11, 8176, 11, 7471, 323, 507, 627, 85664, 25, 578, 5609, 364, 82, 23354, 19543, 304, 1202, 1694, 9960, 555, 1023, 32629, 1174, 1778, 439, 578, 52386, 38099, 315, 473, 15619, 454, 6091, 88, 320, 889, 79722, 5646, 279, 24142, 311, 67265, 37373, 17882, 883, 1174, 3842, 445, 6258, 616, 315, 2435, 34351, 2893, 30835, 323, 19198, 62289, 9636, 389, 872, 74842, 17884, 73415, 8176, 315, 3504, 11028, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1003", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) films(O) use(O) the(O) song(O) zippity(B-song) do(I-song) da(I-song)", "instance": {"id": "1003", "words": ["what", "films", "use", "the", "song", "zippity", "do", "da"], "labels": ["O", "O", "O", "O", "O", "B-song", "I-song", "I-song"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, plot, title, actor, trailer, song, director, year, character, review, genre, rating and O.\nSentence: what films use the song zippity do da", "prompt_labels": "what(O) films(O) use(O) the(O) song(O) zippity(B-song) do(I-song) da(I-song)"}, "label_list": ["average ratings", "plot", "title", "actor", "trailer", "song", "director", "year", "character", "review", "genre", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 7234, 11, 2316, 11, 12360, 11, 19809, 11, 5609, 11, 7690, 11, 1060, 11, 3752, 11, 3477, 11, 17779, 11, 10959, 323, 507, 627, 85664, 25, 1148, 12631, 1005, 279, 5609, 1167, 2877, 488, 656, 3067, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "370", "dataset": "crossner_literature", "split": "dev", "prediction": "Lawrence(B-writer) Hill(I-writer) '(O) s(O) Book(B-book) of(I-book) Negroes(I-book) won(O) the(O) 2008(O) Commonwealth(B-award) Writers(I-award) '(O) Prize(O) Overall(O) Best(O) Book(O) Award(O),(O) while(O) Alice(B-writer) Munro(I-writer) became(O) the(O) first(O) Canadian(O) to(O) win(O) the(O) Nobel(B-award) Prize(I-award) in(I-award) Literature(I-award) in(O) 2013(O).(O)", "instance": {"id": "370", "words": ["Lawrence", "Hill", "'", "s", "Book", "of", "Negroes", "won", "the", "2008", "Commonwealth", "Writers", "'", "Prize", "Overall", "Best", "Book", "Award", ",", "while", "Alice", "Munro", "became", "the", "first", "Canadian", "to", "win", "the", "Nobel", "Prize", "in", "Literature", "in", "2013", "."], "labels": ["B-writer", "I-writer", "O", "O", "B-book", "I-book", "I-book", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O", "O", "B-writer", "I-writer", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, book, writer, magazine, person, organization, country, event, award, poem, literary genre and O.\nSentence: Lawrence Hill ' s Book of Negroes won the 2008 Commonwealth Writers ' Prize Overall Best Book Award , while Alice Munro became the first Canadian to win the Nobel Prize in Literature in 2013 .", "prompt_labels": "Lawrence(B-writer) Hill(I-writer) '(O) s(O) Book(B-book) of(I-book) Negroes(I-book) won(O) the(O) 2008(O) Commonwealth(B-award) Writers(I-award) '(I-award) Prize(I-award) Overall(I-award) Best(I-award) Book(I-award) Award(I-award) ,(O) while(O) Alice(B-writer) Munro(I-writer) became(O) the(O) first(O) Canadian(O) to(O) win(O) the(O) Nobel(B-award) Prize(I-award) in(I-award) Literature(I-award) in(O) 2013(O) .(O)"}, "label_list": ["location", "book", "writer", "magazine", "person", "organization", "country", "event", "award", "poem", "literary genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 2363, 11, 7061, 11, 14756, 11, 1732, 11, 7471, 11, 3224, 11, 1567, 11, 10292, 11, 33894, 11, 32465, 17779, 323, 507, 627, 85664, 25, 28574, 8270, 364, 274, 6017, 315, 57147, 288, 2834, 279, 220, 1049, 23, 38298, 59798, 364, 32293, 28993, 7252, 6017, 17768, 1174, 1418, 30505, 28982, 299, 6244, 279, 1176, 12152, 311, 3243, 279, 48078, 32293, 304, 47470, 304, 220, 679, 18, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "317", "dataset": "crossner_literature", "split": "dev", "prediction": "The(B-title) Ghost(I-title) Writer(I-title),(O) a(O) thriller(B-genre) focusing(O) on(O) a(O) ghostwriter(O) working(O) on(O) the(O) memoirs(O) of(O) a(O) character(O) based(O) loosely(O) on(O) former(O) British(O) prime(O) minister(O) Tony(B-person) Blair(I-person),(O) swept(O) the(O) European(B-event) Film(I-event) Awards(I-event) in(O) 2010(O),(O) winning(O) six(O) awards(O),(O) including(O) best(O) movie(O),(O) director(O),(O) actor(O) and(O) screenplay(O).(O)", "instance": {"id": "317", "words": ["The", "Ghost", "Writer", ",", "a", "thriller", "focusing", "on", "a", "ghostwriter", "working", "on", "the", "memoirs", "of", "a", "character", "based", "loosely", "on", "former", "British", "prime", "minister", "Tony", "Blair", ",", "swept", "the", "European", "Film", "Awards", "in", "2010", ",", "winning", "six", "awards", ",", "including", "best", "movie", ",", "director", ",", "actor", "and", "screenplay", "."], "labels": ["B-book", "I-book", "I-book", "O", "O", "B-literary genre", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "O", "O", "B-award", "I-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, award, country, literary genre, writer, event, person, book, poem, location, magazine and O.\nSentence: The Ghost Writer , a thriller focusing on a ghostwriter working on the memoirs of a character based loosely on former British prime minister Tony Blair , swept the European Film Awards in 2010 , winning six awards , including best movie , director , actor and screenplay .", "prompt_labels": "The(B-book) Ghost(I-book) Writer(I-book) ,(O) a(O) thriller(B-literary genre) focusing(O) on(O) a(O) ghostwriter(O) working(O) on(O) the(O) memoirs(O) of(O) a(O) character(O) based(O) loosely(O) on(O) former(O) British(O) prime(O) minister(O) Tony(B-person) Blair(I-person) ,(O) swept(O) the(O) European(B-award) Film(I-award) Awards(I-award) in(O) 2010(O) ,(O) winning(O) six(O) awards(O) ,(O) including(O) best(O) movie(O) ,(O) director(O) ,(O) actor(O) and(O) screenplay(O) .(O)"}, "label_list": ["organization", "award", "country", "literary genre", "writer", "event", "person", "book", "poem", "location", "magazine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 10292, 11, 3224, 11, 32465, 17779, 11, 7061, 11, 1567, 11, 1732, 11, 2363, 11, 33894, 11, 3813, 11, 14756, 323, 507, 627, 85664, 25, 578, 26099, 30504, 1174, 264, 54461, 21760, 389, 264, 20457, 18688, 3318, 389, 279, 51342, 82, 315, 264, 3752, 3196, 63557, 389, 4846, 8013, 10461, 13015, 19036, 42969, 1174, 41323, 279, 7665, 17042, 23488, 304, 220, 679, 15, 1174, 11230, 4848, 23146, 1174, 2737, 1888, 5818, 1174, 7690, 1174, 12360, 323, 85875, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2069", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) last(O) rated(O) r(B-rating) fantasy(B-genre) movie(O) that(O) came(O) out(O)", "instance": {"id": "2069", "words": ["what", "is", "the", "last", "rated", "r", "fantasy", "movie", "that", "came", "out"], "labels": ["O", "O", "O", "O", "O", "B-rating", "B-genre", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, genre, review, title, character, year, plot, song, actor, trailer, director, rating and O.\nSentence: what is the last rated r fantasy movie that came out", "prompt_labels": "what(O) is(O) the(O) last(O) rated(O) r(B-rating) fantasy(B-genre) movie(O) that(O) came(O) out(O)"}, "label_list": ["average ratings", "genre", "review", "title", "character", "year", "plot", "song", "actor", "trailer", "director", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 17779, 11, 3477, 11, 2316, 11, 3752, 11, 1060, 11, 7234, 11, 5609, 11, 12360, 11, 19809, 11, 7690, 11, 10959, 323, 507, 627, 85664, 25, 1148, 374, 279, 1566, 22359, 436, 18884, 5818, 430, 3782, 704, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2094", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) name(O) of(O) an(O) animated(B-genre) film(O) from(O) the(O) 1990(B-year) s(I-year) directed(O) by(O) fritz(B-director) lang(I-director)", "instance": {"id": "2094", "words": ["what", "is", "the", "name", "of", "an", "animated", "film", "from", "the", "1990", "s", "directed", "by", "fritz", "lang"], "labels": ["O", "O", "O", "O", "O", "O", "B-genre", "O", "O", "O", "B-year", "I-year", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, actor, plot, review, genre, title, song, character, trailer, year, rating, average ratings and O.\nSentence: what is the name of an animated film from the 1990 s directed by fritz lang", "prompt_labels": "what(O) is(O) the(O) name(O) of(O) an(O) animated(B-genre) film(O) from(O) the(O) 1990(B-year) s(I-year) directed(O) by(O) fritz(B-director) lang(I-director)"}, "label_list": ["director", "actor", "plot", "review", "genre", "title", "song", "character", "trailer", "year", "rating", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 12360, 11, 7234, 11, 3477, 11, 17779, 11, 2316, 11, 5609, 11, 3752, 11, 19809, 11, 1060, 11, 10959, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1148, 374, 279, 836, 315, 459, 11625, 4632, 505, 279, 220, 2550, 15, 274, 15910, 555, 282, 57821, 8859, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "509", "dataset": "crossner_politics", "split": "dev", "prediction": "The(O) party(O) seeks(O) the(O) removal(O) of(O) Northern(B-location) Ireland(I-location) from(O) the(O) United(B-country) Kingdom(I-country),(O) the(O) Right2Water(B-organization) Campaign(I-organization),(O) the(O) campaign(O) to(O) Repeal(O) The(O) 8th(O) Amendment(O),(O) and(O) their(O) Public(O) Housing(O) For(O) all(O) campaign(O),(O) which(O) calls(O) for(O) the(O) state(O) to(O) introduce(O) a(O) housing(O) system(O) where(O) all(O) citizens(O) have(O) the(O) legal(O) right(O) to(O) rent(O) a(O) high-quality(O),(O) affordable(O) home(O) regardless(O) of(O) their(O) income(O).(O)", "instance": {"id": "509", "words": ["The", "party", "seeks", "the", "removal", "of", "Northern", "Ireland", "from", "the", "United", "Kingdom", ",", "the", "Right2Water", "Campaign", ",", "the", "campaign", "to", "Repeal", "The", "8th", "Amendment", ",", "and", "their", "Public", "Housing", "For", "all", "campaign", ",", "which", "calls", "for", "the", "state", "to", "introduce", "a", "housing", "system", "where", "all", "citizens", "have", "the", "legal", "right", "to", "rent", "a", "high-quality", ",", "affordable", "home", "regardless", "of", "their", "income", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-country", "I-country", "O", "O", "B-country", "I-country", "O", "O", "B-event", "I-event", "O", "O", "B-event", "I-event", "I-event", "I-event", "I-event", "I-event", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, organization, event, election, location, country, person, politician and O.\nSentence: The party seeks the removal of Northern Ireland from the United Kingdom , the Right2Water Campaign , the campaign to Repeal The 8th Amendment , and their Public Housing For all campaign , which calls for the state to introduce a housing system where all citizens have the legal right to rent a high-quality , affordable home regardless of their income .", "prompt_labels": "The(O) party(O) seeks(O) the(O) removal(O) of(O) Northern(B-country) Ireland(I-country) from(O) the(O) United(B-country) Kingdom(I-country) ,(O) the(O) Right2Water(B-event) Campaign(I-event) ,(O) the(O) campaign(B-event) to(I-event) Repeal(I-event) The(I-event) 8th(I-event) Amendment(I-event) ,(O) and(O) their(O) Public(O) Housing(O) For(O) all(O) campaign(O) ,(O) which(O) calls(O) for(O) the(O) state(O) to(O) introduce(O) a(O) housing(O) system(O) where(O) all(O) citizens(O) have(O) the(O) legal(O) right(O) to(O) rent(O) a(O) high-quality(O) ,(O) affordable(O) home(O) regardless(O) of(O) their(O) income(O) .(O)"}, "label_list": ["political party", "organization", "event", "election", "location", "country", "person", "politician"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5054, 4717, 11, 7471, 11, 1567, 11, 6355, 11, 3813, 11, 3224, 11, 1732, 11, 37038, 323, 507, 627, 85664, 25, 578, 4717, 26737, 279, 17065, 315, 17355, 14990, 505, 279, 3723, 15422, 1174, 279, 10291, 17, 29353, 27643, 1174, 279, 4901, 311, 1050, 375, 278, 578, 220, 23, 339, 22454, 1174, 323, 872, 3142, 31433, 1789, 682, 4901, 1174, 902, 6880, 369, 279, 1614, 311, 19678, 264, 11983, 1887, 1405, 682, 10495, 617, 279, 5897, 1314, 311, 8175, 264, 1579, 22867, 1174, 17049, 2162, 15851, 315, 872, 8070, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1730", "dataset": "mit-movie", "split": "dev", "prediction": "name(O) a(O) musical(B-genre) that(O) was(O) directed(O) by(O) billy(B-director) wilder(I-director)", "instance": {"id": "1730", "words": ["name", "a", "musical", "that", "was", "directed", "by", "billy", "wilder"], "labels": ["O", "O", "B-genre", "O", "O", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, genre, plot, title, rating, trailer, character, review, song, year, director, average ratings and O.\nSentence: name a musical that was directed by billy wilder", "prompt_labels": "name(O) a(O) musical(B-genre) that(O) was(O) directed(O) by(O) billy(B-director) wilder(I-director)"}, "label_list": ["actor", "genre", "plot", "title", "rating", "trailer", "character", "review", "song", "year", "director", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 17779, 11, 7234, 11, 2316, 11, 10959, 11, 19809, 11, 3752, 11, 3477, 11, 5609, 11, 1060, 11, 7690, 11, 5578, 18594, 323, 507, 627, 85664, 25, 836, 264, 18273, 430, 574, 15910, 555, 293, 14722, 8545, 261, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1118", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) is(O) the(O) best(B-Rating) coffee(B-Cuisine) house(I-Cuisine) near(B-Location) here(I-Location)", "instance": {"id": "1118", "words": ["what", "is", "the", "best", "coffee", "house", "near", "here"], "labels": ["O", "O", "O", "B-Rating", "B-Cuisine", "I-Cuisine", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Cuisine, Price, Restaurant Name, Dish, Hours, Rating, Amenity and O.\nSentence: what is the best coffee house near here", "prompt_labels": "what(O) is(O) the(O) best(B-Rating) coffee(B-Cuisine) house(I-Cuisine) near(B-Location) here(I-Location)"}, "label_list": ["Location", "Cuisine", "Price", "Restaurant Name", "Dish", "Hours", "Rating", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 81961, 11, 8650, 11, 26568, 4076, 11, 49268, 11, 30192, 11, 19767, 11, 3383, 56685, 323, 507, 627, 85664, 25, 1148, 374, 279, 1888, 11033, 3838, 3221, 1618, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "511", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) year(B-year) did(O) star(B-title) wars(I-title) a(I-title) new(I-title) hope(I-title) come(O) out(O)", "instance": {"id": "511", "words": ["what", "year", "did", "star", "wars", "a", "new", "hope", "come", "out"], "labels": ["O", "O", "O", "B-title", "I-title", "I-title", "I-title", "I-title", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, actor, character, trailer, genre, average ratings, year, rating, song, plot, title, director and O.\nSentence: what year did star wars a new hope come out", "prompt_labels": "what(O) year(O) did(O) star(B-title) wars(I-title) a(I-title) new(I-title) hope(I-title) come(O) out(O)"}, "label_list": ["review", "actor", "character", "trailer", "genre", "average ratings", "year", "rating", "song", "plot", "title", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 12360, 11, 3752, 11, 19809, 11, 17779, 11, 5578, 18594, 11, 1060, 11, 10959, 11, 5609, 11, 7234, 11, 2316, 11, 7690, 323, 507, 627, 85664, 25, 1148, 1060, 1550, 6917, 25981, 264, 502, 3987, 2586, 704, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "356", "dataset": "crossner_literature", "split": "dev", "prediction": "Only(O) The(B-book) Graveyard(I-book) Book(I-book) by(O) Neil(B-writer) Gaiman(I-writer) ((O) 2009(O) )(O) has(O) won(O) both(O) the(O) Carnegie(B-award) Medal(I-award) and(O) the(O) equivalent(O) American(O) award(O),(O) the(O) Newbery(B-award) Medal(I-award).(O)", "instance": {"id": "356", "words": ["Only", "The", "Graveyard", "Book", "by", "Neil", "Gaiman", "(", "2009", ")", "has", "won", "both", "the", "Carnegie", "Medal", "and", "the", "equivalent", "American", "award", ",", "the", "Newbery", "Medal", "."], "labels": ["O", "B-book", "I-book", "I-book", "O", "B-writer", "I-writer", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, person, location, organization, writer, literary genre, award, country, poem, book, magazine and O.\nSentence: Only The Graveyard Book by Neil Gaiman ( 2009 ) has won both the Carnegie Medal and the equivalent American award , the Newbery Medal .", "prompt_labels": "Only(O) The(B-book) Graveyard(I-book) Book(I-book) by(O) Neil(B-writer) Gaiman(I-writer) ((O) 2009(O) )(O) has(O) won(O) both(O) the(O) Carnegie(B-award) Medal(I-award) and(O) the(O) equivalent(O) American(O) award(O) ,(O) the(O) Newbery(B-award) Medal(I-award) .(O)"}, "label_list": ["event", "person", "location", "organization", "writer", "literary genre", "award", "country", "poem", "book", "magazine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 1732, 11, 3813, 11, 7471, 11, 7061, 11, 32465, 17779, 11, 10292, 11, 3224, 11, 33894, 11, 2363, 11, 14756, 323, 507, 627, 85664, 25, 8442, 578, 74842, 17884, 6017, 555, 34221, 480, 2706, 276, 320, 220, 1049, 24, 883, 706, 2834, 2225, 279, 64373, 17867, 323, 279, 13890, 3778, 10292, 1174, 279, 1561, 31304, 17867, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "359", "dataset": "mit-restaurant", "split": "dev", "prediction": "find(O) me(O) a(O) cheap(B-Price) restaurant(O) with(O) a(O) no(B-Amenity) smoking(I-Amenity) area(I-Amenity)", "instance": {"id": "359", "words": ["find", "me", "a", "cheap", "restaurant", "with", "a", "no", "smoking", "area"], "labels": ["O", "O", "O", "B-Price", "O", "O", "O", "B-Amenity", "I-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Price, Hours, Amenity, Dish, Rating, Cuisine, Location and O.\nSentence: find me a cheap restaurant with a no smoking area", "prompt_labels": "find(O) me(O) a(O) cheap(B-Price) restaurant(O) with(O) a(O) no(B-Amenity) smoking(I-Amenity) area(I-Amenity)"}, "label_list": ["Restaurant Name", "Price", "Hours", "Amenity", "Dish", "Rating", "Cuisine", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 8650, 11, 30192, 11, 3383, 56685, 11, 49268, 11, 19767, 11, 81961, 11, 10067, 323, 507, 627, 85664, 25, 1505, 757, 264, 12136, 10960, 449, 264, 912, 20149, 3158, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "23", "dataset": "crossner_music", "split": "dev", "prediction": "She(O) rose(O) to(O) stardom(O) in(O) the(O) romantic(B-genre) comedy(I-genre) Roman(B-title) Holiday(I-title) ((O) 1953(O) )(O),(O) alongside(O) Gregory(B-musical artist) Peck(I-musical artist),(O) for(O) which(O) she(O) was(O) the(O) first(O) actress(O) to(O) win(O) an(O) Academy(B-award) Awards(I-award),(O) a(O) Golden(B-award) Globe(I-award) Awards(I-award),(O) and(O) a(O) British(B-award) Academy(I-award) Film(I-award) Awards(I-award) for(O) a(O) single(O) performance(O).(O)", "instance": {"id": "23", "words": ["She", "rose", "to", "stardom", "in", "the", "romantic", "comedy", "Roman", "Holiday", "(", "1953", ")", ",", "alongside", "Gregory", "Peck", ",", "for", "which", "she", "was", "the", "first", "actress", "to", "win", "an", "Academy", "Awards", ",", "a", "Golden", "Globe", "Awards", ",", "and", "a", "British", "Academy", "Film", "Awards", "for", "a", "single", "performance", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "O", "O", "B-award", "I-award", "I-award", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, location, album, song, band, country, award, organization, musical artist, event, musical instrument, music genre and O.\nSentence: She rose to stardom in the romantic comedy Roman Holiday ( 1953 ) , alongside Gregory Peck , for which she was the first actress to win an Academy Awards , a Golden Globe Awards , and a British Academy Film Awards for a single performance .", "prompt_labels": "She(O) rose(O) to(O) stardom(O) in(O) the(O) romantic(O) comedy(O) Roman(O) Holiday(O) ((O) 1953(O) )(O) ,(O) alongside(O) Gregory(B-person) Peck(I-person) ,(O) for(O) which(O) she(O) was(O) the(O) first(O) actress(O) to(O) win(O) an(O) Academy(B-award) Awards(I-award) ,(O) a(O) Golden(B-award) Globe(I-award) Awards(I-award) ,(O) and(O) a(O) British(B-award) Academy(I-award) Film(I-award) Awards(I-award) for(O) a(O) single(O) performance(O) .(O)"}, "label_list": ["person", "location", "album", "song", "band", "country", "award", "organization", "musical artist", "event", "musical instrument", "music genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 3813, 11, 8176, 11, 5609, 11, 7200, 11, 3224, 11, 10292, 11, 7471, 11, 18273, 10255, 11, 1567, 11, 18273, 14473, 11, 4731, 17779, 323, 507, 627, 85664, 25, 3005, 16392, 311, 357, 569, 316, 304, 279, 24364, 23160, 13041, 32769, 320, 220, 6280, 18, 883, 1174, 16662, 44069, 5250, 377, 1174, 369, 902, 1364, 574, 279, 1176, 24577, 311, 3243, 459, 16192, 23488, 1174, 264, 18288, 41910, 23488, 1174, 323, 264, 8013, 16192, 17042, 23488, 369, 264, 3254, 5178, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "29", "dataset": "crossner_music", "split": "dev", "prediction": "In(O) central(B-location) Europe(I-location),(O) Italo(B-music genre) disco(I-music genre) ((O) a.k.a.(O) 1980s(B-music genre) Euro(I-music genre) disco(I-music genre) )(O) and(O) Euro(B-music genre) house(I-music genre) were(O) the(O) predominant(O) attempts(O) by(O) young(O) musicians(O) to(O) have(O) a(O) hit(O) record(O) in(O) and(O) beyond(O) the(O) borders(O) of(O) their(O) own(O) country(O).(O)", "instance": {"id": "29", "words": ["In", "central", "Europe", ",", "Italo", "disco", "(", "a.k.a.", "1980s", "Euro", "disco", ")", "and", "Euro", "house", "were", "the", "predominant", "attempts", "by", "young", "musicians", "to", "have", "a", "hit", "record", "in", "and", "beyond", "the", "borders", "of", "their", "own", "country", "."], "labels": ["O", "B-location", "I-location", "O", "B-music genre", "I-music genre", "O", "O", "O", "B-music genre", "I-music genre", "O", "O", "B-music genre", "I-music genre", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, musical instrument, award, person, location, country, album, music genre, event, organization, band, song and O.\nSentence: In central Europe , Italo disco ( a.k.a. 1980s Euro disco ) and Euro house were the predominant attempts by young musicians to have a hit record in and beyond the borders of their own country .", "prompt_labels": "In(O) central(B-location) Europe(I-location) ,(O) Italo(B-music genre) disco(I-music genre) ((O) a.k.a.(O) 1980s(O) Euro(B-music genre) disco(I-music genre) )(O) and(O) Euro(B-music genre) house(I-music genre) were(O) the(O) predominant(O) attempts(O) by(O) young(O) musicians(O) to(O) have(O) a(O) hit(O) record(O) in(O) and(O) beyond(O) the(O) borders(O) of(O) their(O) own(O) country(O) .(O)"}, "label_list": ["musical artist", "musical instrument", "award", "person", "location", "country", "album", "music genre", "event", "organization", "band", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18273, 10255, 11, 18273, 14473, 11, 10292, 11, 1732, 11, 3813, 11, 3224, 11, 8176, 11, 4731, 17779, 11, 1567, 11, 7471, 11, 7200, 11, 5609, 323, 507, 627, 85664, 25, 763, 8792, 4606, 1174, 1102, 12812, 54969, 320, 264, 5314, 5973, 13, 220, 3753, 15, 82, 20026, 54969, 883, 323, 20026, 3838, 1051, 279, 96531, 13865, 555, 3995, 32629, 311, 617, 264, 4295, 3335, 304, 323, 7953, 279, 24743, 315, 872, 1866, 3224, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "95", "dataset": "mit-restaurant", "split": "dev", "prediction": "are(O) there(O) any(O) vegan(B-Cuisine) spots(O) that(O) are(O) open(B-Hours) after(I-Hours) 11(I-Hours) at(I-Hours) night(I-Hours)", "instance": {"id": "95", "words": ["are", "there", "any", "vegan", "spots", "that", "are", "open", "after", "11", "at", "night"], "labels": ["O", "O", "O", "B-Cuisine", "I-Cuisine", "O", "O", "B-Hours", "I-Hours", "I-Hours", "I-Hours", "I-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Dish, Hours, Cuisine, Price, Restaurant Name, Rating, Amenity and O.\nSentence: are there any vegan spots that are open after 11 at night", "prompt_labels": "are(O) there(O) any(O) vegan(B-Cuisine) spots(I-Cuisine) that(O) are(O) open(B-Hours) after(I-Hours) 11(I-Hours) at(I-Hours) night(I-Hours)"}, "label_list": ["Location", "Dish", "Hours", "Cuisine", "Price", "Restaurant Name", "Rating", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 49268, 11, 30192, 11, 81961, 11, 8650, 11, 26568, 4076, 11, 19767, 11, 3383, 56685, 323, 507, 627, 85664, 25, 527, 1070, 904, 30249, 19300, 430, 527, 1825, 1306, 220, 806, 520, 3814, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1773", "dataset": "mit-movie", "split": "dev", "prediction": "that(O) comedy(B-genre) was(O) so(O) funny(O) that(O) id(O) give(O) it(O) ten(B-average ratings) stars(I-average ratings)", "instance": {"id": "1773", "words": ["that", "comedy", "was", "so", "funny", "that", "id", "give", "it", "ten", "stars"], "labels": ["O", "O", "O", "O", "B-genre", "O", "O", "O", "O", "B-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, review, song, trailer, director, year, actor, average ratings, rating, plot, character, title and O.\nSentence: that comedy was so funny that id give it ten stars", "prompt_labels": "that(O) comedy(O) was(O) so(O) funny(B-genre) that(O) id(O) give(O) it(O) ten(B-average ratings) stars(I-average ratings)"}, "label_list": ["genre", "review", "song", "trailer", "director", "year", "actor", "average ratings", "rating", "plot", "character", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 3477, 11, 5609, 11, 19809, 11, 7690, 11, 1060, 11, 12360, 11, 5578, 18594, 11, 10959, 11, 7234, 11, 3752, 11, 2316, 323, 507, 627, 85664, 25, 430, 23160, 574, 779, 15526, 430, 887, 3041, 433, 5899, 9958, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "293", "dataset": "crossner_ai", "split": "dev", "prediction": "In(O) the(O) United(B-country) States(I-country) he(O) is(O) a(O) Member(O) of(O) the(O) National(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization),(O) the(O) American(B-organization) Academy(I-organization) of(I-organization) Arts(I-organization) and(I-organization) Sciences(I-organization),(O) the(O) Linguistic(B-organization) Society(I-organization) of(I-organization) America(I-organization),(O) the(O) American(B-organization) Philosophical(I-organization) Association(I-organization),(O) and(O) the(O) American(B-organization) Association(I-organization) for(I-organization) the(I-organization) Advancement(I-organization) of(I-organization) Science(I-organization).(O)", "instance": {"id": "293", "words": ["In", "the", "United", "States", "he", "is", "a", "Member", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "Linguistic", "Society", "of", "America", ",", "the", "American", "Philosophical", "Association", ",", "and", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "labels": ["O", "O", "B-country", "I-country", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, location, person, metric, algorithm, field, organization, product, researcher, country, conference, programming language, task and O.\nSentence: In the United States he is a Member of the National Academy of Sciences , the American Academy of Arts and Sciences , the Linguistic Society of America , the American Philosophical Association , and the American Association for the Advancement of Science .", "prompt_labels": "In(O) the(O) United(B-country) States(I-country) he(O) is(O) a(O) Member(O) of(O) the(O) National(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) ,(O) the(O) American(B-organization) Academy(I-organization) of(I-organization) Arts(I-organization) and(I-organization) Sciences(I-organization) ,(O) the(O) Linguistic(B-organization) Society(I-organization) of(I-organization) America(I-organization) ,(O) the(O) American(B-organization) Philosophical(I-organization) Association(I-organization) ,(O) and(O) the(O) American(B-organization) Association(I-organization) for(I-organization) the(I-organization) Advancement(I-organization) of(I-organization) Science(I-organization) .(O)"}, "label_list": ["university", "location", "person", "metric", "algorithm", "field", "organization", "product", "researcher", "country", "conference", "programming language", "task"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12374, 11, 3813, 11, 1732, 11, 18767, 11, 12384, 11, 2115, 11, 7471, 11, 2027, 11, 32185, 11, 3224, 11, 10017, 11, 15840, 4221, 11, 3465, 323, 507, 627, 85664, 25, 763, 279, 3723, 4273, 568, 374, 264, 12308, 315, 279, 5165, 16192, 315, 23199, 1174, 279, 3778, 16192, 315, 17979, 323, 23199, 1174, 279, 89333, 4633, 13581, 315, 5270, 1174, 279, 3778, 38356, 950, 10229, 1174, 323, 279, 3778, 10229, 369, 279, 12605, 16887, 315, 10170, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "639", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) want(O) something(O) full(B-Dish) of(I-Dish) grease(I-Dish)", "instance": {"id": "639", "words": ["i", "want", "something", "full", "of", "grease"], "labels": ["O", "O", "O", "O", "O", "B-Cuisine"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Rating, Dish, Hours, Location, Restaurant Name, Price, Amenity and O.\nSentence: i want something full of grease", "prompt_labels": "i(O) want(O) something(O) full(O) of(O) grease(B-Cuisine)"}, "label_list": ["Cuisine", "Rating", "Dish", "Hours", "Location", "Restaurant Name", "Price", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 19767, 11, 49268, 11, 30192, 11, 10067, 11, 26568, 4076, 11, 8650, 11, 3383, 56685, 323, 507, 627, 85664, 25, 602, 1390, 2555, 2539, 315, 63471, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1414", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) is(O) the(O) closest(B-Location) jimmie(B-Restaurant Name) johns(I-Restaurant Name)", "instance": {"id": "1414", "words": ["where", "is", "the", "closest", "jimmie", "johns"], "labels": ["O", "O", "O", "B-Location", "B-Restaurant Name", "I-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Rating, Dish, Restaurant Name, Location, Cuisine, Hours, Price and O.\nSentence: where is the closest jimmie johns", "prompt_labels": "where(O) is(O) the(O) closest(B-Location) jimmie(B-Restaurant Name) johns(I-Restaurant Name)"}, "label_list": ["Amenity", "Rating", "Dish", "Restaurant Name", "Location", "Cuisine", "Hours", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 19767, 11, 49268, 11, 26568, 4076, 11, 10067, 11, 81961, 11, 30192, 11, 8650, 323, 507, 627, 85664, 25, 1405, 374, 279, 18585, 503, 12828, 648, 40742, 82, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "194", "dataset": "crossner_music", "split": "dev", "prediction": "He(O) was(O) the(O) guitarist(O) for(O) the(O) 1980s(B-year) Hi-NRG(B-music genre),(O) Synth-pop(B-music genre) band(O),(O) Frankie(B-band) Goes(I-band) to(I-band) Hollywood(I-band).(O)", "instance": {"id": "194", "words": ["He", "was", "the", "guitarist", "for", "the", "1980s", "Hi-NRG", ",", "Synth-pop", "band", ",", "Frankie", "Goes", "to", "Hollywood", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-music genre", "O", "B-music genre", "O", "O", "B-band", "I-band", "I-band", "I-band", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, country, location, musical artist, album, song, event, award, band, person, musical instrument, music genre and O.\nSentence: He was the guitarist for the 1980s Hi-NRG , Synth-pop band , Frankie Goes to Hollywood .", "prompt_labels": "He(O) was(O) the(O) guitarist(O) for(O) the(O) 1980s(O) Hi-NRG(B-music genre) ,(O) Synth-pop(B-music genre) band(O) ,(O) Frankie(B-band) Goes(I-band) to(I-band) Hollywood(I-band) .(O)"}, "label_list": ["organization", "country", "location", "musical artist", "album", "song", "event", "award", "band", "person", "musical instrument", "music genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 3224, 11, 3813, 11, 18273, 10255, 11, 8176, 11, 5609, 11, 1567, 11, 10292, 11, 7200, 11, 1732, 11, 18273, 14473, 11, 4731, 17779, 323, 507, 627, 85664, 25, 1283, 574, 279, 62740, 369, 279, 220, 3753, 15, 82, 21694, 11500, 33460, 1174, 24028, 339, 41352, 7200, 1174, 94545, 61261, 311, 17681, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1442", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) robert(B-actor) de(I-actor) niro(I-actor) in(O) any(O) disaster(B-genre) movies(O)", "instance": {"id": "1442", "words": ["is", "robert", "de", "niro", "in", "any", "disaster", "movies"], "labels": ["O", "B-actor", "I-actor", "I-actor", "O", "O", "B-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, title, genre, review, average ratings, rating, character, actor, year, plot, director, song and O.\nSentence: is robert de niro in any disaster movies", "prompt_labels": "is(O) robert(B-actor) de(I-actor) niro(I-actor) in(O) any(O) disaster(B-genre) movies(O)"}, "label_list": ["trailer", "title", "genre", "review", "average ratings", "rating", "character", "actor", "year", "plot", "director", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 2316, 11, 17779, 11, 3477, 11, 5578, 18594, 11, 10959, 11, 3752, 11, 12360, 11, 1060, 11, 7234, 11, 7690, 11, 5609, 323, 507, 627, 85664, 25, 374, 89993, 409, 308, 8869, 304, 904, 21426, 9698, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "44", "dataset": "crossner_literature", "split": "dev", "prediction": "Hesser(B-person) lives(O) in(O) Brooklyn(B-location) Heights(I-location) with(O) her(O) husband(O),(O) Tad(B-person) Friend(I-person),(O) a(O) staff(O) writer(O) for(O) The(B-magazine) New(I-magazine) Yorker(I-magazine),(O) and(O) their(O) two(O) children(O).(O)", "instance": {"id": "44", "words": ["Hesser", "lives", "in", "Brooklyn", "Heights", "with", "her", "husband", ",", "Tad", "Friend", ",", "a", "staff", "writer", "for", "The", "New", "Yorker", ",", "and", "their", "two", "children", "."], "labels": ["B-writer", "O", "O", "B-location", "I-location", "O", "O", "O", "O", "B-writer", "I-writer", "O", "O", "O", "O", "O", "B-magazine", "I-magazine", "I-magazine", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, location, country, magazine, writer, poem, book, person, event, literary genre, organization and O.\nSentence: Hesser lives in Brooklyn Heights with her husband , Tad Friend , a staff writer for The New Yorker , and their two children .", "prompt_labels": "Hesser(B-writer) lives(O) in(O) Brooklyn(B-location) Heights(I-location) with(O) her(O) husband(O) ,(O) Tad(B-writer) Friend(I-writer) ,(O) a(O) staff(O) writer(O) for(O) The(B-magazine) New(I-magazine) Yorker(I-magazine) ,(O) and(O) their(O) two(O) children(O) .(O)"}, "label_list": ["award", "location", "country", "magazine", "writer", "poem", "book", "person", "event", "literary genre", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10292, 11, 3813, 11, 3224, 11, 14756, 11, 7061, 11, 33894, 11, 2363, 11, 1732, 11, 1567, 11, 32465, 17779, 11, 7471, 323, 507, 627, 85664, 25, 473, 37470, 6439, 304, 26832, 40503, 449, 1077, 10177, 1174, 350, 329, 11848, 1174, 264, 5687, 7061, 369, 578, 1561, 64874, 1174, 323, 872, 1403, 2911, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "115", "dataset": "crossner_literature", "split": "dev", "prediction": "He(O) particularly(O) revered(O) Johann(B-writer) Wolfgang(I-writer) von(I-writer) Goethe(I-writer),(O) Petrarch(B-writer),(O) Pedro(B-writer) Calder\u00f3n(I-writer) de(I-writer) la(I-writer) Barca(I-writer) and(O) William(B-writer) Shakespeare(I-writer).(O)", "instance": {"id": "115", "words": ["He", "particularly", "revered", "Johann", "Wolfgang", "von", "Goethe", ",", "Petrarch", ",", "Pedro", "Calder\u00f3n", "de", "la", "Barca", "and", "William", "Shakespeare", "."], "labels": ["O", "O", "O", "B-writer", "I-writer", "I-writer", "I-writer", "O", "B-writer", "O", "B-writer", "I-writer", "I-writer", "I-writer", "I-writer", "O", "B-writer", "I-writer", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, poem, organization, award, person, event, literary genre, book, location, magazine, writer and O.\nSentence: He particularly revered Johann Wolfgang von Goethe , Petrarch , Pedro Calder\u00f3n de la Barca and William Shakespeare .", "prompt_labels": "He(O) particularly(O) revered(O) Johann(B-writer) Wolfgang(I-writer) von(I-writer) Goethe(I-writer) ,(O) Petrarch(B-writer) ,(O) Pedro(B-writer) Calder\u00f3n(I-writer) de(I-writer) la(I-writer) Barca(I-writer) and(O) William(B-writer) Shakespeare(I-writer) .(O)"}, "label_list": ["country", "poem", "organization", "award", "person", "event", "literary genre", "book", "location", "magazine", "writer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 33894, 11, 7471, 11, 10292, 11, 1732, 11, 1567, 11, 32465, 17779, 11, 2363, 11, 3813, 11, 14756, 11, 7061, 323, 507, 627, 85664, 25, 1283, 8104, 85761, 88964, 87598, 6675, 6122, 19030, 1174, 96876, 1132, 1174, 43582, 76400, 3244, 409, 1208, 4821, 936, 323, 12656, 42482, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1127", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) bette(B-actor) davis(I-actor) ever(O) star(O) in(O) a(O) movie(O) directed(O) by(O) martin(B-director) scorsese(I-director)", "instance": {"id": "1127", "words": ["did", "bette", "davis", "ever", "star", "in", "a", "movie", "directed", "by", "martin", "scorsese"], "labels": ["O", "B-actor", "I-actor", "O", "O", "O", "O", "O", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, review, genre, character, title, plot, year, director, song, rating, trailer, actor and O.\nSentence: did bette davis ever star in a movie directed by martin scorsese", "prompt_labels": "did(O) bette(B-actor) davis(I-actor) ever(O) star(O) in(O) a(O) movie(O) directed(O) by(O) martin(B-director) scorsese(I-director)"}, "label_list": ["average ratings", "review", "genre", "character", "title", "plot", "year", "director", "song", "rating", "trailer", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 3477, 11, 17779, 11, 3752, 11, 2316, 11, 7234, 11, 1060, 11, 7690, 11, 5609, 11, 10959, 11, 19809, 11, 12360, 323, 507, 627, 85664, 25, 1550, 1297, 668, 294, 23156, 3596, 6917, 304, 264, 5818, 15910, 555, 96016, 1156, 1105, 2423, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "494", "dataset": "crossner_politics", "split": "dev", "prediction": "Once(O) the(O) Armistice(O) of(O) Mudanya(O) was(O) signed(O),(O) replacing(O) the(O) Armistice(O) of(O) Mundros(O) ((O) signed(O) by(O) the(O) Ottoman(B-country) Empire(I-country) in(O) 1918(O) at(O) the(O) end(O) of(O) World(B-event) War(I-event) I(I-event) ((O) signed(O) by(O) the(O) Ottoman(B-political party) Empire(I-political party) in(O) 1918(O) at(O) the(O) end(O) of(O) World(B-event) War(I-event) I(I-event) ((O) signed(O) by(O) the(O) Ottoman(B-political party) Empire(I-political party) in(O) 1918(O) at(O) the(O) end(O) of(O) World(B-event) War(I-event) I(I-event) ((O) signed(O) by(O) the(O) Ottoman(B-political party) Empire(I-political party) in(O) 1918(O) at(O) the(O) end(O) of(O) World(B-event) War(I-event) I(I-event) ((O) signed(O) by(O) the(O) Ottoman(B-political party) Empire(I-political party) in(O) 1918(O) at(O) the(O) end(O) of(O) World(B-event) War(I-event) I(I-event) ((O) signed(O) by(O) the(O) Ottoman(B-political party) Empire(I-political party) in(O) 1918(O) at(O) the(O) end(O) of(O) World(B-event) War(I-event) I(I-event) ((O) signed(O) by(O) the(O) Ottoman(B-political party) Empire(I-political party) in(O) 1918(O) at(O) the(O) end(O) of(O) World(B-event) War(I-event) I(I-event) ((O) signed(O) by(O) the(O) Ottoman(B-political party) Empire(I-political party) in(O) 1918(O) at(O) the(O) end(O) of(O) World(B-event) War(I-event) I(I-event) ((O) signed(O) by(O) the(O) Ottoman(B-political party) Empire(I-political party) in(O) 1918(O) at(O) the(O) end(O) of(O) World(B-event) War(I-event) I(I-event) ((O) signed(O) by(O) the(O) Ottoman(B-political party) Empire(I-political party) in(O) 1918(O) at(O) the(O) end(O) of(O) World(B-event) War(I-event) I(I-event) ((O) signed(O) by(O) the(O) Ottoman(B-political party) Empire(I-political party) in(O) 1918(O) at(O) the(O) end(O) of(O) World(B-event) War(I-event) I(I-event) ((O) signed(O) by(O) the(O) Ottoman(B-political party) Empire(I-political party) in(O) 1918(O) at(O) the(O) end(O) of(O) World(B-event) War(I-event) I(I-event) ((O) signed(O) by(O) the(O) Ottoman(B-political party) Empire(I-political party) in(O) 1918(O) at(O) the(O) end(O) of(O) World(B-event) War(I-event) I(I-event) ((O) signed(O) by(O) the(O) Ottoman(B-political party) Empire(I-political party) in(O) 1918(O) at(O) the(O) end(O) of(O) World(B-event) War(I-event) I(I-event) ((O) signed(O) by(O) the(O) Ottoman(B-political party) Empire(I-political party) in(O) 1918(O) at(O) the(O) end(O) of(O) World(B-event) War(I-event) I(I-event) ((O) signed(O) by(O) the(O) Ottoman(B-political party) Empire(I-political party) in(O) 1918(O) at(O) the(O) end(O) of(O) World(B-event) War(I-event) I(I-event) ((O) signed(O) by(O) the(O) Ottoman(B-political party) Empire(I-political party) in(O) 1918(O) at(O) the(O) end(O) of(O) World(B-event) War(I-event) I(I-event) ((O) signed(O) by(O) the(O) Ottoman(B-political party) Empire(I-political party) in(O) 1918(O) at(O) the(O) end(O) of(O) World(B-event) War(I-event) I(I-event) ((O) signed(O) by", "instance": {"id": "494", "words": ["Once", "the", "Armistice", "of", "Mudanya", "was", "signed", ",", "replacing", "the", "Armistice", "of", "Mundros", "(", "signed", "by", "the", "Ottoman", "Empire", "in", "1918", "at", "the", "end", "of", "World", "War", "I", ")", "and", "ending", "the", "Turkish", "War", "of", "Independence", ",", "the", "GNA", "abolished", "the", "imperial", "Sultanate", ",", "which", "was", "accused", "of", "collaborating", "with", "the", "Allies", "of", "World", "War", "I", "during", "the", "occupation", "of", "Turkey", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-country", "I-country", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "O", "O", "O", "O", "B-event", "I-event", "I-event", "I-event", "O", "O", "B-organization", "O", "O", "O", "B-country", "O", "O", "O", "O", "O", "O", "O", "O", "B-country", "O", "B-event", "I-event", "I-event", "O", "O", "O", "O", "B-country", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, organization, location, person, political party, politician, election, country and O.\nSentence: Once the Armistice of Mudanya was signed , replacing the Armistice of Mundros ( signed by the Ottoman Empire in 1918 at the end of World War I ) and ending the Turkish War of Independence , the GNA abolished the imperial Sultanate , which was accused of collaborating with the Allies of World War I during the occupation of Turkey .", "prompt_labels": "Once(O) the(O) Armistice(O) of(O) Mudanya(O) was(O) signed(O) ,(O) replacing(O) the(O) Armistice(O) of(O) Mundros(O) ((O) signed(O) by(O) the(O) Ottoman(B-country) Empire(I-country) in(O) 1918(O) at(O) the(O) end(O) of(O) World(B-event) War(I-event) I(I-event) )(O) and(O) ending(O) the(O) Turkish(B-event) War(I-event) of(I-event) Independence(I-event) ,(O) the(O) GNA(B-organization) abolished(O) the(O) imperial(O) Sultanate(B-country) ,(O) which(O) was(O) accused(O) of(O) collaborating(O) with(O) the(O) Allies(B-country) of(O) World(B-event) War(I-event) I(I-event) during(O) the(O) occupation(O) of(O) Turkey(B-country) .(O)"}, "label_list": ["event", "organization", "location", "person", "political party", "politician", "election", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 7471, 11, 3813, 11, 1732, 11, 5054, 4717, 11, 37038, 11, 6355, 11, 3224, 323, 507, 627, 85664, 25, 9843, 279, 13287, 380, 560, 315, 69440, 25041, 574, 8667, 1174, 25935, 279, 13287, 380, 560, 315, 67661, 3714, 320, 8667, 555, 279, 70110, 21080, 304, 220, 7529, 23, 520, 279, 842, 315, 4435, 5111, 358, 883, 323, 13696, 279, 24666, 5111, 315, 44177, 1174, 279, 480, 7476, 81081, 279, 35379, 76086, 349, 1174, 902, 574, 13487, 315, 73301, 449, 279, 81774, 315, 4435, 5111, 358, 2391, 279, 30747, 315, 17442, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "111", "dataset": "crossner_music", "split": "dev", "prediction": "British(B-music genre) genres(O) such(O) as(O) Lovers(B-music genre) rock(I-music genre),(O) Ragga(B-music genre) jungle(I-music genre) and(O) grime(B-music genre) are(O) also(O) influenced(O) by(O) Jamaican(B-music genre) music(O).(O)", "instance": {"id": "111", "words": ["British", "genres", "such", "as", "Lovers", "rock", ",", "Ragga", "jungle", "and", "grime", "are", "also", "influenced", "by", "Jamaican", "music", "."], "labels": ["O", "O", "O", "O", "B-music genre", "I-music genre", "O", "B-music genre", "I-music genre", "O", "B-music genre", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, person, music genre, location, band, country, award, event, album, song, organization, musical instrument and O.\nSentence: British genres such as Lovers rock , Ragga jungle and grime are also influenced by Jamaican music .", "prompt_labels": "British(O) genres(O) such(O) as(O) Lovers(B-music genre) rock(I-music genre) ,(O) Ragga(B-music genre) jungle(I-music genre) and(O) grime(B-music genre) are(O) also(O) influenced(O) by(O) Jamaican(O) music(O) .(O)"}, "label_list": ["musical artist", "person", "music genre", "location", "band", "country", "award", "event", "album", "song", "organization", "musical instrument"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18273, 10255, 11, 1732, 11, 4731, 17779, 11, 3813, 11, 7200, 11, 3224, 11, 10292, 11, 1567, 11, 8176, 11, 5609, 11, 7471, 11, 18273, 14473, 323, 507, 627, 85664, 25, 8013, 36744, 1778, 439, 445, 9146, 7091, 1174, 51359, 6885, 45520, 323, 1099, 547, 527, 1101, 28160, 555, 41259, 7210, 4731, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "340", "dataset": "crossner_science", "split": "dev", "prediction": "At(O) the(O) end(O) of(O) 2012(O) the(O) journal(O) was(O) split(O) into(O) three(O) independent(O) journals(O) :(O) Journal(B-academic journal) of(I-academic journal) Materials(I-academic journal) Chemistry(I-academic journal) A(I-academic journal) ((O) energy(B-discipline) and(I-discipline) sustainability(I-discipline) )(O),(O) Journal(B-academic journal) of(I-academic journal) Materials(I-academic journal) Chemistry(I-academic journal) B(I-academic journal) ((O) biology(B-discipline) and(I-discipline) medicine(I-discipline) )(O) and(O) Journal(B-academic journal) of(I-academic journal) Materials(I-academic journal) Chemistry(I-academic journal) C(I-academic journal) ((O) optical(B-discipline),(O) magnetic(B-discipline) and(I-discipline) electronic(I-discipline) devices(I-discipline) )(O).(O)", "instance": {"id": "340", "words": ["At", "the", "end", "of", "2012", "the", "journal", "was", "split", "into", "three", "independent", "journals", ":", "Journal", "of", "Materials", "Chemistry", "A", "(", "energy", "and", "sustainability", ")", ",", "Journal", "of", "Materials", "Chemistry", "B", "(", "biology", "and", "medicine", ")", "and", "Journal", "of", "Materials", "Chemistry", "C", "(", "optical", ",", "magnetic", "and", "electronic", "devices", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O", "B-discipline", "I-discipline", "I-discipline", "O", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O", "B-discipline", "O", "B-discipline", "O", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, organization, country, academic journal, university, theory, protein, chemical element, event, location, enzyme, chemical compound, astronomical object, award, scientist, discipline and O.\nSentence: At the end of 2012 the journal was split into three independent journals : Journal of Materials Chemistry A ( energy and sustainability ) , Journal of Materials Chemistry B ( biology and medicine ) and Journal of Materials Chemistry C ( optical , magnetic and electronic devices ) .", "prompt_labels": "At(O) the(O) end(O) of(O) 2012(O) the(O) journal(O) was(O) split(O) into(O) three(O) independent(O) journals(O) :(O) Journal(B-academic journal) of(I-academic journal) Materials(I-academic journal) Chemistry(I-academic journal) A(I-academic journal) ((O) energy(B-discipline) and(I-discipline) sustainability(I-discipline) )(O) ,(O) Journal(B-academic journal) of(I-academic journal) Materials(I-academic journal) Chemistry(I-academic journal) B(I-academic journal) ((O) biology(B-discipline) and(O) medicine(B-discipline) )(O) and(O) Journal(B-academic journal) of(I-academic journal) Materials(I-academic journal) Chemistry(I-academic journal) C(I-academic journal) ((O) optical(O) ,(O) magnetic(O) and(O) electronic(O) devices(O) )(O) .(O)"}, "label_list": ["person", "organization", "country", "academic journal", "university", "theory", "protein", "chemical element", "event", "location", "enzyme", "chemical compound", "astronomical object", "award", "scientist", "discipline"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 7471, 11, 3224, 11, 14584, 8486, 11, 12374, 11, 10334, 11, 13128, 11, 11742, 2449, 11, 1567, 11, 3813, 11, 49242, 11, 11742, 24549, 11, 87283, 1665, 11, 10292, 11, 28568, 11, 26434, 323, 507, 627, 85664, 25, 2468, 279, 842, 315, 220, 679, 17, 279, 8486, 574, 6859, 1139, 2380, 9678, 42780, 551, 10139, 315, 32009, 42846, 362, 320, 4907, 323, 41329, 883, 1174, 10139, 315, 32009, 42846, 426, 320, 34458, 323, 16088, 883, 323, 10139, 315, 32009, 42846, 356, 320, 29393, 1174, 24924, 323, 14683, 7766, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "305", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movies(O) got(O) a(O) great(O) review(O) by(O) roger(B-review) ebert(I-review) in(O) 2011(B-year)", "instance": {"id": "305", "words": ["what", "movies", "got", "a", "great", "review", "by", "roger", "ebert", "in", "2011"], "labels": ["O", "O", "O", "O", "B-average ratings", "I-average ratings", "O", "O", "O", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, character, plot, rating, average ratings, year, song, genre, actor, title, trailer, director and O.\nSentence: what movies got a great review by roger ebert in 2011", "prompt_labels": "what(O) movies(O) got(O) a(O) great(B-average ratings) review(I-average ratings) by(O) roger(O) ebert(O) in(O) 2011(B-year)"}, "label_list": ["review", "character", "plot", "rating", "average ratings", "year", "song", "genre", "actor", "title", "trailer", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 3752, 11, 7234, 11, 10959, 11, 5578, 18594, 11, 1060, 11, 5609, 11, 17779, 11, 12360, 11, 2316, 11, 19809, 11, 7690, 323, 507, 627, 85664, 25, 1148, 9698, 2751, 264, 2294, 3477, 555, 938, 1414, 384, 9339, 304, 220, 679, 16, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2146", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movies(O) did(O) steve(B-actor) mcqueen(I-actor) have(O) a(O) role(O) in(O)", "instance": {"id": "2146", "words": ["what", "movies", "did", "steve", "mcqueen", "have", "a", "role", "in"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, plot, average ratings, review, director, actor, genre, year, rating, song, title, trailer and O.\nSentence: what movies did steve mcqueen have a role in", "prompt_labels": "what(O) movies(O) did(O) steve(B-actor) mcqueen(I-actor) have(O) a(O) role(O) in(O)"}, "label_list": ["character", "plot", "average ratings", "review", "director", "actor", "genre", "year", "rating", "song", "title", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 7234, 11, 5578, 18594, 11, 3477, 11, 7690, 11, 12360, 11, 17779, 11, 1060, 11, 10959, 11, 5609, 11, 2316, 11, 19809, 323, 507, 627, 85664, 25, 1148, 9698, 1550, 4179, 588, 19777, 94214, 617, 264, 3560, 304, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "279", "dataset": "mit-restaurant", "split": "dev", "prediction": "does(O) caribe(B-Restaurant Name) have(O) a(O) smoking(B-Amenity) area(I-Amenity)", "instance": {"id": "279", "words": ["does", "caribe", "have", "a", "smoking", "area"], "labels": ["O", "B-Restaurant Name", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Price, Rating, Location, Dish, Amenity, Restaurant Name, Hours and O.\nSentence: does caribe have a smoking area", "prompt_labels": "does(O) caribe(B-Restaurant Name) have(O) a(O) smoking(B-Amenity) area(I-Amenity)"}, "label_list": ["Cuisine", "Price", "Rating", "Location", "Dish", "Amenity", "Restaurant Name", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 8650, 11, 19767, 11, 10067, 11, 49268, 11, 3383, 56685, 11, 26568, 4076, 11, 30192, 323, 507, 627, 85664, 25, 1587, 1841, 24459, 617, 264, 20149, 3158, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "286", "dataset": "mit-restaurant", "split": "dev", "prediction": "does(O) jaimes(B-Restaurant Name) bakery(I-Restaurant Name) have(O) a(O) great(B-Amenity) decor(I-Amenity)", "instance": {"id": "286", "words": ["does", "jaimes", "bakery", "have", "a", "great", "decor"], "labels": ["O", "B-Restaurant Name", "I-Restaurant Name", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Amenity, Location, Hours, Rating, Price, Restaurant Name, Cuisine and O.\nSentence: does jaimes bakery have a great decor", "prompt_labels": "does(O) jaimes(B-Restaurant Name) bakery(I-Restaurant Name) have(O) a(O) great(B-Amenity) decor(I-Amenity)"}, "label_list": ["Dish", "Amenity", "Location", "Hours", "Rating", "Price", "Restaurant Name", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 3383, 56685, 11, 10067, 11, 30192, 11, 19767, 11, 8650, 11, 26568, 4076, 11, 81961, 323, 507, 627, 85664, 25, 1587, 12203, 1769, 66244, 617, 264, 2294, 10799, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "877", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) a(O) taco(B-Cuisine) joint(I-Cuisine) near(B-Location) the(I-Location) college(I-Location)", "instance": {"id": "877", "words": ["is", "there", "a", "taco", "joint", "near", "the", "college"], "labels": ["O", "O", "O", "B-Cuisine", "I-Cuisine", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Hours, Restaurant Name, Rating, Cuisine, Location, Amenity, Price and O.\nSentence: is there a taco joint near the college", "prompt_labels": "is(O) there(O) a(O) taco(B-Cuisine) joint(I-Cuisine) near(B-Location) the(I-Location) college(I-Location)"}, "label_list": ["Dish", "Hours", "Restaurant Name", "Rating", "Cuisine", "Location", "Amenity", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 30192, 11, 26568, 4076, 11, 19767, 11, 81961, 11, 10067, 11, 3383, 56685, 11, 8650, 323, 507, 627, 85664, 25, 374, 1070, 264, 91941, 10496, 3221, 279, 7926, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1120", "dataset": "mit-movie", "split": "dev", "prediction": "could(O) you(O) help(O) me(O) find(O) a(O) movie(O) starring(O) larenz(B-actor) tate(I-actor) that(O) was(O) made(O) in(O) the(O) past(B-year) eight(I-year) years(I-year) that(O) was(O) rated(B-average ratings) well(I-average ratings)", "instance": {"id": "1120", "words": ["could", "you", "help", "me", "find", "a", "movie", "starring", "larenz", "tate", "that", "was", "made", "in", "the", "past", "eight", "years", "that", "was", "rated", "well"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-actor", "I-actor", "O", "O", "O", "O", "O", "B-year", "I-year", "I-year", "O", "O", "B-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, title, song, average ratings, actor, genre, year, rating, character, plot, director, review and O.\nSentence: could you help me find a movie starring larenz tate that was made in the past eight years that was rated well", "prompt_labels": "could(O) you(O) help(O) me(O) find(O) a(O) movie(O) starring(O) larenz(B-actor) tate(I-actor) that(O) was(O) made(O) in(O) the(O) past(B-year) eight(I-year) years(I-year) that(O) was(O) rated(B-average ratings) well(I-average ratings)"}, "label_list": ["trailer", "title", "song", "average ratings", "actor", "genre", "year", "rating", "character", "plot", "director", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 2316, 11, 5609, 11, 5578, 18594, 11, 12360, 11, 17779, 11, 1060, 11, 10959, 11, 3752, 11, 7234, 11, 7690, 11, 3477, 323, 507, 627, 85664, 25, 1436, 499, 1520, 757, 1505, 264, 5818, 40500, 326, 9329, 89, 259, 349, 430, 574, 1903, 304, 279, 3347, 8223, 1667, 430, 574, 22359, 1664, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "759", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) a(O) movie(O) with(O) lots(B-title) of(I-title) sky(I-title) diving(I-title) in(O) it(O)", "instance": {"id": "759", "words": ["show", "me", "a", "movie", "with", "lots", "of", "sky", "diving", "in", "it"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-plot", "I-plot", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, review, song, character, title, average ratings, genre, year, rating, actor, director, trailer and O.\nSentence: show me a movie with lots of sky diving in it", "prompt_labels": "show(O) me(O) a(O) movie(O) with(O) lots(O) of(O) sky(B-plot) diving(I-plot) in(O) it(O)"}, "label_list": ["plot", "review", "song", "character", "title", "average ratings", "genre", "year", "rating", "actor", "director", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 3477, 11, 5609, 11, 3752, 11, 2316, 11, 5578, 18594, 11, 17779, 11, 1060, 11, 10959, 11, 12360, 11, 7690, 11, 19809, 323, 507, 627, 85664, 25, 1501, 757, 264, 5818, 449, 10283, 315, 13180, 43515, 304, 433, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "623", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) zombie(B-plot) movie(O) features(O) a(O) zombie(B-plot) tiger(I-plot)", "instance": {"id": "623", "words": ["what", "zombie", "movie", "features", "a", "zombie", "tiger"], "labels": ["O", "B-genre", "I-genre", "O", "O", "B-character", "I-character"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, character, title, song, trailer, rating, review, year, director, average ratings, plot, genre and O.\nSentence: what zombie movie features a zombie tiger", "prompt_labels": "what(O) zombie(B-genre) movie(I-genre) features(O) a(O) zombie(B-character) tiger(I-character)"}, "label_list": ["actor", "character", "title", "song", "trailer", "rating", "review", "year", "director", "average ratings", "plot", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 3752, 11, 2316, 11, 5609, 11, 19809, 11, 10959, 11, 3477, 11, 1060, 11, 7690, 11, 5578, 18594, 11, 7234, 11, 17779, 323, 507, 627, 85664, 25, 1148, 38836, 5818, 4519, 264, 38836, 52835, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1335", "dataset": "mit-movie", "split": "dev", "prediction": "i(O) would(O) like(O) a(O) war(B-genre) movie(O) directed(O) by(O) harry(B-director) elfont(I-director) from(O) last(B-year) year(I-year) rated(O) pg(B-rating) 13(I-rating)", "instance": {"id": "1335", "words": ["i", "would", "like", "a", "war", "movie", "directed", "by", "harry", "elfont", "from", "last", "year", "rated", "pg", "13"], "labels": ["O", "O", "O", "O", "B-plot", "O", "O", "O", "B-director", "I-director", "O", "B-year", "I-year", "O", "B-rating", "I-rating"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, average ratings, song, director, year, title, character, genre, rating, plot, trailer, actor and O.\nSentence: i would like a war movie directed by harry elfont from last year rated pg 13", "prompt_labels": "i(O) would(O) like(O) a(O) war(B-plot) movie(O) directed(O) by(O) harry(B-director) elfont(I-director) from(O) last(B-year) year(I-year) rated(O) pg(B-rating) 13(I-rating)"}, "label_list": ["review", "average ratings", "song", "director", "year", "title", "character", "genre", "rating", "plot", "trailer", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 5578, 18594, 11, 5609, 11, 7690, 11, 1060, 11, 2316, 11, 3752, 11, 17779, 11, 10959, 11, 7234, 11, 19809, 11, 12360, 323, 507, 627, 85664, 25, 602, 1053, 1093, 264, 4208, 5818, 15910, 555, 4960, 894, 41845, 546, 505, 1566, 1060, 22359, 17953, 220, 1032, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "313", "dataset": "crossner_ai", "split": "dev", "prediction": "They(O) presented(O) their(O) method(O) and(O) results(O) in(O) SIGGRAPH(B-conference) 2000(I-conference).(O)", "instance": {"id": "313", "words": ["They", "presented", "their", "method", "and", "results", "in", "SIGGRAPH", "2000", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-conference", "I-conference", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, programming language, university, product, researcher, task, location, organization, algorithm, field, conference, country, metric and O.\nSentence: They presented their method and results in SIGGRAPH 2000 .", "prompt_labels": "They(O) presented(O) their(O) method(O) and(O) results(O) in(O) SIGGRAPH(B-conference) 2000(I-conference) .(O)"}, "label_list": ["person", "programming language", "university", "product", "researcher", "task", "location", "organization", "algorithm", "field", "conference", "country", "metric"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 15840, 4221, 11, 12374, 11, 2027, 11, 32185, 11, 3465, 11, 3813, 11, 7471, 11, 12384, 11, 2115, 11, 10017, 11, 3224, 11, 18767, 323, 507, 627, 85664, 25, 2435, 10666, 872, 1749, 323, 3135, 304, 26093, 41084, 220, 1049, 15, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "47", "dataset": "mit-restaurant", "split": "dev", "prediction": "are(O) there(O) any(O) hamburger(B-Cuisine) restaurants(O) close(B-Location) by(I-Location)", "instance": {"id": "47", "words": ["are", "there", "any", "hamburger", "restaurants", "close", "by"], "labels": ["O", "O", "O", "B-Cuisine", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Price, Rating, Hours, Amenity, Cuisine, Dish, Location and O.\nSentence: are there any hamburger restaurants close by", "prompt_labels": "are(O) there(O) any(O) hamburger(B-Cuisine) restaurants(O) close(B-Location) by(I-Location)"}, "label_list": ["Restaurant Name", "Price", "Rating", "Hours", "Amenity", "Cuisine", "Dish", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 8650, 11, 19767, 11, 30192, 11, 3383, 56685, 11, 81961, 11, 49268, 11, 10067, 323, 507, 627, 85664, 25, 527, 1070, 904, 89847, 15926, 3345, 555, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2142", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movie(O) stared(O) terry(B-actor) farrell(I-actor) as(O) a(O) cowboy(B-plot) in(O) mexico(B-plot)", "instance": {"id": "2142", "words": ["what", "movie", "stared", "terry", "farrell", "as", "a", "cowboy", "in", "mexico"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O", "O", "B-genre", "O", "B-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, director, average ratings, genre, trailer, actor, plot, year, title, rating, character, song and O.\nSentence: what movie stared terry farrell as a cowboy in mexico", "prompt_labels": "what(O) movie(O) stared(O) terry(B-actor) farrell(I-actor) as(O) a(O) cowboy(B-genre) in(O) mexico(B-plot)"}, "label_list": ["review", "director", "average ratings", "genre", "trailer", "actor", "plot", "year", "title", "rating", "character", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 7690, 11, 5578, 18594, 11, 17779, 11, 19809, 11, 12360, 11, 7234, 11, 1060, 11, 2316, 11, 10959, 11, 3752, 11, 5609, 323, 507, 627, 85664, 25, 1148, 5818, 45135, 259, 5515, 3117, 16684, 439, 264, 81272, 304, 77476, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "216", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) directed(O) the(O) film(O) the(B-title) lorax(I-title)", "instance": {"id": "216", "words": ["who", "directed", "the", "film", "the", "lorax"], "labels": ["O", "O", "O", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, plot, actor, average ratings, genre, rating, title, director, year, character, song, trailer and O.\nSentence: who directed the film the lorax", "prompt_labels": "who(O) directed(O) the(O) film(O) the(B-title) lorax(I-title)"}, "label_list": ["review", "plot", "actor", "average ratings", "genre", "rating", "title", "director", "year", "character", "song", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 7234, 11, 12360, 11, 5578, 18594, 11, 17779, 11, 10959, 11, 2316, 11, 7690, 11, 1060, 11, 3752, 11, 5609, 11, 19809, 323, 507, 627, 85664, 25, 889, 15910, 279, 4632, 279, 67311, 710, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "554", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) am(O) looking(O) for(O) lunch(B-Cuisine) buffets(I-Cuisine) within(B-Location) 15(I-Location) minutes(I-Location) driving(I-Location) distance(I-Location)", "instance": {"id": "554", "words": ["i", "am", "looking", "for", "lunch", "buffets", "within", "15", "minutes", "driving", "distance"], "labels": ["O", "O", "O", "O", "B-Hours", "B-Amenity", "B-Location", "I-Location", "I-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Rating, Cuisine, Location, Restaurant Name, Price, Hours, Dish and O.\nSentence: i am looking for lunch buffets within 15 minutes driving distance", "prompt_labels": "i(O) am(O) looking(O) for(O) lunch(B-Hours) buffets(B-Amenity) within(B-Location) 15(I-Location) minutes(I-Location) driving(I-Location) distance(I-Location)"}, "label_list": ["Amenity", "Rating", "Cuisine", "Location", "Restaurant Name", "Price", "Hours", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 19767, 11, 81961, 11, 10067, 11, 26568, 4076, 11, 8650, 11, 30192, 11, 49268, 323, 507, 627, 85664, 25, 602, 1097, 3411, 369, 16163, 11783, 1441, 2949, 220, 868, 4520, 10043, 6138, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "171", "dataset": "crossner_music", "split": "dev", "prediction": "Juliana(B-musical artist) Hatfield(I-musical artist) is(O) an(O) American(O) musician(O) and(O) singer-songwriter(O) from(O) the(O) Boston(B-location) area(I-location),(O) formerly(O) of(O) the(O) indie(B-music genre) rock(I-music genre) bands(O) Blake(B-band) Babies(I-band),(O) Some(B-band) Girls(I-band),(O) and(O) The(B-band) Lemonheads(I-band).(O)", "instance": {"id": "171", "words": ["Juliana", "Hatfield", "is", "an", "American", "musician", "and", "singer-songwriter", "from", "the", "Boston", "area", ",", "formerly", "of", "the", "indie", "rock", "bands", "Blake", "Babies", ",", "Some", "Girls", ",", "and", "The", "Lemonheads", "."], "labels": ["B-musical artist", "I-musical artist", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "O", "O", "O", "O", "O", "B-music genre", "O", "B-band", "I-band", "O", "B-band", "I-band", "O", "O", "B-band", "I-band", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, country, person, music genre, album, organization, musical artist, musical instrument, event, award, location, band and O.\nSentence: Juliana Hatfield is an American musician and singer-songwriter from the Boston area , formerly of the indie rock bands Blake Babies , Some Girls , and The Lemonheads .", "prompt_labels": "Juliana(B-musical artist) Hatfield(I-musical artist) is(O) an(O) American(O) musician(O) and(O) singer-songwriter(O) from(O) the(O) Boston(B-location) area(I-location) ,(O) formerly(O) of(O) the(O) indie(O) rock(B-music genre) bands(O) Blake(B-band) Babies(I-band) ,(O) Some(B-band) Girls(I-band) ,(O) and(O) The(B-band) Lemonheads(I-band) .(O)"}, "label_list": ["song", "country", "person", "music genre", "album", "organization", "musical artist", "musical instrument", "event", "award", "location", "band"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 3224, 11, 1732, 11, 4731, 17779, 11, 8176, 11, 7471, 11, 18273, 10255, 11, 18273, 14473, 11, 1567, 11, 10292, 11, 3813, 11, 7200, 323, 507, 627, 85664, 25, 10263, 12699, 22050, 2630, 374, 459, 3778, 39844, 323, 23597, 77740, 18688, 505, 279, 10406, 3158, 1174, 34833, 315, 279, 44578, 7091, 21562, 31994, 93792, 1174, 4427, 20666, 1174, 323, 578, 52310, 36910, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "164", "dataset": "crossner_politics", "split": "dev", "prediction": "The(O) Socialist(B-political party) Party(I-political party) of(I-political party) the(I-political party) United(I-political party) States(I-political party) ((O) SPUS(B-political party) )(O) -(O) its(O) name(O) inspired(O) by(O) co-thinkers(O) in(O) the(O) Socialist(B-political party) Party(I-political party) of(I-political party) Great(I-political party) Britain(I-political party) ((O) SPGB(B-political party) )(O) and(O) the(O) original(O) ((O) non-WSM(B-political party) )(O) Socialist(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) ((O) SPC(B-political party) )(O) -(O) was(O) established(O) on(O) July(O) 7(O),(O) 1916(O) by(O) 42(O) defecting(O) members(O) of(O) Local(B-location) Detroit(I-location) of(O) the(O) Socialist(B-political party) Party(I-political party) of(I-political party) America(I-political party) ((O) SPA(B-political party) )(O).(O)", "instance": {"id": "164", "words": ["The", "Socialist", "Party", "of", "the", "United", "States", "(", "SPUS", ")", "-", "its", "name", "inspired", "by", "co-thinkers", "in", "the", "Socialist", "Party", "of", "Great", "Britain", "(", "SPGB", ")", "and", "the", "original", "(", "non-WSM", ")", "Socialist", "Party", "of", "Canada", "(", "SPC", ")", "-", "was", "established", "on", "July", "7", ",", "1916", "by", "42", "defecting", "members", "of", "Local", "Detroit", "of", "the", "Socialist", "Party", "of", "America", "(", "SPA", ")", "."], "labels": ["O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "B-political party", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "B-political party", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "B-political party", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "B-political party", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, event, location, election, country, political party, person, politician and O.\nSentence: The Socialist Party of the United States ( SPUS ) - its name inspired by co-thinkers in the Socialist Party of Great Britain ( SPGB ) and the original ( non-WSM ) Socialist Party of Canada ( SPC ) - was established on July 7 , 1916 by 42 defecting members of Local Detroit of the Socialist Party of America ( SPA ) .", "prompt_labels": "The(O) Socialist(B-political party) Party(I-political party) of(I-political party) the(I-political party) United(I-political party) States(I-political party) ((O) SPUS(B-political party) )(O) -(O) its(O) name(O) inspired(O) by(O) co-thinkers(O) in(O) the(O) Socialist(B-political party) Party(I-political party) of(I-political party) Great(I-political party) Britain(I-political party) ((O) SPGB(B-political party) )(O) and(O) the(O) original(O) ((O) non-WSM(O) )(O) Socialist(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) ((O) SPC(B-political party) )(O) -(O) was(O) established(O) on(O) July(O) 7(O) ,(O) 1916(O) by(O) 42(O) defecting(O) members(O) of(O) Local(B-location) Detroit(I-location) of(O) the(O) Socialist(B-political party) Party(I-political party) of(I-political party) America(I-political party) ((O) SPA(B-political party) )(O) .(O)"}, "label_list": ["organization", "event", "location", "election", "country", "political party", "person", "politician"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 1567, 11, 3813, 11, 6355, 11, 3224, 11, 5054, 4717, 11, 1732, 11, 37038, 323, 507, 627, 85664, 25, 578, 57210, 8722, 315, 279, 3723, 4273, 320, 9440, 2078, 883, 482, 1202, 836, 14948, 555, 1080, 7716, 771, 388, 304, 279, 57210, 8722, 315, 8681, 13527, 320, 9440, 5494, 883, 323, 279, 4113, 320, 2536, 12, 7585, 44, 883, 57210, 8722, 315, 7008, 320, 328, 4977, 883, 482, 574, 9749, 389, 5887, 220, 22, 1174, 220, 7529, 21, 555, 220, 2983, 23011, 287, 3697, 315, 8949, 20344, 315, 279, 57210, 8722, 315, 5270, 320, 77508, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "289", "dataset": "mit-restaurant", "split": "dev", "prediction": "does(O) mcdonalds(B-Restaurant Name) serve(O) ice(B-Dish) cream(I-Dish) during(O) breakfast(B-Hours) hours(O)", "instance": {"id": "289", "words": ["does", "mcdonalds", "serve", "ice", "cream", "during", "breakfast", "hours"], "labels": ["O", "B-Restaurant Name", "O", "B-Dish", "I-Dish", "I-Dish", "B-Hours", "I-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Price, Location, Cuisine, Hours, Restaurant Name, Amenity, Dish and O.\nSentence: does mcdonalds serve ice cream during breakfast hours", "prompt_labels": "does(O) mcdonalds(B-Restaurant Name) serve(O) ice(B-Dish) cream(I-Dish) during(I-Dish) breakfast(B-Hours) hours(I-Hours)"}, "label_list": ["Rating", "Price", "Location", "Cuisine", "Hours", "Restaurant Name", "Amenity", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 8650, 11, 10067, 11, 81961, 11, 30192, 11, 26568, 4076, 11, 3383, 56685, 11, 49268, 323, 507, 627, 85664, 25, 1587, 296, 4484, 80794, 82, 8854, 10054, 12932, 2391, 17954, 4207, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1870", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) r(B-rating) rated(O) movie(O) was(O) released(O) this(B-year) year(I-year) about(O) the(O) 1960(B-year) s(I-year) that(O) has(O) an(O) eight(B-average ratings) star(I-average ratings) rating(O)", "instance": {"id": "1870", "words": ["what", "r", "rated", "movie", "was", "released", "this", "year", "about", "the", "1960", "s", "that", "has", "an", "eight", "star", "rating"], "labels": ["O", "B-rating", "O", "O", "O", "O", "B-year", "I-year", "O", "O", "B-plot", "I-plot", "O", "O", "O", "B-average ratings", "I-average ratings", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, title, director, rating, song, trailer, average ratings, actor, year, review, genre, character and O.\nSentence: what r rated movie was released this year about the 1960 s that has an eight star rating", "prompt_labels": "what(O) r(B-rating) rated(O) movie(O) was(O) released(O) this(B-year) year(I-year) about(O) the(O) 1960(B-plot) s(I-plot) that(O) has(O) an(O) eight(B-average ratings) star(I-average ratings) rating(O)"}, "label_list": ["plot", "title", "director", "rating", "song", "trailer", "average ratings", "actor", "year", "review", "genre", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 2316, 11, 7690, 11, 10959, 11, 5609, 11, 19809, 11, 5578, 18594, 11, 12360, 11, 1060, 11, 3477, 11, 17779, 11, 3752, 323, 507, 627, 85664, 25, 1148, 436, 22359, 5818, 574, 6004, 420, 1060, 922, 279, 220, 5162, 15, 274, 430, 706, 459, 8223, 6917, 10959, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1044", "dataset": "mit-restaurant", "split": "dev", "prediction": "red(B-Restaurant Name) robins(I-Restaurant Name) restaurant(I-Restaurant Name)", "instance": {"id": "1044", "words": ["red", "robins", "restaurant"], "labels": ["B-Restaurant Name", "I-Restaurant Name", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Location, Rating, Dish, Cuisine, Price, Amenity, Restaurant Name and O.\nSentence: red robins restaurant", "prompt_labels": "red(B-Restaurant Name) robins(I-Restaurant Name) restaurant(O)"}, "label_list": ["Hours", "Location", "Rating", "Dish", "Cuisine", "Price", "Amenity", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 10067, 11, 19767, 11, 49268, 11, 81961, 11, 8650, 11, 3383, 56685, 11, 26568, 4076, 323, 507, 627, 85664, 25, 2579, 10773, 1354, 10960, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "128", "dataset": "crossner_music", "split": "dev", "prediction": "They(O) restarted(O) to(O) perform(O) live(O) regularly(O),(O) touring(O) the(O) world(O) with(O) rapturous(O) feedbacks(O) :(O) they(O) brought(O) their(O) distinguishable(O) sound(O) in(O) great(O) venues(O) such(O) as(O) the(O) Kings(B-location) Place(I-location) in(O) London(B-location),(O) the(O) Soma(B-event) Festival(I-event) in(O) Belfast(B-location),(O) the(O) Bolshoi(B-event) Theatre(I-event) in(O) Moscow(B-location) and(O) the(O) Star(B-location) Pine(I-location)'s(I-location) cafe(I-location) in(O) Tokyo(B-location).(O)", "instance": {"id": "128", "words": ["They", "restarted", "to", "perform", "live", "regularly", ",", "touring", "the", "world", "with", "rapturous", "feedbacks", ":", "they", "brought", "their", "distinguishable", "sound", "in", "great", "venues", "such", "as", "the", "Kings", "Place", "in", "London", ",", "the", "Soma", "Festival", "in", "Belfast", ",", "the", "Bolshoi", "Theatre", "in", "Moscow", "and", "the", "Star", "Pine", "'s", "cafe", "in", "Tokyo", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "O", "B-location", "O", "O", "B-event", "I-event", "O", "B-location", "O", "O", "B-location", "I-location", "O", "B-location", "O", "O", "B-location", "I-location", "I-location", "I-location", "O", "B-location", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, musical artist, music genre, album, person, organization, award, musical instrument, event, location, song, band and O.\nSentence: They restarted to perform live regularly , touring the world with rapturous feedbacks : they brought their distinguishable sound in great venues such as the Kings Place in London , the Soma Festival in Belfast , the Bolshoi Theatre in Moscow and the Star Pine 's cafe in Tokyo .", "prompt_labels": "They(O) restarted(O) to(O) perform(O) live(O) regularly(O) ,(O) touring(O) the(O) world(O) with(O) rapturous(O) feedbacks(O) :(O) they(O) brought(O) their(O) distinguishable(O) sound(O) in(O) great(O) venues(O) such(O) as(O) the(O) Kings(B-location) Place(I-location) in(O) London(B-location) ,(O) the(O) Soma(B-event) Festival(I-event) in(O) Belfast(B-location) ,(O) the(O) Bolshoi(B-location) Theatre(I-location) in(O) Moscow(B-location) and(O) the(O) Star(B-location) Pine(I-location) 's(I-location) cafe(I-location) in(O) Tokyo(B-location) .(O)"}, "label_list": ["country", "musical artist", "music genre", "album", "person", "organization", "award", "musical instrument", "event", "location", "song", "band"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 18273, 10255, 11, 4731, 17779, 11, 8176, 11, 1732, 11, 7471, 11, 10292, 11, 18273, 14473, 11, 1567, 11, 3813, 11, 5609, 11, 7200, 323, 507, 627, 85664, 25, 2435, 81754, 311, 2804, 3974, 15870, 1174, 48551, 279, 1917, 449, 436, 2756, 55709, 11302, 82, 551, 814, 7263, 872, 33137, 481, 5222, 304, 2294, 37278, 1778, 439, 279, 24980, 11004, 304, 7295, 1174, 279, 328, 7942, 17772, 304, 55339, 1174, 279, 25007, 939, 6870, 27315, 304, 23223, 323, 279, 7834, 42609, 364, 82, 42030, 304, 27286, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "647", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) want(O) to(O) eat(O) hamburgers(B-Dish)", "instance": {"id": "647", "words": ["i", "want", "to", "eat", "hamburgers"], "labels": ["O", "O", "O", "O", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Dish, Price, Cuisine, Location, Hours, Restaurant Name, Rating and O.\nSentence: i want to eat hamburgers", "prompt_labels": "i(O) want(O) to(O) eat(O) hamburgers(B-Dish)"}, "label_list": ["Amenity", "Dish", "Price", "Cuisine", "Location", "Hours", "Restaurant Name", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 49268, 11, 8650, 11, 81961, 11, 10067, 11, 30192, 11, 26568, 4076, 11, 19767, 323, 507, 627, 85664, 25, 602, 1390, 311, 8343, 57947, 388, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "998", "dataset": "mit-restaurant", "split": "dev", "prediction": "may(O) i(O) have(O) the(O) business(O) hours(O) for(O) the(O) nearest(B-Location) red(B-Restaurant Name) lobster(I-Restaurant Name)", "instance": {"id": "998", "words": ["may", "i", "have", "the", "business", "hours", "for", "the", "nearest", "red", "lobster"], "labels": ["O", "O", "O", "O", "B-Hours", "O", "O", "O", "B-Location", "B-Restaurant Name", "I-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Price, Restaurant Name, Location, Rating, Cuisine, Amenity, Hours and O.\nSentence: may i have the business hours for the nearest red lobster", "prompt_labels": "may(O) i(O) have(O) the(O) business(B-Hours) hours(O) for(O) the(O) nearest(B-Location) red(B-Restaurant Name) lobster(I-Restaurant Name)"}, "label_list": ["Dish", "Price", "Restaurant Name", "Location", "Rating", "Cuisine", "Amenity", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 8650, 11, 26568, 4076, 11, 10067, 11, 19767, 11, 81961, 11, 3383, 56685, 11, 30192, 323, 507, 627, 85664, 25, 1253, 602, 617, 279, 2626, 4207, 369, 279, 24379, 2579, 80815, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "479", "dataset": "mit-restaurant", "split": "dev", "prediction": "help(O) me(O) find(O) a(O) good(B-Rating) place(O) to(O) eat(O)", "instance": {"id": "479", "words": ["help", "me", "find", "a", "good", "place", "to", "eat"], "labels": ["O", "O", "O", "O", "B-Rating", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Restaurant Name, Rating, Dish, Price, Amenity, Hours, Location and O.\nSentence: help me find a good place to eat", "prompt_labels": "help(O) me(O) find(O) a(O) good(B-Rating) place(O) to(O) eat(O)"}, "label_list": ["Cuisine", "Restaurant Name", "Rating", "Dish", "Price", "Amenity", "Hours", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 26568, 4076, 11, 19767, 11, 49268, 11, 8650, 11, 3383, 56685, 11, 30192, 11, 10067, 323, 507, 627, 85664, 25, 1520, 757, 1505, 264, 1695, 2035, 311, 8343, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "194", "dataset": "mit-movie", "split": "dev", "prediction": "when(O) did(O) runaway(B-title) jury(I-title) come(O) out(O)", "instance": {"id": "194", "words": ["when", "did", "runaway", "jury", "come", "out"], "labels": ["O", "O", "B-title", "I-title", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, title, average ratings, trailer, plot, genre, song, review, actor, character, director, year and O.\nSentence: when did runaway jury come out", "prompt_labels": "when(O) did(O) runaway(B-title) jury(I-title) come(O) out(O)"}, "label_list": ["rating", "title", "average ratings", "trailer", "plot", "genre", "song", "review", "actor", "character", "director", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 2316, 11, 5578, 18594, 11, 19809, 11, 7234, 11, 17779, 11, 5609, 11, 3477, 11, 12360, 11, 3752, 11, 7690, 11, 1060, 323, 507, 627, 85664, 25, 994, 1550, 91740, 21928, 2586, 704, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "77", "dataset": "crossner_politics", "split": "dev", "prediction": "In(O) recent(O) years(O),(O) the(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) of(I-political party) Canada(I-political party) has(O) had(O) the(O) most(O) success(O) in(O) the(O) city(O) :(O) its(O) members(O) were(O) elected(O) in(O) all(O) but(O) four(O) elections(O) since(O) 1953(O) :(O) 1974(B-election) Canadian(I-election) federal(I-election) election(I-election),(O) 1980(B-election) Canadian(I-election) federal(I-election) election(I-election),(O) 2004(B-election) Canadian(I-election) federal(I-election) election(I-election),(O) and(O) 2006(B-election) Canadian(I-election) federal(I-election) election(I-election).(O)", "instance": {"id": "77", "words": ["In", "recent", "years", ",", "the", "Progressive", "Conservative", "Party", "of", "Canada", "has", "had", "the", "most", "success", "in", "the", "city", ":", "its", "members", "were", "elected", "in", "all", "but", "four", "elections", "since", "1953", ":", "1974", "Canadian", "federal", "election", ",", "1980", "Canadian", "federal", "election", ",", "2004", "Canadian", "federal", "election", ",", "and", "2006", "Canadian", "federal", "election", "."], "labels": ["O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, country, organization, person, location, political party, election, event and O.\nSentence: In recent years , the Progressive Conservative Party of Canada has had the most success in the city : its members were elected in all but four elections since 1953 : 1974 Canadian federal election , 1980 Canadian federal election , 2004 Canadian federal election , and 2006 Canadian federal election .", "prompt_labels": "In(O) recent(O) years(O) ,(O) the(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) of(I-political party) Canada(I-political party) has(O) had(O) the(O) most(O) success(O) in(O) the(O) city(O) :(O) its(O) members(O) were(O) elected(O) in(O) all(O) but(O) four(O) elections(O) since(O) 1953(O) :(O) 1974(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) 1980(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) 2004(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) and(O) 2006(B-election) Canadian(I-election) federal(I-election) election(I-election) .(O)"}, "label_list": ["politician", "country", "organization", "person", "location", "political party", "election", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 37038, 11, 3224, 11, 7471, 11, 1732, 11, 3813, 11, 5054, 4717, 11, 6355, 11, 1567, 323, 507, 627, 85664, 25, 763, 3293, 1667, 1174, 279, 52870, 30071, 8722, 315, 7008, 706, 1047, 279, 1455, 2450, 304, 279, 3363, 551, 1202, 3697, 1051, 16689, 304, 682, 719, 3116, 16374, 2533, 220, 6280, 18, 551, 220, 4468, 19, 12152, 6918, 6355, 1174, 220, 3753, 15, 12152, 6918, 6355, 1174, 220, 1049, 19, 12152, 6918, 6355, 1174, 323, 220, 1049, 21, 12152, 6918, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "52", "dataset": "mit-restaurant", "split": "dev", "prediction": "are(O) there(O) any(O) japanese(B-Cuisine) restaurants(O) in(B-Location) town(I-Location) that(O) do(O) discounts(B-Amenity) for(I-Amenity) bulk(I-Amenity) orders(I-Amenity) of(O) sushi(B-Dish)", "instance": {"id": "52", "words": ["are", "there", "any", "japanese", "restaurants", "in", "town", "that", "do", "discounts", "for", "bulk", "orders", "of", "sushi"], "labels": ["O", "O", "O", "B-Cuisine", "O", "B-Location", "I-Location", "O", "O", "B-Amenity", "I-Amenity", "I-Amenity", "I-Amenity", "O", "B-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Dish, Location, Restaurant Name, Rating, Price, Hours, Amenity and O.\nSentence: are there any japanese restaurants in town that do discounts for bulk orders of sushi", "prompt_labels": "are(O) there(O) any(O) japanese(B-Cuisine) restaurants(O) in(B-Location) town(I-Location) that(O) do(O) discounts(B-Amenity) for(I-Amenity) bulk(I-Amenity) orders(I-Amenity) of(O) sushi(B-Amenity)"}, "label_list": ["Cuisine", "Dish", "Location", "Restaurant Name", "Rating", "Price", "Hours", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 49268, 11, 10067, 11, 26568, 4076, 11, 19767, 11, 8650, 11, 30192, 11, 3383, 56685, 323, 507, 627, 85664, 25, 527, 1070, 904, 54048, 15926, 304, 6424, 430, 656, 32162, 369, 20155, 10373, 315, 67322, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1242", "dataset": "mit-restaurant", "split": "dev", "prediction": "whats(O) the(O) phone(O) number(O) for(O) that(O) family(B-Amenity) owned(I-Amenity) thai(B-Cuisine) restaurant(O) on(O) the(O) north(B-Location) side(I-Location)", "instance": {"id": "1242", "words": ["whats", "the", "phone", "number", "for", "that", "family", "owned", "thai", "restaurant", "on", "the", "north", "side"], "labels": ["O", "O", "O", "O", "O", "O", "B-Amenity", "I-Amenity", "B-Cuisine", "O", "O", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Cuisine, Location, Restaurant Name, Amenity, Dish, Rating, Hours and O.\nSentence: whats the phone number for that family owned thai restaurant on the north side", "prompt_labels": "whats(O) the(O) phone(O) number(O) for(O) that(O) family(B-Amenity) owned(I-Amenity) thai(B-Cuisine) restaurant(O) on(O) the(O) north(B-Location) side(I-Location)"}, "label_list": ["Price", "Cuisine", "Location", "Restaurant Name", "Amenity", "Dish", "Rating", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 81961, 11, 10067, 11, 26568, 4076, 11, 3383, 56685, 11, 49268, 11, 19767, 11, 30192, 323, 507, 627, 85664, 25, 41209, 279, 4641, 1396, 369, 430, 3070, 13234, 18420, 10960, 389, 279, 10411, 3185, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1169", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) stephen(B-actor) j(I-actor) anderson(I-actor) star(O) in(O) any(O) sci(B-genre) fi(I-genre) movie(O) during(O) the(O) 1950(B-year) s(I-year)", "instance": {"id": "1169", "words": ["did", "stephen", "j", "anderson", "star", "in", "any", "sci", "fi", "movie", "during", "the", "1950", "s"], "labels": ["O", "B-director", "I-director", "I-director", "O", "O", "O", "B-genre", "I-genre", "O", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, director, year, plot, character, song, genre, actor, title, rating, trailer, average ratings and O.\nSentence: did stephen j anderson star in any sci fi movie during the 1950 s", "prompt_labels": "did(O) stephen(B-director) j(I-director) anderson(I-director) star(O) in(O) any(O) sci(B-genre) fi(I-genre) movie(O) during(O) the(O) 1950(B-year) s(I-year)"}, "label_list": ["review", "director", "year", "plot", "character", "song", "genre", "actor", "title", "rating", "trailer", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 7690, 11, 1060, 11, 7234, 11, 3752, 11, 5609, 11, 17779, 11, 12360, 11, 2316, 11, 10959, 11, 19809, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1550, 3094, 12301, 503, 323, 1293, 6917, 304, 904, 39074, 9314, 5818, 2391, 279, 220, 6280, 15, 274, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2062", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) best(O) horror(B-genre) movies(O) made(O) in(O) 1977(B-year)", "instance": {"id": "2062", "words": ["what", "is", "the", "best", "horror", "movies", "made", "in", "1977"], "labels": ["O", "O", "O", "O", "B-genre", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, average ratings, character, review, song, actor, title, rating, plot, year, director, trailer and O.\nSentence: what is the best horror movies made in 1977", "prompt_labels": "what(O) is(O) the(O) best(O) horror(B-genre) movies(O) made(O) in(O) 1977(O)"}, "label_list": ["genre", "average ratings", "character", "review", "song", "actor", "title", "rating", "plot", "year", "director", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 5578, 18594, 11, 3752, 11, 3477, 11, 5609, 11, 12360, 11, 2316, 11, 10959, 11, 7234, 11, 1060, 11, 7690, 11, 19809, 323, 507, 627, 85664, 25, 1148, 374, 279, 1888, 22169, 9698, 1903, 304, 220, 4468, 22, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1447", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) is(O) the(O) nearest(B-Location) sushi(B-Cuisine) bar(I-Cuisine)", "instance": {"id": "1447", "words": ["where", "is", "the", "nearest", "sushi", "bar"], "labels": ["O", "O", "O", "B-Location", "B-Cuisine", "I-Cuisine"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Amenity, Hours, Restaurant Name, Rating, Price, Location, Cuisine and O.\nSentence: where is the nearest sushi bar", "prompt_labels": "where(O) is(O) the(O) nearest(B-Location) sushi(B-Cuisine) bar(I-Cuisine)"}, "label_list": ["Dish", "Amenity", "Hours", "Restaurant Name", "Rating", "Price", "Location", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 3383, 56685, 11, 30192, 11, 26568, 4076, 11, 19767, 11, 8650, 11, 10067, 11, 81961, 323, 507, 627, 85664, 25, 1405, 374, 279, 24379, 67322, 3703, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "547", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) was(O) the(O) name(O) of(O) ariels(B-character) prince(I-character) in(O) the(O) little(B-title) mermaid(I-title)", "instance": {"id": "547", "words": ["what", "was", "the", "name", "of", "ariels", "prince", "in", "the", "little", "mermaid"], "labels": ["O", "O", "O", "O", "O", "B-character", "O", "O", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, year, song, review, director, character, actor, average ratings, title, trailer, genre, rating and O.\nSentence: what was the name of ariels prince in the little mermaid", "prompt_labels": "what(O) was(O) the(O) name(O) of(O) ariels(B-character) prince(O) in(O) the(O) little(B-title) mermaid(I-title)"}, "label_list": ["plot", "year", "song", "review", "director", "character", "actor", "average ratings", "title", "trailer", "genre", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 1060, 11, 5609, 11, 3477, 11, 7690, 11, 3752, 11, 12360, 11, 5578, 18594, 11, 2316, 11, 19809, 11, 17779, 11, 10959, 323, 507, 627, 85664, 25, 1148, 574, 279, 836, 315, 264, 462, 2053, 42826, 304, 279, 2697, 4809, 46342, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "490", "dataset": "mit-restaurant", "split": "dev", "prediction": "hi(O) i(O) would(O) like(O) some(O) thai(B-Cuisine) food(O) is(O) there(O) any(O) nearby(B-Location)", "instance": {"id": "490", "words": ["hi", "i", "would", "like", "some", "thai", "food", "is", "there", "any", "nearby"], "labels": ["O", "O", "O", "O", "O", "B-Cuisine", "O", "O", "O", "O", "B-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Location, Amenity, Price, Dish, Rating, Hours, Cuisine and O.\nSentence: hi i would like some thai food is there any nearby", "prompt_labels": "hi(O) i(O) would(O) like(O) some(O) thai(B-Cuisine) food(O) is(O) there(O) any(O) nearby(B-Location)"}, "label_list": ["Restaurant Name", "Location", "Amenity", "Price", "Dish", "Rating", "Hours", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 10067, 11, 3383, 56685, 11, 8650, 11, 49268, 11, 19767, 11, 30192, 11, 81961, 323, 507, 627, 85664, 25, 15960, 602, 1053, 1093, 1063, 18420, 3691, 374, 1070, 904, 14373, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2122", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) title(O) of(O) the(O) mystery(B-genre) film(O) with(O) paul(B-actor) reiser(I-actor) that(O) was(O) rated(O) an(O) eight(B-average ratings)", "instance": {"id": "2122", "words": ["what", "is", "the", "title", "of", "the", "mystery", "film", "with", "paul", "reiser", "that", "was", "rated", "an", "eight"], "labels": ["O", "O", "O", "O", "O", "O", "B-genre", "O", "O", "B-actor", "I-actor", "O", "O", "O", "O", "B-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, song, year, character, rating, genre, actor, director, plot, title, review, average ratings and O.\nSentence: what is the title of the mystery film with paul reiser that was rated an eight", "prompt_labels": "what(O) is(O) the(O) title(O) of(O) the(O) mystery(B-genre) film(O) with(O) paul(B-actor) reiser(I-actor) that(O) was(O) rated(O) an(O) eight(B-average ratings)"}, "label_list": ["trailer", "song", "year", "character", "rating", "genre", "actor", "director", "plot", "title", "review", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 5609, 11, 1060, 11, 3752, 11, 10959, 11, 17779, 11, 12360, 11, 7690, 11, 7234, 11, 2316, 11, 3477, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1148, 374, 279, 2316, 315, 279, 23347, 4632, 449, 68111, 312, 12329, 430, 574, 22359, 459, 8223, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1050", "dataset": "mit-restaurant", "split": "dev", "prediction": "search(O) for(O) a(O) place(O) that(O) serves(O) meatloaf(B-Dish)", "instance": {"id": "1050", "words": ["search", "for", "a", "place", "that", "serves", "meatloaf"], "labels": ["O", "O", "O", "O", "O", "O", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Restaurant Name, Amenity, Cuisine, Rating, Price, Dish, Location and O.\nSentence: search for a place that serves meatloaf", "prompt_labels": "search(O) for(O) a(O) place(O) that(O) serves(O) meatloaf(B-Dish)"}, "label_list": ["Hours", "Restaurant Name", "Amenity", "Cuisine", "Rating", "Price", "Dish", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 26568, 4076, 11, 3383, 56685, 11, 81961, 11, 19767, 11, 8650, 11, 49268, 11, 10067, 323, 507, 627, 85664, 25, 2778, 369, 264, 2035, 430, 17482, 13339, 385, 2642, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "447", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) action(B-genre) movies(O) starring(O) sylvester(B-actor) stallone(I-actor)", "instance": {"id": "447", "words": ["show", "me", "action", "movies", "starring", "sylvester", "stallone"], "labels": ["O", "O", "B-genre", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, year, rating, director, character, actor, trailer, title, genre, plot, song, review and O.\nSentence: show me action movies starring sylvester stallone", "prompt_labels": "show(O) me(O) action(B-genre) movies(O) starring(O) sylvester(B-actor) stallone(I-actor)"}, "label_list": ["average ratings", "year", "rating", "director", "character", "actor", "trailer", "title", "genre", "plot", "song", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 1060, 11, 10959, 11, 7690, 11, 3752, 11, 12360, 11, 19809, 11, 2316, 11, 17779, 11, 7234, 11, 5609, 11, 3477, 323, 507, 627, 85664, 25, 1501, 757, 1957, 9698, 40500, 274, 15095, 5302, 43793, 606, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1751", "dataset": "mit-movie", "split": "dev", "prediction": "please(O) list(O) some(O) mediocre(B-average ratings) film(B-genre) noir(I-genre) movies(O) released(O) in(O) the(O) past(B-year) two(I-year) decades(I-year) directed(O) by(O) robert(B-director) hiltzik(I-director)", "instance": {"id": "1751", "words": ["please", "list", "some", "mediocre", "film", "noir", "movies", "released", "in", "the", "past", "two", "decades", "directed", "by", "robert", "hiltzik"], "labels": ["O", "O", "O", "B-average ratings", "B-genre", "I-genre", "O", "O", "O", "O", "B-year", "I-year", "I-year", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, song, genre, year, title, rating, plot, director, actor, trailer, review, character and O.\nSentence: please list some mediocre film noir movies released in the past two decades directed by robert hiltzik", "prompt_labels": "please(O) list(O) some(O) mediocre(B-average ratings) film(B-genre) noir(I-genre) movies(O) released(O) in(O) the(O) past(B-year) two(I-year) decades(I-year) directed(O) by(O) robert(B-director) hiltzik(I-director)"}, "label_list": ["average ratings", "song", "genre", "year", "title", "rating", "plot", "director", "actor", "trailer", "review", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 5609, 11, 17779, 11, 1060, 11, 2316, 11, 10959, 11, 7234, 11, 7690, 11, 12360, 11, 19809, 11, 3477, 11, 3752, 323, 507, 627, 85664, 25, 4587, 1160, 1063, 68480, 4632, 56662, 9698, 6004, 304, 279, 3347, 1403, 11026, 15910, 555, 89993, 305, 3036, 76574, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "138", "dataset": "crossner_science", "split": "dev", "prediction": "catalyzed(O) by(O) Phosphoenolpyruvate(O) carboxylase(O) ((O) PEPC(O) )(O),(O) to(O) carboxylate(O) phosphoenolpyruvate(O) ((O) PEP(O) )(O) to(O) oxaloacetate(O) ((O) OAA(O) )(O) which(O) is(O) a(O) Csub4(O) /(O) sub(O) dicarboxylic(O) acid(O).(O)", "instance": {"id": "138", "words": ["catalyzed", "by", "Phosphoenolpyruvate", "carboxylase", "(", "PEPC", ")", ",", "to", "carboxylate", "phosphoenolpyruvate", "(", "PEP", ")", "to", "oxaloacetate", "(", "OAA", ")", "which", "is", "a", "Csub4", "/", "sub", "dicarboxylic", "acid", "."], "labels": ["O", "O", "B-enzyme", "I-enzyme", "O", "B-enzyme", "O", "O", "O", "B-chemical compound", "I-chemical compound", "O", "B-chemical compound", "O", "O", "B-chemical compound", "O", "B-chemical compound", "O", "O", "O", "O", "B-chemical compound", "I-chemical compound", "I-chemical compound", "I-chemical compound", "I-chemical compound", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: discipline, academic journal, astronomical object, university, protein, theory, country, location, event, chemical compound, person, enzyme, organization, chemical element, award, scientist and O.\nSentence: catalyzed by Phosphoenolpyruvate carboxylase ( PEPC ) , to carboxylate phosphoenolpyruvate ( PEP ) to oxaloacetate ( OAA ) which is a Csub4 / sub dicarboxylic acid .", "prompt_labels": "catalyzed(O) by(O) Phosphoenolpyruvate(B-enzyme) carboxylase(I-enzyme) ((O) PEPC(B-enzyme) )(O) ,(O) to(O) carboxylate(B-chemical compound) phosphoenolpyruvate(I-chemical compound) ((O) PEP(B-chemical compound) )(O) to(O) oxaloacetate(B-chemical compound) ((O) OAA(B-chemical compound) )(O) which(O) is(O) a(O) Csub4(B-chemical compound) /(I-chemical compound) sub(I-chemical compound) dicarboxylic(I-chemical compound) acid(I-chemical compound) .(O)"}, "label_list": ["discipline", "academic journal", "astronomical object", "university", "protein", "theory", "country", "location", "event", "chemical compound", "person", "enzyme", "organization", "chemical element", "award", "scientist"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26434, 11, 14584, 8486, 11, 87283, 1665, 11, 12374, 11, 13128, 11, 10334, 11, 3224, 11, 3813, 11, 1567, 11, 11742, 24549, 11, 1732, 11, 49242, 11, 7471, 11, 11742, 2449, 11, 10292, 11, 28568, 323, 507, 627, 85664, 25, 34454, 88, 16284, 555, 2405, 24527, 16355, 337, 3368, 2739, 85, 349, 1841, 2054, 4010, 521, 320, 22557, 4977, 883, 1174, 311, 1841, 2054, 4010, 349, 33088, 16355, 337, 3368, 2739, 85, 349, 320, 393, 9377, 883, 311, 19488, 12812, 68323, 349, 320, 507, 6157, 883, 902, 374, 264, 356, 2008, 19, 611, 1207, 21945, 277, 2054, 88, 416, 13935, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1275", "dataset": "mit-movie", "split": "dev", "prediction": "has(O) julie(B-actor) andrews(I-actor) ever(O) been(O) a(O) rated(O) r(B-rating) film(B-genre) noir(I-genre) movie(O)", "instance": {"id": "1275", "words": ["has", "julie", "andrews", "ever", "been", "a", "rated", "r", "film", "noir", "movie"], "labels": ["O", "B-actor", "I-actor", "O", "O", "O", "O", "B-rating", "B-genre", "I-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, year, trailer, plot, character, song, average ratings, director, rating, title, review, actor and O.\nSentence: has julie andrews ever been a rated r film noir movie", "prompt_labels": "has(O) julie(B-actor) andrews(I-actor) ever(O) been(O) a(O) rated(O) r(B-rating) film(B-genre) noir(I-genre) movie(O)"}, "label_list": ["genre", "year", "trailer", "plot", "character", "song", "average ratings", "director", "rating", "title", "review", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 1060, 11, 19809, 11, 7234, 11, 3752, 11, 5609, 11, 5578, 18594, 11, 7690, 11, 10959, 11, 2316, 11, 3477, 11, 12360, 323, 507, 627, 85664, 25, 706, 41638, 648, 323, 4361, 82, 3596, 1027, 264, 22359, 436, 4632, 56662, 5818, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1917", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) are(O) some(O) titles(O) of(O) animation(B-genre) films(O) directed(O) by(O) tomm(B-director) coker(I-director) that(O) received(O) average(B-average ratings) ratings(O)", "instance": {"id": "1917", "words": ["what", "are", "some", "titles", "of", "animation", "films", "directed", "by", "tomm", "coker", "that", "received", "average", "ratings"], "labels": ["O", "O", "O", "O", "O", "B-genre", "O", "O", "O", "B-director", "I-director", "O", "O", "B-average ratings", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, title, song, trailer, character, plot, actor, rating, average ratings, genre, year, review and O.\nSentence: what are some titles of animation films directed by tomm coker that received average ratings", "prompt_labels": "what(O) are(O) some(O) titles(O) of(O) animation(B-genre) films(O) directed(O) by(O) tomm(B-director) coker(I-director) that(O) received(O) average(B-average ratings) ratings(O)"}, "label_list": ["director", "title", "song", "trailer", "character", "plot", "actor", "rating", "average ratings", "genre", "year", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 2316, 11, 5609, 11, 19809, 11, 3752, 11, 7234, 11, 12360, 11, 10959, 11, 5578, 18594, 11, 17779, 11, 1060, 11, 3477, 323, 507, 627, 85664, 25, 1148, 527, 1063, 15671, 315, 10571, 12631, 15910, 555, 311, 3906, 272, 10668, 430, 4036, 5578, 18594, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "710", "dataset": "mit-restaurant", "split": "dev", "prediction": "id(O) like(O) to(O) find(O) a(O) chinese(B-Cuisine) restaurant(O) nearby(B-Location)", "instance": {"id": "710", "words": ["id", "like", "to", "find", "a", "chinese", "restaurant", "nearby"], "labels": ["O", "O", "O", "O", "O", "B-Cuisine", "O", "B-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Hours, Dish, Location, Cuisine, Rating, Amenity, Restaurant Name and O.\nSentence: id like to find a chinese restaurant nearby", "prompt_labels": "id(O) like(O) to(O) find(O) a(O) chinese(B-Cuisine) restaurant(O) nearby(B-Location)"}, "label_list": ["Price", "Hours", "Dish", "Location", "Cuisine", "Rating", "Amenity", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 30192, 11, 49268, 11, 10067, 11, 81961, 11, 19767, 11, 3383, 56685, 11, 26568, 4076, 323, 507, 627, 85664, 25, 887, 1093, 311, 1505, 264, 57487, 10960, 14373, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "417", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) worst(B-average ratings) viewer(I-average ratings) rated(I-average ratings) vampire(B-plot) film(O)", "instance": {"id": "417", "words": ["what", "is", "the", "worst", "viewer", "rated", "vampire", "film"], "labels": ["O", "O", "O", "B-average ratings", "I-average ratings", "I-average ratings", "B-plot", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, genre, character, plot, title, year, actor, rating, director, song, average ratings, review and O.\nSentence: what is the worst viewer rated vampire film", "prompt_labels": "what(O) is(O) the(O) worst(B-average ratings) viewer(I-average ratings) rated(I-average ratings) vampire(B-plot) film(O)"}, "label_list": ["trailer", "genre", "character", "plot", "title", "year", "actor", "rating", "director", "song", "average ratings", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 17779, 11, 3752, 11, 7234, 11, 2316, 11, 1060, 11, 12360, 11, 10959, 11, 7690, 11, 5609, 11, 5578, 18594, 11, 3477, 323, 507, 627, 85664, 25, 1148, 374, 279, 12047, 26792, 22359, 51587, 4632, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "290", "dataset": "crossner_politics", "split": "dev", "prediction": "After(O) the(O) April(O) 2009(O) Moldovan(O) parliamentary(O) election(O),(O) the(O) 2009(O) Moldova(B-country) civil(O) unrest(O),(O) the(O) July(O) 2009(O) Moldovan(B-country) parliamentary(O) election(O) and(O) the(O) creation(O) of(O) the(O) governing(O) Alliance(B-political party) for(I-political party) European(I-political party) Integration(I-political party),(O) a(O) new(O) wave(O) of(O) speculations(O) about(O) the(O) union(O) followed(O).(O)", "instance": {"id": "290", "words": ["After", "the", "April", "2009", "Moldovan", "parliamentary", "election", ",", "the", "2009", "Moldova", "civil", "unrest", ",", "the", "July", "2009", "Moldovan", "parliamentary", "election", "and", "the", "creation", "of", "the", "governing", "Alliance", "for", "European", "Integration", ",", "a", "new", "wave", "of", "speculations", "about", "the", "union", "followed", "."], "labels": ["O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-event", "I-event", "I-event", "I-event", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, location, country, organization, event, politician, political party, election and O.\nSentence: After the April 2009 Moldovan parliamentary election , the 2009 Moldova civil unrest , the July 2009 Moldovan parliamentary election and the creation of the governing Alliance for European Integration , a new wave of speculations about the union followed .", "prompt_labels": "After(O) the(O) April(B-election) 2009(I-election) Moldovan(I-election) parliamentary(I-election) election(I-election) ,(O) the(O) 2009(B-event) Moldova(I-event) civil(I-event) unrest(I-event) ,(O) the(O) July(B-election) 2009(I-election) Moldovan(I-election) parliamentary(I-election) election(I-election) and(O) the(O) creation(O) of(O) the(O) governing(O) Alliance(B-organization) for(I-organization) European(I-organization) Integration(I-organization) ,(O) a(O) new(O) wave(O) of(O) speculations(O) about(O) the(O) union(O) followed(O) .(O)"}, "label_list": ["person", "location", "country", "organization", "event", "politician", "political party", "election"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 3813, 11, 3224, 11, 7471, 11, 1567, 11, 37038, 11, 5054, 4717, 11, 6355, 323, 507, 627, 85664, 25, 4740, 279, 5936, 220, 1049, 24, 55263, 43757, 44250, 6355, 1174, 279, 220, 1049, 24, 55263, 12949, 8431, 59322, 1174, 279, 5887, 220, 1049, 24, 55263, 43757, 44250, 6355, 323, 279, 9886, 315, 279, 10217, 23590, 369, 7665, 41169, 1174, 264, 502, 12330, 315, 1424, 7607, 922, 279, 11552, 8272, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1652", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) action(B-genre) movies(O) that(O) star(O) satoshi(B-actor) kon(I-actor)", "instance": {"id": "1652", "words": ["list", "action", "movies", "that", "star", "satoshi", "kon"], "labels": ["O", "B-genre", "O", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, director, genre, song, plot, character, year, review, average ratings, rating, actor, trailer and O.\nSentence: list action movies that star satoshi kon", "prompt_labels": "list(O) action(B-genre) movies(O) that(O) star(O) satoshi(B-director) kon(I-director)"}, "label_list": ["title", "director", "genre", "song", "plot", "character", "year", "review", "average ratings", "rating", "actor", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 7690, 11, 17779, 11, 5609, 11, 7234, 11, 3752, 11, 1060, 11, 3477, 11, 5578, 18594, 11, 10959, 11, 12360, 11, 19809, 323, 507, 627, 85664, 25, 1160, 1957, 9698, 430, 6917, 7731, 32945, 16947, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "3", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) science(B-genre) fiction(I-genre) films(O) have(O) come(O) out(O) recently(O)", "instance": {"id": "3", "words": ["what", "science", "fiction", "films", "have", "come", "out", "recently"], "labels": ["O", "B-genre", "I-genre", "O", "O", "O", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, year, genre, director, review, character, rating, average ratings, song, trailer, actor, title and O.\nSentence: what science fiction films have come out recently", "prompt_labels": "what(O) science(B-genre) fiction(I-genre) films(O) have(O) come(O) out(O) recently(B-year)"}, "label_list": ["plot", "year", "genre", "director", "review", "character", "rating", "average ratings", "song", "trailer", "actor", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 1060, 11, 17779, 11, 7690, 11, 3477, 11, 3752, 11, 10959, 11, 5578, 18594, 11, 5609, 11, 19809, 11, 12360, 11, 2316, 323, 507, 627, 85664, 25, 1148, 8198, 17422, 12631, 617, 2586, 704, 6051, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "80", "dataset": "crossner_music", "split": "dev", "prediction": "This(O) is(O) the(O) method(O) used(O) by(O) Bands(B-organization) of(I-organization) America(I-organization),(O) the(O) Indiana(B-organization) State(I-organization) School(I-organization) Music(I-organization) Association(I-organization),(O) Kentucky(B-organization) Music(I-organization) Educators(I-organization) Association(I-organization) and(O) the(O) University(B-organization) Interscholastic(I-organization) League(I-organization).(O)", "instance": {"id": "80", "words": ["This", "is", "the", "method", "used", "by", "Bands", "of", "America", ",", "the", "Indiana", "State", "School", "Music", "Association", ",", "Kentucky", "Music", "Educators", "Association", "and", "the", "University", "Interscholastic", "League", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, location, musical artist, musical instrument, band, country, music genre, organization, event, album, award, person and O.\nSentence: This is the method used by Bands of America , the Indiana State School Music Association , Kentucky Music Educators Association and the University Interscholastic League .", "prompt_labels": "This(O) is(O) the(O) method(O) used(O) by(O) Bands(B-organization) of(I-organization) America(I-organization) ,(O) the(O) Indiana(B-organization) State(I-organization) School(I-organization) Music(I-organization) Association(I-organization) ,(O) Kentucky(B-organization) Music(I-organization) Educators(I-organization) Association(I-organization) and(O) the(O) University(B-organization) Interscholastic(I-organization) League(I-organization) .(O)"}, "label_list": ["song", "location", "musical artist", "musical instrument", "band", "country", "music genre", "organization", "event", "album", "award", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 3813, 11, 18273, 10255, 11, 18273, 14473, 11, 7200, 11, 3224, 11, 4731, 17779, 11, 7471, 11, 1567, 11, 8176, 11, 10292, 11, 1732, 323, 507, 627, 85664, 25, 1115, 374, 279, 1749, 1511, 555, 88402, 315, 5270, 1174, 279, 22319, 3314, 6150, 10948, 10229, 1174, 26036, 10948, 10355, 3046, 10229, 323, 279, 3907, 1357, 388, 331, 337, 5174, 9130, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "997", "dataset": "mit-restaurant", "split": "dev", "prediction": "make(O) me(O) reservations(O) for(O) three(O) people(O) at(O) devitos(B-Restaurant Name) italian(I-Restaurant Name)", "instance": {"id": "997", "words": ["make", "me", "reservations", "for", "three", "people", "at", "devitos", "italian"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-Restaurant Name", "I-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Hours, Dish, Rating, Restaurant Name, Cuisine, Amenity, Price and O.\nSentence: make me reservations for three people at devitos italian", "prompt_labels": "make(O) me(O) reservations(O) for(O) three(O) people(O) at(O) devitos(B-Restaurant Name) italian(I-Restaurant Name)"}, "label_list": ["Location", "Hours", "Dish", "Rating", "Restaurant Name", "Cuisine", "Amenity", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 30192, 11, 49268, 11, 19767, 11, 26568, 4076, 11, 81961, 11, 3383, 56685, 11, 8650, 323, 507, 627, 85664, 25, 1304, 757, 41162, 369, 2380, 1274, 520, 3567, 26675, 29048, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1743", "dataset": "mit-movie", "split": "dev", "prediction": "name(O) the(O) harold(B-director) f(I-director) kress(I-director) unrated(B-rating) film(O) with(O) good(B-average ratings) ratings(I-average ratings) that(O) centers(O) on(O) a(O) parole(B-plot) hearing(I-plot)", "instance": {"id": "1743", "words": ["name", "the", "harold", "f", "kress", "unrated", "film", "with", "good", "ratings", "that", "centers", "on", "a", "parole", "hearing"], "labels": ["O", "O", "B-director", "I-director", "I-director", "B-rating", "O", "O", "B-average ratings", "O", "O", "O", "O", "O", "B-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, song, actor, review, year, director, average ratings, title, character, plot, trailer, rating and O.\nSentence: name the harold f kress unrated film with good ratings that centers on a parole hearing", "prompt_labels": "name(O) the(O) harold(B-director) f(I-director) kress(I-director) unrated(B-rating) film(O) with(O) good(B-average ratings) ratings(O) that(O) centers(O) on(O) a(O) parole(B-plot) hearing(I-plot)"}, "label_list": ["genre", "song", "actor", "review", "year", "director", "average ratings", "title", "character", "plot", "trailer", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 5609, 11, 12360, 11, 3477, 11, 1060, 11, 7690, 11, 5578, 18594, 11, 2316, 11, 3752, 11, 7234, 11, 19809, 11, 10959, 323, 507, 627, 85664, 25, 836, 279, 4960, 820, 282, 597, 676, 41480, 660, 4632, 449, 1695, 18594, 430, 19169, 389, 264, 49361, 11011, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "453", "dataset": "mit-movie", "split": "dev", "prediction": "whats(O) the(O) highest(B-average ratings) rated(I-average ratings) drama(B-genre) of(O) 1990(B-year)", "instance": {"id": "453", "words": ["whats", "the", "highest", "rated", "drama", "of", "1990"], "labels": ["O", "O", "B-review", "I-review", "B-genre", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, plot, title, average ratings, year, character, actor, genre, song, trailer, rating, review and O.\nSentence: whats the highest rated drama of 1990", "prompt_labels": "whats(O) the(O) highest(B-review) rated(I-review) drama(B-genre) of(O) 1990(B-year)"}, "label_list": ["director", "plot", "title", "average ratings", "year", "character", "actor", "genre", "song", "trailer", "rating", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 7234, 11, 2316, 11, 5578, 18594, 11, 1060, 11, 3752, 11, 12360, 11, 17779, 11, 5609, 11, 19809, 11, 10959, 11, 3477, 323, 507, 627, 85664, 25, 41209, 279, 8592, 22359, 20156, 315, 220, 2550, 15, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1629", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) a(O) musical(B-genre) directed(O) by(O) susan(B-director) muska(I-director)", "instance": {"id": "1629", "words": ["list", "a", "musical", "directed", "by", "susan", "muska"], "labels": ["O", "O", "B-genre", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, character, plot, song, review, director, genre, title, average ratings, trailer, actor, year and O.\nSentence: list a musical directed by susan muska", "prompt_labels": "list(O) a(O) musical(B-genre) directed(O) by(O) susan(B-director) muska(I-director)"}, "label_list": ["rating", "character", "plot", "song", "review", "director", "genre", "title", "average ratings", "trailer", "actor", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 3752, 11, 7234, 11, 5609, 11, 3477, 11, 7690, 11, 17779, 11, 2316, 11, 5578, 18594, 11, 19809, 11, 12360, 11, 1060, 323, 507, 627, 85664, 25, 1160, 264, 18273, 15910, 555, 4582, 276, 3167, 4657, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1849", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) pg(B-rating) movie(O) released(O) within(O) the(O) last(B-year) two(I-year) years(I-year) featured(O) david(B-actor) cassidy(I-actor) and(O) was(B-average ratings) liked(I-average ratings) by(I-average ratings) many(I-average ratings)", "instance": {"id": "1849", "words": ["what", "pg", "movie", "released", "within", "the", "last", "two", "years", "featured", "david", "cassidy", "and", "was", "liked", "by", "many"], "labels": ["O", "B-rating", "O", "O", "O", "O", "B-year", "I-year", "I-year", "O", "B-actor", "I-actor", "O", "O", "B-average ratings", "I-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, year, genre, actor, plot, song, rating, review, character, title, director, trailer and O.\nSentence: what pg movie released within the last two years featured david cassidy and was liked by many", "prompt_labels": "what(O) pg(B-rating) movie(O) released(O) within(O) the(O) last(B-year) two(I-year) years(I-year) featured(O) david(B-actor) cassidy(I-actor) and(O) was(O) liked(B-average ratings) by(I-average ratings) many(I-average ratings)"}, "label_list": ["average ratings", "year", "genre", "actor", "plot", "song", "rating", "review", "character", "title", "director", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 1060, 11, 17779, 11, 12360, 11, 7234, 11, 5609, 11, 10959, 11, 3477, 11, 3752, 11, 2316, 11, 7690, 11, 19809, 323, 507, 627, 85664, 25, 1148, 17953, 5818, 6004, 2949, 279, 1566, 1403, 1667, 15109, 55046, 45324, 43686, 323, 574, 15262, 555, 1690, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "74", "dataset": "crossner_ai", "split": "dev", "prediction": "In(O) August(O) 2011(O),(O) it(O) was(O) announced(O) that(O) Hitachi(O) would(O) donate(O) an(O) electron(B-product) microscope(I-product) to(O) each(O) of(O) five(O) universities(O) in(O) Indonesia(B-country) ((O) the(O) University(B-university) of(I-university) North(I-university) Sumatra(I-university) in(O) Medan(B-location),(O) the(O) Indonesian(B-university) Christian(I-university) University(I-university) in(O) Jakarta(B-location),(O) Padjadjaran(B-university) University(I-university) in(O) Bandung(B-location),(O) Jenderal(B-university) Soedirman(I-university) University(I-university) in(O) Purwokerto(B-location) and(O) Muhammadiyah(B-university) University(I-university) in(O) Malang(B-location) )(O).(O)", "instance": {"id": "74", "words": ["In", "August", "2011", ",", "it", "was", "announced", "that", "Hitachi", "would", "donate", "an", "electron", "microscope", "to", "each", "of", "five", "universities", "in", "Indonesia", "(", "the", "University", "of", "North", "Sumatra", "in", "Medan", ",", "the", "Indonesian", "Christian", "University", "in", "Jakarta", ",", "Padjadjaran", "University", "in", "Bandung", ",", "Jenderal", "Soedirman", "University", "in", "Purwokerto", "and", "Muhammadiyah", "University", "in", "Malang", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "O", "O", "O", "B-product", "I-product", "O", "O", "O", "O", "O", "O", "B-country", "O", "O", "B-university", "I-university", "I-university", "I-university", "O", "B-location", "O", "O", "B-university", "I-university", "I-university", "O", "B-location", "O", "B-university", "I-university", "O", "B-location", "O", "B-university", "I-university", "I-university", "O", "B-location", "O", "B-university", "I-university", "O", "B-location", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, field, conference, task, country, algorithm, metric, university, location, product, person, researcher, programming language and O.\nSentence: In August 2011 , it was announced that Hitachi would donate an electron microscope to each of five universities in Indonesia ( the University of North Sumatra in Medan , the Indonesian Christian University in Jakarta , Padjadjaran University in Bandung , Jenderal Soedirman University in Purwokerto and Muhammadiyah University in Malang ) .", "prompt_labels": "In(O) August(O) 2011(O) ,(O) it(O) was(O) announced(O) that(O) Hitachi(B-organization) would(O) donate(O) an(O) electron(B-product) microscope(I-product) to(O) each(O) of(O) five(O) universities(O) in(O) Indonesia(B-country) ((O) the(O) University(B-university) of(I-university) North(I-university) Sumatra(I-university) in(O) Medan(B-location) ,(O) the(O) Indonesian(B-university) Christian(I-university) University(I-university) in(O) Jakarta(B-location) ,(O) Padjadjaran(B-university) University(I-university) in(O) Bandung(B-location) ,(O) Jenderal(B-university) Soedirman(I-university) University(I-university) in(O) Purwokerto(B-location) and(O) Muhammadiyah(B-university) University(I-university) in(O) Malang(B-location) )(O) .(O)"}, "label_list": ["organization", "field", "conference", "task", "country", "algorithm", "metric", "university", "location", "product", "person", "researcher", "programming language"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 2115, 11, 10017, 11, 3465, 11, 3224, 11, 12384, 11, 18767, 11, 12374, 11, 3813, 11, 2027, 11, 1732, 11, 32185, 11, 15840, 4221, 323, 507, 627, 85664, 25, 763, 6287, 220, 679, 16, 1174, 433, 574, 7376, 430, 16261, 31464, 1053, 33009, 459, 17130, 73757, 311, 1855, 315, 4330, 23978, 304, 24922, 320, 279, 3907, 315, 4892, 8279, 40658, 304, 3344, 276, 1174, 279, 59929, 9052, 3907, 304, 64133, 1174, 393, 25770, 329, 19571, 276, 3907, 304, 17366, 2234, 1174, 622, 1693, 278, 2100, 101081, 1543, 3907, 304, 14874, 86, 564, 14200, 323, 117970, 76, 2836, 95780, 3907, 304, 8560, 526, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "336", "dataset": "mit-movie", "split": "dev", "prediction": "look(O) for(O) dramas(B-genre) that(O) have(O) denzel(B-actor) washington(I-actor) and(O) are(O) academy(B-review) award(I-review) winners(I-review) or(O) nominees(O)", "instance": {"id": "336", "words": ["look", "for", "dramas", "that", "have", "denzel", "washington", "and", "are", "academy", "award", "winners", "or", "nominees"], "labels": ["O", "O", "B-genre", "O", "O", "B-actor", "I-actor", "O", "O", "B-average ratings", "I-average ratings", "I-average ratings", "I-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, director, genre, year, average ratings, plot, rating, song, review, character, trailer, title and O.\nSentence: look for dramas that have denzel washington and are academy award winners or nominees", "prompt_labels": "look(O) for(O) dramas(B-genre) that(O) have(O) denzel(B-actor) washington(I-actor) and(O) are(O) academy(B-average ratings) award(I-average ratings) winners(I-average ratings) or(I-average ratings) nominees(I-average ratings)"}, "label_list": ["actor", "director", "genre", "year", "average ratings", "plot", "rating", "song", "review", "character", "trailer", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 7690, 11, 17779, 11, 1060, 11, 5578, 18594, 11, 7234, 11, 10959, 11, 5609, 11, 3477, 11, 3752, 11, 19809, 11, 2316, 323, 507, 627, 85664, 25, 1427, 369, 88826, 430, 617, 3453, 28493, 94771, 323, 527, 44445, 10292, 26526, 477, 60142, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "412", "dataset": "mit-restaurant", "split": "dev", "prediction": "find(O) me(O) a(O) tgi(B-Restaurant Name) fridays(I-Restaurant Name) near(B-Location) me(O)", "instance": {"id": "412", "words": ["find", "me", "a", "tgi", "fridays", "near", "me"], "labels": ["O", "O", "O", "B-Restaurant Name", "I-Restaurant Name", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Rating, Price, Location, Cuisine, Restaurant Name, Dish, Amenity and O.\nSentence: find me a tgi fridays near me", "prompt_labels": "find(O) me(O) a(O) tgi(B-Restaurant Name) fridays(I-Restaurant Name) near(B-Location) me(I-Location)"}, "label_list": ["Hours", "Rating", "Price", "Location", "Cuisine", "Restaurant Name", "Dish", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 19767, 11, 8650, 11, 10067, 11, 81961, 11, 26568, 4076, 11, 49268, 11, 3383, 56685, 323, 507, 627, 85664, 25, 1505, 757, 264, 259, 8376, 1448, 307, 954, 3221, 757, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "191", "dataset": "crossner_literature", "split": "dev", "prediction": "Of(O) Things(O) to(O) Come(O),(O) The(O) New(B-magazine) York(I-magazine) Times(I-magazine) Book(I-magazine) Review(I-magazine),(O) October(O) 26(O),(O) 1975(O) Theodore(B-writer) Sturgeon(I-writer) praised(O) The(B-book) Dispossessed(I-book) as(O) a(O) beautifully(O) written(O),(O) beautifully(O) composed(O) book(O),(O) saying(O) it(O) performs(O) one(O) of(O) science(B-literary genre) fiction(I-literary genre) '(O) s(O) prime(O) functions(O),(O) which(O) is(O) to(O) create(O) another(O) kind(O) of(O) social(O) system(O) to(O) see(O) how(O) it(O) would(O) work(O).(O)", "instance": {"id": "191", "words": ["Of", "Things", "to", "Come", ",", "The", "New", "York", "Times", "Book", "Review", ",", "October", "26", ",", "1975", "Theodore", "Sturgeon", "praised", "The", "Dispossessed", "as", "a", "beautifully", "written", ",", "beautifully", "composed", "book", ",", "saying", "it", "performs", "one", "of", "science", "fiction", "'s", "prime", "functions", ",", "which", "is", "to", "create", "another", "kind", "of", "social", "system", "to", "see", "how", "it", "would", "work", "."], "labels": ["O", "O", "O", "O", "O", "B-magazine", "I-magazine", "I-magazine", "I-magazine", "I-magazine", "I-magazine", "O", "O", "O", "O", "O", "B-writer", "I-writer", "O", "B-book", "I-book", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-literary genre", "I-literary genre", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, writer, poem, organization, book, person, literary genre, event, country, award, magazine and O.\nSentence: Of Things to Come , The New York Times Book Review , October 26 , 1975 Theodore Sturgeon praised The Dispossessed as a beautifully written , beautifully composed book , saying it performs one of science fiction 's prime functions , which is to create another kind of social system to see how it would work .", "prompt_labels": "Of(O) Things(O) to(O) Come(O) ,(O) The(B-magazine) New(I-magazine) York(I-magazine) Times(I-magazine) Book(I-magazine) Review(I-magazine) ,(O) October(O) 26(O) ,(O) 1975(O) Theodore(B-writer) Sturgeon(I-writer) praised(O) The(B-book) Dispossessed(I-book) as(O) a(O) beautifully(O) written(O) ,(O) beautifully(O) composed(O) book(O) ,(O) saying(O) it(O) performs(O) one(O) of(O) science(B-literary genre) fiction(I-literary genre) 's(O) prime(O) functions(O) ,(O) which(O) is(O) to(O) create(O) another(O) kind(O) of(O) social(O) system(O) to(O) see(O) how(O) it(O) would(O) work(O) .(O)"}, "label_list": ["location", "writer", "poem", "organization", "book", "person", "literary genre", "event", "country", "award", "magazine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 7061, 11, 33894, 11, 7471, 11, 2363, 11, 1732, 11, 32465, 17779, 11, 1567, 11, 3224, 11, 10292, 11, 14756, 323, 507, 627, 85664, 25, 5046, 20695, 311, 15936, 1174, 578, 1561, 4356, 8691, 6017, 10506, 1174, 6664, 220, 1627, 1174, 220, 4468, 20, 77449, 800, 81562, 37475, 578, 4185, 9007, 22456, 439, 264, 32719, 5439, 1174, 32719, 24306, 2363, 1174, 5605, 433, 27772, 832, 315, 8198, 17422, 364, 82, 10461, 5865, 1174, 902, 374, 311, 1893, 2500, 3169, 315, 3674, 1887, 311, 1518, 1268, 433, 1053, 990, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "324", "dataset": "crossner_politics", "split": "dev", "prediction": "His(O) father(O) Patrick(B-politician) Reynolds(I-politician) was(O) elected(O) as(O) a(O) Cumann(B-political party) na(I-political party) nGaedheal(I-political party) Teachta(I-political party) D\u00e1la(I-political party) ((O) TD(O) )(O) for(O) Leitrim-Sligo(B-location) at(O) the(O) September(O) 1927(B-election) Irish(I-election) general(I-election) election(I-election),(O) but(O) was(O) fatally(O) shot(O) during(O) the(O) 1932(B-election) Irish(I-election) general(I-election) election(I-election) campaign(O).(O)", "instance": {"id": "324", "words": ["His", "father", "Patrick", "Reynolds", "was", "elected", "as", "a", "Cumann", "na", "nGaedheal", "Teachta", "D\u00e1la", "(", "TD", ")", "for", "Leitrim-Sligo", "at", "the", "September", "1927", "Irish", "general", "election", ",", "but", "was", "fatally", "shot", "during", "the", "1932", "Irish", "general", "election", "campaign", "."], "labels": ["O", "O", "B-politician", "I-politician", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "B-political party", "O", "O", "B-location", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, event, country, location, election, person, organization, politician and O.\nSentence: His father Patrick Reynolds was elected as a Cumann na nGaedheal Teachta D\u00e1la ( TD ) for Leitrim-Sligo at the September 1927 Irish general election , but was fatally shot during the 1932 Irish general election campaign .", "prompt_labels": "His(O) father(O) Patrick(B-politician) Reynolds(I-politician) was(O) elected(O) as(O) a(O) Cumann(B-political party) na(I-political party) nGaedheal(I-political party) Teachta(I-political party) D\u00e1la(I-political party) ((O) TD(B-political party) )(O) for(O) Leitrim-Sligo(B-location) at(O) the(O) September(B-election) 1927(I-election) Irish(I-election) general(I-election) election(I-election) ,(O) but(O) was(O) fatally(O) shot(O) during(O) the(O) 1932(B-election) Irish(I-election) general(I-election) election(I-election) campaign(O) .(O)"}, "label_list": ["political party", "event", "country", "location", "election", "person", "organization", "politician"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5054, 4717, 11, 1567, 11, 3224, 11, 3813, 11, 6355, 11, 1732, 11, 7471, 11, 37038, 323, 507, 627, 85664, 25, 5414, 7126, 20199, 46172, 574, 16689, 439, 264, 32678, 1036, 4415, 308, 38, 62554, 383, 278, 70377, 2629, 423, 119756, 320, 28816, 883, 369, 2009, 275, 6417, 6354, 7864, 78, 520, 279, 6250, 220, 5926, 22, 18088, 4689, 6355, 1174, 719, 574, 72461, 6689, 2391, 279, 220, 7285, 17, 18088, 4689, 6355, 4901, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "652", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) want(O) to(O) find(O) a(O) burger(B-Cuisine) that(O) isnt(B-Cuisine) fast(I-Cuisine) food(I-Cuisine)", "instance": {"id": "652", "words": ["i", "want", "to", "find", "a", "burger", "that", "isnt", "fast", "food"], "labels": ["O", "O", "O", "O", "O", "B-Dish", "O", "B-Rating", "I-Rating", "I-Rating"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Location, Cuisine, Restaurant Name, Dish, Rating, Hours, Price and O.\nSentence: i want to find a burger that isnt fast food", "prompt_labels": "i(O) want(O) to(O) find(O) a(O) burger(B-Dish) that(O) isnt(B-Rating) fast(I-Rating) food(I-Rating)"}, "label_list": ["Amenity", "Location", "Cuisine", "Restaurant Name", "Dish", "Rating", "Hours", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 10067, 11, 81961, 11, 26568, 4076, 11, 49268, 11, 19767, 11, 30192, 11, 8650, 323, 507, 627, 85664, 25, 602, 1390, 311, 1505, 264, 45723, 430, 70058, 5043, 3691, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2035", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) a(O) really(B-average ratings) good(I-average ratings) scary(B-genre) movie(O) about(O) an(O) axe(B-plot) murder(I-plot)", "instance": {"id": "2035", "words": ["what", "is", "a", "really", "good", "scary", "movie", "about", "an", "axe", "murder"], "labels": ["O", "O", "O", "B-average ratings", "I-average ratings", "B-genre", "O", "O", "O", "B-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, review, genre, year, actor, title, song, character, average ratings, director, trailer, rating and O.\nSentence: what is a really good scary movie about an axe murder", "prompt_labels": "what(O) is(O) a(O) really(B-average ratings) good(I-average ratings) scary(B-genre) movie(O) about(O) an(O) axe(B-plot) murder(I-plot)"}, "label_list": ["plot", "review", "genre", "year", "actor", "title", "song", "character", "average ratings", "director", "trailer", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 3477, 11, 17779, 11, 1060, 11, 12360, 11, 2316, 11, 5609, 11, 3752, 11, 5578, 18594, 11, 7690, 11, 19809, 11, 10959, 323, 507, 627, 85664, 25, 1148, 374, 264, 2216, 1695, 29565, 5818, 922, 459, 51564, 10102, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "375", "dataset": "crossner_music", "split": "dev", "prediction": "Justincase(B-band) was(O) an(O) American(O) Alternative(B-music genre) rock(I-music genre) -(I-music genre) Pop(I-music genre) music(I-music genre) band(O) from(O) Charlotte(B-location),(I-location) North(I-location) Carolina(I-location),(O) best(O) known(O) for(O) their(O) 2002(O) single(O) Don(B-song) 't(I-song) Cry(I-song) for(I-song) Us(I-song),(O) which(O) was(O) co-written(O) by(O) Michelle(B-musical artist) Branch(I-musical artist),(O) who(O) was(O) one(O) of(O) the(O) band(O)'s(O) early(O) champions(O).(O)", "instance": {"id": "375", "words": ["Justincase", "was", "an", "American", "Alternative", "rock", "-", "Pop", "music", "band", "from", "Charlotte", ",", "North", "Carolina", ",", "best", "known", "for", "their", "2002", "single", "Don", "'t", "Cry", "for", "Us", ",", "which", "was", "co-written", "by", "Michelle", "Branch", ",", "who", "was", "one", "of", "the", "band", "'s", "early", "champions", "."], "labels": ["B-band", "O", "O", "O", "B-music genre", "I-music genre", "O", "B-music genre", "I-music genre", "O", "O", "B-location", "O", "B-location", "I-location", "O", "O", "O", "O", "O", "O", "O", "B-song", "I-song", "I-song", "I-song", "I-song", "O", "O", "O", "O", "O", "B-musical artist", "I-musical artist", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, event, musical artist, music genre, location, country, award, musical instrument, band, album, organization, song and O.\nSentence: Justincase was an American Alternative rock - Pop music band from Charlotte , North Carolina , best known for their 2002 single Don 't Cry for Us , which was co-written by Michelle Branch , who was one of the band 's early champions .", "prompt_labels": "Justincase(B-band) was(O) an(O) American(O) Alternative(B-music genre) rock(I-music genre) -(O) Pop(B-music genre) music(I-music genre) band(O) from(O) Charlotte(B-location) ,(O) North(B-location) Carolina(I-location) ,(O) best(O) known(O) for(O) their(O) 2002(O) single(O) Don(B-song) 't(I-song) Cry(I-song) for(I-song) Us(I-song) ,(O) which(O) was(O) co-written(O) by(O) Michelle(B-musical artist) Branch(I-musical artist) ,(O) who(O) was(O) one(O) of(O) the(O) band(O) 's(O) early(O) champions(O) .(O)"}, "label_list": ["person", "event", "musical artist", "music genre", "location", "country", "award", "musical instrument", "band", "album", "organization", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 1567, 11, 18273, 10255, 11, 4731, 17779, 11, 3813, 11, 3224, 11, 10292, 11, 18273, 14473, 11, 7200, 11, 8176, 11, 7471, 11, 5609, 323, 507, 627, 85664, 25, 4702, 2910, 521, 574, 459, 3778, 42209, 7091, 482, 10466, 4731, 7200, 505, 29473, 1174, 4892, 13030, 1174, 1888, 3967, 369, 872, 220, 1049, 17, 3254, 4418, 364, 83, 43805, 369, 4073, 1174, 902, 574, 1080, 67383, 555, 33126, 26176, 1174, 889, 574, 832, 315, 279, 7200, 364, 82, 4216, 34838, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1398", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) is(O) station(B-Restaurant Name) donuts(I-Restaurant Name)", "instance": {"id": "1398", "words": ["where", "is", "station", "donuts"], "labels": ["O", "O", "B-Restaurant Name", "I-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Hours, Amenity, Price, Restaurant Name, Location, Cuisine, Rating and O.\nSentence: where is station donuts", "prompt_labels": "where(O) is(O) station(B-Restaurant Name) donuts(I-Restaurant Name)"}, "label_list": ["Dish", "Hours", "Amenity", "Price", "Restaurant Name", "Location", "Cuisine", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 30192, 11, 3383, 56685, 11, 8650, 11, 26568, 4076, 11, 10067, 11, 81961, 11, 19767, 323, 507, 627, 85664, 25, 1405, 374, 8216, 1541, 6256, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "220", "dataset": "crossner_science", "split": "dev", "prediction": "Pupin(B-scientist) was(O) a(O) founding(O) member(O) of(O) National(B-organization) Advisory(I-organization) Committee(I-organization) for(I-organization) Aeronautics(I-organization) ((O) NACA(B-organization) )(O) on(O) 3(O) March(O) 1915(O),(O) which(O) later(O) became(O) NASA(B-organization),(O) and(O) he(O) participated(O) in(O) the(O) founding(O) of(O) American(B-organization) Mathematical(I-organization) Society(I-organization) and(O) American(B-organization) Physical(I-organization) Society(I-organization).(O)", "instance": {"id": "220", "words": ["Pupin", "was", "a", "founding", "member", "of", "National", "Advisory", "Committee", "for", "Aeronautics", "(", "NACA", ")", "on", "3", "March", "1915", ",", "which", "later", "became", "NASA", ",", "and", "he", "participated", "in", "the", "founding", "of", "American", "Mathematical", "Society", "and", "American", "Physical", "Society", "."], "labels": ["B-scientist", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "B-organization", "I-organization", "I-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: theory, person, award, enzyme, academic journal, country, protein, university, chemical element, location, discipline, organization, astronomical object, event, chemical compound, scientist and O.\nSentence: Pupin was a founding member of National Advisory Committee for Aeronautics ( NACA ) on 3 March 1915 , which later became NASA , and he participated in the founding of American Mathematical Society and American Physical Society .", "prompt_labels": "Pupin(B-scientist) was(O) a(O) founding(O) member(O) of(O) National(B-organization) Advisory(I-organization) Committee(I-organization) for(I-organization) Aeronautics(I-organization) ((O) NACA(B-organization) )(O) on(O) 3(O) March(O) 1915(O) ,(O) which(O) later(O) became(O) NASA(B-organization) ,(O) and(O) he(O) participated(O) in(O) the(O) founding(O) of(O) American(B-organization) Mathematical(I-organization) Society(I-organization) and(O) American(B-organization) Physical(I-organization) Society(I-organization) .(O)"}, "label_list": ["theory", "person", "award", "enzyme", "academic journal", "country", "protein", "university", "chemical element", "location", "discipline", "organization", "astronomical object", "event", "chemical compound", "scientist"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10334, 11, 1732, 11, 10292, 11, 49242, 11, 14584, 8486, 11, 3224, 11, 13128, 11, 12374, 11, 11742, 2449, 11, 3813, 11, 26434, 11, 7471, 11, 87283, 1665, 11, 1567, 11, 11742, 24549, 11, 28568, 323, 507, 627, 85664, 25, 393, 455, 258, 574, 264, 36330, 4562, 315, 5165, 45013, 10554, 369, 362, 20110, 2784, 1233, 320, 452, 63638, 883, 389, 220, 18, 5587, 220, 7529, 20, 1174, 902, 3010, 6244, 22146, 1174, 323, 568, 31408, 304, 279, 36330, 315, 3778, 92102, 13581, 323, 3778, 28479, 13581, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "406", "dataset": "crossner_science", "split": "dev", "prediction": "By(O) being(O) an(O) AMP-activated(B-protein) protein(I-protein) kinase(I-protein) activator(O) like(O) Metformin(B-protein),(O) it(O) acts(O) similar(O),(O) affecting(O) metabolism(O) in(O) a(O) way(O) that(O) may(O) reveal(O) useful(O) applications(O) to(O) treat(O).(O)", "instance": {"id": "406", "words": ["By", "being", "an", "AMP-activated", "protein", "kinase", "activator", "like", "Metformin", ",", "it", "acts", "similar", ",", "affecting", "metabolism", "in", "a", "way", "that", "may", "reveal", "useful", "applications", "to", "treat", "."], "labels": ["O", "O", "O", "B-enzyme", "I-enzyme", "I-enzyme", "O", "O", "B-enzyme", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: theory, university, discipline, astronomical object, scientist, event, person, protein, location, award, country, chemical compound, enzyme, organization, chemical element, academic journal and O.\nSentence: By being an AMP-activated protein kinase activator like Metformin , it acts similar , affecting metabolism in a way that may reveal useful applications to treat .", "prompt_labels": "By(O) being(O) an(O) AMP-activated(B-enzyme) protein(I-enzyme) kinase(I-enzyme) activator(O) like(O) Metformin(B-enzyme) ,(O) it(O) acts(O) similar(O) ,(O) affecting(O) metabolism(O) in(O) a(O) way(O) that(O) may(O) reveal(O) useful(O) applications(O) to(O) treat(O) .(O)"}, "label_list": ["theory", "university", "discipline", "astronomical object", "scientist", "event", "person", "protein", "location", "award", "country", "chemical compound", "enzyme", "organization", "chemical element", "academic journal"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10334, 11, 12374, 11, 26434, 11, 87283, 1665, 11, 28568, 11, 1567, 11, 1732, 11, 13128, 11, 3813, 11, 10292, 11, 3224, 11, 11742, 24549, 11, 49242, 11, 7471, 11, 11742, 2449, 11, 14584, 8486, 323, 507, 627, 85664, 25, 3296, 1694, 459, 64008, 12, 31262, 13128, 82160, 4197, 859, 1093, 6344, 630, 258, 1174, 433, 14385, 4528, 1174, 28987, 39097, 304, 264, 1648, 430, 1253, 16805, 5505, 8522, 311, 4322, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "13", "dataset": "crossner_politics", "split": "dev", "prediction": "In(O) Australia(B-country),(O) a(O) number(O) of(O) single(O) issue(O) parties(O) have(O) been(O) elected(O) to(O) federal(O) and(O) state(O) parliaments(O) such(O) as(O) the(O) Animal(B-political party) Justice(I-political party) Party(I-political party),(O) Dignity(B-political party) for(I-political party) Disability(I-political party),(O) Australian(B-political party) Motoring(I-political party) Enthusiast(I-political party) Party(I-political party) and(O) the(O) Australian(B-political party) Sex(I-political party) Party(I-political party).(O)", "instance": {"id": "13", "words": ["In", "Australia", ",", "a", "number", "of", "single", "issue", "parties", "have", "been", "elected", "to", "federal", "and", "state", "parliaments", "such", "as", "the", "Animal", "Justice", "Party", ",", "Dignity", "for", "Disability", ",", "Australian", "Motoring", "Enthusiast", "Party", "and", "the", "Australian", "Sex", "Party", "."], "labels": ["O", "B-country", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "O", "B-political party", "I-political party", "I-political party", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, event, political party, country, politician, election, organization, person and O.\nSentence: In Australia , a number of single issue parties have been elected to federal and state parliaments such as the Animal Justice Party , Dignity for Disability , Australian Motoring Enthusiast Party and the Australian Sex Party .", "prompt_labels": "In(O) Australia(B-country) ,(O) a(O) number(O) of(O) single(O) issue(O) parties(O) have(O) been(O) elected(O) to(O) federal(O) and(O) state(O) parliaments(O) such(O) as(O) the(O) Animal(B-political party) Justice(I-political party) Party(I-political party) ,(O) Dignity(B-political party) for(I-political party) Disability(I-political party) ,(O) Australian(B-political party) Motoring(I-political party) Enthusiast(I-political party) Party(I-political party) and(O) the(O) Australian(B-political party) Sex(I-political party) Party(I-political party) .(O)"}, "label_list": ["location", "event", "political party", "country", "politician", "election", "organization", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 1567, 11, 5054, 4717, 11, 3224, 11, 37038, 11, 6355, 11, 7471, 11, 1732, 323, 507, 627, 85664, 25, 763, 8494, 1174, 264, 1396, 315, 3254, 4360, 9875, 617, 1027, 16689, 311, 6918, 323, 1614, 1370, 747, 24469, 1778, 439, 279, 21995, 12007, 8722, 1174, 423, 625, 488, 369, 75368, 1174, 13673, 19514, 5620, 2998, 34232, 72, 561, 8722, 323, 279, 13673, 6834, 8722, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "288", "dataset": "crossner_ai", "split": "dev", "prediction": "The(O) values(O) of(O) sensitivity(B-metric) and(O) specificity(B-metric) are(O) agnostic(O) to(O) the(O) percent(O) of(O) positive(O) cases(O) in(O) the(O) population(O) of(O) interest(O) ((O) as(O) opposed(O) to(O),(O) for(O) example(O),(O) precision(B-metric) )(O).(O)", "instance": {"id": "288", "words": ["The", "values", "of", "sensitivity", "and", "specificity", "are", "agnostic", "to", "the", "percent", "of", "positive", "cases", "in", "the", "population", "of", "interest", "(", "as", "opposed", "to", ",", "for", "example", ",", "precision", ")", "."], "labels": ["O", "O", "O", "B-metric", "O", "B-metric", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-metric", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, country, researcher, programming language, conference, university, task, product, field, person, metric, organization, location and O.\nSentence: The values of sensitivity and specificity are agnostic to the percent of positive cases in the population of interest ( as opposed to , for example , precision ) .", "prompt_labels": "The(O) values(O) of(O) sensitivity(B-metric) and(O) specificity(B-metric) are(O) agnostic(O) to(O) the(O) percent(O) of(O) positive(O) cases(O) in(O) the(O) population(O) of(O) interest(O) ((O) as(O) opposed(O) to(O) ,(O) for(O) example(O) ,(O) precision(B-metric) )(O) .(O)"}, "label_list": ["algorithm", "country", "researcher", "programming language", "conference", "university", "task", "product", "field", "person", "metric", "organization", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12384, 11, 3224, 11, 32185, 11, 15840, 4221, 11, 10017, 11, 12374, 11, 3465, 11, 2027, 11, 2115, 11, 1732, 11, 18767, 11, 7471, 11, 3813, 323, 507, 627, 85664, 25, 578, 2819, 315, 27541, 323, 76041, 527, 945, 87524, 311, 279, 3346, 315, 6928, 5157, 304, 279, 7187, 315, 2802, 320, 439, 16475, 311, 1174, 369, 3187, 1174, 16437, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1240", "dataset": "mit-restaurant", "split": "dev", "prediction": "whats(O) the(O) most(B-Rating) popular(I-Rating) steak(B-Cuisine) house(I-Cuisine) around(B-Location) here(I-Location)", "instance": {"id": "1240", "words": ["whats", "the", "most", "popular", "steak", "house", "around", "here"], "labels": ["O", "O", "O", "B-Rating", "B-Cuisine", "I-Cuisine", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Dish, Restaurant Name, Location, Hours, Price, Amenity, Rating and O.\nSentence: whats the most popular steak house around here", "prompt_labels": "whats(O) the(O) most(O) popular(B-Rating) steak(B-Cuisine) house(I-Cuisine) around(B-Location) here(I-Location)"}, "label_list": ["Cuisine", "Dish", "Restaurant Name", "Location", "Hours", "Price", "Amenity", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 49268, 11, 26568, 4076, 11, 10067, 11, 30192, 11, 8650, 11, 3383, 56685, 11, 19767, 323, 507, 627, 85664, 25, 41209, 279, 1455, 5526, 50059, 3838, 2212, 1618, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1937", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) biography(B-genre) movies(O) are(O) about(O) warsaw(B-plot) poland(I-plot)", "instance": {"id": "1937", "words": ["what", "biography", "movies", "are", "about", "warsaw", "poland"], "labels": ["O", "B-genre", "O", "O", "O", "B-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, plot, director, average ratings, review, genre, rating, title, trailer, actor, year, song and O.\nSentence: what biography movies are about warsaw poland", "prompt_labels": "what(O) biography(B-genre) movies(O) are(O) about(O) warsaw(B-plot) poland(I-plot)"}, "label_list": ["character", "plot", "director", "average ratings", "review", "genre", "rating", "title", "trailer", "actor", "year", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 7234, 11, 7690, 11, 5578, 18594, 11, 3477, 11, 17779, 11, 10959, 11, 2316, 11, 19809, 11, 12360, 11, 1060, 11, 5609, 323, 507, 627, 85664, 25, 1148, 48345, 9698, 527, 922, 25981, 675, 1499, 438, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1996", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) a(O) pg(B-rating) thriller(B-genre) rated(O) seven(B-average ratings) stars(I-average ratings) directed(O) by(O) hironobu(B-director) sakaguchi(I-director)", "instance": {"id": "1996", "words": ["what", "is", "a", "pg", "thriller", "rated", "seven", "stars", "directed", "by", "hironobu", "sakaguchi"], "labels": ["O", "O", "O", "B-rating", "B-genre", "O", "B-average ratings", "I-average ratings", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, trailer, average ratings, plot, rating, actor, character, review, genre, song, director, title and O.\nSentence: what is a pg thriller rated seven stars directed by hironobu sakaguchi", "prompt_labels": "what(O) is(O) a(O) pg(B-rating) thriller(B-genre) rated(O) seven(B-average ratings) stars(I-average ratings) directed(O) by(O) hironobu(B-director) sakaguchi(I-director)"}, "label_list": ["year", "trailer", "average ratings", "plot", "rating", "actor", "character", "review", "genre", "song", "director", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 19809, 11, 5578, 18594, 11, 7234, 11, 10959, 11, 12360, 11, 3752, 11, 3477, 11, 17779, 11, 5609, 11, 7690, 11, 2316, 323, 507, 627, 85664, 25, 1148, 374, 264, 17953, 54461, 22359, 8254, 9958, 15910, 555, 305, 2534, 677, 84, 78410, 351, 56017, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "729", "dataset": "mit-restaurant", "split": "dev", "prediction": "im(O) in(O) the(O) mood(O) for(O) some(O) texas(B-Dish) chili(I-Dish)", "instance": {"id": "729", "words": ["im", "in", "the", "mood", "for", "some", "texas", "chili"], "labels": ["O", "O", "O", "O", "O", "O", "B-Dish", "I-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Restaurant Name, Location, Rating, Price, Hours, Dish, Amenity and O.\nSentence: im in the mood for some texas chili", "prompt_labels": "im(O) in(O) the(O) mood(O) for(O) some(O) texas(B-Dish) chili(I-Dish)"}, "label_list": ["Cuisine", "Restaurant Name", "Location", "Rating", "Price", "Hours", "Dish", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 26568, 4076, 11, 10067, 11, 19767, 11, 8650, 11, 30192, 11, 49268, 11, 3383, 56685, 323, 507, 627, 85664, 25, 737, 304, 279, 20247, 369, 1063, 60348, 59717, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1087", "dataset": "mit-restaurant", "split": "dev", "prediction": "want(O) to(O) find(O) a(O) restaurant(O) that(O) specilizes(O) in(O) spagetti(B-Dish)", "instance": {"id": "1087", "words": ["want", "to", "find", "a", "restaurant", "that", "specilizes", "in", "spagetti"], "labels": ["O", "O", "O", "O", "O", "O", "B-Amenity", "I-Amenity", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Price, Amenity, Cuisine, Restaurant Name, Hours, Rating, Dish and O.\nSentence: want to find a restaurant that specilizes in spagetti", "prompt_labels": "want(O) to(O) find(O) a(O) restaurant(O) that(O) specilizes(B-Amenity) in(I-Amenity) spagetti(B-Dish)"}, "label_list": ["Location", "Price", "Amenity", "Cuisine", "Restaurant Name", "Hours", "Rating", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 8650, 11, 3383, 56685, 11, 81961, 11, 26568, 4076, 11, 30192, 11, 19767, 11, 49268, 323, 507, 627, 85664, 25, 1390, 311, 1505, 264, 10960, 430, 1424, 321, 4861, 304, 993, 351, 29037, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "349", "dataset": "crossner_music", "split": "dev", "prediction": "In(O) the(O) days(O) following(O) his(O) death(O),(O) tributes(O) were(O) paid(O) by(O) then-President(O) George(B-person) W.(I-person) Bush(I-person),(O) the(O) United(B-organization) States(I-organization) House(I-organization) of(I-organization) Representatives(I-organization),(O) and(O) many(O) musicians(O) and(O) performers(O),(O) including(O) B.(B-musical artist) B.(I-musical artist) King(I-musical artist),(O) Ronnie(B-musical artist) Hawkins(I-musical artist),(O) Mick(B-musical artist) Jagger(I-musical artist),(O) Ronnie(B-musical artist) Wood(I-musical artist),(O) George(B-musical artist) Thorogood(I-musical artist),(O) Eric(B-musical artist) Clapton(I-musical artist),(O) Tom(B-musical artist) Petty(I-musical artist),(O) Robert(B-musical artist) Plant(I-musical artist),(O) Elvis(B-musical artist) Costello(I-musical artist),(O) Bonnie(B-musical artist) Raitt(I-musical artist),(O) Robert(B-musical artist) Randolph(I-musical artist) and(O) the(O) Family(B-musical artist) Band(I-musical artist) and(O) Eric(B-musical artist) Burdon(I-musical artist).(O)", "instance": {"id": "349", "words": ["In", "the", "days", "following", "his", "death", ",", "tributes", "were", "paid", "by", "then-President", "George", "W.", "Bush", ",", "the", "United", "States", "House", "of", "Representatives", ",", "and", "many", "musicians", "and", "performers", ",", "including", "B.", "B.", "King", ",", "Ronnie", "Hawkins", ",", "Mick", "Jagger", ",", "Ronnie", "Wood", ",", "George", "Thorogood", ",", "Eric", "Clapton", ",", "Tom", "Petty", ",", "Robert", "Plant", ",", "Elvis", "Costello", ",", "Bonnie", "Raitt", ",", "Robert", "Randolph", "and", "the", "Family", "Band", "and", "Eric", "Burdon", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "I-person", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-musical artist", "I-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-band", "I-band", "I-band", "I-band", "I-band", "I-band", "O", "B-musical artist", "I-musical artist", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, event, musical artist, album, organization, location, music genre, band, musical instrument, person, award, country and O.\nSentence: In the days following his death , tributes were paid by then-President George W. Bush , the United States House of Representatives , and many musicians and performers , including B. B. King , Ronnie Hawkins , Mick Jagger , Ronnie Wood , George Thorogood , Eric Clapton , Tom Petty , Robert Plant , Elvis Costello , Bonnie Raitt , Robert Randolph and the Family Band and Eric Burdon .", "prompt_labels": "In(O) the(O) days(O) following(O) his(O) death(O) ,(O) tributes(O) were(O) paid(O) by(O) then-President(O) George(B-person) W.(I-person) Bush(I-person) ,(O) the(O) United(O) States(O) House(O) of(O) Representatives(O) ,(O) and(O) many(O) musicians(O) and(O) performers(O) ,(O) including(O) B.(B-musical artist) B.(I-musical artist) King(I-musical artist) ,(O) Ronnie(B-musical artist) Hawkins(I-musical artist) ,(O) Mick(B-musical artist) Jagger(I-musical artist) ,(O) Ronnie(B-musical artist) Wood(I-musical artist) ,(O) George(B-musical artist) Thorogood(I-musical artist) ,(O) Eric(B-musical artist) Clapton(I-musical artist) ,(O) Tom(B-musical artist) Petty(I-musical artist) ,(O) Robert(B-musical artist) Plant(I-musical artist) ,(O) Elvis(B-musical artist) Costello(I-musical artist) ,(O) Bonnie(B-musical artist) Raitt(I-musical artist) ,(O) Robert(B-band) Randolph(I-band) and(I-band) the(I-band) Family(I-band) Band(I-band) and(O) Eric(B-musical artist) Burdon(I-musical artist) .(O)"}, "label_list": ["song", "event", "musical artist", "album", "organization", "location", "music genre", "band", "musical instrument", "person", "award", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 1567, 11, 18273, 10255, 11, 8176, 11, 7471, 11, 3813, 11, 4731, 17779, 11, 7200, 11, 18273, 14473, 11, 1732, 11, 10292, 11, 3224, 323, 507, 627, 85664, 25, 763, 279, 2919, 2768, 813, 4648, 1174, 14121, 2142, 1051, 7318, 555, 1243, 86481, 10058, 468, 13, 14409, 1174, 279, 3723, 4273, 4783, 315, 40845, 1174, 323, 1690, 32629, 323, 45518, 1174, 2737, 426, 13, 426, 13, 6342, 1174, 84805, 70687, 1174, 60333, 622, 10322, 1174, 84805, 12404, 1174, 10058, 29550, 540, 1411, 1174, 16645, 2493, 391, 783, 1174, 8529, 95798, 1174, 8563, 18317, 1174, 67306, 11443, 4896, 1174, 74295, 432, 1339, 83, 1174, 8563, 86852, 323, 279, 12517, 17366, 323, 16645, 12649, 15357, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "105", "dataset": "crossner_music", "split": "dev", "prediction": "The(O) group(O)'s(O) evolution(O) can(O) be(O) traced(O) through(O) the(O) albums(O) The(B-album) John(I-album) Coltrane(I-album) Quartet(I-album) Plays(I-album),(O) Living(B-album) Space(I-album),(O) Transition(B-album),(O) New(B-album) Thing(I-album) at(I-album) Newport(I-album),(O) Sun(B-album) Ship(I-album),(O) and(O) First(B-album) Meditations(I-album).(O)", "instance": {"id": "105", "words": ["The", "group", "'s", "evolution", "can", "be", "traced", "through", "the", "albums", "The", "John", "Coltrane", "Quartet", "Plays", ",", "Living", "Space", ",", "Transition", ",", "New", "Thing", "at", "Newport", ",", "Sun", "Ship", ",", "and", "First", "Meditations", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-album", "I-album", "I-album", "I-album", "I-album", "O", "B-album", "I-album", "O", "B-album", "O", "B-album", "I-album", "I-album", "I-album", "O", "B-album", "I-album", "O", "O", "B-album", "I-album", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, music genre, band, album, organization, person, location, musical artist, award, country, song, musical instrument and O.\nSentence: The group 's evolution can be traced through the albums The John Coltrane Quartet Plays , Living Space , Transition , New Thing at Newport , Sun Ship , and First Meditations .", "prompt_labels": "The(O) group(O) 's(O) evolution(O) can(O) be(O) traced(O) through(O) the(O) albums(O) The(B-album) John(I-album) Coltrane(I-album) Quartet(I-album) Plays(I-album) ,(O) Living(B-album) Space(I-album) ,(O) Transition(B-album) ,(O) New(B-album) Thing(I-album) at(I-album) Newport(I-album) ,(O) Sun(B-album) Ship(I-album) ,(O) and(O) First(B-album) Meditations(I-album) .(O)"}, "label_list": ["event", "music genre", "band", "album", "organization", "person", "location", "musical artist", "award", "country", "song", "musical instrument"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 4731, 17779, 11, 7200, 11, 8176, 11, 7471, 11, 1732, 11, 3813, 11, 18273, 10255, 11, 10292, 11, 3224, 11, 5609, 11, 18273, 14473, 323, 507, 627, 85664, 25, 578, 1912, 364, 82, 15740, 649, 387, 51400, 1555, 279, 28785, 578, 3842, 4349, 376, 2194, 70184, 295, 77265, 1174, 19048, 11746, 1174, 38821, 1174, 1561, 38300, 520, 59900, 1174, 8219, 27901, 1174, 323, 5629, 3344, 31767, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "832", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) a(O) mcdonalds(B-Restaurant Name) nearby(B-Location)", "instance": {"id": "832", "words": ["is", "there", "a", "mcdonalds", "nearby"], "labels": ["O", "O", "O", "B-Restaurant Name", "B-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Price, Dish, Cuisine, Amenity, Location, Restaurant Name, Rating and O.\nSentence: is there a mcdonalds nearby", "prompt_labels": "is(O) there(O) a(O) mcdonalds(B-Restaurant Name) nearby(B-Location)"}, "label_list": ["Hours", "Price", "Dish", "Cuisine", "Amenity", "Location", "Restaurant Name", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 8650, 11, 49268, 11, 81961, 11, 3383, 56685, 11, 10067, 11, 26568, 4076, 11, 19767, 323, 507, 627, 85664, 25, 374, 1070, 264, 296, 4484, 80794, 82, 14373, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1767", "dataset": "mit-movie", "split": "dev", "prediction": "tell(O) me(O) about(O) the(O) movie(O) lemonade(B-title) mouth(I-title)", "instance": {"id": "1767", "words": ["tell", "me", "about", "the", "movie", "lemonade", "mouth"], "labels": ["O", "O", "O", "O", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, plot, genre, year, actor, character, rating, average ratings, song, director, review, title and O.\nSentence: tell me about the movie lemonade mouth", "prompt_labels": "tell(O) me(O) about(O) the(O) movie(O) lemonade(B-title) mouth(I-title)"}, "label_list": ["trailer", "plot", "genre", "year", "actor", "character", "rating", "average ratings", "song", "director", "review", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 7234, 11, 17779, 11, 1060, 11, 12360, 11, 3752, 11, 10959, 11, 5578, 18594, 11, 5609, 11, 7690, 11, 3477, 11, 2316, 323, 507, 627, 85664, 25, 3371, 757, 922, 279, 5818, 30564, 1037, 11013, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "457", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) all(O) of(O) the(O) films(O) directed(O) by(O) clint(B-director) eastwood(I-director)", "instance": {"id": "457", "words": ["show", "me", "all", "of", "the", "films", "directed", "by", "clint", "eastwood"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, character, rating, trailer, plot, genre, title, year, review, actor, average ratings, director and O.\nSentence: show me all of the films directed by clint eastwood", "prompt_labels": "show(O) me(O) all(O) of(O) the(O) films(O) directed(O) by(O) clint(B-director) eastwood(I-director)"}, "label_list": ["song", "character", "rating", "trailer", "plot", "genre", "title", "year", "review", "actor", "average ratings", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 3752, 11, 10959, 11, 19809, 11, 7234, 11, 17779, 11, 2316, 11, 1060, 11, 3477, 11, 12360, 11, 5578, 18594, 11, 7690, 323, 507, 627, 85664, 25, 1501, 757, 682, 315, 279, 12631, 15910, 555, 1206, 396, 11226, 6798, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "224", "dataset": "crossner_science", "split": "dev", "prediction": "He(O) is(O) also(O) a(O) two-time(O) Academy(B-award) Award(I-award) nominee(O),(O) receiving(O) a(O) 2014(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Original(I-award) Song(I-award) nomination(O) for(O) Happy(B-title) ((O) which(O) was(O) featured(O) in(O) Despicable(B-title) Me(I-title) 2(I-title) )(O) and(O) a(O) 2017(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Picture(I-award) nomination(O) as(O) one(O) of(O) the(O) producers(O) of(O) Hidden(B-title) Figures(I-title).(O)", "instance": {"id": "224", "words": ["He", "is", "also", "a", "two-time", "Academy", "Award", "nominee", ",", "receiving", "a", "2014", "Academy", "Award", "for", "Best", "Original", "Song", "nomination", "for", "Happy", "(", "which", "was", "featured", "in", "Despicable", "Me", "2", ")", "and", "a", "2017", "Academy", "Award", "for", "Best", "Picture", "nomination", "as", "one", "of", "the", "producers", "of", "Hidden", "Figures", "."], "labels": ["O", "O", "O", "O", "O", "B-award", "I-award", "O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical element, organization, academic journal, scientist, university, theory, chemical compound, protein, astronomical object, person, discipline, enzyme, event, award, country, location and O.\nSentence: He is also a two-time Academy Award nominee , receiving a 2014 Academy Award for Best Original Song nomination for Happy ( which was featured in Despicable Me 2 ) and a 2017 Academy Award for Best Picture nomination as one of the producers of Hidden Figures .", "prompt_labels": "He(O) is(O) also(O) a(O) two-time(O) Academy(B-award) Award(I-award) nominee(O) ,(O) receiving(O) a(O) 2014(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Original(I-award) Song(I-award) nomination(O) for(O) Happy(O) ((O) which(O) was(O) featured(O) in(O) Despicable(O) Me(O) 2(O) )(O) and(O) a(O) 2017(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Picture(I-award) nomination(O) as(O) one(O) of(O) the(O) producers(O) of(O) Hidden(O) Figures(O) .(O)"}, "label_list": ["chemical element", "organization", "academic journal", "scientist", "university", "theory", "chemical compound", "protein", "astronomical object", "person", "discipline", "enzyme", "event", "award", "country", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 11742, 2449, 11, 7471, 11, 14584, 8486, 11, 28568, 11, 12374, 11, 10334, 11, 11742, 24549, 11, 13128, 11, 87283, 1665, 11, 1732, 11, 26434, 11, 49242, 11, 1567, 11, 10292, 11, 3224, 11, 3813, 323, 507, 627, 85664, 25, 1283, 374, 1101, 264, 1403, 7394, 16192, 17768, 29311, 1174, 12588, 264, 220, 679, 19, 16192, 17768, 369, 7252, 17674, 19508, 29804, 369, 24241, 320, 902, 574, 15109, 304, 3959, 95118, 2206, 220, 17, 883, 323, 264, 220, 679, 22, 16192, 17768, 369, 7252, 25586, 29804, 439, 832, 315, 279, 24190, 315, 35342, 69356, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "316", "dataset": "crossner_politics", "split": "dev", "prediction": "He(O) was(O) an(O) AKP(B-political party) parliamentary(O) candidate(O) in(O) 2011(B-election) Turkish(I-election) general(I-election) election(I-election) and(O) the(O) leader(O) of(O) the(O) AKP(B-political party) in(O) both(O) the(O) June(B-election) 2015(I-election) Turkish(I-election) general(I-election) election(I-election) and(O) November(B-election) 2015(I-election) Turkish(I-election) general(I-election) election(I-election) general(O) elections(O).(O)", "instance": {"id": "316", "words": ["He", "was", "an", "AKP", "parliamentary", "candidate", "in", "2011", "Turkish", "general", "election", "and", "the", "leader", "of", "the", "AKP", "in", "both", "the", "June", "2015", "Turkish", "general", "election", "and", "November", "2015", "Turkish", "general", "election", "general", "elections", "."], "labels": ["O", "O", "O", "B-political party", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "B-political party", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, organization, country, election, person, location, political party, politician and O.\nSentence: He was an AKP parliamentary candidate in 2011 Turkish general election and the leader of the AKP in both the June 2015 Turkish general election and November 2015 Turkish general election general elections .", "prompt_labels": "He(O) was(O) an(O) AKP(B-political party) parliamentary(O) candidate(O) in(O) 2011(B-election) Turkish(I-election) general(I-election) election(I-election) and(O) the(O) leader(O) of(O) the(O) AKP(B-political party) in(O) both(O) the(O) June(B-election) 2015(I-election) Turkish(I-election) general(I-election) election(I-election) and(O) November(B-election) 2015(I-election) Turkish(I-election) general(I-election) election(I-election) general(O) elections(O) .(O)"}, "label_list": ["event", "organization", "country", "election", "person", "location", "political party", "politician"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 7471, 11, 3224, 11, 6355, 11, 1732, 11, 3813, 11, 5054, 4717, 11, 37038, 323, 507, 627, 85664, 25, 1283, 574, 459, 31672, 47, 44250, 9322, 304, 220, 679, 16, 24666, 4689, 6355, 323, 279, 7808, 315, 279, 31672, 47, 304, 2225, 279, 5651, 220, 679, 20, 24666, 4689, 6355, 323, 6841, 220, 679, 20, 24666, 4689, 6355, 4689, 16374, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "38", "dataset": "crossner_ai", "split": "dev", "prediction": "Image(B-task) segmentation(I-task) using(O) k-means(B-algorithm) clustering(I-algorithm) algorithms(O) has(O) long(O) been(O) used(O) for(O) pattern(B-task) recognition(I-task),(O) object(B-task) detection(I-task),(O) and(O) medical(B-task) imaging(I-task).(O)", "instance": {"id": "38", "words": ["Image", "segmentation", "using", "k-means", "clustering", "algorithms", "has", "long", "been", "used", "for", "pattern", "recognition", ",", "object", "detection", ",", "and", "medical", "imaging", "."], "labels": ["B-task", "I-task", "O", "B-algorithm", "I-algorithm", "I-algorithm", "O", "O", "O", "O", "O", "B-field", "I-field", "O", "B-task", "I-task", "O", "O", "B-field", "I-field", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, algorithm, location, field, product, programming language, task, organization, metric, person, country, researcher, university and O.\nSentence: Image segmentation using k-means clustering algorithms has long been used for pattern recognition , object detection , and medical imaging .", "prompt_labels": "Image(B-task) segmentation(I-task) using(O) k-means(B-algorithm) clustering(I-algorithm) algorithms(I-algorithm) has(O) long(O) been(O) used(O) for(O) pattern(B-field) recognition(I-field) ,(O) object(B-task) detection(I-task) ,(O) and(O) medical(B-field) imaging(I-field) .(O)"}, "label_list": ["conference", "algorithm", "location", "field", "product", "programming language", "task", "organization", "metric", "person", "country", "researcher", "university"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10017, 11, 12384, 11, 3813, 11, 2115, 11, 2027, 11, 15840, 4221, 11, 3465, 11, 7471, 11, 18767, 11, 1732, 11, 3224, 11, 32185, 11, 12374, 323, 507, 627, 85664, 25, 4758, 60852, 1701, 597, 35073, 598, 59454, 26249, 706, 1317, 1027, 1511, 369, 5497, 18324, 1174, 1665, 18468, 1174, 323, 6593, 32758, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1134", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) is(O) the(O) favorite(O) type(O) of(O) food(O) people(O) eat(O) out(O) here(O) and(O) where(O) can(O) i(O) get(O) it(O)", "instance": {"id": "1134", "words": ["what", "is", "the", "favorite", "type", "of", "food", "people", "eat", "out", "here", "and", "where", "can", "i", "get", "it"], "labels": ["O", "O", "O", "B-Rating", "O", "O", "O", "O", "O", "B-Location", "I-Location", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Rating, Amenity, Dish, Restaurant Name, Cuisine, Location, Hours and O.\nSentence: what is the favorite type of food people eat out here and where can i get it", "prompt_labels": "what(O) is(O) the(O) favorite(B-Rating) type(O) of(O) food(O) people(O) eat(O) out(B-Location) here(I-Location) and(O) where(O) can(O) i(O) get(O) it(O)"}, "label_list": ["Price", "Rating", "Amenity", "Dish", "Restaurant Name", "Cuisine", "Location", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 19767, 11, 3383, 56685, 11, 49268, 11, 26568, 4076, 11, 81961, 11, 10067, 11, 30192, 323, 507, 627, 85664, 25, 1148, 374, 279, 7075, 955, 315, 3691, 1274, 8343, 704, 1618, 323, 1405, 649, 602, 636, 433, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1039", "dataset": "mit-restaurant", "split": "dev", "prediction": "please(O) take(O) me(O) to(O) a(O) highly(B-Rating) rated(I-Rating) family(B-Cuisine) diner(I-Cuisine)", "instance": {"id": "1039", "words": ["please", "take", "me", "to", "a", "highly", "rated", "family", "diner"], "labels": ["O", "O", "O", "O", "O", "B-Rating", "I-Rating", "B-Cuisine", "I-Cuisine"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Restaurant Name, Hours, Rating, Dish, Cuisine, Amenity, Location and O.\nSentence: please take me to a highly rated family diner", "prompt_labels": "please(O) take(O) me(O) to(O) a(O) highly(B-Rating) rated(I-Rating) family(B-Cuisine) diner(I-Cuisine)"}, "label_list": ["Price", "Restaurant Name", "Hours", "Rating", "Dish", "Cuisine", "Amenity", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 26568, 4076, 11, 30192, 11, 19767, 11, 49268, 11, 81961, 11, 3383, 56685, 11, 10067, 323, 507, 627, 85664, 25, 4587, 1935, 757, 311, 264, 7701, 22359, 3070, 89206, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1418", "dataset": "mit-movie", "split": "dev", "prediction": "in(O) the(O) last(B-year) ten(I-year) years(I-year) did(O) gene(B-actor) kelly(I-actor) star(O) in(O) any(O) very(B-average ratings) popular(I-average ratings) fantasy(B-genre) movies(O)", "instance": {"id": "1418", "words": ["in", "the", "last", "ten", "years", "did", "gene", "kelly", "star", "in", "any", "very", "popular", "fantasy", "movies"], "labels": ["O", "O", "B-year", "I-year", "I-year", "O", "B-actor", "I-actor", "O", "O", "O", "B-average ratings", "I-average ratings", "B-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, plot, actor, year, review, character, genre, trailer, title, song, rating, director and O.\nSentence: in the last ten years did gene kelly star in any very popular fantasy movies", "prompt_labels": "in(O) the(O) last(B-year) ten(I-year) years(I-year) did(O) gene(B-actor) kelly(I-actor) star(O) in(O) any(O) very(B-average ratings) popular(I-average ratings) fantasy(B-genre) movies(O)"}, "label_list": ["average ratings", "plot", "actor", "year", "review", "character", "genre", "trailer", "title", "song", "rating", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 7234, 11, 12360, 11, 1060, 11, 3477, 11, 3752, 11, 17779, 11, 19809, 11, 2316, 11, 5609, 11, 10959, 11, 7690, 323, 507, 627, 85664, 25, 304, 279, 1566, 5899, 1667, 1550, 15207, 597, 12160, 6917, 304, 904, 1633, 5526, 18884, 9698, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "944", "dataset": "mit-movie", "split": "dev", "prediction": "i(O) want(O) to(O) find(O) the(O) movies(O) with(O) music(O) by(O) the(O) bee(B-song) gees(I-song)", "instance": {"id": "944", "words": ["i", "want", "to", "find", "the", "movies", "with", "music", "by", "the", "bee", "gees"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-song", "I-song", "I-song", "I-song", "I-song"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, trailer, review, rating, average ratings, actor, year, title, song, director, genre, plot and O.\nSentence: i want to find the movies with music by the bee gees", "prompt_labels": "i(O) want(O) to(O) find(O) the(O) movies(O) with(O) music(B-song) by(I-song) the(I-song) bee(I-song) gees(I-song)"}, "label_list": ["character", "trailer", "review", "rating", "average ratings", "actor", "year", "title", "song", "director", "genre", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 19809, 11, 3477, 11, 10959, 11, 5578, 18594, 11, 12360, 11, 1060, 11, 2316, 11, 5609, 11, 7690, 11, 17779, 11, 7234, 323, 507, 627, 85664, 25, 602, 1390, 311, 1505, 279, 9698, 449, 4731, 555, 279, 38328, 3980, 288, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "196", "dataset": "crossner_politics", "split": "dev", "prediction": "The(O) same(O) boundaries(O) were(O) used(O) in(O) the(O) 1922(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) the(O) 1923(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) the(O) 1924(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) the(O) 1929(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) the(O) 1931(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) the(O) 1935(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) the(O) 1945(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election).(O)", "instance": {"id": "196", "words": ["The", "same", "boundaries", "were", "used", "in", "the", "1922", "United", "Kingdom", "general", "election", ",", "the", "1923", "United", "Kingdom", "general", "election", ",", "the", "1924", "United", "Kingdom", "general", "election", ",", "the", "1929", "United", "Kingdom", "general", "election", ",", "the", "1931", "United", "Kingdom", "general", "election", ",", "the", "1935", "United", "Kingdom", "general", "election", "and", "the", "1945", "United", "Kingdom", "general", "election", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, politician, country, election, political party, location, person, event and O.\nSentence: The same boundaries were used in the 1922 United Kingdom general election , the 1923 United Kingdom general election , the 1924 United Kingdom general election , the 1929 United Kingdom general election , the 1931 United Kingdom general election , the 1935 United Kingdom general election and the 1945 United Kingdom general election .", "prompt_labels": "The(O) same(O) boundaries(O) were(O) used(O) in(O) the(O) 1922(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1923(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1924(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1929(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1931(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1935(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) the(O) 1945(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)"}, "label_list": ["organization", "politician", "country", "election", "political party", "location", "person", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 37038, 11, 3224, 11, 6355, 11, 5054, 4717, 11, 3813, 11, 1732, 11, 1567, 323, 507, 627, 85664, 25, 578, 1890, 23546, 1051, 1511, 304, 279, 220, 5926, 17, 3723, 15422, 4689, 6355, 1174, 279, 220, 5926, 18, 3723, 15422, 4689, 6355, 1174, 279, 220, 5926, 19, 3723, 15422, 4689, 6355, 1174, 279, 220, 5926, 24, 3723, 15422, 4689, 6355, 1174, 279, 220, 7285, 16, 3723, 15422, 4689, 6355, 1174, 279, 220, 7285, 20, 3723, 15422, 4689, 6355, 323, 279, 220, 6393, 20, 3723, 15422, 4689, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "379", "dataset": "crossner_politics", "split": "dev", "prediction": "He(O) was(O) elected(O) to(O) the(O) Parliament(O) of(O) Norway(B-country) from(O) Finnmark(B-location) in(O) 1973(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election),(O) and(O) was(O) re-elected(O) in(O) 1977(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election) and(O) 1981(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election).(O)", "instance": {"id": "379", "words": ["He", "was", "elected", "to", "the", "Parliament", "of", "Norway", "from", "Finnmark", "in", "1973", "Norwegian", "parliamentary", "election", ",", "and", "was", "re-elected", "in", "1977", "Norwegian", "parliamentary", "election", "and", "1981", "Norwegian", "parliamentary", "election", "."], "labels": ["O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "B-location", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, country, political party, location, event, organization, person, politician and O.\nSentence: He was elected to the Parliament of Norway from Finnmark in 1973 Norwegian parliamentary election , and was re-elected in 1977 Norwegian parliamentary election and 1981 Norwegian parliamentary election .", "prompt_labels": "He(O) was(O) elected(O) to(O) the(O) Parliament(B-organization) of(I-organization) Norway(I-organization) from(O) Finnmark(B-location) in(O) 1973(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election) ,(O) and(O) was(O) re-elected(O) in(O) 1977(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election) and(O) 1981(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election) .(O)"}, "label_list": ["election", "country", "political party", "location", "event", "organization", "person", "politician"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 6355, 11, 3224, 11, 5054, 4717, 11, 3813, 11, 1567, 11, 7471, 11, 1732, 11, 37038, 323, 507, 627, 85664, 25, 1283, 574, 16689, 311, 279, 20302, 315, 32603, 505, 35162, 4075, 304, 220, 4468, 18, 45721, 44250, 6355, 1174, 323, 574, 312, 96805, 304, 220, 4468, 22, 45721, 44250, 6355, 323, 220, 3753, 16, 45721, 44250, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "314", "dataset": "crossner_ai", "split": "dev", "prediction": "The(O) KDD(B-conference) Conference(I-conference) grew(O) from(O) KDD(B-conference) ((O) Knowledge(B-field) Discovery(I-field) and(I-field) Data(I-field) Mining(I-field) )(O) workshops(O) at(O) AAAI(B-conference) conferences(O),(O) which(O) were(O) started(O) by(O) Gregory(B-researcher) I.(I-researcher) Piatetsky-Shapiro(I-researcher) in(O) 1989(O),(O) 1991(O),(O) and(O) 1993(O),(O) and(O) Usama(B-researcher) Fayyad(I-researcher) in(O) 1994(O).(O) Machinery(O) |(O) ACM(O).(O)", "instance": {"id": "314", "words": ["The", "KDD", "Conference", "grew", "from", "KDD", "(", "Knowledge", "Discovery", "and", "Data", "Mining", ")", "workshops", "at", "AAAI", "conferences", ",", "which", "were", "started", "by", "Gregory", "I.", "Piatetsky-Shapiro", "in", "1989", ",", "1991", ",", "and", "1993", ",", "and", "Usama", "Fayyad", "in", "1994", ".", "Machinery", "|", "ACM", "."], "labels": ["O", "B-conference", "I-conference", "O", "O", "B-conference", "O", "B-conference", "I-conference", "I-conference", "I-conference", "I-conference", "O", "O", "O", "B-conference", "I-conference", "O", "O", "O", "O", "O", "B-researcher", "I-researcher", "I-researcher", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-researcher", "I-researcher", "O", "O", "O", "B-conference", "I-conference", "I-conference", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, researcher, metric, location, programming language, university, algorithm, organization, country, product, conference, task, field and O.\nSentence: The KDD Conference grew from KDD ( Knowledge Discovery and Data Mining ) workshops at AAAI conferences , which were started by Gregory I. Piatetsky-Shapiro in 1989 , 1991 , and 1993 , and Usama Fayyad in 1994 . Machinery | ACM .", "prompt_labels": "The(O) KDD(B-conference) Conference(I-conference) grew(O) from(O) KDD(B-conference) ((O) Knowledge(B-conference) Discovery(I-conference) and(I-conference) Data(I-conference) Mining(I-conference) )(O) workshops(O) at(O) AAAI(B-conference) conferences(I-conference) ,(O) which(O) were(O) started(O) by(O) Gregory(B-researcher) I.(I-researcher) Piatetsky-Shapiro(I-researcher) in(O) 1989(O) ,(O) 1991(O) ,(O) and(O) 1993(O) ,(O) and(O) Usama(B-researcher) Fayyad(I-researcher) in(O) 1994(O) .(O) Machinery(B-conference) |(I-conference) ACM(I-conference) .(O)"}, "label_list": ["person", "researcher", "metric", "location", "programming language", "university", "algorithm", "organization", "country", "product", "conference", "task", "field"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 32185, 11, 18767, 11, 3813, 11, 15840, 4221, 11, 12374, 11, 12384, 11, 7471, 11, 3224, 11, 2027, 11, 10017, 11, 3465, 11, 2115, 323, 507, 627, 85664, 25, 578, 735, 4195, 15217, 14264, 505, 735, 4195, 320, 33025, 39193, 323, 2956, 26917, 883, 35936, 520, 48197, 40, 38614, 1174, 902, 1051, 3940, 555, 44069, 358, 13, 393, 10574, 1441, 8050, 31361, 70579, 304, 220, 3753, 24, 1174, 220, 2550, 16, 1174, 323, 220, 2550, 18, 1174, 323, 4073, 3105, 90405, 88, 329, 304, 220, 2550, 19, 662, 45206, 765, 90315, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1015", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) 1960(B-year) horror(B-genre) movies(O) with(O) zombies(B-plot)", "instance": {"id": "1015", "words": ["show", "me", "1960", "horror", "movies", "with", "zombies"], "labels": ["O", "O", "B-year", "B-genre", "I-genre", "O", "B-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, character, average ratings, director, song, title, genre, trailer, actor, year, review, rating and O.\nSentence: show me 1960 horror movies with zombies", "prompt_labels": "show(O) me(O) 1960(B-year) horror(B-genre) movies(I-genre) with(O) zombies(B-plot)"}, "label_list": ["plot", "character", "average ratings", "director", "song", "title", "genre", "trailer", "actor", "year", "review", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 3752, 11, 5578, 18594, 11, 7690, 11, 5609, 11, 2316, 11, 17779, 11, 19809, 11, 12360, 11, 1060, 11, 3477, 11, 10959, 323, 507, 627, 85664, 25, 1501, 757, 220, 5162, 15, 22169, 9698, 449, 48173, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1668", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) an(O) r(B-rating) rated(O) highly(B-average ratings) recommended(I-average ratings) political(B-genre) film(O) from(O) the(O) past(B-year) year(I-year)", "instance": {"id": "1668", "words": ["list", "an", "r", "rated", "highly", "recommended", "political", "film", "from", "the", "past", "year"], "labels": ["O", "O", "B-rating", "O", "B-average ratings", "I-average ratings", "B-genre", "O", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, character, genre, review, actor, trailer, plot, song, year, rating, director, title and O.\nSentence: list an r rated highly recommended political film from the past year", "prompt_labels": "list(O) an(O) r(B-rating) rated(O) highly(B-average ratings) recommended(I-average ratings) political(B-genre) film(O) from(O) the(O) past(B-year) year(I-year)"}, "label_list": ["average ratings", "character", "genre", "review", "actor", "trailer", "plot", "song", "year", "rating", "director", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 3752, 11, 17779, 11, 3477, 11, 12360, 11, 19809, 11, 7234, 11, 5609, 11, 1060, 11, 10959, 11, 7690, 11, 2316, 323, 507, 627, 85664, 25, 1160, 459, 436, 22359, 7701, 11349, 5054, 4632, 505, 279, 3347, 1060, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1230", "dataset": "mit-movie", "split": "dev", "prediction": "eddie(B-actor) cibrian(I-actor) starred(O) in(O) what(O) merit(B-title) badge(I-title) tale(I-title) that(O) people(O) found(O) ok(B-average ratings) made(O) in(O) the(O) past(B-year) four(I-year) years(I-year)", "instance": {"id": "1230", "words": ["eddie", "cibrian", "starred", "in", "what", "merit", "badge", "tale", "that", "people", "found", "ok", "made", "in", "the", "past", "four", "years"], "labels": ["B-actor", "I-actor", "O", "O", "O", "B-plot", "I-plot", "B-genre", "O", "O", "O", "B-average ratings", "O", "O", "O", "B-year", "I-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, trailer, rating, character, song, director, title, actor, average ratings, genre, review, year and O.\nSentence: eddie cibrian starred in what merit badge tale that people found ok made in the past four years", "prompt_labels": "eddie(B-actor) cibrian(I-actor) starred(O) in(O) what(O) merit(B-plot) badge(I-plot) tale(B-genre) that(O) people(O) found(O) ok(B-average ratings) made(O) in(O) the(O) past(B-year) four(I-year) years(I-year)"}, "label_list": ["plot", "trailer", "rating", "character", "song", "director", "title", "actor", "average ratings", "genre", "review", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 19809, 11, 10959, 11, 3752, 11, 5609, 11, 7690, 11, 2316, 11, 12360, 11, 5578, 18594, 11, 17779, 11, 3477, 11, 1060, 323, 507, 627, 85664, 25, 1608, 27591, 272, 581, 7414, 59335, 304, 1148, 38559, 24914, 24162, 430, 1274, 1766, 5509, 1903, 304, 279, 3347, 3116, 1667, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2302", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) directed(O) crimson(B-title) rivers(I-title) 2(I-title) angels(I-title) of(I-title) the(I-title) apocalypse(I-title)", "instance": {"id": "2302", "words": ["who", "directed", "crimson", "rivers", "2", "angels", "of", "the", "apocalypse"], "labels": ["O", "O", "B-title", "I-title", "I-title", "I-title", "I-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, song, rating, character, average ratings, year, director, trailer, review, plot, genre, actor and O.\nSentence: who directed crimson rivers 2 angels of the apocalypse", "prompt_labels": "who(O) directed(O) crimson(B-title) rivers(I-title) 2(I-title) angels(I-title) of(I-title) the(I-title) apocalypse(I-title)"}, "label_list": ["title", "song", "rating", "character", "average ratings", "year", "director", "trailer", "review", "plot", "genre", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 5609, 11, 10959, 11, 3752, 11, 5578, 18594, 11, 1060, 11, 7690, 11, 19809, 11, 3477, 11, 7234, 11, 17779, 11, 12360, 323, 507, 627, 85664, 25, 889, 15910, 97119, 36617, 220, 17, 46968, 315, 279, 88914, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "474", "dataset": "mit-restaurant", "split": "dev", "prediction": "hard(B-Restaurant Name) rock(I-Restaurant Name) hotel(I-Restaurant Name) restaurant(O) near(B-Location) me(I-Location)", "instance": {"id": "474", "words": ["hard", "rock", "hotel", "restaurant", "near", "me"], "labels": ["B-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Location, Dish, Rating, Cuisine, Price, Amenity, Restaurant Name and O.\nSentence: hard rock hotel restaurant near me", "prompt_labels": "hard(B-Restaurant Name) rock(I-Restaurant Name) hotel(I-Restaurant Name) restaurant(O) near(B-Location) me(I-Location)"}, "label_list": ["Hours", "Location", "Dish", "Rating", "Cuisine", "Price", "Amenity", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 10067, 11, 49268, 11, 19767, 11, 81961, 11, 8650, 11, 3383, 56685, 11, 26568, 4076, 323, 507, 627, 85664, 25, 2653, 7091, 9689, 10960, 3221, 757, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "374", "dataset": "crossner_music", "split": "dev", "prediction": "The(O) Hives(B-band) have(O) released(O) five(O) studio(O) albums(O) :(O) Barely(B-album) Legal(I-album) ((O) 1997(O) )(O),(O) Veni(B-album) Vidi(I-album) Vicious(I-album) ((O) 2000(O) )(O),(O) Tyrannosaurus(B-album) Hives(I-album) ((O) 2004(O) )(O),(O) The(B-album) Black(I-album) and(I-album) White(I-album) Album(I-album) ((O) 2007(O) )(O) and(O) Lex(B-album) Hives(I-album) ((O) 2012(O) )(O).(O)", "instance": {"id": "374", "words": ["The", "Hives", "have", "released", "five", "studio", "albums", ":", "Barely", "Legal", "(", "1997", ")", ",", "Veni", "Vidi", "Vicious", "(", "2000", ")", ",", "Tyrannosaurus", "Hives", "(", "2004", ")", ",", "The", "Black", "and", "White", "Album", "(", "2007", ")", "and", "Lex", "Hives", "(", "2012", ")", "."], "labels": ["B-band", "I-band", "O", "O", "O", "O", "O", "O", "B-album", "I-album", "O", "O", "O", "O", "B-album", "I-album", "I-album", "O", "O", "O", "O", "B-album", "I-album", "O", "O", "O", "O", "B-album", "I-album", "I-album", "I-album", "I-album", "O", "O", "O", "O", "B-album", "I-album", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, award, music genre, organization, musical artist, band, musical instrument, location, person, song, event, album and O.\nSentence: The Hives have released five studio albums : Barely Legal ( 1997 ) , Veni Vidi Vicious ( 2000 ) , Tyrannosaurus Hives ( 2004 ) , The Black and White Album ( 2007 ) and Lex Hives ( 2012 ) .", "prompt_labels": "The(B-band) Hives(I-band) have(O) released(O) five(O) studio(O) albums(O) :(O) Barely(B-album) Legal(I-album) ((O) 1997(O) )(O) ,(O) Veni(B-album) Vidi(I-album) Vicious(I-album) ((O) 2000(O) )(O) ,(O) Tyrannosaurus(B-album) Hives(I-album) ((O) 2004(O) )(O) ,(O) The(B-album) Black(I-album) and(I-album) White(I-album) Album(I-album) ((O) 2007(O) )(O) and(O) Lex(B-album) Hives(I-album) ((O) 2012(O) )(O) .(O)"}, "label_list": ["country", "award", "music genre", "organization", "musical artist", "band", "musical instrument", "location", "person", "song", "event", "album"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 10292, 11, 4731, 17779, 11, 7471, 11, 18273, 10255, 11, 7200, 11, 18273, 14473, 11, 3813, 11, 1732, 11, 5609, 11, 1567, 11, 8176, 323, 507, 627, 85664, 25, 578, 473, 1924, 617, 6004, 4330, 14356, 28785, 551, 61892, 398, 25705, 320, 220, 2550, 22, 883, 1174, 18732, 72, 650, 12558, 650, 9824, 320, 220, 1049, 15, 883, 1174, 50595, 1036, 437, 43613, 473, 1924, 320, 220, 1049, 19, 883, 1174, 578, 5348, 323, 5929, 26749, 320, 220, 1049, 22, 883, 323, 27917, 473, 1924, 320, 220, 679, 17, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "14", "dataset": "crossner_literature", "split": "dev", "prediction": "He(O) is(O) the(O) protagonist(O) of(O) Robert(B-writer) Coover(I-writer) '(O) s(O) short(O) story(O) Charlie(B-poem) in(O) the(O) House(O) of(O) Rue(O) ((O) 1980(O) ;O) reprinted(O) in(O) Coover(O) '(O) s(O) 1987(O) collection(O) A(B-poem) Night(I-poem) at(I-poem) the(I-poem) Movies(I-poem) )(O),(O) and(O) of(O) Glen(B-writer) David(I-writer) Gold(I-writer) '(O) s(O) Sunnyside(B-poem) ((O) 2009(O) )(O),(O) a(O) historical(O) novel(O) set(O) in(O) the(O) First(B-event) World(I-event) War(I-event) period(O).(O)", "instance": {"id": "14", "words": ["He", "is", "the", "protagonist", "of", "Robert", "Coover", "'", "s", "short", "story", "Charlie", "in", "the", "House", "of", "Rue", "(", "1980", ";", "reprinted", "in", "Coover", "'s", "1987", "collection", "A", "Night", "at", "the", "Movies", ")", ",", "and", "of", "Glen", "David", "Gold", "'", "s", "Sunnyside", "(", "2009", ")", ",", "a", "historical", "novel", "set", "in", "the", "First", "World", "War", "period", "."], "labels": ["O", "O", "O", "O", "O", "B-book", "I-book", "O", "O", "B-literary genre", "I-literary genre", "B-book", "I-book", "I-book", "I-book", "I-book", "I-book", "O", "O", "O", "O", "O", "B-writer", "O", "O", "O", "B-book", "I-book", "I-book", "I-book", "I-book", "O", "O", "O", "O", "B-writer", "I-writer", "I-writer", "O", "O", "B-book", "O", "O", "O", "O", "O", "B-literary genre", "I-literary genre", "O", "O", "O", "B-event", "I-event", "I-event", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, person, event, literary genre, award, book, poem, writer, country, location, magazine and O.\nSentence: He is the protagonist of Robert Coover ' s short story Charlie in the House of Rue ( 1980 ; reprinted in Coover 's 1987 collection A Night at the Movies ) , and of Glen David Gold ' s Sunnyside ( 2009 ) , a historical novel set in the First World War period .", "prompt_labels": "He(O) is(O) the(O) protagonist(O) of(O) Robert(B-book) Coover(I-book) '(O) s(O) short(B-literary genre) story(I-literary genre) Charlie(B-book) in(I-book) the(I-book) House(I-book) of(I-book) Rue(I-book) ((O) 1980(O) ;(O) reprinted(O) in(O) Coover(B-writer) 's(O) 1987(O) collection(O) A(B-book) Night(I-book) at(I-book) the(I-book) Movies(I-book) )(O) ,(O) and(O) of(O) Glen(B-writer) David(I-writer) Gold(I-writer) '(O) s(O) Sunnyside(B-book) ((O) 2009(O) )(O) ,(O) a(O) historical(B-literary genre) novel(I-literary genre) set(O) in(O) the(O) First(B-event) World(I-event) War(I-event) period(O) .(O)"}, "label_list": ["organization", "person", "event", "literary genre", "award", "book", "poem", "writer", "country", "location", "magazine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 1732, 11, 1567, 11, 32465, 17779, 11, 10292, 11, 2363, 11, 33894, 11, 7061, 11, 3224, 11, 3813, 11, 14756, 323, 507, 627, 85664, 25, 1283, 374, 279, 46684, 315, 8563, 3623, 2017, 364, 274, 2875, 3446, 25972, 304, 279, 4783, 315, 79151, 320, 220, 3753, 15, 2652, 312, 53313, 304, 3623, 2017, 364, 82, 220, 3753, 22, 4526, 362, 13120, 520, 279, 27019, 883, 1174, 323, 315, 41061, 6941, 7573, 364, 274, 8219, 77, 1065, 579, 320, 220, 1049, 24, 883, 1174, 264, 13970, 11775, 743, 304, 279, 5629, 4435, 5111, 4261, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "13", "dataset": "crossner_science", "split": "dev", "prediction": "In(O) addition(O) to(O) his(O) steady(O) research(O) output(O),(O) Naqvi(B-scientist) has(O) manifested(O) his(O) commitment(O) to(O) teaching(O) by(O) contributing(O) to(O) journals(O) devoted(O) to(O) didactical(O) aspects(O) of(O) science(O) ((O) American(B-academic journal) Journal(I-academic journal) of(I-academic journal) Physics(I-academic journal),(O) European(B-academic journal) Journal(I-academic journal) of(I-academic journal) Physics(I-academic journal),(O) Journal(B-academic journal) of(I-academic journal) Chemical(I-academic journal) Education(I-academic journal) )(O).(O)", "instance": {"id": "13", "words": ["In", "addition", "to", "his", "steady", "research", "output", ",", "Naqvi", "has", "manifested", "his", "commitment", "to", "teaching", "by", "contributing", "to", "journals", "devoted", "to", "didactical", "aspects", "of", "science", "(", "American", "Journal", "of", "Physics", ",", "European", "Journal", "of", "Physics", ",", "Journal", "of", "Chemical", "Education", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-scientist", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, chemical element, event, academic journal, country, scientist, location, protein, person, astronomical object, award, organization, discipline, chemical compound, enzyme, theory and O.\nSentence: In addition to his steady research output , Naqvi has manifested his commitment to teaching by contributing to journals devoted to didactical aspects of science ( American Journal of Physics , European Journal of Physics , Journal of Chemical Education ) .", "prompt_labels": "In(O) addition(O) to(O) his(O) steady(O) research(O) output(O) ,(O) Naqvi(B-scientist) has(O) manifested(O) his(O) commitment(O) to(O) teaching(O) by(O) contributing(O) to(O) journals(O) devoted(O) to(O) didactical(O) aspects(O) of(O) science(O) ((O) American(B-academic journal) Journal(I-academic journal) of(I-academic journal) Physics(I-academic journal) ,(O) European(B-academic journal) Journal(I-academic journal) of(I-academic journal) Physics(I-academic journal) ,(O) Journal(B-academic journal) of(I-academic journal) Chemical(I-academic journal) Education(I-academic journal) )(O) .(O)"}, "label_list": ["university", "chemical element", "event", "academic journal", "country", "scientist", "location", "protein", "person", "astronomical object", "award", "organization", "discipline", "chemical compound", "enzyme", "theory"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12374, 11, 11742, 2449, 11, 1567, 11, 14584, 8486, 11, 3224, 11, 28568, 11, 3813, 11, 13128, 11, 1732, 11, 87283, 1665, 11, 10292, 11, 7471, 11, 26434, 11, 11742, 24549, 11, 49242, 11, 10334, 323, 507, 627, 85664, 25, 763, 5369, 311, 813, 24981, 3495, 2612, 1174, 13106, 80, 10176, 706, 79754, 813, 15507, 311, 12917, 555, 29820, 311, 42780, 29329, 311, 1550, 37119, 13878, 315, 8198, 320, 3778, 10139, 315, 28415, 1174, 7665, 10139, 315, 28415, 1174, 10139, 315, 36424, 11930, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "842", "dataset": "mit-movie", "split": "dev", "prediction": "find(O) me(O) a(O) film(O) with(O) the(O) song(O) under(B-title) the(I-title) sea(I-title)", "instance": {"id": "842", "words": ["find", "me", "a", "film", "with", "the", "song", "under", "the", "sea"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-song", "I-song", "I-song"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, director, plot, trailer, genre, year, rating, average ratings, song, title, review, character and O.\nSentence: find me a film with the song under the sea", "prompt_labels": "find(O) me(O) a(O) film(O) with(O) the(O) song(O) under(B-song) the(I-song) sea(I-song)"}, "label_list": ["actor", "director", "plot", "trailer", "genre", "year", "rating", "average ratings", "song", "title", "review", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 7690, 11, 7234, 11, 19809, 11, 17779, 11, 1060, 11, 10959, 11, 5578, 18594, 11, 5609, 11, 2316, 11, 3477, 11, 3752, 323, 507, 627, 85664, 25, 1505, 757, 264, 4632, 449, 279, 5609, 1234, 279, 9581, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1092", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) are(O) some(O) of(O) the(O) locally(B-Rating) favourite(I-Rating) restaurants(O)", "instance": {"id": "1092", "words": ["what", "are", "some", "of", "the", "locally", "favourite", "restaurants"], "labels": ["O", "O", "O", "O", "O", "B-Location", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Hours, Restaurant Name, Location, Rating, Amenity, Dish, Price and O.\nSentence: what are some of the locally favourite restaurants", "prompt_labels": "what(O) are(O) some(O) of(O) the(O) locally(B-Location) favourite(O) restaurants(O)"}, "label_list": ["Cuisine", "Hours", "Restaurant Name", "Location", "Rating", "Amenity", "Dish", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 30192, 11, 26568, 4076, 11, 10067, 11, 19767, 11, 3383, 56685, 11, 49268, 11, 8650, 323, 507, 627, 85664, 25, 1148, 527, 1063, 315, 279, 24392, 19214, 15926, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "127", "dataset": "crossner_ai", "split": "dev", "prediction": "Artificial(B-product) intelligence(I-product) has(O) retained(O) the(O) most(O) attention(O) regarding(O) applied(O) ontology(O) in(O) subfields(O) like(O) natural(B-field) language(I-field) processing(I-field) within(O) machine(B-field) and(O) knowledge(B-field) representation(I-field),(O) but(O) ontology(O) editors(O) are(O) being(O) used(O) often(O) in(O) a(O) range(O) of(O) fields(O) like(O) education(B-field) without(O) the(O) intent(O) to(O) contribute(O) to(O) AI(B-field).(O)", "instance": {"id": "127", "words": ["Artificial", "intelligence", "has", "retained", "the", "most", "attention", "regarding", "applied", "ontology", "in", "subfields", "like", "natural", "language", "processing", "within", "machine", "and", "knowledge", "representation", ",", "but", "ontology", "editors", "are", "being", "used", "often", "in", "a", "range", "of", "fields", "like", "education", "without", "the", "intent", "to", "contribute", "to", "AI", "."], "labels": ["B-field", "I-field", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-field", "I-field", "I-field", "O", "B-task", "O", "B-task", "I-task", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-field", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, university, programming language, conference, person, organization, country, algorithm, location, metric, researcher, product, task and O.\nSentence: Artificial intelligence has retained the most attention regarding applied ontology in subfields like natural language processing within machine and knowledge representation , but ontology editors are being used often in a range of fields like education without the intent to contribute to AI .", "prompt_labels": "Artificial(B-field) intelligence(I-field) has(O) retained(O) the(O) most(O) attention(O) regarding(O) applied(O) ontology(O) in(O) subfields(O) like(O) natural(B-field) language(I-field) processing(I-field) within(O) machine(B-task) and(O) knowledge(B-task) representation(I-task) ,(O) but(O) ontology(O) editors(O) are(O) being(O) used(O) often(O) in(O) a(O) range(O) of(O) fields(O) like(O) education(O) without(O) the(O) intent(O) to(O) contribute(O) to(O) AI(B-field) .(O)"}, "label_list": ["field", "university", "programming language", "conference", "person", "organization", "country", "algorithm", "location", "metric", "researcher", "product", "task"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2115, 11, 12374, 11, 15840, 4221, 11, 10017, 11, 1732, 11, 7471, 11, 3224, 11, 12384, 11, 3813, 11, 18767, 11, 32185, 11, 2027, 11, 3465, 323, 507, 627, 85664, 25, 59294, 11478, 706, 35363, 279, 1455, 6666, 9002, 9435, 84369, 304, 1207, 9184, 1093, 5933, 4221, 8863, 2949, 5780, 323, 6677, 13340, 1174, 719, 84369, 29846, 527, 1694, 1511, 3629, 304, 264, 2134, 315, 5151, 1093, 6873, 2085, 279, 7537, 311, 17210, 311, 15592, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2260", "dataset": "mit-movie", "split": "dev", "prediction": "when(O) did(O) alpha(B-title) and(I-title) omega(I-title) come(O) out(O)", "instance": {"id": "2260", "words": ["when", "did", "alpha", "and", "omega", "come", "out"], "labels": ["O", "O", "B-title", "I-title", "I-title", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, actor, song, trailer, year, director, genre, rating, average ratings, review, plot, character and O.\nSentence: when did alpha and omega come out", "prompt_labels": "when(O) did(O) alpha(B-title) and(I-title) omega(I-title) come(O) out(O)"}, "label_list": ["title", "actor", "song", "trailer", "year", "director", "genre", "rating", "average ratings", "review", "plot", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 12360, 11, 5609, 11, 19809, 11, 1060, 11, 7690, 11, 17779, 11, 10959, 11, 5578, 18594, 11, 3477, 11, 7234, 11, 3752, 323, 507, 627, 85664, 25, 994, 1550, 8451, 323, 34998, 2586, 704, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "167", "dataset": "crossner_ai", "split": "dev", "prediction": "During(O) his(O) time(O) at(O) Duke(B-university),(O) he(O) worked(O) on(O) an(O) automated(O) crossword(O) solver(O) PROVERB(O),(O) which(O) won(O) an(O) Outstanding(B-metric) Paper(I-metric) Award(I-metric) in(O) 1999(O) from(O) AAAI(B-conference) and(O) competed(O) in(O) the(O) American(B-conference) Crossword(I-conference) Puzzle(I-conference) Tournament(I-conference).(O)", "instance": {"id": "167", "words": ["During", "his", "time", "at", "Duke", ",", "he", "worked", "on", "an", "automated", "crossword", "solver", "PROVERB", ",", "which", "won", "an", "Outstanding", "Paper", "Award", "in", "1999", "from", "AAAI", "and", "competed", "in", "the", "American", "Crossword", "Puzzle", "Tournament", "."], "labels": ["O", "O", "O", "O", "B-university", "O", "O", "O", "O", "O", "O", "O", "O", "B-product", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-conference", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, product, field, university, metric, task, country, algorithm, location, organization, programming language, person, researcher and O.\nSentence: During his time at Duke , he worked on an automated crossword solver PROVERB , which won an Outstanding Paper Award in 1999 from AAAI and competed in the American Crossword Puzzle Tournament .", "prompt_labels": "During(O) his(O) time(O) at(O) Duke(B-university) ,(O) he(O) worked(O) on(O) an(O) automated(O) crossword(O) solver(O) PROVERB(B-product) ,(O) which(O) won(O) an(O) Outstanding(O) Paper(O) Award(O) in(O) 1999(O) from(O) AAAI(B-conference) and(O) competed(O) in(O) the(O) American(O) Crossword(O) Puzzle(O) Tournament(O) .(O)"}, "label_list": ["conference", "product", "field", "university", "metric", "task", "country", "algorithm", "location", "organization", "programming language", "person", "researcher"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10017, 11, 2027, 11, 2115, 11, 12374, 11, 18767, 11, 3465, 11, 3224, 11, 12384, 11, 3813, 11, 7471, 11, 15840, 4221, 11, 1732, 11, 32185, 323, 507, 627, 85664, 25, 12220, 813, 892, 520, 27453, 1174, 568, 6575, 389, 459, 28598, 92496, 30061, 5421, 3848, 33, 1174, 902, 2834, 459, 76441, 18343, 17768, 304, 220, 2550, 24, 505, 48197, 40, 323, 67235, 304, 279, 3778, 11511, 1178, 61112, 18877, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "385", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) a(O) trailer(B-trailer) for(O) an(O) alec(B-actor) guiness(I-actor) flick(O)", "instance": {"id": "385", "words": ["show", "me", "a", "trailer", "for", "an", "alec", "guiness", "flick"], "labels": ["O", "O", "O", "B-trailer", "O", "O", "B-actor", "I-actor", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, plot, character, year, average ratings, title, review, trailer, actor, director, song, rating and O.\nSentence: show me a trailer for an alec guiness flick", "prompt_labels": "show(O) me(O) a(O) trailer(B-trailer) for(O) an(O) alec(B-actor) guiness(I-actor) flick(O)"}, "label_list": ["genre", "plot", "character", "year", "average ratings", "title", "review", "trailer", "actor", "director", "song", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 7234, 11, 3752, 11, 1060, 11, 5578, 18594, 11, 2316, 11, 3477, 11, 19809, 11, 12360, 11, 7690, 11, 5609, 11, 10959, 323, 507, 627, 85664, 25, 1501, 757, 264, 19809, 369, 459, 22180, 66, 1709, 1918, 29447, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1", "dataset": "crossner_music", "split": "dev", "prediction": "Squarepusher(B-musical artist) continues(O) to(O) push(O) new(O) boundaries(O) to(O) this(O) day(O),(O) where(O) he(O) still(O) calls(O) Warp(B-organization) Records(I-organization) his(O) home(O),(O) having(O) released(O) numerous(O) albums(O) to(O) critical(O) acclaim(O) in(O) the(O) years(O) to(O) follow(O),(O) such(O) as(O) Go(B-album) Plastic(I-album),(O) Do(B-album) You(I-album) Know(I-album) Squarepusher(I-album),(O) Ultravisitor(B-album),(O) Hello(B-album) Everything(I-album),(O) Just(O) a(O) Souvenir(O),(O) Solo(B-album) Electric(I-album) Bass(I-album) 1(I-album),(O) Ufabulum(B-album) and(O) Damogen(B-album) Furies(I-album).(O)", "instance": {"id": "1", "words": ["Squarepusher", "continues", "to", "push", "new", "boundaries", "to", "this", "day", ",", "where", "he", "still", "calls", "Warp", "Records", "his", "home", ",", "having", "released", "numerous", "albums", "to", "critical", "acclaim", "in", "the", "years", "to", "follow", ",", "such", "as", "Go", "Plastic", ",", "Do", "You", "Know", "Squarepusher", ",", "Ultravisitor", ",", "Hello", "Everything", ",", "Just", "a", "Souvenir", ",", "Solo", "Electric", "Bass", "1", ",", "Ufabulum", "and", "Damogen", "Furies", "."], "labels": ["B-musical artist", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-album", "I-album", "O", "B-album", "I-album", "I-album", "I-album", "O", "B-album", "O", "B-album", "I-album", "O", "B-album", "I-album", "I-album", "O", "B-album", "I-album", "I-album", "I-album", "O", "B-album", "O", "B-album", "I-album", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, music genre, award, musical instrument, event, musical artist, organization, song, band, person, album, country and O.\nSentence: Squarepusher continues to push new boundaries to this day , where he still calls Warp Records his home , having released numerous albums to critical acclaim in the years to follow , such as Go Plastic , Do You Know Squarepusher , Ultravisitor , Hello Everything , Just a Souvenir , Solo Electric Bass 1 , Ufabulum and Damogen Furies .", "prompt_labels": "Squarepusher(B-musical artist) continues(O) to(O) push(O) new(O) boundaries(O) to(O) this(O) day(O) ,(O) where(O) he(O) still(O) calls(O) Warp(B-organization) Records(I-organization) his(O) home(O) ,(O) having(O) released(O) numerous(O) albums(O) to(O) critical(O) acclaim(O) in(O) the(O) years(O) to(O) follow(O) ,(O) such(O) as(O) Go(B-album) Plastic(I-album) ,(O) Do(B-album) You(I-album) Know(I-album) Squarepusher(I-album) ,(O) Ultravisitor(B-album) ,(O) Hello(B-album) Everything(I-album) ,(O) Just(B-album) a(I-album) Souvenir(I-album) ,(O) Solo(B-album) Electric(I-album) Bass(I-album) 1(I-album) ,(O) Ufabulum(B-album) and(O) Damogen(B-album) Furies(I-album) .(O)"}, "label_list": ["location", "music genre", "award", "musical instrument", "event", "musical artist", "organization", "song", "band", "person", "album", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 4731, 17779, 11, 10292, 11, 18273, 14473, 11, 1567, 11, 18273, 10255, 11, 7471, 11, 5609, 11, 7200, 11, 1732, 11, 8176, 11, 3224, 323, 507, 627, 85664, 25, 15992, 9254, 261, 9731, 311, 4585, 502, 23546, 311, 420, 1938, 1174, 1405, 568, 2103, 6880, 78910, 22293, 813, 2162, 1174, 3515, 6004, 12387, 28785, 311, 9200, 97963, 304, 279, 1667, 311, 1833, 1174, 1778, 439, 6122, 37108, 1174, 3234, 1472, 14521, 15992, 9254, 261, 1174, 67957, 23156, 1960, 1174, 22691, 20696, 1174, 4702, 264, 9424, 43406, 1174, 36223, 21246, 37053, 220, 16, 1174, 549, 37955, 16903, 323, 16758, 11968, 435, 10612, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "434", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movies(O) has(O) ellen(B-actor) page(I-actor) been(O) in(O)", "instance": {"id": "434", "words": ["what", "movies", "has", "ellen", "page", "been", "in"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, title, genre, rating, actor, song, plot, trailer, character, year, review, director and O.\nSentence: what movies has ellen page been in", "prompt_labels": "what(O) movies(O) has(O) ellen(B-actor) page(I-actor) been(O) in(O)"}, "label_list": ["average ratings", "title", "genre", "rating", "actor", "song", "plot", "trailer", "character", "year", "review", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 2316, 11, 17779, 11, 10959, 11, 12360, 11, 5609, 11, 7234, 11, 19809, 11, 3752, 11, 1060, 11, 3477, 11, 7690, 323, 507, 627, 85664, 25, 1148, 9698, 706, 220, 16046, 2199, 1027, 304, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "109", "dataset": "crossner_science", "split": "dev", "prediction": "He(O) has(O) received(O) Academy(B-award) Awards(I-award),(O) Grammy(B-award) Award(I-award),(O) and(O) Golden(B-award) Globe(I-award) Award(I-award) s(I-award),(O) and(O) he(O) is(O) an(O) inductee(O) to(O) the(O) Rock(B-organization) and(I-organization) Roll(I-organization) Hall(I-organization) of(I-organization) Fame(I-organization).(O)", "instance": {"id": "109", "words": ["He", "has", "received", "Academy", "Awards", ",", "Grammy", "Award", ",", "and", "Golden", "Globe", "Award", "s", ",", "and", "he", "is", "an", "inductee", "to", "the", "Rock", "and", "Roll", "Hall", "of", "Fame", "."], "labels": ["O", "O", "O", "B-award", "I-award", "O", "B-award", "I-award", "O", "O", "B-award", "I-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, award, protein, location, theory, enzyme, chemical compound, chemical element, country, astronomical object, person, university, academic journal, organization, scientist, discipline and O.\nSentence: He has received Academy Awards , Grammy Award , and Golden Globe Award s , and he is an inductee to the Rock and Roll Hall of Fame .", "prompt_labels": "He(O) has(O) received(O) Academy(B-award) Awards(I-award) ,(O) Grammy(B-award) Award(I-award) ,(O) and(O) Golden(B-award) Globe(I-award) Award(I-award) s(O) ,(O) and(O) he(O) is(O) an(O) inductee(O) to(O) the(O) Rock(B-organization) and(I-organization) Roll(I-organization) Hall(I-organization) of(I-organization) Fame(I-organization) .(O)"}, "label_list": ["event", "award", "protein", "location", "theory", "enzyme", "chemical compound", "chemical element", "country", "astronomical object", "person", "university", "academic journal", "organization", "scientist", "discipline"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 10292, 11, 13128, 11, 3813, 11, 10334, 11, 49242, 11, 11742, 24549, 11, 11742, 2449, 11, 3224, 11, 87283, 1665, 11, 1732, 11, 12374, 11, 14584, 8486, 11, 7471, 11, 28568, 11, 26434, 323, 507, 627, 85664, 25, 1283, 706, 4036, 16192, 23488, 1174, 74679, 17768, 1174, 323, 18288, 41910, 17768, 274, 1174, 323, 568, 374, 459, 304, 1076, 2176, 311, 279, 9305, 323, 15028, 11166, 315, 39627, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "244", "dataset": "mit-movie", "split": "dev", "prediction": "when(O) did(O) the(O) game(O) come(O) out(O)", "instance": {"id": "244", "words": ["when", "did", "the", "game", "come", "out"], "labels": ["O", "O", "B-title", "I-title", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, actor, trailer, genre, rating, year, character, average ratings, song, title, director, review and O.\nSentence: when did the game come out", "prompt_labels": "when(O) did(O) the(B-title) game(I-title) come(O) out(O)"}, "label_list": ["plot", "actor", "trailer", "genre", "rating", "year", "character", "average ratings", "song", "title", "director", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 12360, 11, 19809, 11, 17779, 11, 10959, 11, 1060, 11, 3752, 11, 5578, 18594, 11, 5609, 11, 2316, 11, 7690, 11, 3477, 323, 507, 627, 85664, 25, 994, 1550, 279, 1847, 2586, 704, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "155", "dataset": "crossner_music", "split": "dev", "prediction": "It(O) also(O) produced(O) the(O) Top(O) 5(O) single(O) Rage(B-song) Hard(I-song) ((O) #(O) 1(O) in(O) Germany(B-country) )(O),(O) Top(O) 20(O) single(O) Warriors(B-song) of(I-song) the(I-song) Wasteland(I-song) and(O) Top(O) 30(O) single(O) Watching(B-song) the(I-song) Wildlife(I-song).(O)", "instance": {"id": "155", "words": ["It", "also", "produced", "the", "Top", "5", "single", "Rage", "Hard", "(", "#", "1", "in", "Germany", ")", ",", "Top", "20", "single", "Warriors", "of", "the", "Wasteland", "and", "Top", "30", "single", "Watching", "the", "Wildlife", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-song", "I-song", "O", "O", "O", "O", "B-country", "O", "O", "O", "O", "O", "B-song", "I-song", "I-song", "I-song", "O", "O", "O", "O", "B-song", "I-song", "I-song", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, musical artist, person, song, music genre, organization, location, album, musical instrument, event, award, band and O.\nSentence: It also produced the Top 5 single Rage Hard ( # 1 in Germany ) , Top 20 single Warriors of the Wasteland and Top 30 single Watching the Wildlife .", "prompt_labels": "It(O) also(O) produced(O) the(O) Top(O) 5(O) single(O) Rage(B-song) Hard(I-song) ((O) #(O) 1(O) in(O) Germany(B-country) )(O) ,(O) Top(O) 20(O) single(O) Warriors(B-song) of(I-song) the(I-song) Wasteland(I-song) and(O) Top(O) 30(O) single(O) Watching(B-song) the(I-song) Wildlife(I-song) .(O)"}, "label_list": ["country", "musical artist", "person", "song", "music genre", "organization", "location", "album", "musical instrument", "event", "award", "band"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 18273, 10255, 11, 1732, 11, 5609, 11, 4731, 17779, 11, 7471, 11, 3813, 11, 8176, 11, 18273, 14473, 11, 1567, 11, 10292, 11, 7200, 323, 507, 627, 85664, 25, 1102, 1101, 9124, 279, 7054, 220, 20, 3254, 66567, 11481, 320, 674, 220, 16, 304, 10057, 883, 1174, 7054, 220, 508, 3254, 32987, 315, 279, 468, 561, 18615, 323, 7054, 220, 966, 3254, 69676, 279, 42649, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "429", "dataset": "crossner_politics", "split": "dev", "prediction": "The(B-title) Front(I-title) Runner(I-title) is(O) a(O) 2018(B-year) American(I-year) political(I-year) drama(I-year) film(O) directed(O) by(O) Jason(B-director) Reitman(I-director),(O) based(O) on(O) the(O) 2014(O) book(O) All(B-title) the(I-title) Truth(I-title) Is(I-title) Out(I-title) :(O) The(O) Week(O) Politics(O) Went(O) Tabloid(O) by(O) Matt(B-politician) Bai(I-politician),(O) who(O) co-wrote(O) the(O) screenplay(O) with(O) Reitman(B-director) and(O) Jay(B-politician) Carson(I-politician).(O)", "instance": {"id": "429", "words": ["The", "Front", "Runner", "is", "a", "2018", "American", "political", "drama", "film", "directed", "by", "Jason", "Reitman", ",", "based", "on", "the", "2014", "book", "All", "the", "Truth", "Is", "Out", ":", "The", "Week", "Politics", "Went", "Tabloid", "by", "Matt", "Bai", ",", "who", "co-wrote", "the", "screenplay", "with", "Reitman", "and", "Jay", "Carson", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "O", "O", "O", "O", "O", "B-person", "O", "B-person", "I-person", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, organization, event, politician, country, person, location, political party and O.\nSentence: The Front Runner is a 2018 American political drama film directed by Jason Reitman , based on the 2014 book All the Truth Is Out : The Week Politics Went Tabloid by Matt Bai , who co-wrote the screenplay with Reitman and Jay Carson .", "prompt_labels": "The(O) Front(O) Runner(O) is(O) a(O) 2018(O) American(O) political(O) drama(O) film(O) directed(O) by(O) Jason(B-person) Reitman(I-person) ,(O) based(O) on(O) the(O) 2014(O) book(O) All(O) the(O) Truth(O) Is(O) Out(O) :(O) The(O) Week(O) Politics(O) Went(O) Tabloid(O) by(O) Matt(B-person) Bai(I-person) ,(O) who(O) co-wrote(O) the(O) screenplay(O) with(O) Reitman(B-person) and(O) Jay(B-person) Carson(I-person) .(O)"}, "label_list": ["election", "organization", "event", "politician", "country", "person", "location", "political party"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 6355, 11, 7471, 11, 1567, 11, 37038, 11, 3224, 11, 1732, 11, 3813, 11, 5054, 4717, 323, 507, 627, 85664, 25, 578, 15248, 46046, 374, 264, 220, 679, 23, 3778, 5054, 20156, 4632, 15910, 555, 18984, 1050, 275, 1543, 1174, 3196, 389, 279, 220, 679, 19, 2363, 2052, 279, 30198, 2209, 4470, 551, 578, 10563, 35979, 54859, 15490, 52196, 555, 13678, 86008, 1174, 889, 1080, 2695, 5646, 279, 85875, 449, 1050, 275, 1543, 323, 19455, 41276, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2188", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) short(B-genre) films(O) by(O) bob(B-director) gray(I-director) received(O) excellent(B-average ratings) ratings(I-average ratings)", "instance": {"id": "2188", "words": ["what", "short", "films", "by", "bob", "gray", "received", "excellent", "ratings"], "labels": ["O", "B-genre", "O", "O", "B-director", "I-director", "O", "B-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, average ratings, genre, rating, plot, review, title, year, director, character, song, trailer and O.\nSentence: what short films by bob gray received excellent ratings", "prompt_labels": "what(O) short(B-genre) films(O) by(O) bob(B-director) gray(I-director) received(O) excellent(B-average ratings) ratings(I-average ratings)"}, "label_list": ["actor", "average ratings", "genre", "rating", "plot", "review", "title", "year", "director", "character", "song", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 5578, 18594, 11, 17779, 11, 10959, 11, 7234, 11, 3477, 11, 2316, 11, 1060, 11, 7690, 11, 3752, 11, 5609, 11, 19809, 323, 507, 627, 85664, 25, 1148, 2875, 12631, 555, 36292, 18004, 4036, 9250, 18594, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1919", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) are(O) some(O) titles(O) of(O) crime(B-genre) films(O) from(O) the(O) 1950(B-year) s(I-year)", "instance": {"id": "1919", "words": ["what", "are", "some", "titles", "of", "crime", "films", "from", "the", "1950", "s"], "labels": ["O", "O", "O", "O", "O", "B-genre", "O", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, director, plot, average ratings, trailer, title, year, rating, review, character, actor, song and O.\nSentence: what are some titles of crime films from the 1950 s", "prompt_labels": "what(O) are(O) some(O) titles(O) of(O) crime(B-genre) films(O) from(O) the(O) 1950(B-year) s(I-year)"}, "label_list": ["genre", "director", "plot", "average ratings", "trailer", "title", "year", "rating", "review", "character", "actor", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 7690, 11, 7234, 11, 5578, 18594, 11, 19809, 11, 2316, 11, 1060, 11, 10959, 11, 3477, 11, 3752, 11, 12360, 11, 5609, 323, 507, 627, 85664, 25, 1148, 527, 1063, 15671, 315, 9977, 12631, 505, 279, 220, 6280, 15, 274, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "261", "dataset": "crossner_politics", "split": "dev", "prediction": "Since(O) 2008(O) it(O) was(O) part(O) of(O) the(O) Sammarinese(O) Union(O) of(O) Moderates(O) together(O) with(O) Sammarinese(B-political party) Populars(I-political party) and(O) stood(O) in(O) opposition(O) to(O) the(O) 2006-2008(O) coalition(O) government(O) consisting(O) of(O) the(O) Party(O) of(O) Socialists(O) and(O) Democrats(O),(O) the(O) Popular(O) Alliance(O) and(O) the(O) United(B-political party) Left(I-political party).(O)", "instance": {"id": "261", "words": ["Since", "2008", "it", "was", "part", "of", "the", "Sammarinese", "Union", "of", "Moderates", "together", "with", "Sammarinese", "Populars", "and", "stood", "in", "opposition", "to", "the", "2006-2008", "coalition", "government", "consisting", "of", "the", "Party", "of", "Socialists", "and", "Democrats", ",", "the", "Popular", "Alliance", "and", "the", "United", "Left", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "O", "O", "B-organization", "I-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, political party, organization, location, event, politician, election, person and O.\nSentence: Since 2008 it was part of the Sammarinese Union of Moderates together with Sammarinese Populars and stood in opposition to the 2006-2008 coalition government consisting of the Party of Socialists and Democrats , the Popular Alliance and the United Left .", "prompt_labels": "Since(O) 2008(O) it(O) was(O) part(O) of(O) the(O) Sammarinese(B-political party) Union(I-political party) of(I-political party) Moderates(I-political party) together(O) with(O) Sammarinese(B-political party) Populars(I-political party) and(O) stood(O) in(O) opposition(O) to(O) the(O) 2006-2008(O) coalition(O) government(O) consisting(O) of(O) the(O) Party(B-political party) of(I-political party) Socialists(I-political party) and(I-political party) Democrats(I-political party) ,(O) the(O) Popular(B-political party) Alliance(I-political party) and(O) the(O) United(B-organization) Left(I-organization) .(O)"}, "label_list": ["country", "political party", "organization", "location", "event", "politician", "election", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 5054, 4717, 11, 7471, 11, 3813, 11, 1567, 11, 37038, 11, 6355, 11, 1732, 323, 507, 627, 85664, 25, 8876, 220, 1049, 23, 433, 574, 961, 315, 279, 8388, 5730, 7496, 9323, 315, 44527, 988, 3871, 449, 8388, 5730, 7496, 32495, 82, 323, 14980, 304, 14076, 311, 279, 220, 1049, 21, 12, 1049, 23, 26283, 3109, 31706, 315, 279, 8722, 315, 9983, 1705, 323, 12643, 1174, 279, 32495, 23590, 323, 279, 3723, 14043, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1205", "dataset": "mit-movie", "split": "dev", "prediction": "do(O) you(O) have(O) the(O) pg(B-rating) 13(I-rating) movie(O) from(O) 1970(B-year) about(O) a(O) road(B-plot) trip(I-plot) directed(O) by(O) karen(B-director) harley(I-director) thats(O) good(O) for(O) a(O) laugh(B-genre)", "instance": {"id": "1205", "words": ["do", "you", "have", "the", "pg", "13", "movie", "from", "1970", "about", "a", "road", "trip", "directed", "by", "karen", "harley", "thats", "good", "for", "a", "laugh"], "labels": ["O", "O", "O", "O", "B-rating", "I-rating", "O", "O", "B-year", "O", "O", "B-plot", "I-plot", "O", "O", "B-director", "I-director", "O", "O", "O", "O", "B-genre"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, review, plot, director, actor, rating, song, character, title, average ratings, year, genre and O.\nSentence: do you have the pg 13 movie from 1970 about a road trip directed by karen harley thats good for a laugh", "prompt_labels": "do(O) you(O) have(O) the(O) pg(B-rating) 13(I-rating) movie(O) from(O) 1970(B-year) about(O) a(O) road(B-plot) trip(I-plot) directed(O) by(O) karen(B-director) harley(I-director) thats(O) good(O) for(O) a(O) laugh(B-genre)"}, "label_list": ["trailer", "review", "plot", "director", "actor", "rating", "song", "character", "title", "average ratings", "year", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 3477, 11, 7234, 11, 7690, 11, 12360, 11, 10959, 11, 5609, 11, 3752, 11, 2316, 11, 5578, 18594, 11, 1060, 11, 17779, 323, 507, 627, 85664, 25, 656, 499, 617, 279, 17953, 220, 1032, 5818, 505, 220, 4468, 15, 922, 264, 5754, 8577, 15910, 555, 597, 9329, 4960, 3258, 41136, 1695, 369, 264, 12835, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1074", "dataset": "mit-movie", "split": "dev", "prediction": "any(O) highly(B-average ratings) recommended(I-average ratings) movies(O) for(O) the(O) 1980(B-year) s(I-year) about(O) military(B-genre) guerrilla(B-plot) warfare(I-plot)", "instance": {"id": "1074", "words": ["any", "highly", "recommended", "movies", "for", "the", "1980", "s", "about", "military", "guerrilla", "warfare"], "labels": ["O", "B-average ratings", "I-average ratings", "O", "O", "O", "B-year", "I-year", "O", "B-genre", "B-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, song, plot, year, title, review, character, director, genre, average ratings, actor, rating and O.\nSentence: any highly recommended movies for the 1980 s about military guerrilla warfare", "prompt_labels": "any(O) highly(B-average ratings) recommended(I-average ratings) movies(O) for(O) the(O) 1980(B-year) s(I-year) about(O) military(B-genre) guerrilla(B-plot) warfare(I-plot)"}, "label_list": ["trailer", "song", "plot", "year", "title", "review", "character", "director", "genre", "average ratings", "actor", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 5609, 11, 7234, 11, 1060, 11, 2316, 11, 3477, 11, 3752, 11, 7690, 11, 17779, 11, 5578, 18594, 11, 12360, 11, 10959, 323, 507, 627, 85664, 25, 904, 7701, 11349, 9698, 369, 279, 220, 3753, 15, 274, 922, 6411, 76270, 6374, 39307, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1488", "dataset": "mit-restaurant", "split": "dev", "prediction": "which(O) places(O) serve(O) large(B-Amenity) portions(I-Amenity)", "instance": {"id": "1488", "words": ["which", "places", "serve", "large", "portions"], "labels": ["O", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Hours, Restaurant Name, Amenity, Cuisine, Dish, Price, Location and O.\nSentence: which places serve large portions", "prompt_labels": "which(O) places(O) serve(O) large(B-Amenity) portions(I-Amenity)"}, "label_list": ["Rating", "Hours", "Restaurant Name", "Amenity", "Cuisine", "Dish", "Price", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 30192, 11, 26568, 4076, 11, 3383, 56685, 11, 81961, 11, 49268, 11, 8650, 11, 10067, 323, 507, 627, 85664, 25, 902, 7634, 8854, 3544, 19885, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "364", "dataset": "crossner_science", "split": "dev", "prediction": "Max(B-scientist) Volmer(I-scientist) and(O) Robert(B-scientist) D\u00f6pel(I-scientist) were(O) assigned(O) to(O) this(O) facility(O).(O)", "instance": {"id": "364", "words": ["Max", "Volmer", "and", "Robert", "D\u00f6pel", "were", "assigned", "to", "this", "facility", "."], "labels": ["B-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, enzyme, person, event, university, chemical compound, chemical element, academic journal, theory, discipline, award, country, protein, scientist, astronomical object, location and O.\nSentence: Max Volmer and Robert D\u00f6pel were assigned to this facility .", "prompt_labels": "Max(B-scientist) Volmer(I-scientist) and(O) Robert(B-scientist) D\u00f6pel(I-scientist) were(O) assigned(O) to(O) this(O) facility(O) .(O)"}, "label_list": ["organization", "enzyme", "person", "event", "university", "chemical compound", "chemical element", "academic journal", "theory", "discipline", "award", "country", "protein", "scientist", "astronomical object", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 49242, 11, 1732, 11, 1567, 11, 12374, 11, 11742, 24549, 11, 11742, 2449, 11, 14584, 8486, 11, 10334, 11, 26434, 11, 10292, 11, 3224, 11, 13128, 11, 28568, 11, 87283, 1665, 11, 3813, 323, 507, 627, 85664, 25, 7639, 11119, 1195, 323, 8563, 423, 3029, 48624, 1051, 12893, 311, 420, 12764, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2268", "dataset": "mit-movie", "split": "dev", "prediction": "when(O) is(O) a(O) good(O) romantic(B-genre) comedy(I-genre) based(O) on(O) a(O) book(O) coming(O) out(O)", "instance": {"id": "2268", "words": ["when", "is", "a", "good", "romantic", "comedy", "based", "on", "a", "book", "coming", "out"], "labels": ["O", "O", "O", "O", "B-genre", "I-genre", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, director, plot, average ratings, actor, character, year, rating, genre, review, song, title and O.\nSentence: when is a good romantic comedy based on a book coming out", "prompt_labels": "when(O) is(O) a(O) good(O) romantic(B-genre) comedy(I-genre) based(O) on(O) a(O) book(O) coming(O) out(O)"}, "label_list": ["trailer", "director", "plot", "average ratings", "actor", "character", "year", "rating", "genre", "review", "song", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 7690, 11, 7234, 11, 5578, 18594, 11, 12360, 11, 3752, 11, 1060, 11, 10959, 11, 17779, 11, 3477, 11, 5609, 11, 2316, 323, 507, 627, 85664, 25, 994, 374, 264, 1695, 24364, 23160, 3196, 389, 264, 2363, 5108, 704, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "230", "dataset": "crossner_ai", "split": "dev", "prediction": "At(O) UCSD(B-university),(O) Norman(B-researcher) was(O) a(O) founder(O) of(O) the(O) Institute(B-organization) for(I-organization) Cognitive(I-organization) Science(I-organization) and(O) one(O) of(O) the(O) organizers(O) of(O) the(O) Cognitive(B-conference) Science(I-conference) Society(I-conference) ((O) along(O) with(O) Roger(B-researcher) Schank(I-researcher),(O) Allan(B-researcher) M.(I-researcher) Collins(I-researcher),(O) and(O) others(O) )(O),(O) which(O) held(O) its(O) first(O) meeting(O) at(O) the(O) UCSD(B-location) campus(I-location) in(O) 1979(O).(O)", "instance": {"id": "230", "words": ["At", "UCSD", ",", "Norman", "was", "a", "founder", "of", "the", "Institute", "for", "Cognitive", "Science", "and", "one", "of", "the", "organizers", "of", "the", "Cognitive", "Science", "Society", "(", "along", "with", "Roger", "Schank", ",", "Allan", "M.", "Collins", ",", "and", "others", ")", ",", "which", "held", "its", "first", "meeting", "at", "the", "UCSD", "campus", "in", "1979", "."], "labels": ["O", "B-university", "O", "B-researcher", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "O", "B-researcher", "I-researcher", "O", "B-researcher", "I-researcher", "I-researcher", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-university", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, person, researcher, organization, country, metric, programming language, university, field, location, algorithm, task, product and O.\nSentence: At UCSD , Norman was a founder of the Institute for Cognitive Science and one of the organizers of the Cognitive Science Society ( along with Roger Schank , Allan M. Collins , and others ) , which held its first meeting at the UCSD campus in 1979 .", "prompt_labels": "At(O) UCSD(B-university) ,(O) Norman(B-researcher) was(O) a(O) founder(O) of(O) the(B-organization) Institute(I-organization) for(I-organization) Cognitive(I-organization) Science(I-organization) and(O) one(O) of(O) the(O) organizers(O) of(O) the(O) Cognitive(B-organization) Science(I-organization) Society(I-organization) ((O) along(O) with(O) Roger(B-researcher) Schank(I-researcher) ,(O) Allan(B-researcher) M.(I-researcher) Collins(I-researcher) ,(O) and(O) others(O) )(O) ,(O) which(O) held(O) its(O) first(O) meeting(O) at(O) the(O) UCSD(B-university) campus(O) in(O) 1979(O) .(O)"}, "label_list": ["conference", "person", "researcher", "organization", "country", "metric", "programming language", "university", "field", "location", "algorithm", "task", "product"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10017, 11, 1732, 11, 32185, 11, 7471, 11, 3224, 11, 18767, 11, 15840, 4221, 11, 12374, 11, 2115, 11, 3813, 11, 12384, 11, 3465, 11, 2027, 323, 507, 627, 85664, 25, 2468, 31613, 5608, 1174, 41168, 574, 264, 19533, 315, 279, 10181, 369, 73235, 10170, 323, 832, 315, 279, 44318, 315, 279, 73235, 10170, 13581, 320, 3235, 449, 29607, 5124, 1201, 1174, 61325, 386, 13, 29770, 1174, 323, 3885, 883, 1174, 902, 5762, 1202, 1176, 6574, 520, 279, 31613, 5608, 15679, 304, 220, 4468, 24, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "238", "dataset": "mit-movie", "split": "dev", "prediction": "how(O) many(O) star(B-title) wars(I-title) films(O) are(O) there(O)", "instance": {"id": "238", "words": ["how", "many", "star", "wars", "films", "are", "there"], "labels": ["O", "O", "B-title", "I-title", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, trailer, plot, genre, actor, character, rating, review, average ratings, title, year, song and O.\nSentence: how many star wars films are there", "prompt_labels": "how(O) many(O) star(B-title) wars(I-title) films(O) are(O) there(O)"}, "label_list": ["director", "trailer", "plot", "genre", "actor", "character", "rating", "review", "average ratings", "title", "year", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 19809, 11, 7234, 11, 17779, 11, 12360, 11, 3752, 11, 10959, 11, 3477, 11, 5578, 18594, 11, 2316, 11, 1060, 11, 5609, 323, 507, 627, 85664, 25, 1268, 1690, 6917, 25981, 12631, 527, 1070, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2290", "dataset": "mit-movie", "split": "dev", "prediction": "which(O) biography(B-genre) about(O) a(O) classical(B-plot) composer(I-plot) featuring(O) deforest(B-actor) kelly(I-actor) received(O) an(O) eight(B-average ratings) star(I-average ratings) rating(O)", "instance": {"id": "2290", "words": ["which", "biography", "about", "a", "classical", "composer", "featuring", "deforest", "kelly", "received", "an", "eight", "star", "rating"], "labels": ["O", "B-genre", "O", "O", "B-plot", "I-plot", "O", "B-actor", "I-actor", "O", "O", "B-average ratings", "I-average ratings", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, review, plot, year, actor, rating, director, genre, title, song, character, average ratings and O.\nSentence: which biography about a classical composer featuring deforest kelly received an eight star rating", "prompt_labels": "which(O) biography(B-genre) about(O) a(O) classical(B-plot) composer(I-plot) featuring(O) deforest(B-actor) kelly(I-actor) received(O) an(O) eight(B-average ratings) star(I-average ratings) rating(O)"}, "label_list": ["trailer", "review", "plot", "year", "actor", "rating", "director", "genre", "title", "song", "character", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 3477, 11, 7234, 11, 1060, 11, 12360, 11, 10959, 11, 7690, 11, 17779, 11, 2316, 11, 5609, 11, 3752, 11, 5578, 18594, 323, 507, 627, 85664, 25, 902, 48345, 922, 264, 29924, 40550, 16850, 711, 42519, 597, 12160, 4036, 459, 8223, 6917, 10959, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "781", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) live(O) action(O) movie(O) based(O) on(O) action(O) figure(O) toys(O) was(O) released(O) in(O) 2009(B-year)", "instance": {"id": "781", "words": ["what", "live", "action", "movie", "based", "on", "action", "figure", "toys", "was", "released", "in", "2009"], "labels": ["O", "B-genre", "I-genre", "O", "O", "O", "B-plot", "I-plot", "I-plot", "O", "O", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, rating, trailer, title, year, genre, actor, average ratings, song, director, character, review and O.\nSentence: what live action movie based on action figure toys was released in 2009", "prompt_labels": "what(O) live(B-genre) action(I-genre) movie(O) based(O) on(O) action(B-plot) figure(I-plot) toys(I-plot) was(O) released(O) in(O) 2009(B-year)"}, "label_list": ["plot", "rating", "trailer", "title", "year", "genre", "actor", "average ratings", "song", "director", "character", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 10959, 11, 19809, 11, 2316, 11, 1060, 11, 17779, 11, 12360, 11, 5578, 18594, 11, 5609, 11, 7690, 11, 3752, 11, 3477, 323, 507, 627, 85664, 25, 1148, 3974, 1957, 5818, 3196, 389, 1957, 7216, 23939, 574, 6004, 304, 220, 1049, 24, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "222", "dataset": "crossner_music", "split": "dev", "prediction": "Music(O) critic(O) Richie(B-person) Unterberger(I-person) has(O) noted(O) that(O) the(O) commercial(O) success(O) of(O) the(O) Byrds(B-band) '(O) cover(O) version(O) of(O) Dylan(B-song) '(O) s(O) Mr.(B-song) Tambourine(I-song) Man(I-song),(O) along(O) with(O) Dylan(B-song) '(O) own(O) contributions(O) to(O) the(O) genre(O) on(O) the(O) albums(O) Bringing(B-album) It(I-album) All(I-album) Back(I-album) Home(I-album),(O) Highway(B-album) 61(I-album) Revisited(I-album),(O) and(O) Blonde(B-album) on(I-album) Blonde(I-album),(O) initiated(O) an(O) explosion(O) of(O) emulators(O) and(O) imitators(O).(O)", "instance": {"id": "222", "words": ["Music", "critic", "Richie", "Unterberger", "has", "noted", "that", "the", "commercial", "success", "of", "the", "Byrds", "'", "cover", "version", "of", "Dylan", "'s", "Mr.", "Tambourine", "Man", ",", "along", "with", "Dylan", "'s", "own", "contributions", "to", "the", "genre", "on", "the", "albums", "Bringing", "It", "All", "Back", "Home", ",", "Highway", "61", "Revisited", ",", "and", "Blonde", "on", "Blonde", ",", "initiated", "an", "explosion", "of", "emulators", "and", "imitators", "."], "labels": ["O", "O", "B-person", "I-person", "O", "O", "O", "O", "O", "O", "O", "O", "B-band", "O", "O", "O", "O", "B-musical artist", "O", "B-song", "I-song", "I-song", "O", "O", "O", "B-musical artist", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-album", "I-album", "I-album", "I-album", "I-album", "O", "B-album", "I-album", "I-album", "O", "O", "B-album", "I-album", "I-album", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, album, organization, award, musical instrument, person, musical artist, music genre, event, country, band, song and O.\nSentence: Music critic Richie Unterberger has noted that the commercial success of the Byrds ' cover version of Dylan 's Mr. Tambourine Man , along with Dylan 's own contributions to the genre on the albums Bringing It All Back Home , Highway 61 Revisited , and Blonde on Blonde , initiated an explosion of emulators and imitators .", "prompt_labels": "Music(O) critic(O) Richie(B-person) Unterberger(I-person) has(O) noted(O) that(O) the(O) commercial(O) success(O) of(O) the(O) Byrds(B-band) '(O) cover(O) version(O) of(O) Dylan(B-musical artist) 's(O) Mr.(B-song) Tambourine(I-song) Man(I-song) ,(O) along(O) with(O) Dylan(B-musical artist) 's(O) own(O) contributions(O) to(O) the(O) genre(O) on(O) the(O) albums(O) Bringing(B-album) It(I-album) All(I-album) Back(I-album) Home(I-album) ,(O) Highway(B-album) 61(I-album) Revisited(I-album) ,(O) and(O) Blonde(B-album) on(I-album) Blonde(I-album) ,(O) initiated(O) an(O) explosion(O) of(O) emulators(O) and(O) imitators(O) .(O)"}, "label_list": ["location", "album", "organization", "award", "musical instrument", "person", "musical artist", "music genre", "event", "country", "band", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 8176, 11, 7471, 11, 10292, 11, 18273, 14473, 11, 1732, 11, 18273, 10255, 11, 4731, 17779, 11, 1567, 11, 3224, 11, 7200, 11, 5609, 323, 507, 627, 85664, 25, 10948, 9940, 100074, 34412, 49120, 706, 10555, 430, 279, 8518, 2450, 315, 279, 3296, 81, 5469, 364, 3504, 2373, 315, 44458, 364, 82, 4491, 13, 59226, 414, 483, 2418, 1174, 3235, 449, 44458, 364, 82, 1866, 19564, 311, 279, 17779, 389, 279, 28785, 98173, 1102, 2052, 6984, 5492, 1174, 29866, 220, 5547, 1050, 29968, 1174, 323, 53556, 389, 53556, 1174, 33230, 459, 25176, 315, 991, 42391, 323, 737, 275, 3046, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2266", "dataset": "mit-movie", "split": "dev", "prediction": "when(O) did(O) the(O) movie(O) titled(O) b(B-title) girl(I-title) come(O) out(O)", "instance": {"id": "2266", "words": ["when", "did", "the", "movie", "titled", "b", "girl", "come", "out"], "labels": ["O", "O", "O", "O", "O", "B-title", "I-title", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, song, plot, actor, genre, average ratings, review, trailer, title, character, rating, year and O.\nSentence: when did the movie titled b girl come out", "prompt_labels": "when(O) did(O) the(O) movie(O) titled(O) b(B-title) girl(I-title) come(O) out(O)"}, "label_list": ["director", "song", "plot", "actor", "genre", "average ratings", "review", "trailer", "title", "character", "rating", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 5609, 11, 7234, 11, 12360, 11, 17779, 11, 5578, 18594, 11, 3477, 11, 19809, 11, 2316, 11, 3752, 11, 10959, 11, 1060, 323, 507, 627, 85664, 25, 994, 1550, 279, 5818, 25891, 293, 3828, 2586, 704, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1491", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) there(O) a(O) good(O) psychological(B-genre) drama(I-genre) bout(O) a(O) struggle(B-plot)", "instance": {"id": "1491", "words": ["is", "there", "a", "good", "psychological", "drama", "bout", "a", "struggle"], "labels": ["O", "O", "O", "O", "B-genre", "I-genre", "O", "O", "B-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, plot, genre, director, character, title, average ratings, song, trailer, rating, review, year and O.\nSentence: is there a good psychological drama bout a struggle", "prompt_labels": "is(O) there(O) a(O) good(O) psychological(B-genre) drama(I-genre) bout(O) a(O) struggle(B-plot)"}, "label_list": ["actor", "plot", "genre", "director", "character", "title", "average ratings", "song", "trailer", "rating", "review", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 7234, 11, 17779, 11, 7690, 11, 3752, 11, 2316, 11, 5578, 18594, 11, 5609, 11, 19809, 11, 10959, 11, 3477, 11, 1060, 323, 507, 627, 85664, 25, 374, 1070, 264, 1695, 24064, 20156, 25646, 264, 14993, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "98", "dataset": "mit-movie", "split": "dev", "prediction": "i(O) am(O) looking(O) for(O) a(O) movie(O) about(O) talking(B-plot) animals(I-plot)", "instance": {"id": "98", "words": ["i", "am", "looking", "for", "a", "movie", "about", "talking", "animals"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, rating, average ratings, plot, review, title, actor, character, song, year, trailer, genre and O.\nSentence: i am looking for a movie about talking animals", "prompt_labels": "i(O) am(O) looking(O) for(O) a(O) movie(O) about(O) talking(B-plot) animals(I-plot)"}, "label_list": ["director", "rating", "average ratings", "plot", "review", "title", "actor", "character", "song", "year", "trailer", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 10959, 11, 5578, 18594, 11, 7234, 11, 3477, 11, 2316, 11, 12360, 11, 3752, 11, 5609, 11, 1060, 11, 19809, 11, 17779, 323, 507, 627, 85664, 25, 602, 1097, 3411, 369, 264, 5818, 922, 7556, 10099, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "873", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) is(O) doing(O) the(O) soundtrack(B-song) for(O) prometheus(B-title)", "instance": {"id": "873", "words": ["who", "is", "doing", "the", "soundtrack", "for", "prometheus"], "labels": ["B-song", "I-song", "I-song", "I-song", "I-song", "I-song", "I-song"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, song, average ratings, title, year, character, review, genre, actor, rating, director, plot and O.\nSentence: who is doing the soundtrack for prometheus", "prompt_labels": "who(B-song) is(I-song) doing(I-song) the(I-song) soundtrack(I-song) for(I-song) prometheus(I-song)"}, "label_list": ["trailer", "song", "average ratings", "title", "year", "character", "review", "genre", "actor", "rating", "director", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 5609, 11, 5578, 18594, 11, 2316, 11, 1060, 11, 3752, 11, 3477, 11, 17779, 11, 12360, 11, 10959, 11, 7690, 11, 7234, 323, 507, 627, 85664, 25, 889, 374, 3815, 279, 45999, 369, 2773, 40805, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "533", "dataset": "mit-movie", "split": "dev", "prediction": "how(O) many(O) movies(O) did(O) bela(B-actor) lugosi(I-actor) appear(O) in(O)", "instance": {"id": "533", "words": ["how", "many", "movies", "did", "bela", "lugosi", "appear", "in"], "labels": ["O", "O", "O", "O", "B-actor", "I-actor", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, title, review, character, plot, genre, director, trailer, song, rating, actor, average ratings and O.\nSentence: how many movies did bela lugosi appear in", "prompt_labels": "how(O) many(O) movies(O) did(O) bela(B-actor) lugosi(I-actor) appear(O) in(O)"}, "label_list": ["year", "title", "review", "character", "plot", "genre", "director", "trailer", "song", "rating", "actor", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 2316, 11, 3477, 11, 3752, 11, 7234, 11, 17779, 11, 7690, 11, 19809, 11, 5609, 11, 10959, 11, 12360, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1268, 1690, 9698, 1550, 1689, 64, 54510, 31824, 5101, 304, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "212", "dataset": "crossner_music", "split": "dev", "prediction": "The(O) film(O) won(O) Academy(B-review) Award(I-review) for(I-review) Best(I-review) Picture(I-review),(O) Academy(B-review) Award(I-review) for(I-review) Best(I-review) Director(I-review) and(O) Academy(B-review) Award(I-review) for(I-review) Best(I-review) Adapted(I-review) Screenplay(I-review),(O) and(O) Hopkins(B-person) also(O) picked(O) up(O) his(O) first(O) BAFTA(B-review) for(I-review) Best(I-review) Actor(I-review).(O)", "instance": {"id": "212", "words": ["The", "film", "won", "Academy", "Award", "for", "Best", "Picture", ",", "Academy", "Award", "for", "Best", "Director", "and", "Academy", "Award", "for", "Best", "Adapted", "Screenplay", ",", "and", "Hopkins", "also", "picked", "up", "his", "first", "BAFTA", "for", "Best", "Actor", "."], "labels": ["O", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O", "O", "B-person", "O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, band, album, event, organization, country, location, award, musical artist, person, music genre, song and O.\nSentence: The film won Academy Award for Best Picture , Academy Award for Best Director and Academy Award for Best Adapted Screenplay , and Hopkins also picked up his first BAFTA for Best Actor .", "prompt_labels": "The(O) film(O) won(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Picture(I-award) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Director(I-award) and(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Adapted(I-award) Screenplay(I-award) ,(O) and(O) Hopkins(B-person) also(O) picked(O) up(O) his(O) first(O) BAFTA(B-award) for(I-award) Best(I-award) Actor(I-award) .(O)"}, "label_list": ["musical instrument", "band", "album", "event", "organization", "country", "location", "award", "musical artist", "person", "music genre", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18273, 14473, 11, 7200, 11, 8176, 11, 1567, 11, 7471, 11, 3224, 11, 3813, 11, 10292, 11, 18273, 10255, 11, 1732, 11, 4731, 17779, 11, 5609, 323, 507, 627, 85664, 25, 578, 4632, 2834, 16192, 17768, 369, 7252, 25586, 1174, 16192, 17768, 369, 7252, 10783, 323, 16192, 17768, 369, 7252, 59531, 291, 14275, 1387, 1174, 323, 45316, 1101, 13061, 709, 813, 1176, 34589, 59512, 369, 7252, 25749, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "848", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movies(O) has(O) edward(B-actor) norton(I-actor) been(O) in(O)", "instance": {"id": "848", "words": ["what", "movies", "has", "edward", "norton", "been", "in"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, character, year, director, title, rating, actor, trailer, review, genre, song, plot and O.\nSentence: what movies has edward norton been in", "prompt_labels": "what(O) movies(O) has(O) edward(B-actor) norton(I-actor) been(O) in(O)"}, "label_list": ["average ratings", "character", "year", "director", "title", "rating", "actor", "trailer", "review", "genre", "song", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 3752, 11, 1060, 11, 7690, 11, 2316, 11, 10959, 11, 12360, 11, 19809, 11, 3477, 11, 17779, 11, 5609, 11, 7234, 323, 507, 627, 85664, 25, 1148, 9698, 706, 1608, 1637, 308, 38200, 1027, 304, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "296", "dataset": "crossner_literature", "split": "dev", "prediction": "In(O) 1947(O),(O) Capp(B-writer) earned(O) a(O) Newsweek(B-magazine) cover(O) story(O).(O)", "instance": {"id": "296", "words": ["In", "1947", ",", "Capp", "earned", "a", "Newsweek", "cover", "story", "."], "labels": ["O", "O", "O", "B-writer", "O", "O", "B-magazine", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, award, location, literary genre, event, poem, writer, person, country, organization, book and O.\nSentence: In 1947 , Capp earned a Newsweek cover story .", "prompt_labels": "In(O) 1947(O) ,(O) Capp(B-writer) earned(O) a(O) Newsweek(B-magazine) cover(O) story(O) .(O)"}, "label_list": ["magazine", "award", "location", "literary genre", "event", "poem", "writer", "person", "country", "organization", "book"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 14756, 11, 10292, 11, 3813, 11, 32465, 17779, 11, 1567, 11, 33894, 11, 7061, 11, 1732, 11, 3224, 11, 7471, 11, 2363, 323, 507, 627, 85664, 25, 763, 220, 6393, 22, 1174, 356, 680, 15662, 264, 5513, 10476, 3504, 3446, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "341", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) directed(O) blazing(B-title) saddles(I-title)", "instance": {"id": "341", "words": ["who", "directed", "blazing", "saddles"], "labels": ["O", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, genre, average ratings, plot, song, rating, character, title, trailer, actor, review, year and O.\nSentence: who directed blazing saddles", "prompt_labels": "who(O) directed(O) blazing(B-title) saddles(I-title)"}, "label_list": ["director", "genre", "average ratings", "plot", "song", "rating", "character", "title", "trailer", "actor", "review", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 17779, 11, 5578, 18594, 11, 7234, 11, 5609, 11, 10959, 11, 3752, 11, 2316, 11, 19809, 11, 12360, 11, 3477, 11, 1060, 323, 507, 627, 85664, 25, 889, 15910, 86350, 58272, 645, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2246", "dataset": "mit-movie", "split": "dev", "prediction": "whats(O) fright(B-title) night(I-title) about(O)", "instance": {"id": "2246", "words": ["whats", "fright", "night", "about"], "labels": ["O", "B-title", "I-title", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, average ratings, trailer, character, year, title, director, plot, actor, song, review, genre and O.\nSentence: whats fright night about", "prompt_labels": "whats(O) fright(B-title) night(I-title) about(O)"}, "label_list": ["rating", "average ratings", "trailer", "character", "year", "title", "director", "plot", "actor", "song", "review", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 5578, 18594, 11, 19809, 11, 3752, 11, 1060, 11, 2316, 11, 7690, 11, 7234, 11, 12360, 11, 5609, 11, 3477, 11, 17779, 323, 507, 627, 85664, 25, 41209, 30647, 3814, 922, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2147", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movies(O) has(O) david(B-director) lean(I-director) directed(O)", "instance": {"id": "2147", "words": ["what", "movies", "has", "david", "lean", "directed"], "labels": ["O", "O", "O", "B-director", "I-director", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, rating, title, song, character, year, review, average ratings, plot, actor, genre, trailer and O.\nSentence: what movies has david lean directed", "prompt_labels": "what(O) movies(O) has(O) david(B-director) lean(I-director) directed(O)"}, "label_list": ["director", "rating", "title", "song", "character", "year", "review", "average ratings", "plot", "actor", "genre", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 10959, 11, 2316, 11, 5609, 11, 3752, 11, 1060, 11, 3477, 11, 5578, 18594, 11, 7234, 11, 12360, 11, 17779, 11, 19809, 323, 507, 627, 85664, 25, 1148, 9698, 706, 55046, 16025, 15910, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "97", "dataset": "crossner_ai", "split": "dev", "prediction": "The(O) back-of-the-envelope(O) calculations(O) by(O) Doug(B-researcher),(O) Alan(B-researcher),(O) and(O) their(O) colleagues(O) ((O) including(O) Marvin(B-researcher) Minsky(I-researcher),(O) Allen(B-researcher) Newell(I-researcher),(O) Edward(B-researcher) Feigenbaum(I-researcher),(O) and(O) John(B-researcher) McCarthy(I-researcher) )(O) indicated(O) that(O) that(O) effort(O) would(O) require(O) between(O) 1000(O) and(O) 3000(O) person-years(O) of(O) effort(O),(O) far(O) beyond(O) the(O) standard(O) academic(O) project(O) model(O).(O)", "instance": {"id": "97", "words": ["The", "back-of-the-envelope", "calculations", "by", "Doug", ",", "Alan", ",", "and", "their", "colleagues", "(", "including", "Marvin", "Minsky", ",", "Allen", "Newell", ",", "Edward", "Feigenbaum", ",", "and", "John", "McCarthy", ")", "indicated", "that", "that", "effort", "would", "require", "between", "1000", "and", "3000", "person-years", "of", "effort", ",", "far", "beyond", "the", "standard", "academic", "project", "model", "."], "labels": ["O", "O", "O", "O", "B-researcher", "O", "B-researcher", "O", "O", "O", "O", "O", "O", "B-researcher", "I-researcher", "O", "B-researcher", "I-researcher", "O", "B-researcher", "I-researcher", "O", "O", "B-researcher", "I-researcher", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: metric, product, programming language, university, organization, conference, country, person, algorithm, task, researcher, location, field and O.\nSentence: The back-of-the-envelope calculations by Doug , Alan , and their colleagues ( including Marvin Minsky , Allen Newell , Edward Feigenbaum , and John McCarthy ) indicated that that effort would require between 1000 and 3000 person-years of effort , far beyond the standard academic project model .", "prompt_labels": "The(O) back-of-the-envelope(O) calculations(O) by(O) Doug(B-researcher) ,(O) Alan(B-researcher) ,(O) and(O) their(O) colleagues(O) ((O) including(O) Marvin(B-researcher) Minsky(I-researcher) ,(O) Allen(B-researcher) Newell(I-researcher) ,(O) Edward(B-researcher) Feigenbaum(I-researcher) ,(O) and(O) John(B-researcher) McCarthy(I-researcher) )(O) indicated(O) that(O) that(O) effort(O) would(O) require(O) between(O) 1000(O) and(O) 3000(O) person-years(O) of(O) effort(O) ,(O) far(O) beyond(O) the(O) standard(O) academic(O) project(O) model(O) .(O)"}, "label_list": ["metric", "product", "programming language", "university", "organization", "conference", "country", "person", "algorithm", "task", "researcher", "location", "field"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18767, 11, 2027, 11, 15840, 4221, 11, 12374, 11, 7471, 11, 10017, 11, 3224, 11, 1732, 11, 12384, 11, 3465, 11, 32185, 11, 3813, 11, 2115, 323, 507, 627, 85664, 25, 578, 1203, 8838, 10826, 64625, 29217, 555, 32608, 1174, 26349, 1174, 323, 872, 18105, 320, 2737, 74626, 386, 52541, 1174, 20661, 1561, 616, 1174, 22653, 3926, 6569, 59611, 1174, 323, 3842, 45040, 883, 16717, 430, 430, 5149, 1053, 1397, 1990, 220, 1041, 15, 323, 220, 3101, 15, 1732, 57188, 315, 5149, 1174, 3117, 7953, 279, 5410, 14584, 2447, 1646, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "565", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) have(O) an(O) important(B-Amenity) business(I-Amenity) luncheon(I-Amenity) and(O) need(O) to(O) find(O) a(O) place(O) that(O) caters(O) to(O) professionals(O)", "instance": {"id": "565", "words": ["i", "have", "an", "important", "business", "luncheon", "and", "need", "to", "find", "a", "place", "that", "caters", "to", "professionals"], "labels": ["O", "O", "O", "O", "B-Amenity", "B-Hours", "O", "O", "O", "O", "O", "O", "O", "B-Amenity", "I-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Price, Hours, Rating, Location, Cuisine, Dish, Restaurant Name and O.\nSentence: i have an important business luncheon and need to find a place that caters to professionals", "prompt_labels": "i(O) have(O) an(O) important(O) business(B-Amenity) luncheon(B-Hours) and(O) need(O) to(O) find(O) a(O) place(O) that(O) caters(B-Amenity) to(I-Amenity) professionals(I-Amenity)"}, "label_list": ["Amenity", "Price", "Hours", "Rating", "Location", "Cuisine", "Dish", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 8650, 11, 30192, 11, 19767, 11, 10067, 11, 81961, 11, 49268, 11, 26568, 4076, 323, 507, 627, 85664, 25, 602, 617, 459, 3062, 2626, 33073, 76269, 323, 1205, 311, 1505, 264, 2035, 430, 8415, 388, 311, 15749, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "56", "dataset": "mit-restaurant", "split": "dev", "prediction": "are(O) there(O) any(O) locally(B-Amenity) owned(I-Amenity) franchises(I-Amenity) that(O) give(O) money(O) to(O) charity(B-Amenity)", "instance": {"id": "56", "words": ["are", "there", "any", "locally", "owned", "franchises", "that", "give", "money", "to", "charity"], "labels": ["O", "O", "O", "B-Amenity", "I-Amenity", "O", "O", "B-Amenity", "I-Amenity", "I-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Amenity, Restaurant Name, Price, Cuisine, Dish, Hours, Location and O.\nSentence: are there any locally owned franchises that give money to charity", "prompt_labels": "are(O) there(O) any(O) locally(B-Amenity) owned(I-Amenity) franchises(O) that(O) give(B-Amenity) money(I-Amenity) to(I-Amenity) charity(I-Amenity)"}, "label_list": ["Rating", "Amenity", "Restaurant Name", "Price", "Cuisine", "Dish", "Hours", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 3383, 56685, 11, 26568, 4076, 11, 8650, 11, 81961, 11, 49268, 11, 30192, 11, 10067, 323, 507, 627, 85664, 25, 527, 1070, 904, 24392, 13234, 65003, 430, 3041, 3300, 311, 23693, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "732", "dataset": "mit-movie", "split": "dev", "prediction": "are(O) there(O) any(O) musicals(B-genre) from(O) the(O) 1990s(B-year)", "instance": {"id": "732", "words": ["are", "there", "any", "musicals", "from", "the", "1990s"], "labels": ["O", "O", "O", "O", "O", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, trailer, average ratings, title, song, year, actor, director, rating, genre, review, plot and O.\nSentence: are there any musicals from the 1990s", "prompt_labels": "are(O) there(O) any(O) musicals(O) from(O) the(O) 1990s(B-year)"}, "label_list": ["character", "trailer", "average ratings", "title", "song", "year", "actor", "director", "rating", "genre", "review", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 19809, 11, 5578, 18594, 11, 2316, 11, 5609, 11, 1060, 11, 12360, 11, 7690, 11, 10959, 11, 17779, 11, 3477, 11, 7234, 323, 507, 627, 85664, 25, 527, 1070, 904, 18273, 82, 505, 279, 220, 2550, 15, 82, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "180", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movie(O) stars(O) reese(B-actor) witherspoon(I-actor) in(O) 2004(B-year)", "instance": {"id": "180", "words": ["what", "movie", "stars", "reese", "witherspoon", "in", "2004"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, plot, character, rating, average ratings, song, actor, title, trailer, year, review, director and O.\nSentence: what movie stars reese witherspoon in 2004", "prompt_labels": "what(O) movie(O) stars(O) reese(B-actor) witherspoon(I-actor) in(O) 2004(B-year)"}, "label_list": ["genre", "plot", "character", "rating", "average ratings", "song", "actor", "title", "trailer", "year", "review", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 7234, 11, 3752, 11, 10959, 11, 5578, 18594, 11, 5609, 11, 12360, 11, 2316, 11, 19809, 11, 1060, 11, 3477, 11, 7690, 323, 507, 627, 85664, 25, 1148, 5818, 9958, 312, 2423, 449, 388, 33076, 304, 220, 1049, 19, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "245", "dataset": "crossner_music", "split": "dev", "prediction": "In(O) the(O) 1970s(B-year) and(O) 1980s(O),(O) tension(O) and(O) conflict(O) emerged(O) between(O) Southern(B-music genre) gospel(I-music genre) and(O) the(O) newer(O) developments(O) of(O) Jesus(B-music genre) music(I-music genre) and(O) Contemporary(B-music genre) Christian(I-music genre) music(I-music genre).(O)", "instance": {"id": "245", "words": ["In", "the", "1970s", "and", "1980s", ",", "tension", "and", "conflict", "emerged", "between", "Southern", "gospel", "and", "the", "newer", "developments", "of", "Jesus", "music", "and", "Contemporary", "Christian", "music", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-music genre", "I-music genre", "O", "O", "O", "O", "O", "B-music genre", "I-music genre", "O", "B-music genre", "I-music genre", "I-music genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, country, song, band, musical artist, event, organization, album, musical instrument, person, location, music genre and O.\nSentence: In the 1970s and 1980s , tension and conflict emerged between Southern gospel and the newer developments of Jesus music and Contemporary Christian music .", "prompt_labels": "In(O) the(O) 1970s(O) and(O) 1980s(O) ,(O) tension(O) and(O) conflict(O) emerged(O) between(O) Southern(B-music genre) gospel(I-music genre) and(O) the(O) newer(O) developments(O) of(O) Jesus(B-music genre) music(I-music genre) and(O) Contemporary(B-music genre) Christian(I-music genre) music(I-music genre) .(O)"}, "label_list": ["award", "country", "song", "band", "musical artist", "event", "organization", "album", "musical instrument", "person", "location", "music genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10292, 11, 3224, 11, 5609, 11, 7200, 11, 18273, 10255, 11, 1567, 11, 7471, 11, 8176, 11, 18273, 14473, 11, 1732, 11, 3813, 11, 4731, 17779, 323, 507, 627, 85664, 25, 763, 279, 220, 4468, 15, 82, 323, 220, 3753, 15, 82, 1174, 24408, 323, 12324, 22763, 1990, 16642, 42582, 323, 279, 26627, 26006, 315, 10811, 4731, 323, 48302, 9052, 4731, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "188", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) dramas(B-genre) about(O) the(O) british(B-plot) royal(I-plot) family(I-plot)", "instance": {"id": "188", "words": ["show", "me", "dramas", "about", "the", "british", "royal", "family"], "labels": ["O", "O", "B-genre", "O", "O", "B-plot", "I-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, rating, review, character, actor, year, song, genre, average ratings, title, director, trailer and O.\nSentence: show me dramas about the british royal family", "prompt_labels": "show(O) me(O) dramas(B-genre) about(O) the(O) british(B-plot) royal(I-plot) family(I-plot)"}, "label_list": ["plot", "rating", "review", "character", "actor", "year", "song", "genre", "average ratings", "title", "director", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 10959, 11, 3477, 11, 3752, 11, 12360, 11, 1060, 11, 5609, 11, 17779, 11, 5578, 18594, 11, 2316, 11, 7690, 11, 19809, 323, 507, 627, 85664, 25, 1501, 757, 88826, 922, 279, 95027, 30336, 3070, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1674", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) an(O) emotional(B-genre) movie(O) during(O) the(O) year(O) 1990(B-year) s(I-year)", "instance": {"id": "1674", "words": ["list", "an", "emotional", "movie", "during", "the", "year", "1990", "s"], "labels": ["O", "O", "B-genre", "O", "O", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, title, rating, year, director, average ratings, genre, actor, character, plot, trailer, review and O.\nSentence: list an emotional movie during the year 1990 s", "prompt_labels": "list(O) an(O) emotional(B-genre) movie(O) during(O) the(O) year(O) 1990(B-year) s(I-year)"}, "label_list": ["song", "title", "rating", "year", "director", "average ratings", "genre", "actor", "character", "plot", "trailer", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 2316, 11, 10959, 11, 1060, 11, 7690, 11, 5578, 18594, 11, 17779, 11, 12360, 11, 3752, 11, 7234, 11, 19809, 11, 3477, 323, 507, 627, 85664, 25, 1160, 459, 14604, 5818, 2391, 279, 1060, 220, 2550, 15, 274, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "610", "dataset": "mit-movie", "split": "dev", "prediction": "find(O) the(O) air(B-title) bud(I-title) movie(O) about(O) baseball(B-plot)", "instance": {"id": "610", "words": ["find", "the", "air", "bud", "movie", "about", "baseball"], "labels": ["O", "O", "B-character", "I-character", "O", "O", "B-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, genre, year, song, character, average ratings, trailer, director, plot, rating, actor, title and O.\nSentence: find the air bud movie about baseball", "prompt_labels": "find(O) the(O) air(B-character) bud(I-character) movie(O) about(O) baseball(B-plot)"}, "label_list": ["review", "genre", "year", "song", "character", "average ratings", "trailer", "director", "plot", "rating", "actor", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 17779, 11, 1060, 11, 5609, 11, 3752, 11, 5578, 18594, 11, 19809, 11, 7690, 11, 7234, 11, 10959, 11, 12360, 11, 2316, 323, 507, 627, 85664, 25, 1505, 279, 3805, 37808, 5818, 922, 20075, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1432", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) is(O) the(O) nearest(B-Location) chinese(B-Cuisine) restaurant(O) with(O) more(B-Rating) than(I-Rating) 3(I-Rating) stars(I-Rating) that(O) is(O) under(B-Price) 10(I-Price) an(O) entree(O)", "instance": {"id": "1432", "words": ["where", "is", "the", "nearest", "chinese", "restaurant", "with", "more", "than", "3", "stars", "that", "is", "under", "10", "an", "entree"], "labels": ["O", "O", "O", "B-Location", "B-Cuisine", "O", "O", "B-Rating", "I-Rating", "I-Rating", "I-Rating", "O", "O", "B-Price", "I-Price", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Rating, Amenity, Location, Dish, Restaurant Name, Price, Hours and O.\nSentence: where is the nearest chinese restaurant with more than 3 stars that is under 10 an entree", "prompt_labels": "where(O) is(O) the(O) nearest(B-Location) chinese(B-Cuisine) restaurant(O) with(O) more(B-Rating) than(I-Rating) 3(I-Rating) stars(I-Rating) that(O) is(O) under(B-Price) 10(I-Price) an(O) entree(O)"}, "label_list": ["Cuisine", "Rating", "Amenity", "Location", "Dish", "Restaurant Name", "Price", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 19767, 11, 3383, 56685, 11, 10067, 11, 49268, 11, 26568, 4076, 11, 8650, 11, 30192, 323, 507, 627, 85664, 25, 1405, 374, 279, 24379, 57487, 10960, 449, 810, 1109, 220, 18, 9958, 430, 374, 1234, 220, 605, 459, 1218, 770, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "299", "dataset": "crossner_science", "split": "dev", "prediction": "A(O) Chamberland(O) filter(O),(O) also(O) known(O) as(O) a(O) Louis(B-scientist) Pasteur(I-scientist) -(O) Chamberland(O) filter(O),(O) is(O) a(O) porcelain(O) water(O) filter(O) invented(O) by(O) Charles(B-scientist) Chamberland(I-scientist) in(O) 1884(O).(O)", "instance": {"id": "299", "words": ["A", "Chamberland", "filter", ",", "also", "known", "as", "a", "Louis", "Pasteur", "-Chamberland", "filter", ",", "is", "a", "porcelain", "water", "filter", "invented", "by", "Charles", "Chamberland", "in", "1884", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-scientist", "I-scientist", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, chemical element, enzyme, organization, theory, scientist, person, academic journal, astronomical object, location, award, country, university, event, discipline, protein and O.\nSentence: A Chamberland filter , also known as a Louis Pasteur -Chamberland filter , is a porcelain water filter invented by Charles Chamberland in 1884 .", "prompt_labels": "A(O) Chamberland(O) filter(O) ,(O) also(O) known(O) as(O) a(O) Louis(O) Pasteur(O) -Chamberland(O) filter(O) ,(O) is(O) a(O) porcelain(O) water(O) filter(O) invented(O) by(O) Charles(B-scientist) Chamberland(I-scientist) in(O) 1884(O) .(O)"}, "label_list": ["chemical compound", "chemical element", "enzyme", "organization", "theory", "scientist", "person", "academic journal", "astronomical object", "location", "award", "country", "university", "event", "discipline", "protein"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 11742, 24549, 11, 11742, 2449, 11, 49242, 11, 7471, 11, 10334, 11, 28568, 11, 1732, 11, 14584, 8486, 11, 87283, 1665, 11, 3813, 11, 10292, 11, 3224, 11, 12374, 11, 1567, 11, 26434, 11, 13128, 323, 507, 627, 85664, 25, 362, 32479, 1974, 4141, 1174, 1101, 3967, 439, 264, 12140, 58325, 324, 482, 1163, 15578, 1974, 4141, 1174, 374, 264, 78742, 3090, 4141, 36592, 555, 15274, 32479, 1974, 304, 220, 9367, 19, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "233", "dataset": "crossner_ai", "split": "dev", "prediction": "This(O) was(O) won(O) by(O) an(O) United(B-country) States(I-country) team(O) from(O) Newton(B-organization) Labs(I-organization),(O) and(O) the(O) competition(O) was(O) shown(O) on(O) CNN(B-organization).(O)", "instance": {"id": "233", "words": ["This", "was", "won", "by", "an", "United", "States", "team", "from", "Newton", "Labs", ",", "and", "the", "competition", "was", "shown", "on", "CNN", "."], "labels": ["O", "O", "O", "O", "O", "B-country", "I-country", "O", "O", "B-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "B-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, country, university, location, conference, algorithm, field, metric, product, programming language, person, researcher, task and O.\nSentence: This was won by an United States team from Newton Labs , and the competition was shown on CNN .", "prompt_labels": "This(O) was(O) won(O) by(O) an(O) United(B-country) States(I-country) team(O) from(O) Newton(B-organization) Labs(I-organization) ,(O) and(O) the(O) competition(O) was(O) shown(O) on(O) CNN(B-organization) .(O)"}, "label_list": ["organization", "country", "university", "location", "conference", "algorithm", "field", "metric", "product", "programming language", "person", "researcher", "task"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 3224, 11, 12374, 11, 3813, 11, 10017, 11, 12384, 11, 2115, 11, 18767, 11, 2027, 11, 15840, 4221, 11, 1732, 11, 32185, 11, 3465, 323, 507, 627, 85664, 25, 1115, 574, 2834, 555, 459, 3723, 4273, 2128, 505, 21324, 41740, 1174, 323, 279, 10937, 574, 6982, 389, 20352, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "256", "dataset": "crossner_literature", "split": "dev", "prediction": "In(O) 1946(O),(O) she(O) was(O) awarded(O) a(O) Guggenheim(B-award) Fellowship(I-award) for(I-award) Creative(I-award) Work(I-award) in(O) the(O) Field(O) of(O) Motion(O) Pictures(O),(O) and(O) won(O) the(O) Grand(B-award) Prix(I-award) Internationale(I-award) for(I-award) 16mm(I-award) experimental(I-award) film(I-award) at(O) the(O) Cannes(B-event) Film(I-event) Festival(I-event) for(O) Meshes(B-book) of(I-book) the(I-book) Afternoon(I-book) ((O) 1943(O) )(O).(O)", "instance": {"id": "256", "words": ["In", "1946", ",", "she", "was", "awarded", "a", "Guggenheim", "Fellowship", "for", "Creative", "Work", "in", "the", "Field", "of", "Motion", "Pictures", ",", "and", "won", "the", "Grand", "Prix", "Internationale", "for", "16mm", "experimental", "film", "at", "the", "Cannes", "Film", "Festival", "for", "Meshes", "of", "the", "Afternoon", "(", "1943", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O", "O", "O", "O", "B-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, magazine, literary genre, person, book, location, writer, award, country, organization, poem and O.\nSentence: In 1946 , she was awarded a Guggenheim Fellowship for Creative Work in the Field of Motion Pictures , and won the Grand Prix Internationale for 16mm experimental film at the Cannes Film Festival for Meshes of the Afternoon ( 1943 ) .", "prompt_labels": "In(O) 1946(O) ,(O) she(O) was(O) awarded(O) a(O) Guggenheim(B-award) Fellowship(I-award) for(I-award) Creative(I-award) Work(I-award) in(I-award) the(I-award) Field(I-award) of(I-award) Motion(I-award) Pictures(I-award) ,(O) and(O) won(O) the(O) Grand(B-award) Prix(I-award) Internationale(O) for(O) 16mm(O) experimental(O) film(O) at(O) the(O) Cannes(B-event) Film(I-event) Festival(I-event) for(O) Meshes(O) of(O) the(O) Afternoon(O) ((O) 1943(O) )(O) .(O)"}, "label_list": ["event", "magazine", "literary genre", "person", "book", "location", "writer", "award", "country", "organization", "poem"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 14756, 11, 32465, 17779, 11, 1732, 11, 2363, 11, 3813, 11, 7061, 11, 10292, 11, 3224, 11, 7471, 11, 33894, 323, 507, 627, 85664, 25, 763, 220, 6393, 21, 1174, 1364, 574, 22034, 264, 480, 2661, 92710, 65742, 369, 25248, 5664, 304, 279, 8771, 315, 27660, 29485, 1174, 323, 2834, 279, 10517, 44394, 4514, 38135, 369, 220, 845, 3906, 22772, 4632, 520, 279, 84620, 17042, 17772, 369, 26179, 288, 315, 279, 4740, 12684, 320, 220, 6393, 18, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "474", "dataset": "crossner_politics", "split": "dev", "prediction": "The(O) USSR(O) anti-religious(O) campaign(O) of(O) 1928-1941(O) was(O) a(O) new(O) phase(O) of(O) anti-religious(O) campaign(O) in(O) the(O) Soviet(O) Union(O) following(O) the(O) anti-religious(O) campaign(O) of(O) 1921-1928(O).(O)", "instance": {"id": "474", "words": ["The", "USSR", "anti-religious", "campaign", "of", "1928-1941", "was", "a", "new", "phase", "of", "anti-religious", "campaign", "in", "the", "Soviet", "Union", "following", "the", "anti-religious", "campaign", "of", "1921-1928", "."], "labels": ["O", "B-event", "I-event", "I-event", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-country", "I-country", "O", "O", "B-event", "I-event", "I-event", "I-event", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, election, organization, political party, country, person, politician, location and O.\nSentence: The USSR anti-religious campaign of 1928-1941 was a new phase of anti-religious campaign in the Soviet Union following the anti-religious campaign of 1921-1928 .", "prompt_labels": "The(O) USSR(B-event) anti-religious(I-event) campaign(I-event) of(O) 1928-1941(O) was(O) a(O) new(O) phase(O) of(O) anti-religious(O) campaign(O) in(O) the(O) Soviet(B-country) Union(I-country) following(O) the(O) anti-religious(B-event) campaign(I-event) of(I-event) 1921-1928(I-event) .(O)"}, "label_list": ["event", "election", "organization", "political party", "country", "person", "politician", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 6355, 11, 7471, 11, 5054, 4717, 11, 3224, 11, 1732, 11, 37038, 11, 3813, 323, 507, 627, 85664, 25, 578, 73315, 7294, 48712, 22941, 4901, 315, 220, 5926, 23, 12, 6393, 16, 574, 264, 502, 10474, 315, 7294, 48712, 22941, 4901, 304, 279, 19953, 9323, 2768, 279, 7294, 48712, 22941, 4901, 315, 220, 5926, 16, 12, 5926, 23, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "750", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) an(O) action(B-genre) movie(O) starring(O) clint(B-actor) eastwood(I-actor)", "instance": {"id": "750", "words": ["show", "me", "an", "action", "movie", "starring", "clint", "eastwood"], "labels": ["O", "O", "O", "B-genre", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, year, title, song, actor, character, director, trailer, average ratings, review, genre, rating and O.\nSentence: show me an action movie starring clint eastwood", "prompt_labels": "show(O) me(O) an(O) action(B-genre) movie(O) starring(O) clint(B-actor) eastwood(I-actor)"}, "label_list": ["plot", "year", "title", "song", "actor", "character", "director", "trailer", "average ratings", "review", "genre", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 1060, 11, 2316, 11, 5609, 11, 12360, 11, 3752, 11, 7690, 11, 19809, 11, 5578, 18594, 11, 3477, 11, 17779, 11, 10959, 323, 507, 627, 85664, 25, 1501, 757, 459, 1957, 5818, 40500, 1206, 396, 11226, 6798, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1416", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) is(O) the(O) closest(B-Location) pizza(B-Restaurant Name) hut(I-Restaurant Name)", "instance": {"id": "1416", "words": ["where", "is", "the", "closest", "pizza", "hut"], "labels": ["O", "O", "O", "B-Location", "B-Restaurant Name", "I-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Restaurant Name, Price, Location, Cuisine, Dish, Hours, Amenity and O.\nSentence: where is the closest pizza hut", "prompt_labels": "where(O) is(O) the(O) closest(B-Location) pizza(B-Restaurant Name) hut(I-Restaurant Name)"}, "label_list": ["Rating", "Restaurant Name", "Price", "Location", "Cuisine", "Dish", "Hours", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 26568, 4076, 11, 8650, 11, 10067, 11, 81961, 11, 49268, 11, 30192, 11, 3383, 56685, 323, 507, 627, 85664, 25, 1405, 374, 279, 18585, 23317, 76979, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "51", "dataset": "crossner_music", "split": "dev", "prediction": "This(O) album(O) featured(O) vocal(O) contributions(O) by(O) Vicotnik(B-musical artist) of(O) Ved(B-band) Buens(I-band) Ende(I-band) and(O) D\u00f8dheimsgard(B-band) and(O) Aldrahn(B-musical artist) of(O) D\u00f8dheimsgard(B-band) and(O) Zyklon-B(I-band).(O)", "instance": {"id": "51", "words": ["This", "album", "featured", "vocal", "contributions", "by", "Vicotnik", "of", "Ved", "Buens", "Ende", "and", "D\u00f8dheimsgard", "and", "Aldrahn", "of", "D\u00f8dheimsgard", "and", "Zyklon-B", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-musical artist", "O", "B-band", "I-band", "I-band", "O", "B-band", "O", "B-musical artist", "O", "B-band", "O", "B-band", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, song, band, organization, country, music genre, album, musical artist, award, location, event, person and O.\nSentence: This album featured vocal contributions by Vicotnik of Ved Buens Ende and D\u00f8dheimsgard and Aldrahn of D\u00f8dheimsgard and Zyklon-B .", "prompt_labels": "This(O) album(O) featured(O) vocal(O) contributions(O) by(O) Vicotnik(B-musical artist) of(O) Ved(B-band) Buens(I-band) Ende(I-band) and(O) D\u00f8dheimsgard(B-band) and(O) Aldrahn(B-musical artist) of(O) D\u00f8dheimsgard(B-band) and(O) Zyklon-B(B-band) .(O)"}, "label_list": ["musical instrument", "song", "band", "organization", "country", "music genre", "album", "musical artist", "award", "location", "event", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18273, 14473, 11, 5609, 11, 7200, 11, 7471, 11, 3224, 11, 4731, 17779, 11, 8176, 11, 18273, 10255, 11, 10292, 11, 3813, 11, 1567, 11, 1732, 323, 507, 627, 85664, 25, 1115, 8176, 15109, 26480, 19564, 555, 44847, 354, 22212, 315, 75887, 28326, 729, 52392, 323, 423, 75820, 21215, 2034, 569, 323, 31447, 969, 25105, 315, 423, 75820, 21215, 2034, 569, 323, 87654, 10784, 263, 7826, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "844", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) a(O) place(O) to(O) eat(O) in(O) the(O) abington(B-Location) theatre(I-Location) district(I-Location) open(B-Hours) after(I-Hours) midnight(I-Hours)", "instance": {"id": "844", "words": ["is", "there", "a", "place", "to", "eat", "in", "the", "abington", "theatre", "district", "open", "after", "midnight"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-Location", "I-Location", "I-Location", "O", "B-Hours", "I-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Rating, Location, Hours, Dish, Restaurant Name, Cuisine, Amenity and O.\nSentence: is there a place to eat in the abington theatre district open after midnight", "prompt_labels": "is(O) there(O) a(O) place(O) to(O) eat(O) in(O) the(O) abington(B-Location) theatre(I-Location) district(I-Location) open(O) after(B-Hours) midnight(I-Hours)"}, "label_list": ["Price", "Rating", "Location", "Hours", "Dish", "Restaurant Name", "Cuisine", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 19767, 11, 10067, 11, 30192, 11, 49268, 11, 26568, 4076, 11, 81961, 11, 3383, 56685, 323, 507, 627, 85664, 25, 374, 1070, 264, 2035, 311, 8343, 304, 279, 671, 4910, 34596, 9474, 1825, 1306, 33433, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "16", "dataset": "crossner_literature", "split": "dev", "prediction": "His(O) works(O) include(O) not(O) only(O) science(B-literary genre) fiction(I-literary genre),(O) but(O) also(O) articles(O) for(O) Playboy(B-magazine) and(O) Family(B-magazine) Circle(I-magazine) magazines(O) and(O) nonfiction(B-literary genre) books(O).(O)", "instance": {"id": "16", "words": ["His", "works", "include", "not", "only", "science", "fiction", ",", "but", "also", "articles", "for", "Playboy", "and", "Family", "Circle", "magazines", "and", "nonfiction", "books", "."], "labels": ["O", "O", "O", "O", "O", "B-literary genre", "I-literary genre", "O", "O", "O", "O", "O", "B-magazine", "O", "B-magazine", "I-magazine", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, award, book, writer, person, location, poem, literary genre, magazine, event, country and O.\nSentence: His works include not only science fiction , but also articles for Playboy and Family Circle magazines and nonfiction books .", "prompt_labels": "His(O) works(O) include(O) not(O) only(O) science(B-literary genre) fiction(I-literary genre) ,(O) but(O) also(O) articles(O) for(O) Playboy(B-magazine) and(O) Family(B-magazine) Circle(I-magazine) magazines(O) and(O) nonfiction(O) books(O) .(O)"}, "label_list": ["organization", "award", "book", "writer", "person", "location", "poem", "literary genre", "magazine", "event", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 10292, 11, 2363, 11, 7061, 11, 1732, 11, 3813, 11, 33894, 11, 32465, 17779, 11, 14756, 11, 1567, 11, 3224, 323, 507, 627, 85664, 25, 5414, 4375, 2997, 539, 1193, 8198, 17422, 1174, 719, 1101, 9908, 369, 91079, 323, 12517, 21918, 32947, 323, 2536, 58162, 6603, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1036", "dataset": "mit-restaurant", "split": "dev", "prediction": "please(O) name(O) all(O) restaurants(O) that(O) offer(O) curb(B-Amenity) side(I-Amenity) pick(I-Amenity) up(I-Amenity) on(O) highway(B-Location) 43(I-Location) south(I-Location)", "instance": {"id": "1036", "words": ["please", "name", "all", "restaurants", "that", "offer", "curb", "side", "pick", "up", "on", "highway", "43", "south"], "labels": ["O", "O", "O", "O", "O", "O", "B-Amenity", "I-Amenity", "I-Amenity", "I-Amenity", "O", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Amenity, Restaurant Name, Cuisine, Price, Location, Dish, Hours and O.\nSentence: please name all restaurants that offer curb side pick up on highway 43 south", "prompt_labels": "please(O) name(O) all(O) restaurants(O) that(O) offer(O) curb(B-Amenity) side(I-Amenity) pick(I-Amenity) up(I-Amenity) on(O) highway(B-Location) 43(I-Location) south(I-Location)"}, "label_list": ["Rating", "Amenity", "Restaurant Name", "Cuisine", "Price", "Location", "Dish", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 3383, 56685, 11, 26568, 4076, 11, 81961, 11, 8650, 11, 10067, 11, 49268, 11, 30192, 323, 507, 627, 85664, 25, 4587, 836, 682, 15926, 430, 3085, 44962, 3185, 3820, 709, 389, 27834, 220, 3391, 10007, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "427", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) are(O) some(O) funny(B-genre) betty(B-actor) white(I-actor) movies(O)", "instance": {"id": "427", "words": ["what", "are", "some", "funny", "betty", "white", "movies"], "labels": ["O", "O", "O", "B-genre", "B-actor", "I-actor", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, genre, average ratings, character, rating, trailer, year, review, actor, title, director, plot and O.\nSentence: what are some funny betty white movies", "prompt_labels": "what(O) are(O) some(O) funny(B-genre) betty(B-actor) white(I-actor) movies(O)"}, "label_list": ["song", "genre", "average ratings", "character", "rating", "trailer", "year", "review", "actor", "title", "director", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 17779, 11, 5578, 18594, 11, 3752, 11, 10959, 11, 19809, 11, 1060, 11, 3477, 11, 12360, 11, 2316, 11, 7690, 11, 7234, 323, 507, 627, 85664, 25, 1148, 527, 1063, 15526, 1297, 1919, 4251, 9698, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1094", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) are(O) the(O) average(B-Price) prices(O) for(O) lunch(B-Hours) at(O) mikanos(B-Restaurant Name)", "instance": {"id": "1094", "words": ["what", "are", "the", "average", "prices", "for", "lunch", "at", "mikanos"], "labels": ["O", "O", "O", "O", "O", "O", "B-Hours", "O", "B-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Location, Dish, Amenity, Hours, Price, Cuisine, Rating and O.\nSentence: what are the average prices for lunch at mikanos", "prompt_labels": "what(O) are(O) the(O) average(O) prices(O) for(O) lunch(B-Hours) at(O) mikanos(B-Restaurant Name)"}, "label_list": ["Restaurant Name", "Location", "Dish", "Amenity", "Hours", "Price", "Cuisine", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 10067, 11, 49268, 11, 3383, 56685, 11, 30192, 11, 8650, 11, 81961, 11, 19767, 323, 507, 627, 85664, 25, 1148, 527, 279, 5578, 7729, 369, 16163, 520, 296, 23014, 437, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1015", "dataset": "mit-restaurant", "split": "dev", "prediction": "of(O) the(O) restaurants(O) that(O) require(O) suit(B-Amenity) jackets(I-Amenity) for(O) men(O) which(O) have(O) the(O) best(B-Rating) service(I-Rating) and(O) food(O)", "instance": {"id": "1015", "words": ["of", "the", "restaurants", "that", "require", "suit", "jackets", "for", "men", "which", "have", "the", "best", "service", "and", "food"], "labels": ["O", "O", "O", "O", "B-Amenity", "I-Amenity", "I-Amenity", "I-Amenity", "I-Amenity", "O", "O", "O", "B-Rating", "I-Rating", "I-Rating", "I-Rating"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Cuisine, Dish, Location, Amenity, Price, Hours, Restaurant Name and O.\nSentence: of the restaurants that require suit jackets for men which have the best service and food", "prompt_labels": "of(O) the(O) restaurants(O) that(O) require(B-Amenity) suit(I-Amenity) jackets(I-Amenity) for(I-Amenity) men(I-Amenity) which(O) have(O) the(O) best(B-Rating) service(I-Rating) and(I-Rating) food(I-Rating)"}, "label_list": ["Rating", "Cuisine", "Dish", "Location", "Amenity", "Price", "Hours", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 81961, 11, 49268, 11, 10067, 11, 3383, 56685, 11, 8650, 11, 30192, 11, 26568, 4076, 323, 507, 627, 85664, 25, 315, 279, 15926, 430, 1397, 7937, 61242, 369, 3026, 902, 617, 279, 1888, 2532, 323, 3691, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "178", "dataset": "crossner_ai", "split": "dev", "prediction": "Decision(B-product) tree(I-product) learning(I-product),(O) neural(B-product) networks(I-product),(O) or(O) a(O) naive(B-metric) Bayes(I-metric) classifier(I-metric) could(O) be(O) used(O) in(O) combination(O) with(O) measures(O) of(O) model(O) quality(O) such(O) as(O) balanced(B-metric) accuracy(I-metric)", "instance": {"id": "178", "words": ["Decision", "tree", "learning", ",", "neural", "networks", ",", "or", "a", "naive", "Bayes", "classifier", "could", "be", "used", "in", "combination", "with", "measures", "of", "model", "quality", "such", "as", "balanced", "accuracy"], "labels": ["B-algorithm", "I-algorithm", "I-algorithm", "O", "B-algorithm", "I-algorithm", "O", "O", "O", "B-algorithm", "I-algorithm", "I-algorithm", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-metric", "I-metric"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, programming language, organization, product, algorithm, field, person, country, university, researcher, task, conference, metric and O.\nSentence: Decision tree learning , neural networks , or a naive Bayes classifier could be used in combination with measures of model quality such as balanced accuracy", "prompt_labels": "Decision(B-algorithm) tree(I-algorithm) learning(I-algorithm) ,(O) neural(B-algorithm) networks(I-algorithm) ,(O) or(O) a(O) naive(B-algorithm) Bayes(I-algorithm) classifier(I-algorithm) could(O) be(O) used(O) in(O) combination(O) with(O) measures(O) of(O) model(O) quality(O) such(O) as(O) balanced(B-metric) accuracy(I-metric)"}, "label_list": ["location", "programming language", "organization", "product", "algorithm", "field", "person", "country", "university", "researcher", "task", "conference", "metric"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 15840, 4221, 11, 7471, 11, 2027, 11, 12384, 11, 2115, 11, 1732, 11, 3224, 11, 12374, 11, 32185, 11, 3465, 11, 10017, 11, 18767, 323, 507, 627, 85664, 25, 41525, 5021, 6975, 1174, 30828, 14488, 1174, 477, 264, 50765, 9332, 288, 34465, 1436, 387, 1511, 304, 10824, 449, 11193, 315, 1646, 4367, 1778, 439, 24770, 13708, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "65", "dataset": "crossner_literature", "split": "dev", "prediction": "Among(O) the(O) books(O) found(O) in(O) his(O) library(O) ((O) as(O) evidenced(O) in(O) Lovecraft(B-writer)'s(O) Library(O) by(O) S.(B-writer) T.(I-writer) Joshi(I-writer) )(O) was(O) The(B-book) Seven(I-book) Who(I-book) Were(I-book) Hanged(I-book) by(O) Leonid(B-writer) Andreyev(I-writer) and(O) A(B-book) Strange(I-book) Manuscript(I-book) Found(I-book) in(I-book) a(I-book) Copper(I-book) Cylinder(I-book) by(O) James(B-writer) De(I-writer) Mille(I-writer).(O)", "instance": {"id": "65", "words": ["Among", "the", "books", "found", "in", "his", "library", "(", "as", "evidenced", "in", "Lovecraft", "'s", "Library", "by", "S.", "T.", "Joshi", ")", "was", "The", "Seven", "Who", "Were", "Hanged", "by", "Leonid", "Andreyev", "and", "A", "Strange", "Manuscript", "Found", "in", "a", "Copper", "Cylinder", "by", "James", "De", "Mille", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-book", "I-book", "I-book", "O", "B-writer", "I-writer", "I-writer", "O", "O", "B-book", "I-book", "I-book", "I-book", "I-book", "O", "B-writer", "I-writer", "O", "B-book", "I-book", "I-book", "I-book", "I-book", "I-book", "I-book", "I-book", "O", "B-writer", "I-writer", "I-writer", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, poem, location, literary genre, book, organization, writer, magazine, event, country, person and O.\nSentence: Among the books found in his library ( as evidenced in Lovecraft 's Library by S. T. Joshi ) was The Seven Who Were Hanged by Leonid Andreyev and A Strange Manuscript Found in a Copper Cylinder by James De Mille .", "prompt_labels": "Among(O) the(O) books(O) found(O) in(O) his(O) library(O) ((O) as(O) evidenced(O) in(O) Lovecraft(B-book) 's(I-book) Library(I-book) by(O) S.(B-writer) T.(I-writer) Joshi(I-writer) )(O) was(O) The(B-book) Seven(I-book) Who(I-book) Were(I-book) Hanged(I-book) by(O) Leonid(B-writer) Andreyev(I-writer) and(O) A(B-book) Strange(I-book) Manuscript(I-book) Found(I-book) in(I-book) a(I-book) Copper(I-book) Cylinder(I-book) by(O) James(B-writer) De(I-writer) Mille(I-writer) .(O)"}, "label_list": ["award", "poem", "location", "literary genre", "book", "organization", "writer", "magazine", "event", "country", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10292, 11, 33894, 11, 3813, 11, 32465, 17779, 11, 2363, 11, 7471, 11, 7061, 11, 14756, 11, 1567, 11, 3224, 11, 1732, 323, 507, 627, 85664, 25, 22395, 279, 6603, 1766, 304, 813, 6875, 320, 439, 69457, 304, 10919, 7868, 364, 82, 11896, 555, 328, 13, 350, 13, 28978, 6151, 883, 574, 578, 31048, 10699, 40070, 473, 3811, 555, 21605, 307, 1628, 8233, 5230, 323, 362, 43693, 96433, 1250, 12595, 304, 264, 43640, 87762, 555, 7957, 1611, 386, 4618, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "156", "dataset": "crossner_science", "split": "dev", "prediction": "An(O) approved(O) residency(O) program(O) and(O) certification(O) ((O) in(O) the(O) U.S.(B-country),(O) the(O) American(B-organization) Board(I-organization) of(I-organization) Pathology(I-organization) or(O) the(O) American(O) Osteopathic(B-organization) Board(I-organization) of(I-organization) Pathology(I-organization) )(O) is(O) usually(O) required(O) to(O) obtain(O) employment(O) or(O) hospital(O) privileges(O).(O)", "instance": {"id": "156", "words": ["An", "approved", "residency", "program", "and", "certification", "(", "in", "the", "U.S.", ",", "the", "American", "Board", "of", "Pathology", "or", "the", "American", "Osteopathic", "Board", "of", "Pathology", ")", "is", "usually", "required", "to", "obtain", "employment", "or", "hospital", "privileges", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-country", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, chemical element, scientist, academic journal, enzyme, location, award, chemical compound, discipline, organization, protein, theory, person, event, astronomical object, country and O.\nSentence: An approved residency program and certification ( in the U.S. , the American Board of Pathology or the American Osteopathic Board of Pathology ) is usually required to obtain employment or hospital privileges .", "prompt_labels": "An(O) approved(O) residency(O) program(O) and(O) certification(O) ((O) in(O) the(O) U.S.(B-country) ,(O) the(O) American(B-organization) Board(I-organization) of(I-organization) Pathology(I-organization) or(O) the(O) American(B-organization) Osteopathic(I-organization) Board(I-organization) of(I-organization) Pathology(I-organization) )(O) is(O) usually(O) required(O) to(O) obtain(O) employment(O) or(O) hospital(O) privileges(O) .(O)"}, "label_list": ["university", "chemical element", "scientist", "academic journal", "enzyme", "location", "award", "chemical compound", "discipline", "organization", "protein", "theory", "person", "event", "astronomical object", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12374, 11, 11742, 2449, 11, 28568, 11, 14584, 8486, 11, 49242, 11, 3813, 11, 10292, 11, 11742, 24549, 11, 26434, 11, 7471, 11, 13128, 11, 10334, 11, 1732, 11, 1567, 11, 87283, 1665, 11, 3224, 323, 507, 627, 85664, 25, 1556, 12054, 53966, 2068, 323, 28706, 320, 304, 279, 549, 815, 13, 1174, 279, 3778, 8925, 315, 8092, 2508, 477, 279, 3778, 507, 5455, 62209, 8925, 315, 8092, 2508, 883, 374, 6118, 2631, 311, 6994, 14740, 477, 8952, 36832, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1604", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) a(O) biographical(B-genre) movie(O) that(O) has(B-average ratings) excellent(I-average ratings) ratings(I-average ratings) starring(O) john(B-actor) travolta(I-actor)", "instance": {"id": "1604", "words": ["list", "a", "biographical", "movie", "that", "has", "excellent", "ratings", "starring", "john", "travolta"], "labels": ["O", "O", "B-genre", "O", "O", "B-average ratings", "I-average ratings", "I-average ratings", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, trailer, rating, plot, actor, song, director, review, character, year, average ratings, title and O.\nSentence: list a biographical movie that has excellent ratings starring john travolta", "prompt_labels": "list(O) a(O) biographical(B-genre) movie(O) that(O) has(B-average ratings) excellent(I-average ratings) ratings(I-average ratings) starring(O) john(B-actor) travolta(I-actor)"}, "label_list": ["genre", "trailer", "rating", "plot", "actor", "song", "director", "review", "character", "year", "average ratings", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 19809, 11, 10959, 11, 7234, 11, 12360, 11, 5609, 11, 7690, 11, 3477, 11, 3752, 11, 1060, 11, 5578, 18594, 11, 2316, 323, 507, 627, 85664, 25, 1160, 264, 6160, 32277, 5818, 430, 706, 9250, 18594, 40500, 40742, 10346, 60954, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
