step,epoch,loss,grad_norm,learning_rate
1,0.003,5.4258,57.5317497253418,0.0
2,0.006,5.5078,63.74260330200195,2.745215624227179e-06
3,0.009,4.6953,56.108192443847656,4.3510638207939e-06
4,0.012,5.7344,39.96726989746094,5.490431248454358e-06
5,0.015,4.6406,68.2396240234375,6.374193284416834e-06
6,0.018,5.4375,60.518795013427734,7.0962794450210784e-06
7,0.022,5.0078,89.36698150634766,7.706794594783609e-06
8,0.025,3.9961,59.42329788208008,8.235646872681536e-06
9,0.028,4.1875,71.17076873779297,8.7021276415878e-06
10,0.031,3.957,72.08007049560547,9.119408908644014e-06
11,0.034,3.2852,86.60801696777344,9.496885730428628e-06
12,0.037,3.8789,62.77805709838867,9.841495069248257e-06
