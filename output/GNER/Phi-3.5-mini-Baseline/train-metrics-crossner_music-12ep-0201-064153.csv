step,epoch,loss,grad_norm,learning_rate
1,0.04,4.0331,48.7724494934082,0.0
2,0.08,4.4224,48.4832878112793,5.578858913022597e-06
3,0.12,3.7713,46.250587463378906,8.842282173954808e-06
4,0.16,3.7831,43.810340881347656,1.1157717826045193e-05
5,0.2,3.4868,39.184417724609375,1.295370924755994e-05
6,0.24,2.7118,43.30793762207031,1.4421141086977404e-05
7,0.28,2.9987,68.6832046508789,1.5661837028938922e-05
8,0.32,2.5053,34.730674743652344,1.6736576739067793e-05
9,0.36,2.1626,41.31871032714844,1.7684564347909616e-05
10,0.4,1.8806,29.4478759765625,1.853256816058254e-05
11,0.44,1.5298,22.613431930541992,1.929968091962688e-05
12,0.48,1.5171,25.967676162719727,2e-05
13,0.52,1.2989,19.400836944580078,2e-05
14,0.56,1.0713,18.057497024536133,1.9930555555555556e-05
15,0.6,0.9962,26.23431968688965,1.9861111111111114e-05
16,0.64,0.6892,13.51997184753418,1.979166666666667e-05
17,0.68,0.8283,14.654605865478516,1.9722222222222224e-05
18,0.72,0.6684,9.060145378112793,1.9652777777777778e-05
19,0.76,0.7234,13.500117301940918,1.9583333333333333e-05
20,0.8,0.5933,10.575023651123047,1.951388888888889e-05
