{"id": "82", "dataset": "crossner_ai", "split": "dev", "prediction": "Researchers(O) have(O) attempted(O) a(O) number(O) of(O) methods(O) such(O) as(O) optical(B-algorithm) flow(I-algorithm),(O) Kalman(B-algorithm) filtering(I-algorithm),(O) Hidden(B-algorithm) Markov(I-algorithm) model(I-algorithm) s(O),(O) etc(O).(O)", "instance": {"id": "82", "words": ["Researchers", "have", "attempted", "a", "number", "of", "methods", "such", "as", "optical", "flow", ",", "Kalman", "filtering", ",", "Hidden", "Markov", "model", "s", ",", "etc", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-algorithm", "I-algorithm", "O", "B-algorithm", "I-algorithm", "O", "B-algorithm", "I-algorithm", "I-algorithm", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, field, task, researcher, location, country, product, programming language, metric, algorithm, conference, person, university and O.\nSentence: Researchers have attempted a number of methods such as optical flow , Kalman filtering , Hidden Markov model s , etc .", "prompt_labels": "Researchers(O) have(O) attempted(O) a(O) number(O) of(O) methods(O) such(O) as(O) optical(B-algorithm) flow(I-algorithm) ,(O) Kalman(B-algorithm) filtering(I-algorithm) ,(O) Hidden(B-algorithm) Markov(I-algorithm) model(I-algorithm) s(O) ,(O) etc(O) .(O)"}, "label_list": ["organization", "field", "task", "researcher", "location", "country", "product", "programming language", "metric", "algorithm", "conference", "person", "university"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 2115, 11, 3465, 11, 32185, 11, 3813, 11, 3224, 11, 2027, 11, 15840, 4221, 11, 18767, 11, 12384, 11, 10017, 11, 1732, 11, 12374, 323, 507, 627, 85664, 25, 59250, 617, 17644, 264, 1396, 315, 5528, 1778, 439, 29393, 6530, 1174, 27930, 1543, 30770, 1174, 35342, 4488, 869, 1646, 274, 1174, 5099, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "778", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) santa(B-Restaurant Name) ramen(I-Restaurant Name) in(O) san(B-Location) mateo(I-Location) busy(O) on(O) thursday(B-Hours) nights(I-Hours)", "instance": {"id": "778", "words": ["is", "santa", "ramen", "in", "san", "mateo", "busy", "on", "thursday", "nights"], "labels": ["O", "B-Restaurant Name", "I-Restaurant Name", "O", "B-Location", "I-Location", "O", "O", "B-Hours", "I-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Dish, Amenity, Rating, Cuisine, Restaurant Name, Price, Location and O.\nSentence: is santa ramen in san mateo busy on thursday nights", "prompt_labels": "is(O) santa(B-Restaurant Name) ramen(I-Restaurant Name) in(O) san(B-Location) mateo(I-Location) busy(O) on(O) thursday(B-Hours) nights(I-Hours)"}, "label_list": ["Hours", "Dish", "Amenity", "Rating", "Cuisine", "Restaurant Name", "Price", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 49268, 11, 3383, 56685, 11, 19767, 11, 81961, 11, 26568, 4076, 11, 8650, 11, 10067, 323, 507, 627, 85664, 25, 374, 72851, 123537, 304, 8528, 30276, 78, 13326, 389, 270, 7329, 22178, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "264", "dataset": "crossner_literature", "split": "dev", "prediction": "Ireland(B-country)'s(O) 1990(B-event) FIFA(I-event) World(I-event) Cup(I-event) Group(I-event) F(I-event) opponents(O) in(O) Italy(B-country) '(O) 90(O) were(O) England(B-country),(O) Egypt(B-country) and(O) the(O) Netherlands(B-country).(O)", "instance": {"id": "264", "words": ["Ireland", "'s", "1990", "FIFA", "World", "Cup", "Group", "F", "opponents", "in", "Italy", "'", "90", "were", "England", ",", "Egypt", "and", "the", "Netherlands", "."], "labels": ["B-country", "O", "B-event", "I-event", "I-event", "I-event", "I-event", "I-event", "O", "O", "B-country", "O", "O", "O", "B-country", "O", "B-country", "O", "O", "B-country", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, book, country, event, poem, magazine, location, writer, award, person, organization and O.\nSentence: Ireland 's 1990 FIFA World Cup Group F opponents in Italy ' 90 were England , Egypt and the Netherlands .", "prompt_labels": "Ireland(B-country) 's(O) 1990(B-event) FIFA(I-event) World(I-event) Cup(I-event) Group(I-event) F(I-event) opponents(O) in(O) Italy(B-country) '(O) 90(O) were(O) England(B-country) ,(O) Egypt(B-country) and(O) the(O) Netherlands(B-country) .(O)"}, "label_list": ["literary genre", "book", "country", "event", "poem", "magazine", "location", "writer", "award", "person", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 32465, 17779, 11, 2363, 11, 3224, 11, 1567, 11, 33894, 11, 14756, 11, 3813, 11, 7061, 11, 10292, 11, 1732, 11, 7471, 323, 507, 627, 85664, 25, 14990, 364, 82, 220, 2550, 15, 44742, 4435, 11098, 5856, 435, 19949, 304, 15704, 364, 220, 1954, 1051, 9635, 1174, 15212, 323, 279, 26746, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1228", "dataset": "mit-movie", "split": "dev", "prediction": "does(O) julia(B-actor) roberts(I-actor) have(O) a(O) voice(O) in(O) wall(B-title) e(I-title)", "instance": {"id": "1228", "words": ["does", "julia", "roberts", "have", "a", "voice", "in", "wall", "e"], "labels": ["O", "B-actor", "I-actor", "O", "O", "O", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, average ratings, rating, genre, title, director, song, plot, actor, trailer, review, year and O.\nSentence: does julia roberts have a voice in wall e", "prompt_labels": "does(O) julia(B-actor) roberts(I-actor) have(O) a(O) voice(O) in(O) wall(B-title) e(I-title)"}, "label_list": ["character", "average ratings", "rating", "genre", "title", "director", "song", "plot", "actor", "trailer", "review", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 5578, 18594, 11, 10959, 11, 17779, 11, 2316, 11, 7690, 11, 5609, 11, 7234, 11, 12360, 11, 19809, 11, 3477, 11, 1060, 323, 507, 627, 85664, 25, 1587, 41638, 689, 89993, 82, 617, 264, 7899, 304, 7147, 384, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1605", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) a(O) chick(B-genre) film(O) in(O) the(O) past(B-year) ten(I-year) decades(I-year)", "instance": {"id": "1605", "words": ["list", "a", "chick", "film", "in", "the", "past", "ten", "decades"], "labels": ["O", "O", "B-genre", "O", "O", "O", "B-year", "I-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, rating, song, review, title, plot, genre, year, trailer, average ratings, director, character and O.\nSentence: list a chick film in the past ten decades", "prompt_labels": "list(O) a(O) chick(B-genre) film(O) in(O) the(O) past(B-year) ten(I-year) decades(I-year)"}, "label_list": ["actor", "rating", "song", "review", "title", "plot", "genre", "year", "trailer", "average ratings", "director", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 10959, 11, 5609, 11, 3477, 11, 2316, 11, 7234, 11, 17779, 11, 1060, 11, 19809, 11, 5578, 18594, 11, 7690, 11, 3752, 323, 507, 627, 85664, 25, 1160, 264, 31863, 4632, 304, 279, 3347, 5899, 11026, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "872", "dataset": "mit-movie", "split": "dev", "prediction": "are(O) there(O) any(O) movies(O) about(O) the(O) korean(B-plot) war(I-plot)", "instance": {"id": "872", "words": ["are", "there", "any", "movies", "about", "the", "korean", "war"], "labels": ["O", "O", "O", "O", "O", "O", "B-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, director, trailer, year, actor, rating, title, song, genre, character, average ratings, plot and O.\nSentence: are there any movies about the korean war", "prompt_labels": "are(O) there(O) any(O) movies(O) about(O) the(O) korean(B-plot) war(I-plot)"}, "label_list": ["review", "director", "trailer", "year", "actor", "rating", "title", "song", "genre", "character", "average ratings", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 7690, 11, 19809, 11, 1060, 11, 12360, 11, 10959, 11, 2316, 11, 5609, 11, 17779, 11, 3752, 11, 5578, 18594, 11, 7234, 323, 507, 627, 85664, 25, 527, 1070, 904, 9698, 922, 279, 597, 46295, 4208, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2140", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movie(O) is(O) known(O) as(O) oliver(B-director) stones(I-director) best(O) work(O)", "instance": {"id": "2140", "words": ["what", "movie", "is", "known", "as", "oliver", "stones", "best", "work"], "labels": ["O", "O", "O", "O", "O", "B-director", "I-director", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, rating, review, year, song, title, average ratings, actor, genre, director, trailer, plot and O.\nSentence: what movie is known as oliver stones best work", "prompt_labels": "what(O) movie(O) is(O) known(O) as(O) oliver(B-director) stones(I-director) best(O) work(O)"}, "label_list": ["character", "rating", "review", "year", "song", "title", "average ratings", "actor", "genre", "director", "trailer", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 10959, 11, 3477, 11, 1060, 11, 5609, 11, 2316, 11, 5578, 18594, 11, 12360, 11, 17779, 11, 7690, 11, 19809, 11, 7234, 323, 507, 627, 85664, 25, 1148, 5818, 374, 3967, 439, 8492, 1553, 27302, 1888, 990, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "199", "dataset": "crossner_ai", "split": "dev", "prediction": "The(O) term(O) Semantic(B-field) Web(I-field) was(O) coined(O) by(O) Tim(B-researcher) Berners-Lee(I-researcher),(O) the(O) inventor(O) of(O) the(O) World(B-product) Wide(I-product) Web(I-product) and(O) director(O) of(O) the(O) World(B-organization) Wide(I-organization) Web(I-organization) Consortium(I-organization) ((O) W3C(B-organization) )(O),(O) which(O) oversees(O) the(O) development(O) of(O) proposed(O) Semantic(B-field) Web(I-field) standards(O).(O)", "instance": {"id": "199", "words": ["The", "term", "Semantic", "Web", "was", "coined", "by", "Tim", "Berners-Lee", ",", "the", "inventor", "of", "the", "World", "Wide", "Web", "and", "director", "of", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "which", "oversees", "the", "development", "of", "proposed", "Semantic", "Web", "standards", "."], "labels": ["O", "O", "B-product", "I-product", "O", "O", "O", "B-researcher", "I-researcher", "O", "O", "O", "O", "O", "B-product", "I-product", "I-product", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "O", "O", "O", "O", "O", "O", "O", "O", "B-product", "I-product", "I-product", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, task, conference, location, university, metric, person, field, country, organization, algorithm, researcher, product and O.\nSentence: The term Semantic Web was coined by Tim Berners-Lee , the inventor of the World Wide Web and director of the World Wide Web Consortium ( W3C ) , which oversees the development of proposed Semantic Web standards .", "prompt_labels": "The(O) term(O) Semantic(B-product) Web(I-product) was(O) coined(O) by(O) Tim(B-researcher) Berners-Lee(I-researcher) ,(O) the(O) inventor(O) of(O) the(O) World(B-product) Wide(I-product) Web(I-product) and(O) director(O) of(O) the(O) World(B-organization) Wide(I-organization) Web(I-organization) Consortium(I-organization) ((O) W3C(B-organization) )(O) ,(O) which(O) oversees(O) the(O) development(O) of(O) proposed(O) Semantic(B-product) Web(I-product) standards(I-product) .(O)"}, "label_list": ["programming language", "task", "conference", "location", "university", "metric", "person", "field", "country", "organization", "algorithm", "researcher", "product"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 15840, 4221, 11, 3465, 11, 10017, 11, 3813, 11, 12374, 11, 18767, 11, 1732, 11, 2115, 11, 3224, 11, 7471, 11, 12384, 11, 32185, 11, 2027, 323, 507, 627, 85664, 25, 578, 4751, 75433, 5000, 574, 78718, 555, 9538, 14502, 388, 8288, 2176, 1174, 279, 72001, 315, 279, 4435, 33845, 5000, 323, 7690, 315, 279, 4435, 33845, 5000, 73547, 320, 468, 18, 34, 883, 1174, 902, 71945, 279, 4500, 315, 11223, 75433, 5000, 10886, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "329", "dataset": "crossner_politics", "split": "dev", "prediction": "Alex(B-politician) T. Atamanenko(I-politician) MP(O) ((O) born(O) January(O) 24(O),(O) 1945(O) )(O) is(O) a(O) Canadian(O) politician(O),(O) who(O) was(O) elected(O) to(O) the(O) House(B-organization) of(I-organization) Commons(I-organization) in(O) 2006(O),(O) winning(O) the(O) riding(O) of(O) British(B-location) Columbia(I-location) Southern(I-location) Interior(I-location) for(O) the(O) New(B-political party) Democratic(I-political party) Party(I-political party) in(O) the(O) 2006(B-election) Canadian(I-election) federal(I-election) election(I-election),(O) and(O) served(O) in(O) parliament(O) until(O) his(O) retirement(O) at(O) the(O) 2015(B-election) Canadian(I-election) federal(I-election) election(I-election).(O)", "instance": {"id": "329", "words": ["Alex", "T.", "Atamanenko", "MP", "(", "born", "January", "24", ",", "1945", ")", "is", "a", "Canadian", "politician", ",", "who", "was", "elected", "to", "the", "House", "of", "Commons", "in", "2006", ",", "winning", "the", "riding", "of", "British", "Columbia", "Southern", "Interior", "for", "the", "New", "Democratic", "Party", "in", "the", "2006", "Canadian", "federal", "election", ",", "and", "served", "in", "parliament", "until", "his", "retirement", "at", "the", "2015", "Canadian", "federal", "election", "."], "labels": ["B-politician", "I-politician", "I-politician", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-political party", "I-political party", "I-political party", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, politician, person, country, location, organization, political party, event and O.\nSentence: Alex T. Atamanenko MP ( born January 24 , 1945 ) is a Canadian politician , who was elected to the House of Commons in 2006 , winning the riding of British Columbia Southern Interior for the New Democratic Party in the 2006 Canadian federal election , and served in parliament until his retirement at the 2015 Canadian federal election .", "prompt_labels": "Alex(B-politician) T.(I-politician) Atamanenko(I-politician) MP(O) ((O) born(O) January(O) 24(O) ,(O) 1945(O) )(O) is(O) a(O) Canadian(O) politician(O) ,(O) who(O) was(O) elected(O) to(O) the(O) House(B-organization) of(I-organization) Commons(I-organization) in(O) 2006(O) ,(O) winning(O) the(O) riding(O) of(O) British(B-organization) Columbia(I-organization) Southern(I-organization) Interior(I-organization) for(O) the(O) New(B-political party) Democratic(I-political party) Party(I-political party) in(O) the(O) 2006(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) and(O) served(O) in(O) parliament(O) until(O) his(O) retirement(O) at(O) the(O) 2015(B-election) Canadian(I-election) federal(I-election) election(I-election) .(O)"}, "label_list": ["election", "politician", "person", "country", "location", "organization", "political party", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 6355, 11, 37038, 11, 1732, 11, 3224, 11, 3813, 11, 7471, 11, 5054, 4717, 11, 1567, 323, 507, 627, 85664, 25, 8683, 350, 13, 2468, 13005, 56155, 9599, 320, 9405, 6186, 220, 1187, 1174, 220, 6393, 20, 883, 374, 264, 12152, 37038, 1174, 889, 574, 16689, 311, 279, 4783, 315, 26667, 304, 220, 1049, 21, 1174, 11230, 279, 20427, 315, 8013, 19326, 16642, 29958, 369, 279, 1561, 11650, 8722, 304, 279, 220, 1049, 21, 12152, 6918, 6355, 1174, 323, 10434, 304, 21814, 3156, 813, 21624, 520, 279, 220, 679, 20, 12152, 6918, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "257", "dataset": "crossner_ai", "split": "dev", "prediction": "Sub-domains(O) of(O) computer(B-field) vision(I-field) include(O) scene(B-task) reconstruction(I-task),(O) event(B-task) detection(I-task),(O) video(B-task) tracking(I-task),(O) object(B-task) recognition(I-task),(O) 3D(B-task) pose(I-task) estimation(I-task),(O) learning(B-field),(O) indexing(B-task),(O) motion(B-task) estimation(I-task),(O) visual(B-task) servoing(I-task),(O) 3D(B-task) scene(I-task) modeling(I-task),(O) and(O) image(B-task) restoration(I-task).(O)", "instance": {"id": "257", "words": ["Sub-domains", "of", "computer", "vision", "include", "scene", "reconstruction", ",", "event", "detection", ",", "video", "tracking", ",", "object", "recognition", ",", "3D", "pose", "estimation", ",", "learning", ",", "indexing", ",", "motion", "estimation", ",", "visual", "servoing", ",", "3D", "scene", "modeling", ",", "and", "image", "restoration", "."], "labels": ["O", "O", "B-field", "I-field", "O", "B-task", "I-task", "O", "B-task", "I-task", "O", "B-task", "I-task", "O", "B-task", "I-task", "O", "B-task", "I-task", "I-task", "O", "B-task", "O", "B-task", "O", "B-task", "I-task", "O", "B-task", "I-task", "O", "B-task", "I-task", "I-task", "O", "O", "B-task", "I-task", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, task, country, field, programming language, conference, product, metric, organization, researcher, university, algorithm, person and O.\nSentence: Sub-domains of computer vision include scene reconstruction , event detection , video tracking , object recognition , 3D pose estimation , learning , indexing , motion estimation , visual servoing , 3D scene modeling , and image restoration .", "prompt_labels": "Sub-domains(O) of(O) computer(B-field) vision(I-field) include(O) scene(B-task) reconstruction(I-task) ,(O) event(B-task) detection(I-task) ,(O) video(B-task) tracking(I-task) ,(O) object(B-task) recognition(I-task) ,(O) 3D(B-task) pose(I-task) estimation(I-task) ,(O) learning(B-task) ,(O) indexing(B-task) ,(O) motion(B-task) estimation(I-task) ,(O) visual(B-task) servoing(I-task) ,(O) 3D(B-task) scene(I-task) modeling(I-task) ,(O) and(O) image(B-task) restoration(I-task) .(O)"}, "label_list": ["location", "task", "country", "field", "programming language", "conference", "product", "metric", "organization", "researcher", "university", "algorithm", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 3465, 11, 3224, 11, 2115, 11, 15840, 4221, 11, 10017, 11, 2027, 11, 18767, 11, 7471, 11, 32185, 11, 12374, 11, 12384, 11, 1732, 323, 507, 627, 85664, 25, 3804, 14766, 1771, 315, 6500, 11376, 2997, 6237, 43738, 1174, 1567, 18468, 1174, 2835, 15194, 1174, 1665, 18324, 1174, 220, 18, 35, 17477, 42304, 1174, 6975, 1174, 53080, 1174, 11633, 42304, 1174, 9302, 59412, 287, 1174, 220, 18, 35, 6237, 34579, 1174, 323, 2217, 35093, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "884", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) a(O) white(B-Restaurant Name) castle(I-Restaurant Name) on(O) berkeley(B-Location) avenue(I-Location)", "instance": {"id": "884", "words": ["is", "there", "a", "white", "castle", "on", "berkeley", "avenue"], "labels": ["O", "O", "O", "B-Restaurant Name", "I-Restaurant Name", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Location, Cuisine, Rating, Amenity, Restaurant Name, Hours, Dish and O.\nSentence: is there a white castle on berkeley avenue", "prompt_labels": "is(O) there(O) a(O) white(B-Restaurant Name) castle(I-Restaurant Name) on(O) berkeley(B-Location) avenue(I-Location)"}, "label_list": ["Price", "Location", "Cuisine", "Rating", "Amenity", "Restaurant Name", "Hours", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 10067, 11, 81961, 11, 19767, 11, 3383, 56685, 11, 26568, 4076, 11, 30192, 11, 49268, 323, 507, 627, 85664, 25, 374, 1070, 264, 4251, 33684, 389, 10418, 28399, 62803, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "107", "dataset": "crossner_politics", "split": "dev", "prediction": "The(O) following(O) parties(O) have(O) won(O) the(O) special(O) seats(O) reserved(O) for(O) national(B-organization) minority(I-organization) representatives(I-organization) ((O) also(O) in(O) alphabetical(O) order(O) )(O) :(O) the(O) Bosnian(B-political party) Democratic(I-political party) Party(I-political party) of(I-political party) Croatia(I-political party),(O) the(O) Democratic(B-political party) Union(I-political party) of(I-political party) Hungarians(I-political party) of(I-political party) Croatia(I-political party),(O) the(O) German(B-political party) People(I-political party)'s(I-political party) Union(I-political party) -(O) National(B-organization) Association(I-organization) of(I-organization) Danube(I-organization) Swabians(I-organization) in(I-organization) Croatia(I-organization),(O) the(O) Independent(B-political party) Democratic(I-political party) Serb(I-political party) Party(I-political party),(O) the(O) Party(B-political party) of(I-political party) Democratic(I-political party) Action(I-political party) of(I-political party) Croatia(I-political party) and(O) the(O) Serb(B-political party) People(I-political party)'s(I-political party) Party(I-political party).(O)", "instance": {"id": "107", "words": ["The", "following", "parties", "have", "won", "the", "special", "seats", "reserved", "for", "national", "minority", "representatives", "(", "also", "in", "alphabetical", "order", ")", ":", "the", "Bosnian", "Democratic", "Party", "of", "Croatia", ",", "the", "Democratic", "Union", "of", "Hungarians", "of", "Croatia", ",", "the", "German", "People", "'s", "Union", "-", "National", "Association", "of", "Danube", "Swabians", "in", "Croatia", ",", "the", "Independent", "Democratic", "Serb", "Party", ",", "the", "Party", "of", "Democratic", "Action", "of", "Croatia", "and", "the", "Serb", "People", "'s", "Party", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, politician, location, organization, election, country, event, person and O.\nSentence: The following parties have won the special seats reserved for national minority representatives ( also in alphabetical order ) : the Bosnian Democratic Party of Croatia , the Democratic Union of Hungarians of Croatia , the German People 's Union - National Association of Danube Swabians in Croatia , the Independent Democratic Serb Party , the Party of Democratic Action of Croatia and the Serb People 's Party .", "prompt_labels": "The(O) following(O) parties(O) have(O) won(O) the(O) special(O) seats(O) reserved(O) for(O) national(O) minority(O) representatives(O) ((O) also(O) in(O) alphabetical(O) order(O) )(O) :(O) the(O) Bosnian(B-political party) Democratic(I-political party) Party(I-political party) of(I-political party) Croatia(I-political party) ,(O) the(O) Democratic(B-political party) Union(I-political party) of(I-political party) Hungarians(I-political party) of(I-political party) Croatia(I-political party) ,(O) the(O) German(B-political party) People(I-political party) 's(I-political party) Union(I-political party) -(I-political party) National(I-political party) Association(I-political party) of(I-political party) Danube(I-political party) Swabians(I-political party) in(I-political party) Croatia(I-political party) ,(O) the(O) Independent(B-political party) Democratic(I-political party) Serb(I-political party) Party(I-political party) ,(O) the(O) Party(B-political party) of(I-political party) Democratic(I-political party) Action(I-political party) of(I-political party) Croatia(I-political party) and(O) the(O) Serb(B-political party) People(I-political party) 's(I-political party) Party(I-political party) .(O)"}, "label_list": ["political party", "politician", "location", "organization", "election", "country", "event", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5054, 4717, 11, 37038, 11, 3813, 11, 7471, 11, 6355, 11, 3224, 11, 1567, 11, 1732, 323, 507, 627, 85664, 25, 578, 2768, 9875, 617, 2834, 279, 3361, 16712, 4694, 369, 5426, 23413, 24005, 320, 1101, 304, 84398, 2015, 883, 551, 279, 29071, 77, 1122, 11650, 8722, 315, 58311, 1174, 279, 11650, 9323, 315, 26604, 30627, 315, 58311, 1174, 279, 6063, 9029, 364, 82, 9323, 482, 5165, 10229, 315, 11824, 3845, 4593, 370, 5493, 304, 58311, 1174, 279, 22765, 11650, 8409, 65, 8722, 1174, 279, 8722, 315, 11650, 5703, 315, 58311, 323, 279, 8409, 65, 9029, 364, 82, 8722, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "281", "dataset": "crossner_literature", "split": "dev", "prediction": "Meanwhile(O),(O) Housman(B-writer) pursued(O) his(O) classical(O) studies(O) independently(O),(O) and(O) published(O) scholarly(O) articles(O) on(O) Horace(B-writer),(O) Propertius(B-writer),(O) Ovid(B-writer),(O) Aeschylus(B-writer),(O) Euripides(B-writer) and(O) Sophocles(B-writer).ref(O) Name(O) =(O) Poets(O) /(O) He(O) also(O) completed(O) an(O) edition(O) of(O) Propertius(B-writer),(O) which(O) however(O) was(O) rejected(O) by(O) both(O) Oxford(B-organization) University(I-organization) Press(I-organization) and(O) Macmillan(B-organization) in(O) 1885(O),(O) and(O) was(O) destroyed(O) after(O) his(O) death(O).(O)", "instance": {"id": "281", "words": ["Meanwhile", ",", "Housman", "pursued", "his", "classical", "studies", "independently", ",", "and", "published", "scholarly", "articles", "on", "Horace", ",", "Propertius", ",", "Ovid", ",", "Aeschylus", ",", "Euripides", "and", "Sophocles", ".ref", "Name", "=", "Poets", "/", "He", "also", "completed", "an", "edition", "of", "Propertius", ",", "which", "however", "was", "rejected", "by", "both", "Oxford", "University", "Press", "and", "Macmillan", "in", "1885", ",", "and", "was", "destroyed", "after", "his", "death", "."], "labels": ["O", "O", "B-writer", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-writer", "O", "B-writer", "O", "B-writer", "O", "B-writer", "O", "B-writer", "O", "B-writer", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-writer", "O", "O", "O", "O", "O", "O", "O", "B-magazine", "I-magazine", "I-magazine", "O", "B-magazine", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, book, award, country, writer, literary genre, poem, magazine, location, organization, event and O.\nSentence: Meanwhile , Housman pursued his classical studies independently , and published scholarly articles on Horace , Propertius , Ovid , Aeschylus , Euripides and Sophocles .ref Name = Poets / He also completed an edition of Propertius , which however was rejected by both Oxford University Press and Macmillan in 1885 , and was destroyed after his death .", "prompt_labels": "Meanwhile(O) ,(O) Housman(B-writer) pursued(O) his(O) classical(O) studies(O) independently(O) ,(O) and(O) published(O) scholarly(O) articles(O) on(O) Horace(B-writer) ,(O) Propertius(B-writer) ,(O) Ovid(B-writer) ,(O) Aeschylus(B-writer) ,(O) Euripides(B-writer) and(O) Sophocles(B-writer) .ref(O) Name(O) =(O) Poets(O) /(O) He(O) also(O) completed(O) an(O) edition(O) of(O) Propertius(B-writer) ,(O) which(O) however(O) was(O) rejected(O) by(O) both(O) Oxford(B-magazine) University(I-magazine) Press(I-magazine) and(O) Macmillan(B-magazine) in(O) 1885(O) ,(O) and(O) was(O) destroyed(O) after(O) his(O) death(O) .(O)"}, "label_list": ["person", "book", "award", "country", "writer", "literary genre", "poem", "magazine", "location", "organization", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 2363, 11, 10292, 11, 3224, 11, 7061, 11, 32465, 17779, 11, 33894, 11, 14756, 11, 3813, 11, 7471, 11, 1567, 323, 507, 627, 85664, 25, 26982, 1174, 473, 788, 1543, 46531, 813, 29924, 7978, 29235, 1174, 323, 4756, 63681, 9908, 389, 15083, 580, 1174, 3998, 531, 9334, 1174, 507, 1325, 1174, 362, 60478, 4010, 355, 1174, 85477, 575, 3422, 323, 34940, 511, 645, 662, 1116, 4076, 284, 14128, 1441, 611, 1283, 1101, 8308, 459, 14002, 315, 3998, 531, 9334, 1174, 902, 4869, 574, 18010, 555, 2225, 26275, 3907, 8612, 323, 7553, 26064, 276, 304, 220, 9367, 20, 1174, 323, 574, 14763, 1306, 813, 4648, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "231", "dataset": "crossner_music", "split": "dev", "prediction": "Soca(B-music genre) is(O) an(O) offshoot(O) of(O) kaiso(B-music genre) /(O) Calypso(B-music genre) music(I-music genre),(O) with(O) influences(O) from(O) Music(B-music genre) of(I-music genre) Latin(I-music genre) America(I-music genre),(O) Cadence(B-music genre) rampa(I-music genre),(O) funk(B-music genre) and(O) Soul(B-music genre) music(I-music genre).(O)", "instance": {"id": "231", "words": ["Soca", "is", "an", "offshoot", "of", "kaiso", "/", "Calypso", "music", ",", "with", "influences", "from", "Music", "of", "Latin", "America", ",", "Cadence", "rampa", ",", "funk", "and", "Soul", "music", "."], "labels": ["B-music genre", "O", "O", "O", "O", "B-music genre", "O", "B-music genre", "I-music genre", "O", "O", "O", "O", "B-music genre", "I-music genre", "I-music genre", "I-music genre", "O", "B-music genre", "I-music genre", "O", "B-music genre", "O", "B-music genre", "I-music genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, album, musical artist, award, event, person, song, band, location, country, organization, musical instrument and O.\nSentence: Soca is an offshoot of kaiso / Calypso music , with influences from Music of Latin America , Cadence rampa , funk and Soul music .", "prompt_labels": "Soca(B-music genre) is(O) an(O) offshoot(O) of(O) kaiso(B-music genre) /(O) Calypso(B-music genre) music(I-music genre) ,(O) with(O) influences(O) from(O) Music(B-music genre) of(I-music genre) Latin(I-music genre) America(I-music genre) ,(O) Cadence(B-music genre) rampa(I-music genre) ,(O) funk(B-music genre) and(O) Soul(B-music genre) music(I-music genre) .(O)"}, "label_list": ["music genre", "album", "musical artist", "award", "event", "person", "song", "band", "location", "country", "organization", "musical instrument"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 4731, 17779, 11, 8176, 11, 18273, 10255, 11, 10292, 11, 1567, 11, 1732, 11, 5609, 11, 7200, 11, 3813, 11, 3224, 11, 7471, 11, 18273, 14473, 323, 507, 627, 85664, 25, 328, 17270, 374, 459, 1022, 68392, 315, 597, 2852, 78, 611, 3400, 1100, 708, 4731, 1174, 449, 34453, 505, 10948, 315, 20023, 5270, 1174, 33160, 768, 23091, 64, 1174, 69392, 323, 30242, 4731, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1382", "dataset": "mit-movie", "split": "dev", "prediction": "im(O) looking(O) for(O) the(O) 1950(B-year) g(B-rating) rated(O) psychological(B-genre) movie(O) about(O) a(O) missing(B-plot) prisoner(I-plot) directed(O) by(O) michael(B-director) staininger(I-director)", "instance": {"id": "1382", "words": ["im", "looking", "for", "the", "1950", "g", "rated", "psychological", "movie", "about", "a", "missing", "prisoner", "directed", "by", "michael", "staininger"], "labels": ["O", "O", "O", "O", "B-year", "B-rating", "O", "B-genre", "O", "O", "O", "B-plot", "I-plot", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, average ratings, trailer, character, year, song, rating, plot, director, title, review, actor and O.\nSentence: im looking for the 1950 g rated psychological movie about a missing prisoner directed by michael staininger", "prompt_labels": "im(O) looking(O) for(O) the(O) 1950(B-year) g(B-rating) rated(O) psychological(B-genre) movie(O) about(O) a(O) missing(B-plot) prisoner(I-plot) directed(O) by(O) michael(B-director) staininger(I-director)"}, "label_list": ["genre", "average ratings", "trailer", "character", "year", "song", "rating", "plot", "director", "title", "review", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 5578, 18594, 11, 19809, 11, 3752, 11, 1060, 11, 5609, 11, 10959, 11, 7234, 11, 7690, 11, 2316, 11, 3477, 11, 12360, 323, 507, 627, 85664, 25, 737, 3411, 369, 279, 220, 6280, 15, 342, 22359, 24064, 5818, 922, 264, 7554, 42950, 15910, 555, 89006, 88896, 261, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "549", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movie(O) had(O) jim(B-actor) carrey(I-actor) as(O) a(O) dr(B-character) seuss(I-character) character(O)", "instance": {"id": "549", "words": ["what", "movie", "had", "jim", "carrey", "as", "a", "dr", "seuss", "character"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O", "O", "B-character", "I-character", "I-character"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, character, song, year, rating, director, trailer, plot, genre, average ratings, title, review and O.\nSentence: what movie had jim carrey as a dr seuss character", "prompt_labels": "what(O) movie(O) had(O) jim(B-actor) carrey(I-actor) as(O) a(O) dr(B-character) seuss(I-character) character(I-character)"}, "label_list": ["actor", "character", "song", "year", "rating", "director", "trailer", "plot", "genre", "average ratings", "title", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 3752, 11, 5609, 11, 1060, 11, 10959, 11, 7690, 11, 19809, 11, 7234, 11, 17779, 11, 5578, 18594, 11, 2316, 11, 3477, 323, 507, 627, 85664, 25, 1148, 5818, 1047, 96544, 1841, 8233, 439, 264, 1377, 513, 1892, 3752, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "83", "dataset": "mit-movie", "split": "dev", "prediction": "find(O) action(B-genre) movies(O) featuring(O) comic(B-character) book(I-character) characters(O)", "instance": {"id": "83", "words": ["find", "action", "movies", "featuring", "comic", "book", "characters"], "labels": ["O", "B-genre", "O", "O", "B-plot", "I-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, plot, genre, title, character, director, average ratings, trailer, review, rating, song, actor and O.\nSentence: find action movies featuring comic book characters", "prompt_labels": "find(O) action(B-genre) movies(O) featuring(O) comic(B-plot) book(I-plot) characters(I-plot)"}, "label_list": ["year", "plot", "genre", "title", "character", "director", "average ratings", "trailer", "review", "rating", "song", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 7234, 11, 17779, 11, 2316, 11, 3752, 11, 7690, 11, 5578, 18594, 11, 19809, 11, 3477, 11, 10959, 11, 5609, 11, 12360, 323, 507, 627, 85664, 25, 1505, 1957, 9698, 16850, 20303, 2363, 5885, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "289", "dataset": "crossner_music", "split": "dev", "prediction": "The(O) success(O) of(O) this(O) performance(O) lead(O) to(O) them(O) embarking(O) on(O) a(O) string(O) of(O) other(O) live(O) performances(O) in(O) 2009(O) and(O) 2010(O),(O) selling(O) out(O) prestigious(O) venues(O),(O) such(O) as(O) the(O) Queen(B-location) Elizabeth(I-location) Hall(I-location) in(O) London(B-location),(O) Volksb\u00fchne(B-location) in(O) Berlin(B-location) and(O) La(B-location) Cigale(I-location) in(O) Paris(B-location) before(O) they(O) returned(O) to(O) their(O) homeland(O) for(O) their(O) performance(O) at(O) The(B-location) Norwegian(I-location) Opera(I-location) House(I-location).(O)", "instance": {"id": "289", "words": ["The", "success", "of", "this", "performance", "lead", "to", "them", "embarking", "on", "a", "string", "of", "other", "live", "performances", "in", "2009", "and", "2010", ",", "selling", "out", "prestigious", "venues", ",", "such", "as", "the", "Queen", "Elizabeth", "Hall", "in", "London", ",", "Volksb\u00fchne", "in", "Berlin", "and", "La", "Cigale", "in", "Paris", "before", "they", "returned", "to", "their", "homeland", "for", "their", "performance", "at", "The", "Norwegian", "Opera", "House", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "I-location", "O", "B-location", "O", "B-location", "O", "B-band", "O", "B-location", "I-location", "O", "B-location", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "I-location", "I-location", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, song, musical artist, location, organization, person, album, band, country, award, music genre, event and O.\nSentence: The success of this performance lead to them embarking on a string of other live performances in 2009 and 2010 , selling out prestigious venues , such as the Queen Elizabeth Hall in London , Volksb\u00fchne in Berlin and La Cigale in Paris before they returned to their homeland for their performance at The Norwegian Opera House .", "prompt_labels": "The(O) success(O) of(O) this(O) performance(O) lead(O) to(O) them(O) embarking(O) on(O) a(O) string(O) of(O) other(O) live(O) performances(O) in(O) 2009(O) and(O) 2010(O) ,(O) selling(O) out(O) prestigious(O) venues(O) ,(O) such(O) as(O) the(O) Queen(B-location) Elizabeth(I-location) Hall(I-location) in(O) London(B-location) ,(O) Volksb\u00fchne(B-location) in(O) Berlin(B-band) and(O) La(B-location) Cigale(I-location) in(O) Paris(B-location) before(O) they(O) returned(O) to(O) their(O) homeland(O) for(O) their(O) performance(O) at(O) The(B-location) Norwegian(I-location) Opera(I-location) House(I-location) .(O)"}, "label_list": ["musical instrument", "song", "musical artist", "location", "organization", "person", "album", "band", "country", "award", "music genre", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18273, 14473, 11, 5609, 11, 18273, 10255, 11, 3813, 11, 7471, 11, 1732, 11, 8176, 11, 7200, 11, 3224, 11, 10292, 11, 4731, 17779, 11, 1567, 323, 507, 627, 85664, 25, 578, 2450, 315, 420, 5178, 3063, 311, 1124, 8126, 34552, 389, 264, 925, 315, 1023, 3974, 24601, 304, 220, 1049, 24, 323, 220, 679, 15, 1174, 11486, 704, 41385, 37278, 1174, 1778, 439, 279, 16657, 21393, 11166, 304, 7295, 1174, 11119, 2857, 65, 22284, 818, 304, 20437, 323, 5034, 356, 343, 1604, 304, 12366, 1603, 814, 6052, 311, 872, 56336, 369, 872, 5178, 520, 578, 45721, 39679, 4783, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "761", "dataset": "mit-movie", "split": "dev", "prediction": "what(B-rating) animated(I-rating) movies(I-rating) were(I-rating) nominated(I-rating) for(I-rating) oscars(I-rating)", "instance": {"id": "761", "words": ["what", "animated", "movies", "were", "nominated", "for", "oscars"], "labels": ["O", "B-genre", "O", "O", "B-average ratings", "I-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, rating, plot, director, trailer, actor, character, average ratings, genre, song, title, review and O.\nSentence: what animated movies were nominated for oscars", "prompt_labels": "what(O) animated(B-genre) movies(O) were(O) nominated(B-average ratings) for(I-average ratings) oscars(I-average ratings)"}, "label_list": ["year", "rating", "plot", "director", "trailer", "actor", "character", "average ratings", "genre", "song", "title", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 10959, 11, 7234, 11, 7690, 11, 19809, 11, 12360, 11, 3752, 11, 5578, 18594, 11, 17779, 11, 5609, 11, 2316, 11, 3477, 323, 507, 627, 85664, 25, 1148, 11625, 9698, 1051, 39048, 369, 32047, 1590, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1104", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) asian(B-Cuisine) restaurants(O) offer(O) carry(B-Amenity) out(I-Amenity)", "instance": {"id": "1104", "words": ["what", "asian", "restaurants", "offer", "carry", "out"], "labels": ["O", "B-Cuisine", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Amenity, Dish, Restaurant Name, Location, Hours, Price, Cuisine and O.\nSentence: what asian restaurants offer carry out", "prompt_labels": "what(O) asian(B-Cuisine) restaurants(O) offer(O) carry(B-Amenity) out(I-Amenity)"}, "label_list": ["Rating", "Amenity", "Dish", "Restaurant Name", "Location", "Hours", "Price", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 3383, 56685, 11, 49268, 11, 26568, 4076, 11, 10067, 11, 30192, 11, 8650, 11, 81961, 323, 507, 627, 85664, 25, 1148, 36725, 15926, 3085, 6920, 704, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2353", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) anthony(B-actor) hopkins(I-actor) in(O) a(O) musical(B-genre)", "instance": {"id": "2353", "words": ["is", "anthony", "hopkins", "in", "a", "musical"], "labels": ["O", "B-actor", "I-actor", "O", "O", "B-genre"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, plot, character, song, year, average ratings, actor, genre, review, rating, trailer, director and O.\nSentence: is anthony hopkins in a musical", "prompt_labels": "is(O) anthony(B-actor) hopkins(I-actor) in(O) a(O) musical(B-genre)"}, "label_list": ["title", "plot", "character", "song", "year", "average ratings", "actor", "genre", "review", "rating", "trailer", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 7234, 11, 3752, 11, 5609, 11, 1060, 11, 5578, 18594, 11, 12360, 11, 17779, 11, 3477, 11, 10959, 11, 19809, 11, 7690, 323, 507, 627, 85664, 25, 374, 23064, 3633, 7598, 11966, 304, 264, 18273, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "144", "dataset": "mit-restaurant", "split": "dev", "prediction": "can(O) you(O) find(O) a(O) site(O) where(O) i(O) can(O) see(O) reviews(B-Rating) on(O) restaurant(O) downtown(B-Location)", "instance": {"id": "144", "words": ["can", "you", "find", "a", "site", "where", "i", "can", "see", "reviews", "on", "restaurant", "downtown"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Hours, Cuisine, Restaurant Name, Price, Rating, Location, Amenity and O.\nSentence: can you find a site where i can see reviews on restaurant downtown", "prompt_labels": "can(O) you(O) find(O) a(O) site(O) where(O) i(O) can(O) see(O) reviews(O) on(O) restaurant(O) downtown(B-Location)"}, "label_list": ["Dish", "Hours", "Cuisine", "Restaurant Name", "Price", "Rating", "Location", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 30192, 11, 81961, 11, 26568, 4076, 11, 8650, 11, 19767, 11, 10067, 11, 3383, 56685, 323, 507, 627, 85664, 25, 649, 499, 1505, 264, 2816, 1405, 602, 649, 1518, 8544, 389, 10960, 19441, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "446", "dataset": "mit-restaurant", "split": "dev", "prediction": "find(O) restaurants(O) within(B-Location) 5(I-Location) miles(I-Location) with(O) entrees(O) under(B-Price) 15(I-Price)", "instance": {"id": "446", "words": ["find", "restaurants", "within", "5", "miles", "with", "entrees", "under", "15"], "labels": ["O", "O", "B-Location", "I-Location", "I-Location", "O", "B-Price", "I-Price", "I-Price"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Dish, Location, Hours, Restaurant Name, Price, Cuisine, Rating and O.\nSentence: find restaurants within 5 miles with entrees under 15", "prompt_labels": "find(O) restaurants(O) within(B-Location) 5(I-Location) miles(I-Location) with(O) entrees(B-Price) under(I-Price) 15(I-Price)"}, "label_list": ["Amenity", "Dish", "Location", "Hours", "Restaurant Name", "Price", "Cuisine", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 49268, 11, 10067, 11, 30192, 11, 26568, 4076, 11, 8650, 11, 81961, 11, 19767, 323, 507, 627, 85664, 25, 1505, 15926, 2949, 220, 20, 8931, 449, 1218, 8016, 1234, 220, 868, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "409", "dataset": "crossner_science", "split": "dev", "prediction": "He(O) won(O) silver(O) medals(O) at(O) the(O) 1989(B-event) Southeast(I-event) Asian(I-event) Games(I-event),(O) 1991(B-event) Southeast(I-event) Asian(I-event) Games(I-event),(O) and(O) 1993(B-event) Southeast(I-event) Asian(I-event) Games(I-event).(O)", "instance": {"id": "409", "words": ["He", "won", "silver", "medals", "at", "the", "1989", "Southeast", "Asian", "Games", ",", "1991", "Southeast", "Asian", "Games", ",", "and", "1993", "Southeast", "Asian", "Games", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "I-event", "O", "B-event", "I-event", "I-event", "I-event", "O", "O", "B-event", "I-event", "I-event", "I-event", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, person, scientist, protein, academic journal, organization, award, university, theory, location, chemical element, astronomical object, discipline, chemical compound, country, enzyme and O.\nSentence: He won silver medals at the 1989 Southeast Asian Games , 1991 Southeast Asian Games , and 1993 Southeast Asian Games .", "prompt_labels": "He(O) won(O) silver(O) medals(O) at(O) the(O) 1989(B-event) Southeast(I-event) Asian(I-event) Games(I-event) ,(O) 1991(B-event) Southeast(I-event) Asian(I-event) Games(I-event) ,(O) and(O) 1993(B-event) Southeast(I-event) Asian(I-event) Games(I-event) .(O)"}, "label_list": ["event", "person", "scientist", "protein", "academic journal", "organization", "award", "university", "theory", "location", "chemical element", "astronomical object", "discipline", "chemical compound", "country", "enzyme"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 1732, 11, 28568, 11, 13128, 11, 14584, 8486, 11, 7471, 11, 10292, 11, 12374, 11, 10334, 11, 3813, 11, 11742, 2449, 11, 87283, 1665, 11, 26434, 11, 11742, 24549, 11, 3224, 11, 49242, 323, 507, 627, 85664, 25, 1283, 2834, 15310, 60082, 520, 279, 220, 3753, 24, 36664, 14875, 11871, 1174, 220, 2550, 16, 36664, 14875, 11871, 1174, 323, 220, 2550, 18, 36664, 14875, 11871, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1238", "dataset": "mit-restaurant", "split": "dev", "prediction": "whats(O) the(O) closest(B-Location) restaurant(O) with(O) a(O) full(O) salad(B-Dish) bar(I-Dish)", "instance": {"id": "1238", "words": ["whats", "the", "closest", "restaurant", "with", "a", "full", "salad", "bar"], "labels": ["O", "O", "B-Location", "O", "O", "O", "B-Cuisine", "I-Cuisine", "I-Cuisine"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Amenity, Price, Cuisine, Hours, Dish, Rating, Restaurant Name and O.\nSentence: whats the closest restaurant with a full salad bar", "prompt_labels": "whats(O) the(O) closest(B-Location) restaurant(O) with(O) a(O) full(B-Cuisine) salad(I-Cuisine) bar(I-Cuisine)"}, "label_list": ["Location", "Amenity", "Price", "Cuisine", "Hours", "Dish", "Rating", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 3383, 56685, 11, 8650, 11, 81961, 11, 30192, 11, 49268, 11, 19767, 11, 26568, 4076, 323, 507, 627, 85664, 25, 41209, 279, 18585, 10960, 449, 264, 2539, 33566, 3703, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "202", "dataset": "crossner_politics", "split": "dev", "prediction": "She(O) was(O) re-elected(O) to(O) additional(O) terms(O) in(O) 1974(B-election) Australian(I-election) federal(I-election) election(I-election),(O) 1975(B-election) Australian(I-election) federal(I-election) election(I-election),(O) and(O) 1980(B-election) Australian(I-election) federal(I-election) election(I-election),(O) retiring(O) on(O) 5(O) June(O) 1987(O) at(O) the(O) end(O) of(O) her(O) final(O) term(O).(O)", "instance": {"id": "202", "words": ["She", "was", "re-elected", "to", "additional", "terms", "in", "1974", "Australian", "federal", "election", ",", "1975", "Australian", "federal", "election", ",", "and", "1980", "Australian", "federal", "election", ",", "retiring", "on", "5", "June", "1987", "at", "the", "end", "of", "her", "final", "term", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, politician, election, organization, event, political party, location, country and O.\nSentence: She was re-elected to additional terms in 1974 Australian federal election , 1975 Australian federal election , and 1980 Australian federal election , retiring on 5 June 1987 at the end of her final term .", "prompt_labels": "She(O) was(O) re-elected(O) to(O) additional(O) terms(O) in(O) 1974(B-election) Australian(I-election) federal(I-election) election(I-election) ,(O) 1975(B-election) Australian(I-election) federal(I-election) election(I-election) ,(O) and(O) 1980(B-election) Australian(I-election) federal(I-election) election(I-election) ,(O) retiring(O) on(O) 5(O) June(O) 1987(O) at(O) the(O) end(O) of(O) her(O) final(O) term(O) .(O)"}, "label_list": ["person", "politician", "election", "organization", "event", "political party", "location", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 37038, 11, 6355, 11, 7471, 11, 1567, 11, 5054, 4717, 11, 3813, 11, 3224, 323, 507, 627, 85664, 25, 3005, 574, 312, 96805, 311, 5217, 3878, 304, 220, 4468, 19, 13673, 6918, 6355, 1174, 220, 4468, 20, 13673, 6918, 6355, 1174, 323, 220, 3753, 15, 13673, 6918, 6355, 1174, 60873, 389, 220, 20, 5651, 220, 3753, 22, 520, 279, 842, 315, 1077, 1620, 4751, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "971", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) scariest(B-review) horror(B-genre) movie(I-genre) from(O) the(O) 90s(B-year)", "instance": {"id": "971", "words": ["what", "is", "the", "scariest", "horror", "movie", "from", "the", "90s"], "labels": ["O", "O", "O", "B-genre", "I-genre", "O", "O", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, song, plot, director, trailer, actor, review, title, rating, character, year, average ratings and O.\nSentence: what is the scariest horror movie from the 90s", "prompt_labels": "what(O) is(O) the(O) scariest(B-genre) horror(I-genre) movie(O) from(O) the(O) 90s(B-year)"}, "label_list": ["genre", "song", "plot", "director", "trailer", "actor", "review", "title", "rating", "character", "year", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 5609, 11, 7234, 11, 7690, 11, 19809, 11, 12360, 11, 3477, 11, 2316, 11, 10959, 11, 3752, 11, 1060, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1148, 374, 279, 1156, 2850, 478, 22169, 5818, 505, 279, 220, 1954, 82, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "272", "dataset": "mit-restaurant", "split": "dev", "prediction": "do(O) you(O) think(O) tin(B-Restaurant Name) whistle(I-Restaurant Name) has(O) fabulous(B-Rating) service(I-Rating)", "instance": {"id": "272", "words": ["do", "you", "think", "tin", "whistle", "has", "fabulous", "service"], "labels": ["O", "O", "O", "B-Restaurant Name", "I-Restaurant Name", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Dish, Price, Rating, Restaurant Name, Hours, Amenity, Location and O.\nSentence: do you think tin whistle has fabulous service", "prompt_labels": "do(O) you(O) think(O) tin(B-Restaurant Name) whistle(I-Restaurant Name) has(O) fabulous(B-Amenity) service(I-Amenity)"}, "label_list": ["Cuisine", "Dish", "Price", "Rating", "Restaurant Name", "Hours", "Amenity", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 49268, 11, 8650, 11, 19767, 11, 26568, 4076, 11, 30192, 11, 3383, 56685, 11, 10067, 323, 507, 627, 85664, 25, 656, 499, 1781, 25826, 40649, 706, 35631, 2532, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "782", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) the(O) chateau(B-Restaurant Name) restaurant(O) affordable(B-Price)", "instance": {"id": "782", "words": ["is", "the", "chateau", "restaurant", "affordable"], "labels": ["O", "O", "B-Restaurant Name", "I-Restaurant Name", "B-Price"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Hours, Dish, Cuisine, Rating, Location, Restaurant Name, Price and O.\nSentence: is the chateau restaurant affordable", "prompt_labels": "is(O) the(O) chateau(B-Restaurant Name) restaurant(I-Restaurant Name) affordable(B-Price)"}, "label_list": ["Amenity", "Hours", "Dish", "Cuisine", "Rating", "Location", "Restaurant Name", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 30192, 11, 49268, 11, 81961, 11, 19767, 11, 10067, 11, 26568, 4076, 11, 8650, 323, 507, 627, 85664, 25, 374, 279, 523, 77725, 10960, 17049, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "329", "dataset": "crossner_music", "split": "dev", "prediction": "Jimmie(B-musical artist) Rodgers(I-musical artist),(O) Moon(B-musical artist) Mullican(I-musical artist),(O) Bob(B-musical artist) Wills(I-musical artist),(O) Bill(B-musical artist) Monroe(I-musical artist) and(O) Hank(B-musical artist) Williams(I-musical artist) have(O) all(O) described(O) themselves(O) as(O) blues(O) singers(O) and(O) their(O) music(O) has(O) a(O) blues(O) feel(O) that(O) is(O) different(O),(O) at(O) first(O) glance(O) at(O) least(O),(O) from(O) the(O) later(O) country(B-music genre) pop(I-music genre) of(O) artists(O) like(O) Eddy(B-musical artist) Arnold(I-musical artist).(O)", "instance": {"id": "329", "words": ["Jimmie", "Rodgers", ",", "Moon", "Mullican", ",", "Bob", "Wills", ",", "Bill", "Monroe", "and", "Hank", "Williams", "have", "all", "described", "themselves", "as", "blues", "singers", "and", "their", "music", "has", "a", "blues", "feel", "that", "is", "different", ",", "at", "first", "glance", "at", "least", ",", "from", "the", "later", "country", "pop", "of", "artists", "like", "Eddy", "Arnold", "."], "labels": ["B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "O", "O", "O", "O", "B-music genre", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-music genre", "I-music genre", "O", "O", "O", "B-musical artist", "I-musical artist", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, band, location, person, event, organization, country, musical instrument, album, musical artist, music genre, award and O.\nSentence: Jimmie Rodgers , Moon Mullican , Bob Wills , Bill Monroe and Hank Williams have all described themselves as blues singers and their music has a blues feel that is different , at first glance at least , from the later country pop of artists like Eddy Arnold .", "prompt_labels": "Jimmie(B-musical artist) Rodgers(I-musical artist) ,(O) Moon(B-musical artist) Mullican(I-musical artist) ,(O) Bob(B-musical artist) Wills(I-musical artist) ,(O) Bill(B-musical artist) Monroe(I-musical artist) and(O) Hank(B-musical artist) Williams(I-musical artist) have(O) all(O) described(O) themselves(O) as(O) blues(B-music genre) singers(O) and(O) their(O) music(O) has(O) a(O) blues(O) feel(O) that(O) is(O) different(O) ,(O) at(O) first(O) glance(O) at(O) least(O) ,(O) from(O) the(O) later(O) country(B-music genre) pop(I-music genre) of(O) artists(O) like(O) Eddy(B-musical artist) Arnold(I-musical artist) .(O)"}, "label_list": ["song", "band", "location", "person", "event", "organization", "country", "musical instrument", "album", "musical artist", "music genre", "award"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 7200, 11, 3813, 11, 1732, 11, 1567, 11, 7471, 11, 3224, 11, 18273, 14473, 11, 8176, 11, 18273, 10255, 11, 4731, 17779, 11, 10292, 323, 507, 627, 85664, 25, 11641, 74696, 50117, 1174, 17781, 30451, 416, 276, 1174, 14596, 468, 3385, 1174, 8766, 50887, 323, 55761, 13926, 617, 682, 7633, 5694, 439, 44695, 68141, 323, 872, 4731, 706, 264, 44695, 2733, 430, 374, 2204, 1174, 520, 1176, 34522, 520, 3325, 1174, 505, 279, 3010, 3224, 2477, 315, 13820, 1093, 469, 54610, 44312, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "98", "dataset": "crossner_politics", "split": "dev", "prediction": "Hugo(B-politician) Ch\u00e1vez(I-politician),(O) the(O) central(O) figure(O) of(O) the(O) Venezuelan(O) political(O) landscape(O) since(O) 1998(O) Venezuelan(O) presidential(O) election(O) as(O) a(O) political(O) outsider(O),(O) died(O) in(O) office(O) in(O) early(O) 2013(O),(O) and(O) was(O) succeeded(O) by(O) Nicol\u00e1s(B-politician) Maduro(I-politician),(O) initially(O) as(O) interim(O) President(O),(O) before(O) winning(O) 2013(B-election) Venezuelan(I-election) presidential(I-election) election(I-election) and(O) re-election(O) in(O) 2018(B-election) Venezuelan(I-election) presidential(I-election) election(I-election).(O)", "instance": {"id": "98", "words": ["Hugo", "Ch\u00e1vez", ",", "the", "central", "figure", "of", "the", "Venezuelan", "political", "landscape", "since", "1998", "Venezuelan", "presidential", "election", "as", "a", "political", "outsider", ",", "died", "in", "office", "in", "early", "2013", ",", "and", "was", "succeeded", "by", "Nicol\u00e1s", "Maduro", ",", "initially", "as", "interim", "President", ",", "before", "winning", "2013", "Venezuelan", "presidential", "election", "and", "re-election", "in", "2018", "Venezuelan", "presidential", "election", "."], "labels": ["B-politician", "I-politician", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-politician", "I-politician", "O", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, election, country, political party, event, person, location, politician and O.\nSentence: Hugo Ch\u00e1vez , the central figure of the Venezuelan political landscape since 1998 Venezuelan presidential election as a political outsider , died in office in early 2013 , and was succeeded by Nicol\u00e1s Maduro , initially as interim President , before winning 2013 Venezuelan presidential election and re-election in 2018 Venezuelan presidential election .", "prompt_labels": "Hugo(B-politician) Ch\u00e1vez(I-politician) ,(O) the(O) central(O) figure(O) of(O) the(O) Venezuelan(O) political(O) landscape(O) since(O) 1998(B-election) Venezuelan(I-election) presidential(I-election) election(I-election) as(O) a(O) political(O) outsider(O) ,(O) died(O) in(O) office(O) in(O) early(O) 2013(O) ,(O) and(O) was(O) succeeded(O) by(O) Nicol\u00e1s(B-politician) Maduro(I-politician) ,(O) initially(O) as(O) interim(O) President(O) ,(O) before(O) winning(O) 2013(B-election) Venezuelan(I-election) presidential(I-election) election(I-election) and(O) re-election(O) in(O) 2018(B-election) Venezuelan(I-election) presidential(I-election) election(I-election) .(O)"}, "label_list": ["organization", "election", "country", "political party", "event", "person", "location", "politician"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 6355, 11, 3224, 11, 5054, 4717, 11, 1567, 11, 1732, 11, 3813, 11, 37038, 323, 507, 627, 85664, 25, 52194, 921, 1995, 19610, 1174, 279, 8792, 7216, 315, 279, 83749, 5054, 18921, 2533, 220, 2550, 23, 83749, 13621, 6355, 439, 264, 5054, 75683, 1174, 8636, 304, 5274, 304, 4216, 220, 679, 18, 1174, 323, 574, 26399, 555, 83440, 7206, 78802, 1174, 15453, 439, 41653, 4900, 1174, 1603, 11230, 220, 679, 18, 83749, 13621, 6355, 323, 312, 43733, 304, 220, 679, 23, 83749, 13621, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "204", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) people(O) like(B-review) or(I-review) hate(I-review) the(O) last(O) twilight(B-title) movie(O)", "instance": {"id": "204", "words": ["did", "people", "like", "or", "hate", "the", "last", "twilight", "movie"], "labels": ["O", "O", "B-review", "O", "B-review", "O", "O", "B-title", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, actor, year, average ratings, character, song, review, title, rating, trailer, genre, plot and O.\nSentence: did people like or hate the last twilight movie", "prompt_labels": "did(O) people(O) like(B-review) or(O) hate(B-review) the(O) last(O) twilight(B-title) movie(O)"}, "label_list": ["director", "actor", "year", "average ratings", "character", "song", "review", "title", "rating", "trailer", "genre", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 12360, 11, 1060, 11, 5578, 18594, 11, 3752, 11, 5609, 11, 3477, 11, 2316, 11, 10959, 11, 19809, 11, 17779, 11, 7234, 323, 507, 627, 85664, 25, 1550, 1274, 1093, 477, 12491, 279, 1566, 93722, 5818, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1017", "dataset": "mit-restaurant", "split": "dev", "prediction": "please(O) find(O) a(O) japanese(B-Cuisine) place(O) that(O) near(B-Location) an(I-Location) indian(I-Location) restaurant(I-Location)", "instance": {"id": "1017", "words": ["please", "find", "a", "japanese", "place", "that", "near", "an", "indian", "restaurant"], "labels": ["O", "O", "O", "B-Cuisine", "O", "O", "B-Location", "O", "B-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Restaurant Name, Cuisine, Hours, Location, Amenity, Rating, Dish and O.\nSentence: please find a japanese place that near an indian restaurant", "prompt_labels": "please(O) find(O) a(O) japanese(B-Cuisine) place(O) that(O) near(B-Location) an(O) indian(B-Cuisine) restaurant(O)"}, "label_list": ["Price", "Restaurant Name", "Cuisine", "Hours", "Location", "Amenity", "Rating", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 26568, 4076, 11, 81961, 11, 30192, 11, 10067, 11, 3383, 56685, 11, 19767, 11, 49268, 323, 507, 627, 85664, 25, 4587, 1505, 264, 54048, 2035, 430, 3221, 459, 43325, 10960, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1146", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) jacob(B-title) ransom(I-title) have(O) a(O) movie(O) about(O) fear(B-plot) of(I-plot) marriage(I-plot) that(O) was(O) rated(O) seven(B-average ratings) in(O) the(O) last(B-year) five(I-year) decades(I-year)", "instance": {"id": "1146", "words": ["did", "jacob", "ransom", "have", "a", "movie", "about", "fear", "of", "marriage", "that", "was", "rated", "seven", "in", "the", "last", "five", "decades"], "labels": ["O", "B-director", "I-director", "O", "O", "O", "O", "B-plot", "I-plot", "I-plot", "O", "O", "O", "B-average ratings", "O", "O", "B-year", "I-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, title, plot, trailer, rating, genre, average ratings, character, director, year, actor, review and O.\nSentence: did jacob ransom have a movie about fear of marriage that was rated seven in the last five decades", "prompt_labels": "did(O) jacob(B-director) ransom(I-director) have(O) a(O) movie(O) about(O) fear(B-plot) of(I-plot) marriage(I-plot) that(O) was(O) rated(O) seven(B-average ratings) in(O) the(O) last(B-year) five(I-year) decades(I-year)"}, "label_list": ["song", "title", "plot", "trailer", "rating", "genre", "average ratings", "character", "director", "year", "actor", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 2316, 11, 7234, 11, 19809, 11, 10959, 11, 17779, 11, 5578, 18594, 11, 3752, 11, 7690, 11, 1060, 11, 12360, 11, 3477, 323, 507, 627, 85664, 25, 1550, 503, 40051, 58686, 617, 264, 5818, 922, 8850, 315, 11103, 430, 574, 22359, 8254, 304, 279, 1566, 4330, 11026, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "246", "dataset": "crossner_literature", "split": "dev", "prediction": "He(O) also(O) led(O) the(O) trend(O) for(O) pastoral(B-literary genre) poetry(I-literary genre) and(O) his(O) pastoral(B-book) opera(I-book) The(B-book) Gentle(I-book) Shepherd(I-book) was(O) one(O) of(O) the(O) most(O) influential(O) works(O) of(O) the(O) era(O).(O)", "instance": {"id": "246", "words": ["He", "also", "led", "the", "trend", "for", "pastoral", "poetry", "and", "his", "pastoral", "opera", "The", "Gentle", "Shepherd", "was", "one", "of", "the", "most", "influential", "works", "of", "the", "era", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-literary genre", "I-literary genre", "O", "O", "B-literary genre", "I-literary genre", "B-poem", "I-poem", "I-poem", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, award, person, country, event, magazine, writer, organization, location, book, poem and O.\nSentence: He also led the trend for pastoral poetry and his pastoral opera The Gentle Shepherd was one of the most influential works of the era .", "prompt_labels": "He(O) also(O) led(O) the(O) trend(O) for(O) pastoral(B-literary genre) poetry(I-literary genre) and(O) his(O) pastoral(B-literary genre) opera(I-literary genre) The(B-poem) Gentle(I-poem) Shepherd(I-poem) was(O) one(O) of(O) the(O) most(O) influential(O) works(O) of(O) the(O) era(O) .(O)"}, "label_list": ["literary genre", "award", "person", "country", "event", "magazine", "writer", "organization", "location", "book", "poem"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 32465, 17779, 11, 10292, 11, 1732, 11, 3224, 11, 1567, 11, 14756, 11, 7061, 11, 7471, 11, 3813, 11, 2363, 11, 33894, 323, 507, 627, 85664, 25, 1283, 1101, 6197, 279, 9327, 369, 90371, 32349, 323, 813, 90371, 43516, 578, 74569, 59646, 574, 832, 315, 279, 1455, 32549, 4375, 315, 279, 11639, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "79", "dataset": "crossner_politics", "split": "dev", "prediction": "He(O) was(O) the(O) American(B-political party) Independent(I-political party) Party(I-political party) vice(O) presidential(O) nominee(O) under(O) John(B-politician) G.(I-politician) Schmitz(I-politician) in(O) 1972(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) and(O) the(O) American(B-political party) Party(I-political party) presidential(O) nominee(O) in(O) 1976(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election).(O)", "instance": {"id": "79", "words": ["He", "was", "the", "American", "Independent", "Party", "vice", "presidential", "nominee", "under", "John", "G.", "Schmitz", "in", "1972", "United", "States", "presidential", "election", "and", "the", "American", "Party", "presidential", "nominee", "in", "1976", "United", "States", "presidential", "election", "."], "labels": ["O", "O", "O", "B-political party", "I-political party", "I-political party", "O", "O", "O", "O", "B-politician", "I-politician", "I-politician", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, event, location, organization, political party, election, politician, country and O.\nSentence: He was the American Independent Party vice presidential nominee under John G. Schmitz in 1972 United States presidential election and the American Party presidential nominee in 1976 United States presidential election .", "prompt_labels": "He(O) was(O) the(O) American(B-political party) Independent(I-political party) Party(I-political party) vice(O) presidential(O) nominee(O) under(O) John(B-politician) G.(I-politician) Schmitz(I-politician) in(O) 1972(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) and(O) the(O) American(O) Party(O) presidential(O) nominee(O) in(O) 1976(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) .(O)"}, "label_list": ["person", "event", "location", "organization", "political party", "election", "politician", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 1567, 11, 3813, 11, 7471, 11, 5054, 4717, 11, 6355, 11, 37038, 11, 3224, 323, 507, 627, 85664, 25, 1283, 574, 279, 3778, 22765, 8722, 17192, 13621, 29311, 1234, 3842, 480, 13, 5124, 1800, 89, 304, 220, 4468, 17, 3723, 4273, 13621, 6355, 323, 279, 3778, 8722, 13621, 29311, 304, 220, 4468, 21, 3723, 4273, 13621, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "223", "dataset": "crossner_politics", "split": "dev", "prediction": "In(O) 1966(O),(O) he(O) used(O) some(O) of(O) his(O) wealth(O) to(O) form(O) the(O) Liberal(B-political party) Reform(I-political party) Group(I-political party),(O) a(O) splinter(O) group(O) of(O) members(O) of(O) the(O) Liberal(B-political party) Party(I-political party) of(I-political party) Australia(I-political party) disenchanted(O) with(O) their(O) party(O)'s(O) support(O) for(O) the(O) Vietnam(B-event) War(I-event) ;(O) this(O) became(O) the(O) Australian(B-political party) Reform(I-political party) Movement(I-political party) and(O) then(O) the(O) Australia(B-political party) Party(I-political party),(O) the(O) precursor(O) of(O) the(O) Australian(B-political party) Democrats(I-political party).(O)", "instance": {"id": "223", "words": ["In", "1966", ",", "he", "used", "some", "of", "his", "wealth", "to", "form", "the", "Liberal", "Reform", "Group", ",", "a", "splinter", "group", "of", "members", "of", "the", "Liberal", "Party", "of", "Australia", "disenchanted", "with", "their", "party", "'s", "support", "for", "the", "Vietnam", "War", ";", "this", "became", "the", "Australian", "Reform", "Movement", "and", "then", "the", "Australia", "Party", ",", "the", "precursor", "of", "the", "Australian", "Democrats", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "O", "O", "O", "B-political party", "I-political party", "O", "O", "O", "O", "O", "B-political party", "I-political party", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, country, political party, organization, location, politician, person, event and O.\nSentence: In 1966 , he used some of his wealth to form the Liberal Reform Group , a splinter group of members of the Liberal Party of Australia disenchanted with their party 's support for the Vietnam War ; this became the Australian Reform Movement and then the Australia Party , the precursor of the Australian Democrats .", "prompt_labels": "In(O) 1966(O) ,(O) he(O) used(O) some(O) of(O) his(O) wealth(O) to(O) form(O) the(O) Liberal(B-political party) Reform(I-political party) Group(I-political party) ,(O) a(O) splinter(O) group(O) of(O) members(O) of(O) the(O) Liberal(B-political party) Party(I-political party) of(I-political party) Australia(I-political party) disenchanted(O) with(O) their(O) party(O) 's(O) support(O) for(O) the(O) Vietnam(B-event) War(I-event) ;(O) this(O) became(O) the(O) Australian(B-political party) Reform(I-political party) Movement(I-political party) and(O) then(O) the(O) Australia(B-political party) Party(I-political party) ,(O) the(O) precursor(O) of(O) the(O) Australian(B-political party) Democrats(I-political party) .(O)"}, "label_list": ["election", "country", "political party", "organization", "location", "politician", "person", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 6355, 11, 3224, 11, 5054, 4717, 11, 7471, 11, 3813, 11, 37038, 11, 1732, 11, 1567, 323, 507, 627, 85664, 25, 763, 220, 5162, 21, 1174, 568, 1511, 1063, 315, 813, 12205, 311, 1376, 279, 31158, 40365, 5856, 1174, 264, 12786, 2295, 1912, 315, 3697, 315, 279, 31158, 8722, 315, 8494, 834, 20345, 7719, 449, 872, 4717, 364, 82, 1862, 369, 279, 23315, 5111, 2652, 420, 6244, 279, 13673, 40365, 29098, 323, 1243, 279, 8494, 8722, 1174, 279, 71261, 315, 279, 13673, 12643, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "188", "dataset": "crossner_music", "split": "dev", "prediction": "They(O) were(O) inducted(O) by(O) Chuck(B-musical artist) D(I-musical artist) and(O) LL(B-musical artist) Cool(I-musical artist) J(I-musical artist) on(O) April(O) 14(O),(O) 2012(O) therefore(O) the(O) group(O) didn(O) 't(O) perform(O) ;(O) instead(O) Black(B-musical artist) Thought(I-musical artist),(O) Travie(B-musical artist) from(O) Gym(B-album) Class(I-album) Heroes(I-album) and(O) Kid(B-musical artist) Rock(I-musical artist) performed(O) a(O) medley(O) of(O) their(O) songs(O).(O)", "instance": {"id": "188", "words": ["They", "were", "inducted", "by", "Chuck", "D", "and", "LL", "Cool", "J", "on", "April", "14", ",", "2012", "therefore", "the", "group", "didn", "'t", "perform", ";", "instead", "Black", "Thought", ",", "Travie", "from", "Gym", "Class", "Heroes", "and", "Kid", "Rock", "performed", "a", "medley", "of", "their", "songs", "."], "labels": ["O", "O", "O", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "I-musical artist", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "O", "B-band", "I-band", "I-band", "O", "B-musical artist", "I-musical artist", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, song, music genre, event, musical artist, award, band, organization, person, location, musical instrument, country and O.\nSentence: They were inducted by Chuck D and LL Cool J on April 14 , 2012 therefore the group didn 't perform ; instead Black Thought , Travie from Gym Class Heroes and Kid Rock performed a medley of their songs .", "prompt_labels": "They(O) were(O) inducted(O) by(O) Chuck(B-musical artist) D(I-musical artist) and(O) LL(B-musical artist) Cool(I-musical artist) J(I-musical artist) on(O) April(O) 14(O) ,(O) 2012(O) therefore(O) the(O) group(O) didn(O) 't(O) perform(O) ;(O) instead(O) Black(B-musical artist) Thought(I-musical artist) ,(O) Travie(B-musical artist) from(O) Gym(B-band) Class(I-band) Heroes(I-band) and(O) Kid(B-musical artist) Rock(I-musical artist) performed(O) a(O) medley(O) of(O) their(O) songs(O) .(O)"}, "label_list": ["album", "song", "music genre", "event", "musical artist", "award", "band", "organization", "person", "location", "musical instrument", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8176, 11, 5609, 11, 4731, 17779, 11, 1567, 11, 18273, 10255, 11, 10292, 11, 7200, 11, 7471, 11, 1732, 11, 3813, 11, 18273, 14473, 11, 3224, 323, 507, 627, 85664, 25, 2435, 1051, 304, 55015, 555, 34349, 423, 323, 20072, 24882, 622, 389, 5936, 220, 975, 1174, 220, 679, 17, 9093, 279, 1912, 3287, 364, 83, 2804, 2652, 4619, 5348, 36287, 1174, 43359, 648, 505, 46631, 3308, 38099, 323, 32666, 9305, 10887, 264, 1812, 3258, 315, 872, 11936, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "270", "dataset": "crossner_music", "split": "dev", "prediction": "In(O) 1974(O) he(O) returned(O) to(O) the(O) No.(O) 1(O) spot(O) on(O) the(O) R(B-music genre) &(I-music genre) B(I-music genre) charts(O) with(O) The(B-album) Payback(I-album),(O) with(O) the(O) The(B-album) Payback(I-album) reaching(O) the(O) same(O) spot(O) on(O) the(O) album(O) charts(O) ;(O) he(O) would(O) reach(O) No.(O) 1(O) two(O) more(O) times(O) in(O) 1974(O),(O) with(O) My(B-album) Thang(I-album) and(O) Papa(B-album) Don(I-album) 't(I-album) Take(I-album) No(I-album) Mess(I-album).(O)", "instance": {"id": "270", "words": ["In", "1974", "he", "returned", "to", "the", "No.", "1", "spot", "on", "the", "R", "&", "B", "charts", "with", "The", "Payback", ",", "with", "the", "The", "Payback", "reaching", "the", "same", "spot", "on", "the", "album", "charts", ";", "he", "would", "reach", "No.", "1", "two", "more", "times", "in", "1974", ",", "with", "My", "Thang", "and", "Papa", "Don", "'t", "Take", "No", "Mess", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-music genre", "I-music genre", "I-music genre", "O", "O", "B-album", "I-album", "O", "O", "O", "B-album", "I-album", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-song", "I-song", "O", "B-song", "I-song", "I-song", "I-song", "I-song", "I-song", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, music genre, album, organization, band, musical artist, musical instrument, person, country, event, location, song and O.\nSentence: In 1974 he returned to the No. 1 spot on the R & B charts with The Payback , with the The Payback reaching the same spot on the album charts ; he would reach No. 1 two more times in 1974 , with My Thang and Papa Don 't Take No Mess .", "prompt_labels": "In(O) 1974(O) he(O) returned(O) to(O) the(O) No.(O) 1(O) spot(O) on(O) the(O) R(B-music genre) &(I-music genre) B(I-music genre) charts(O) with(O) The(B-album) Payback(I-album) ,(O) with(O) the(O) The(B-album) Payback(I-album) reaching(O) the(O) same(O) spot(O) on(O) the(O) album(O) charts(O) ;(O) he(O) would(O) reach(O) No.(O) 1(O) two(O) more(O) times(O) in(O) 1974(O) ,(O) with(O) My(B-song) Thang(I-song) and(O) Papa(B-song) Don(I-song) 't(I-song) Take(I-song) No(I-song) Mess(I-song) .(O)"}, "label_list": ["award", "music genre", "album", "organization", "band", "musical artist", "musical instrument", "person", "country", "event", "location", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10292, 11, 4731, 17779, 11, 8176, 11, 7471, 11, 7200, 11, 18273, 10255, 11, 18273, 14473, 11, 1732, 11, 3224, 11, 1567, 11, 3813, 11, 5609, 323, 507, 627, 85664, 25, 763, 220, 4468, 19, 568, 6052, 311, 279, 2360, 13, 220, 16, 7858, 389, 279, 432, 612, 426, 27223, 449, 578, 11728, 1445, 1174, 449, 279, 578, 11728, 1445, 19261, 279, 1890, 7858, 389, 279, 8176, 27223, 2652, 568, 1053, 5662, 2360, 13, 220, 16, 1403, 810, 3115, 304, 220, 4468, 19, 1174, 449, 3092, 666, 526, 323, 65673, 4418, 364, 83, 12040, 2360, 19234, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "8", "dataset": "crossner_music", "split": "dev", "prediction": "The(O) album(O) was(O) certified(O) seven-times(O) platinum(O) in(O) Australia(B-country) by(O) the(O) Australian(B-organization) Recording(I-organization) Industry(I-organization) Association(I-organization) ((O) ARIA(B-organization) )(O),(O) five-times(O) platinum(O) in(O) the(O) UK(B-country) by(O) the(O) British(B-organization) Phonographic(I-organization) Industry(I-organization) ((O) BPI(B-organization) )(O),(O) and(O) platinum(O) in(O) the(O) US(B-country) by(O) the(O) Recording(B-organization) Industry(I-organization) Association(I-organization) of(I-organization) America(I-organization) ((O) RIAA(B-organization) )(O).(O)", "instance": {"id": "8", "words": ["The", "album", "was", "certified", "seven-times", "platinum", "in", "Australia", "by", "the", "Australian", "Recording", "Industry", "Association", "(", "ARIA", ")", ",", "five-times", "platinum", "in", "the", "UK", "by", "the", "British", "Phonographic", "Industry", "(", "BPI", ")", ",", "and", "platinum", "in", "the", "US", "by", "the", "Recording", "Industry", "Association", "of", "America", "(", "RIAA", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-country", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "O", "O", "O", "O", "O", "O", "B-country", "O", "O", "B-organization", "I-organization", "I-organization", "O", "B-organization", "O", "O", "O", "O", "O", "O", "B-country", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, organization, location, country, album, music genre, musical instrument, song, musical artist, award, person, event and O.\nSentence: The album was certified seven-times platinum in Australia by the Australian Recording Industry Association ( ARIA ) , five-times platinum in the UK by the British Phonographic Industry ( BPI ) , and platinum in the US by the Recording Industry Association of America ( RIAA ) .", "prompt_labels": "The(O) album(O) was(O) certified(O) seven-times(O) platinum(O) in(O) Australia(B-country) by(O) the(O) Australian(B-organization) Recording(I-organization) Industry(I-organization) Association(I-organization) ((O) ARIA(B-organization) )(O) ,(O) five-times(O) platinum(O) in(O) the(O) UK(B-country) by(O) the(O) British(B-organization) Phonographic(I-organization) Industry(I-organization) ((O) BPI(B-organization) )(O) ,(O) and(O) platinum(O) in(O) the(O) US(B-country) by(O) the(O) Recording(B-organization) Industry(I-organization) Association(I-organization) of(I-organization) America(I-organization) ((O) RIAA(B-organization) )(O) .(O)"}, "label_list": ["band", "organization", "location", "country", "album", "music genre", "musical instrument", "song", "musical artist", "award", "person", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7200, 11, 7471, 11, 3813, 11, 3224, 11, 8176, 11, 4731, 17779, 11, 18273, 14473, 11, 5609, 11, 18273, 10255, 11, 10292, 11, 1732, 11, 1567, 323, 507, 627, 85664, 25, 578, 8176, 574, 23759, 8254, 45548, 63327, 304, 8494, 555, 279, 13673, 61647, 24780, 10229, 320, 362, 79363, 883, 1174, 4330, 45548, 63327, 304, 279, 6560, 555, 279, 8013, 71424, 12968, 24780, 320, 426, 1932, 883, 1174, 323, 63327, 304, 279, 2326, 555, 279, 61647, 24780, 10229, 315, 5270, 320, 432, 5987, 32, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "696", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) would(O) like(O) to(O) find(O) a(O) vegeterian(B-Cuisine) restaurant(O)", "instance": {"id": "696", "words": ["i", "would", "like", "to", "find", "a", "vegeterian", "restaurant"], "labels": ["O", "O", "O", "O", "O", "O", "B-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Rating, Hours, Location, Cuisine, Price, Amenity, Dish and O.\nSentence: i would like to find a vegeterian restaurant", "prompt_labels": "i(O) would(O) like(O) to(O) find(O) a(O) vegeterian(B-Cuisine) restaurant(O)"}, "label_list": ["Restaurant Name", "Rating", "Hours", "Location", "Cuisine", "Price", "Amenity", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 19767, 11, 30192, 11, 10067, 11, 81961, 11, 8650, 11, 3383, 56685, 11, 49268, 323, 507, 627, 85664, 25, 602, 1053, 1093, 311, 1505, 264, 13294, 261, 1122, 10960, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1462", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) there(O) a(O) restaurant(O) located(O) within(B-Location) 1(I-Location) mile(I-Location) from(I-Location) here(I-Location)", "instance": {"id": "1462", "words": ["where", "there", "a", "restaurant", "located", "within", "1", "mile", "from", "here"], "labels": ["O", "O", "O", "O", "O", "B-Location", "I-Location", "I-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Price, Rating, Restaurant Name, Hours, Location, Cuisine, Dish and O.\nSentence: where there a restaurant located within 1 mile from here", "prompt_labels": "where(O) there(O) a(O) restaurant(O) located(O) within(B-Location) 1(I-Location) mile(I-Location) from(I-Location) here(I-Location)"}, "label_list": ["Amenity", "Price", "Rating", "Restaurant Name", "Hours", "Location", "Cuisine", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 8650, 11, 19767, 11, 26568, 4076, 11, 30192, 11, 10067, 11, 81961, 11, 49268, 323, 507, 627, 85664, 25, 1405, 1070, 264, 10960, 7559, 2949, 220, 16, 14929, 505, 1618, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "516", "dataset": "mit-restaurant", "split": "dev", "prediction": "how(O) far(O) is(O) the(O) english(B-Cuisine) pub(I-Cuisine) that(O) serves(O) a(O) fry(B-Dish) up(I-Dish)", "instance": {"id": "516", "words": ["how", "far", "is", "the", "english", "pub", "that", "serves", "a", "fry", "up"], "labels": ["O", "O", "O", "O", "B-Amenity", "I-Amenity", "O", "O", "O", "B-Dish", "I-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Cuisine, Restaurant Name, Rating, Amenity, Location, Price, Dish and O.\nSentence: how far is the english pub that serves a fry up", "prompt_labels": "how(O) far(O) is(O) the(O) english(B-Amenity) pub(I-Amenity) that(O) serves(O) a(O) fry(B-Dish) up(I-Dish)"}, "label_list": ["Hours", "Cuisine", "Restaurant Name", "Rating", "Amenity", "Location", "Price", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 81961, 11, 26568, 4076, 11, 19767, 11, 3383, 56685, 11, 10067, 11, 8650, 11, 49268, 323, 507, 627, 85664, 25, 1268, 3117, 374, 279, 30063, 6814, 430, 17482, 264, 53646, 709, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2394", "dataset": "mit-movie", "split": "dev", "prediction": "could(O) you(O) send(O) me(O) to(O) a(O) website(O) with(O) user(B-review) reviews(I-review) of(O) willy(B-title) wonka(I-title) the(I-title) chocolate(I-title) factory(I-title)", "instance": {"id": "2394", "words": ["could", "you", "send", "me", "to", "a", "website", "with", "user", "reviews", "of", "willy", "wonka", "the", "chocolate", "factory"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-review", "O", "B-title", "I-title", "I-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, review, rating, title, trailer, year, average ratings, plot, actor, character, genre, song and O.\nSentence: could you send me to a website with user reviews of willy wonka the chocolate factory", "prompt_labels": "could(O) you(O) send(O) me(O) to(O) a(O) website(O) with(O) user(O) reviews(B-review) of(O) willy(B-title) wonka(I-title) the(I-title) chocolate(I-title) factory(I-title)"}, "label_list": ["director", "review", "rating", "title", "trailer", "year", "average ratings", "plot", "actor", "character", "genre", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 3477, 11, 10959, 11, 2316, 11, 19809, 11, 1060, 11, 5578, 18594, 11, 7234, 11, 12360, 11, 3752, 11, 17779, 11, 5609, 323, 507, 627, 85664, 25, 1436, 499, 3708, 757, 311, 264, 3997, 449, 1217, 8544, 315, 289, 14722, 2834, 4657, 279, 18414, 8803, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "86", "dataset": "mit-restaurant", "split": "dev", "prediction": "are(O) there(O) any(O) restaurants(O) within(B-Location) 5(I-Location) miles(I-Location) that(O) accept(B-Amenity) travelers(I-Amenity) checks(I-Amenity)", "instance": {"id": "86", "words": ["are", "there", "any", "restaurants", "within", "5", "miles", "that", "accept", "travelers", "checks"], "labels": ["O", "O", "O", "O", "B-Location", "I-Location", "I-Location", "O", "B-Amenity", "I-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Restaurant Name, Amenity, Dish, Price, Hours, Rating, Cuisine and O.\nSentence: are there any restaurants within 5 miles that accept travelers checks", "prompt_labels": "are(O) there(O) any(O) restaurants(O) within(B-Location) 5(I-Location) miles(I-Location) that(O) accept(B-Amenity) travelers(I-Amenity) checks(I-Amenity)"}, "label_list": ["Location", "Restaurant Name", "Amenity", "Dish", "Price", "Hours", "Rating", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 26568, 4076, 11, 3383, 56685, 11, 49268, 11, 8650, 11, 30192, 11, 19767, 11, 81961, 323, 507, 627, 85664, 25, 527, 1070, 904, 15926, 2949, 220, 20, 8931, 430, 4287, 40386, 12621, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1498", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) there(O) a(O) good(O) thriller(B-genre) that(O) is(O) rated(O) pg(B-rating) 13(I-rating) that(O) came(O) out(O) in(O) the(O) 2010(B-year) s(I-year)", "instance": {"id": "1498", "words": ["is", "there", "a", "good", "thriller", "that", "is", "rated", "pg", "13", "that", "came", "out", "in", "the", "2010", "s"], "labels": ["O", "O", "O", "O", "B-genre", "O", "O", "O", "B-rating", "I-rating", "O", "O", "O", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, trailer, plot, song, title, character, average ratings, actor, rating, director, review, year and O.\nSentence: is there a good thriller that is rated pg 13 that came out in the 2010 s", "prompt_labels": "is(O) there(O) a(O) good(O) thriller(B-genre) that(O) is(O) rated(O) pg(B-rating) 13(I-rating) that(O) came(O) out(O) in(O) the(O) 2010(B-year) s(I-year)"}, "label_list": ["genre", "trailer", "plot", "song", "title", "character", "average ratings", "actor", "rating", "director", "review", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 19809, 11, 7234, 11, 5609, 11, 2316, 11, 3752, 11, 5578, 18594, 11, 12360, 11, 10959, 11, 7690, 11, 3477, 11, 1060, 323, 507, 627, 85664, 25, 374, 1070, 264, 1695, 54461, 430, 374, 22359, 17953, 220, 1032, 430, 3782, 704, 304, 279, 220, 679, 15, 274, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "255", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) any(O) action(B-genre) movies(O) that(O) are(O) in(O) theatres(B-plot) right(B-year) now(I-year)", "instance": {"id": "255", "words": ["show", "me", "any", "action", "movies", "that", "are", "in", "theatres", "right", "now"], "labels": ["O", "O", "O", "B-genre", "O", "O", "O", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, title, average ratings, trailer, song, year, genre, character, director, rating, plot, actor and O.\nSentence: show me any action movies that are in theatres right now", "prompt_labels": "show(O) me(O) any(O) action(B-genre) movies(O) that(O) are(O) in(O) theatres(O) right(B-year) now(I-year)"}, "label_list": ["review", "title", "average ratings", "trailer", "song", "year", "genre", "character", "director", "rating", "plot", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 2316, 11, 5578, 18594, 11, 19809, 11, 5609, 11, 1060, 11, 17779, 11, 3752, 11, 7690, 11, 10959, 11, 7234, 11, 12360, 323, 507, 627, 85664, 25, 1501, 757, 904, 1957, 9698, 430, 527, 304, 47213, 417, 1314, 1457, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "876", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) a(O) list(O) of(O) r(B-rating) rated(I-rating) movies(O) about(O) aliens(B-plot)", "instance": {"id": "876", "words": ["show", "me", "a", "list", "of", "r", "rated", "movies", "about", "aliens"], "labels": ["O", "O", "O", "O", "O", "B-rating", "I-rating", "O", "O", "B-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, year, plot, rating, title, average ratings, song, character, review, genre, trailer, director and O.\nSentence: show me a list of r rated movies about aliens", "prompt_labels": "show(O) me(O) a(O) list(O) of(O) r(B-rating) rated(I-rating) movies(O) about(O) aliens(B-plot)"}, "label_list": ["actor", "year", "plot", "rating", "title", "average ratings", "song", "character", "review", "genre", "trailer", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 1060, 11, 7234, 11, 10959, 11, 2316, 11, 5578, 18594, 11, 5609, 11, 3752, 11, 3477, 11, 17779, 11, 19809, 11, 7690, 323, 507, 627, 85664, 25, 1501, 757, 264, 1160, 315, 436, 22359, 9698, 922, 37219, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "258", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) a(O) good(O) romance(B-genre) movie(O) with(O) jennifer(B-actor) aniston(I-actor)", "instance": {"id": "258", "words": ["what", "is", "a", "good", "romance", "movie", "with", "jennifer", "aniston"], "labels": ["O", "O", "O", "B-review", "B-genre", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, average ratings, trailer, plot, year, genre, character, song, actor, director, title, review and O.\nSentence: what is a good romance movie with jennifer aniston", "prompt_labels": "what(O) is(O) a(O) good(B-review) romance(B-genre) movie(O) with(O) jennifer(B-actor) aniston(I-actor)"}, "label_list": ["rating", "average ratings", "trailer", "plot", "year", "genre", "character", "song", "actor", "director", "title", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 5578, 18594, 11, 19809, 11, 7234, 11, 1060, 11, 17779, 11, 3752, 11, 5609, 11, 12360, 11, 7690, 11, 2316, 11, 3477, 323, 507, 627, 85664, 25, 1148, 374, 264, 1695, 30363, 5818, 449, 503, 60070, 459, 59919, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "393", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) stared(O) in(O) the(O) movie(O) the(B-title) bank(I-title) job(I-title)", "instance": {"id": "393", "words": ["who", "stared", "in", "the", "movie", "the", "bank", "job"], "labels": ["O", "O", "O", "O", "O", "B-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, title, genre, plot, actor, character, trailer, rating, average ratings, director, song, review and O.\nSentence: who stared in the movie the bank job", "prompt_labels": "who(O) stared(O) in(O) the(O) movie(O) the(B-title) bank(I-title) job(I-title)"}, "label_list": ["year", "title", "genre", "plot", "actor", "character", "trailer", "rating", "average ratings", "director", "song", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 2316, 11, 17779, 11, 7234, 11, 12360, 11, 3752, 11, 19809, 11, 10959, 11, 5578, 18594, 11, 7690, 11, 5609, 11, 3477, 323, 507, 627, 85664, 25, 889, 45135, 304, 279, 5818, 279, 6201, 2683, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "159", "dataset": "crossner_science", "split": "dev", "prediction": "Bennett(B-person) was(O) the(O) flight(O) safety(O) manager(O) for(O) the(O) radioisotope(O) power(O) sources(O) currently(O) in(O) use(O) on(O) the(O) Voyager(B-astronomical object) 1(I-astronomical object) and(O) Voyager(B-astronomical object) 2(I-astronomical object) spacecraft(O) ((O) which(O) went(O) to(O) Jupiter(B-astronomical object),(O) Saturn(B-astronomical object),(O) Uranus(B-astronomical object),(O) Neptune(B-astronomical object) and(O) beyond(O) )(O) and(O) on(O) Lincoln(B-organization) Laboratory(I-organization) '(O) s(O) LES(B-astronomical object) 8(I-astronomical object) and(O) LES(B-astronomical object) 9(I-astronomical object) communications(O) satellites(O).(O)", "instance": {"id": "159", "words": ["Bennett", "was", "the", "flight", "safety", "manager", "for", "the", "radioisotope", "power", "sources", "currently", "in", "use", "on", "the", "Voyager", "1", "and", "Voyager", "2", "spacecraft", "(", "which", "went", "to", "Jupiter", ",", "Saturn", ",", "Uranus", ",", "Neptune", "and", "beyond", ")", "and", "on", "Lincoln", "Laboratory", "'", "s", "LES", "8", "and", "LES", "9", "communications", "satellites", "."], "labels": ["B-person", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-astronomical object", "O", "B-astronomical object", "O", "B-astronomical object", "O", "B-astronomical object", "O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: astronomical object, chemical compound, theory, chemical element, academic journal, enzyme, country, discipline, scientist, location, university, person, event, award, organization, protein and O.\nSentence: Bennett was the flight safety manager for the radioisotope power sources currently in use on the Voyager 1 and Voyager 2 spacecraft ( which went to Jupiter , Saturn , Uranus , Neptune and beyond ) and on Lincoln Laboratory ' s LES 8 and LES 9 communications satellites .", "prompt_labels": "Bennett(B-person) was(O) the(O) flight(O) safety(O) manager(O) for(O) the(O) radioisotope(O) power(O) sources(O) currently(O) in(O) use(O) on(O) the(O) Voyager(O) 1(O) and(O) Voyager(O) 2(O) spacecraft(O) ((O) which(O) went(O) to(O) Jupiter(B-astronomical object) ,(O) Saturn(B-astronomical object) ,(O) Uranus(B-astronomical object) ,(O) Neptune(B-astronomical object) and(O) beyond(O) )(O) and(O) on(O) Lincoln(B-organization) Laboratory(I-organization) '(O) s(O) LES(O) 8(O) and(O) LES(O) 9(O) communications(O) satellites(O) .(O)"}, "label_list": ["astronomical object", "chemical compound", "theory", "chemical element", "academic journal", "enzyme", "country", "discipline", "scientist", "location", "university", "person", "event", "award", "organization", "protein"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 87283, 1665, 11, 11742, 24549, 11, 10334, 11, 11742, 2449, 11, 14584, 8486, 11, 49242, 11, 3224, 11, 26434, 11, 28568, 11, 3813, 11, 12374, 11, 1732, 11, 1567, 11, 10292, 11, 7471, 11, 13128, 323, 507, 627, 85664, 25, 39386, 574, 279, 11213, 7296, 6783, 369, 279, 9063, 285, 51782, 2410, 8336, 5131, 304, 1005, 389, 279, 86260, 220, 16, 323, 86260, 220, 17, 42640, 320, 902, 4024, 311, 50789, 1174, 50253, 1174, 80770, 355, 1174, 80724, 323, 7953, 883, 323, 389, 25379, 32184, 364, 274, 97529, 220, 23, 323, 97529, 220, 24, 17320, 47710, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "223", "dataset": "crossner_ai", "split": "dev", "prediction": "Time(B-task) series(I-task) are(O) used(O) in(O) statistics(B-field),(O) signal(B-field) processing(I-field),(O) pattern(B-field) recognition(I-field),(O) econometrics(B-field),(O) mathematical(B-field) finance(I-field),(O) weather(B-task) forecasting(I-task),(O) earthquake(B-task) prediction(I-task),(O) electroencephalography(B-task),(O) control(B-field) engineering(I-field),(O) astronomy(B-field),(O) communications(B-field) engineering(I-field),(O) and(O) largely(O) in(O) any(O) domain(O) of(O) applied(O) science(O) and(O) engineering(O) which(O) involves(O) temporal(O) measurements(O).(O)", "instance": {"id": "223", "words": ["Time", "series", "are", "used", "in", "statistics", ",", "signal", "processing", ",", "pattern", "recognition", ",", "econometrics", ",", "mathematical", "finance", ",", "weather", "forecasting", ",", "earthquake", "prediction", ",", "electroencephalography", ",", "control", "engineering", ",", "astronomy", ",", "communications", "engineering", ",", "and", "largely", "in", "any", "domain", "of", "applied", "science", "and", "engineering", "which", "involves", "temporal", "measurements", "."], "labels": ["O", "O", "O", "O", "O", "B-field", "O", "B-field", "I-field", "O", "B-field", "I-field", "O", "B-field", "O", "B-field", "I-field", "O", "B-field", "I-field", "O", "B-field", "I-field", "O", "B-field", "O", "B-field", "I-field", "O", "B-field", "O", "B-field", "I-field", "O", "O", "O", "O", "O", "O", "O", "B-field", "I-field", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, metric, country, programming language, university, algorithm, organization, product, researcher, task, conference, location, field and O.\nSentence: Time series are used in statistics , signal processing , pattern recognition , econometrics , mathematical finance , weather forecasting , earthquake prediction , electroencephalography , control engineering , astronomy , communications engineering , and largely in any domain of applied science and engineering which involves temporal measurements .", "prompt_labels": "Time(O) series(O) are(O) used(O) in(O) statistics(B-field) ,(O) signal(B-field) processing(I-field) ,(O) pattern(B-field) recognition(I-field) ,(O) econometrics(B-field) ,(O) mathematical(B-field) finance(I-field) ,(O) weather(B-field) forecasting(I-field) ,(O) earthquake(B-field) prediction(I-field) ,(O) electroencephalography(B-field) ,(O) control(B-field) engineering(I-field) ,(O) astronomy(B-field) ,(O) communications(B-field) engineering(I-field) ,(O) and(O) largely(O) in(O) any(O) domain(O) of(O) applied(B-field) science(I-field) and(O) engineering(O) which(O) involves(O) temporal(O) measurements(O) .(O)"}, "label_list": ["person", "metric", "country", "programming language", "university", "algorithm", "organization", "product", "researcher", "task", "conference", "location", "field"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 18767, 11, 3224, 11, 15840, 4221, 11, 12374, 11, 12384, 11, 7471, 11, 2027, 11, 32185, 11, 3465, 11, 10017, 11, 3813, 11, 2115, 323, 507, 627, 85664, 25, 4212, 4101, 527, 1511, 304, 13443, 1174, 8450, 8863, 1174, 5497, 18324, 1174, 3898, 92891, 1174, 37072, 17452, 1174, 9282, 79482, 1174, 38413, 20212, 1174, 25396, 768, 764, 278, 5814, 1174, 2585, 15009, 1174, 82213, 1174, 17320, 15009, 1174, 323, 14090, 304, 904, 8106, 315, 9435, 8198, 323, 15009, 902, 18065, 37015, 22323, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "375", "dataset": "mit-restaurant", "split": "dev", "prediction": "find(O) me(O) a(O) good(B-Rating) pub(B-Cuisine) that(O) has(O) a(O) dance(B-Amenity) floor(I-Amenity)", "instance": {"id": "375", "words": ["find", "me", "a", "good", "pub", "that", "has", "a", "dance", "floor"], "labels": ["O", "O", "O", "B-Rating", "B-Cuisine", "O", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Price, Hours, Location, Amenity, Cuisine, Rating, Restaurant Name and O.\nSentence: find me a good pub that has a dance floor", "prompt_labels": "find(O) me(O) a(O) good(B-Rating) pub(B-Cuisine) that(O) has(O) a(O) dance(B-Amenity) floor(I-Amenity)"}, "label_list": ["Dish", "Price", "Hours", "Location", "Amenity", "Cuisine", "Rating", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 8650, 11, 30192, 11, 10067, 11, 3383, 56685, 11, 81961, 11, 19767, 11, 26568, 4076, 323, 507, 627, 85664, 25, 1505, 757, 264, 1695, 6814, 430, 706, 264, 15612, 6558, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "739", "dataset": "mit-restaurant", "split": "dev", "prediction": "im(O) looking(O) for(O) a(O) romantic(B-Amenity) restaurant(O) where(O) are(O) some(O) near(B-Location) me(I-Location)", "instance": {"id": "739", "words": ["im", "looking", "for", "a", "romantic", "restaurant", "where", "are", "some", "near", "me"], "labels": ["O", "O", "O", "O", "B-Amenity", "O", "O", "O", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Dish, Hours, Location, Cuisine, Amenity, Restaurant Name, Rating and O.\nSentence: im looking for a romantic restaurant where are some near me", "prompt_labels": "im(O) looking(O) for(O) a(O) romantic(B-Amenity) restaurant(O) where(O) are(O) some(O) near(B-Location) me(I-Location)"}, "label_list": ["Price", "Dish", "Hours", "Location", "Cuisine", "Amenity", "Restaurant Name", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 49268, 11, 30192, 11, 10067, 11, 81961, 11, 3383, 56685, 11, 26568, 4076, 11, 19767, 323, 507, 627, 85664, 25, 737, 3411, 369, 264, 24364, 10960, 1405, 527, 1063, 3221, 757, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1207", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) time(O) does(O) on(B-Restaurant Name) the(I-Restaurant Name) rocks(I-Restaurant Name) on(O) seminary(B-Location) stop(O) serving(O) food(O)", "instance": {"id": "1207", "words": ["what", "time", "does", "on", "the", "rocks", "on", "seminary", "stop", "serving", "food"], "labels": ["O", "B-Hours", "O", "B-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name", "O", "B-Location", "B-Hours", "I-Hours", "I-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Rating, Amenity, Location, Hours, Dish, Restaurant Name, Price and O.\nSentence: what time does on the rocks on seminary stop serving food", "prompt_labels": "what(O) time(B-Hours) does(O) on(B-Restaurant Name) the(I-Restaurant Name) rocks(I-Restaurant Name) on(O) seminary(B-Location) stop(B-Hours) serving(I-Hours) food(I-Hours)"}, "label_list": ["Cuisine", "Rating", "Amenity", "Location", "Hours", "Dish", "Restaurant Name", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 19767, 11, 3383, 56685, 11, 10067, 11, 30192, 11, 49268, 11, 26568, 4076, 11, 8650, 323, 507, 627, 85664, 25, 1148, 892, 1587, 389, 279, 23902, 389, 5347, 3367, 3009, 13788, 3691, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "33", "dataset": "crossner_literature", "split": "dev", "prediction": "The(O) poem(B-literary genre) is(O) quoted(O) by(O) Sue(B-writer) Bridehead(I-writer) in(O) Thomas(B-writer) Hardy(I-writer) '(O) s(O) 1895(O) novel(O),(O) Jude(B-book) the(I-book) Obscure(I-book) and(O) also(O) by(O) Edward(B-writer) Ashburnham(I-writer) in(O) Ford(B-writer) Madox(I-writer).(O) Ford(B-writer) '(O) s(O) The(B-book) Good(I-book) Soldier(I-book).(O)", "instance": {"id": "33", "words": ["The", "poem", "is", "quoted", "by", "Sue", "Bridehead", "in", "Thomas", "Hardy", "'", "s", "1895", "novel", ",", "Jude", "the", "Obscure", "and", "also", "by", "Edward", "Ashburnham", "in", "Ford", "Madox", ".", "Ford", "'", "s", "The", "Good", "Soldier", "."], "labels": ["O", "B-literary genre", "O", "O", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "O", "O", "B-literary genre", "O", "B-book", "I-book", "I-book", "O", "O", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "B-writer", "O", "O", "B-book", "I-book", "I-book", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, magazine, award, book, literary genre, poem, country, organization, event, writer, location and O.\nSentence: The poem is quoted by Sue Bridehead in Thomas Hardy ' s 1895 novel , Jude the Obscure and also by Edward Ashburnham in Ford Madox . Ford ' s The Good Soldier .", "prompt_labels": "The(O) poem(B-literary genre) is(O) quoted(O) by(O) Sue(B-writer) Bridehead(I-writer) in(O) Thomas(B-writer) Hardy(I-writer) '(O) s(O) 1895(O) novel(B-literary genre) ,(O) Jude(B-book) the(I-book) Obscure(I-book) and(O) also(O) by(O) Edward(B-writer) Ashburnham(I-writer) in(O) Ford(B-writer) Madox(I-writer) .(O) Ford(B-writer) '(O) s(O) The(B-book) Good(I-book) Soldier(I-book) .(O)"}, "label_list": ["person", "magazine", "award", "book", "literary genre", "poem", "country", "organization", "event", "writer", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 14756, 11, 10292, 11, 2363, 11, 32465, 17779, 11, 33894, 11, 3224, 11, 7471, 11, 1567, 11, 7061, 11, 3813, 323, 507, 627, 85664, 25, 578, 33894, 374, 24116, 555, 48749, 78160, 2025, 304, 11355, 58374, 364, 274, 220, 9378, 20, 11775, 1174, 62734, 279, 51541, 66, 554, 323, 1101, 555, 22653, 14937, 22464, 5721, 304, 14337, 386, 40197, 662, 14337, 364, 274, 578, 7839, 53529, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "98", "dataset": "crossner_science", "split": "dev", "prediction": "It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O),(O) by(O) Ingrid(B-scientist) van(I-scientist) Houten-Groeneveld(I-scientist) and(O) Cornelis(B-scientist) van(I-scientist) Houten(I-scientist) at(O) Leiden(B-location),(O) and(O) Tom(B-scientist) Gehrels(I-scientist) at(O) Palomar(B-location) Observatory(I-location) in(O) California(B-location).(O)", "instance": {"id": "98", "words": ["It", "was", "discovered", "on", "24", "September", "1960", ",", "by", "Ingrid", "van", "Houten-Groeneveld", "and", "Cornelis", "van", "Houten", "at", "Leiden", ",", "and", "Tom", "Gehrels", "at", "Palomar", "Observatory", "in", "California", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-scientist", "I-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "I-scientist", "O", "B-location", "O", "O", "B-scientist", "I-scientist", "O", "B-location", "I-location", "O", "B-location", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, enzyme, discipline, astronomical object, scientist, academic journal, chemical compound, chemical element, person, location, theory, country, event, university, award, protein and O.\nSentence: It was discovered on 24 September 1960 , by Ingrid van Houten-Groeneveld and Cornelis van Houten at Leiden , and Tom Gehrels at Palomar Observatory in California .", "prompt_labels": "It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O) ,(O) by(O) Ingrid(B-scientist) van(I-scientist) Houten-Groeneveld(I-scientist) and(O) Cornelis(B-scientist) van(I-scientist) Houten(I-scientist) at(O) Leiden(B-location) ,(O) and(O) Tom(B-scientist) Gehrels(I-scientist) at(O) Palomar(B-location) Observatory(I-location) in(O) California(B-location) .(O)"}, "label_list": ["organization", "enzyme", "discipline", "astronomical object", "scientist", "academic journal", "chemical compound", "chemical element", "person", "location", "theory", "country", "event", "university", "award", "protein"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 49242, 11, 26434, 11, 87283, 1665, 11, 28568, 11, 14584, 8486, 11, 11742, 24549, 11, 11742, 2449, 11, 1732, 11, 3813, 11, 10334, 11, 3224, 11, 1567, 11, 12374, 11, 10292, 11, 13128, 323, 507, 627, 85664, 25, 1102, 574, 11352, 389, 220, 1187, 6250, 220, 5162, 15, 1174, 555, 763, 4297, 5355, 473, 412, 268, 12279, 299, 1994, 85, 789, 323, 99045, 285, 5355, 473, 412, 268, 520, 2009, 12770, 1174, 323, 8529, 74680, 54883, 520, 11165, 316, 277, 58974, 304, 7188, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "186", "dataset": "crossner_science", "split": "dev", "prediction": "He(O) was(O) awarded(O) honorary(O) doctorate(O) degrees(O) by(O) Princeton(B-university) University(I-university) ((O) 1958(O) )(O),(O) Moscow(B-university) State(I-university) University(I-university) ((O) 1992(O) )(O),(O) and(O) the(O) Chinese(B-university) University(I-university) of(I-university) Hong(I-university) Kong(I-university) ((O) 1997(O) )(O).(O)", "instance": {"id": "186", "words": ["He", "was", "awarded", "honorary", "doctorate", "degrees", "by", "Princeton", "University", "(", "1958", ")", ",", "Moscow", "State", "University", "(", "1992", ")", ",", "and", "the", "Chinese", "University", "of", "Hong", "Kong", "(", "1997", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-university", "I-university", "O", "O", "O", "O", "B-university", "I-university", "I-university", "O", "O", "O", "O", "O", "O", "B-university", "I-university", "I-university", "I-university", "I-university", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: protein, university, enzyme, event, astronomical object, chemical compound, country, academic journal, discipline, person, award, scientist, location, chemical element, organization, theory and O.\nSentence: He was awarded honorary doctorate degrees by Princeton University ( 1958 ) , Moscow State University ( 1992 ) , and the Chinese University of Hong Kong ( 1997 ) .", "prompt_labels": "He(O) was(O) awarded(O) honorary(O) doctorate(O) degrees(O) by(O) Princeton(B-university) University(I-university) ((O) 1958(O) )(O) ,(O) Moscow(B-university) State(I-university) University(I-university) ((O) 1992(O) )(O) ,(O) and(O) the(O) Chinese(B-university) University(I-university) of(I-university) Hong(I-university) Kong(I-university) ((O) 1997(O) )(O) .(O)"}, "label_list": ["protein", "university", "enzyme", "event", "astronomical object", "chemical compound", "country", "academic journal", "discipline", "person", "award", "scientist", "location", "chemical element", "organization", "theory"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 13128, 11, 12374, 11, 49242, 11, 1567, 11, 87283, 1665, 11, 11742, 24549, 11, 3224, 11, 14584, 8486, 11, 26434, 11, 1732, 11, 10292, 11, 28568, 11, 3813, 11, 11742, 2449, 11, 7471, 11, 10334, 323, 507, 627, 85664, 25, 1283, 574, 22034, 99119, 10896, 349, 12628, 555, 50421, 3907, 320, 220, 6280, 23, 883, 1174, 23223, 3314, 3907, 320, 220, 2550, 17, 883, 1174, 323, 279, 8620, 3907, 315, 19730, 18711, 320, 220, 2550, 22, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "7", "dataset": "mit-movie", "split": "dev", "prediction": "can(O) you(O) get(O) a(O) soundtrac(B-song) for(O) the(O) harry(B-title) potter(I-title) films(O)", "instance": {"id": "7", "words": ["can", "you", "get", "a", "soundtrac", "for", "the", "harry", "potter", "films"], "labels": ["O", "O", "O", "O", "B-song", "O", "O", "B-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, director, average ratings, genre, year, song, rating, title, review, plot, trailer, actor and O.\nSentence: can you get a soundtrac for the harry potter films", "prompt_labels": "can(O) you(O) get(O) a(O) soundtrac(B-song) for(O) the(O) harry(B-title) potter(I-title) films(I-title)"}, "label_list": ["character", "director", "average ratings", "genre", "year", "song", "rating", "title", "review", "plot", "trailer", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 7690, 11, 5578, 18594, 11, 17779, 11, 1060, 11, 5609, 11, 10959, 11, 2316, 11, 3477, 11, 7234, 11, 19809, 11, 12360, 323, 507, 627, 85664, 25, 649, 499, 636, 264, 5222, 376, 582, 369, 279, 4960, 894, 3419, 466, 12631, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "425", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) said(O) asta(B-title) la(I-title) vista(I-title) baby(I-title)", "instance": {"id": "425", "words": ["who", "said", "asta", "la", "vista", "baby"], "labels": ["O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, review, director, year, trailer, genre, character, plot, average ratings, title, rating, song and O.\nSentence: who said asta la vista baby", "prompt_labels": "who(O) said(O) asta(O) la(O) vista(O) baby(O)"}, "label_list": ["actor", "review", "director", "year", "trailer", "genre", "character", "plot", "average ratings", "title", "rating", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 3477, 11, 7690, 11, 1060, 11, 19809, 11, 17779, 11, 3752, 11, 7234, 11, 5578, 18594, 11, 2316, 11, 10959, 11, 5609, 323, 507, 627, 85664, 25, 889, 1071, 12025, 64, 1208, 40136, 8945, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "64", "dataset": "crossner_literature", "split": "dev", "prediction": "Among(O) his(O) childhood(O) favorites(O) were(O) Charles(B-writer) Dickens(I-writer),(O) Tobias(B-writer) Smollett(I-writer),(O) Mark(B-writer) Twain(I-writer),(O) Booth(B-writer) Tarkington(I-writer),(O) and(O) later(O),(O) Robert(B-writer) Benchley(I-writer) and(O) S.(B-writer) J.(I-writer) Perelman(I-writer).(O)", "instance": {"id": "64", "words": ["Among", "his", "childhood", "favorites", "were", "Charles", "Dickens", ",", "Tobias", "Smollett", ",", "Mark", "Twain", ",", "Booth", "Tarkington", ",", "and", "later", ",", "Robert", "Benchley", "and", "S.", "J.", "Perelman", "."], "labels": ["O", "O", "O", "O", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "O", "O", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "I-writer", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: poem, event, literary genre, country, organization, location, writer, magazine, person, book, award and O.\nSentence: Among his childhood favorites were Charles Dickens , Tobias Smollett , Mark Twain , Booth Tarkington , and later , Robert Benchley and S. J. Perelman .", "prompt_labels": "Among(O) his(O) childhood(O) favorites(O) were(O) Charles(B-writer) Dickens(I-writer) ,(O) Tobias(B-writer) Smollett(I-writer) ,(O) Mark(B-writer) Twain(I-writer) ,(O) Booth(B-writer) Tarkington(I-writer) ,(O) and(O) later(O) ,(O) Robert(B-writer) Benchley(I-writer) and(O) S.(B-writer) J.(I-writer) Perelman(I-writer) .(O)"}, "label_list": ["poem", "event", "literary genre", "country", "organization", "location", "writer", "magazine", "person", "book", "award"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 33894, 11, 1567, 11, 32465, 17779, 11, 3224, 11, 7471, 11, 3813, 11, 7061, 11, 14756, 11, 1732, 11, 2363, 11, 10292, 323, 507, 627, 85664, 25, 22395, 813, 20587, 27672, 1051, 15274, 93999, 1174, 80102, 4487, 337, 28163, 1174, 4488, 12015, 467, 1174, 64370, 350, 847, 4910, 1174, 323, 3010, 1174, 8563, 36358, 3258, 323, 328, 13, 622, 13, 3700, 64641, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "853", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) a(O) rancho(B-Restaurant Name) veo(I-Restaurant Name) restaurant(I-Restaurant Name) in(B-Location) north(I-Location) memphis(I-Location)", "instance": {"id": "853", "words": ["is", "there", "a", "rancho", "veo", "restaurant", "in", "north", "memphis"], "labels": ["O", "O", "O", "B-Restaurant Name", "I-Restaurant Name", "O", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Location, Price, Restaurant Name, Rating, Amenity, Dish, Cuisine and O.\nSentence: is there a rancho veo restaurant in north memphis", "prompt_labels": "is(O) there(O) a(O) rancho(B-Restaurant Name) veo(I-Restaurant Name) restaurant(O) in(O) north(B-Location) memphis(I-Location)"}, "label_list": ["Hours", "Location", "Price", "Restaurant Name", "Rating", "Amenity", "Dish", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 10067, 11, 8650, 11, 26568, 4076, 11, 19767, 11, 3383, 56685, 11, 49268, 11, 81961, 323, 507, 627, 85664, 25, 374, 1070, 264, 10837, 971, 5320, 78, 10960, 304, 10411, 1871, 37889, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "169", "dataset": "crossner_literature", "split": "dev", "prediction": "It(O) is(O) based(O) on(O) H.(B-writer) P.(I-writer) Lovecraft(I-writer) '(O) s(O) Cthulhu(B-book) Mythos(I-book),(O) particularly(O) At(B-book) the(I-book) Mountains(I-book) of(I-book) Madness(I-book),(O) and(O) is(O) a(O) follow-up(O) to(O) Infogrames(O) '(O) earlier(O) Shadow(B-book) of(I-book) the(I-book) Comet(I-book).(O)", "instance": {"id": "169", "words": ["It", "is", "based", "on", "H.", "P.", "Lovecraft", "'", "s", "Cthulhu", "Mythos", ",", "particularly", "At", "the", "Mountains", "of", "Madness", ",", "and", "is", "a", "follow-up", "to", "Infogrames", "'", "earlier", "Shadow", "of", "the", "Comet", "."], "labels": ["O", "O", "O", "O", "B-writer", "I-writer", "I-writer", "O", "O", "O", "O", "O", "O", "B-book", "I-book", "I-book", "I-book", "I-book", "O", "O", "O", "O", "O", "O", "B-organization", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: writer, location, book, poem, literary genre, person, organization, country, award, event, magazine and O.\nSentence: It is based on H. P. Lovecraft ' s Cthulhu Mythos , particularly At the Mountains of Madness , and is a follow-up to Infogrames ' earlier Shadow of the Comet .", "prompt_labels": "It(O) is(O) based(O) on(O) H.(B-writer) P.(I-writer) Lovecraft(I-writer) '(O) s(O) Cthulhu(O) Mythos(O) ,(O) particularly(O) At(B-book) the(I-book) Mountains(I-book) of(I-book) Madness(I-book) ,(O) and(O) is(O) a(O) follow-up(O) to(O) Infogrames(B-organization) '(O) earlier(O) Shadow(O) of(O) the(O) Comet(O) .(O)"}, "label_list": ["writer", "location", "book", "poem", "literary genre", "person", "organization", "country", "award", "event", "magazine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7061, 11, 3813, 11, 2363, 11, 33894, 11, 32465, 17779, 11, 1732, 11, 7471, 11, 3224, 11, 10292, 11, 1567, 11, 14756, 323, 507, 627, 85664, 25, 1102, 374, 3196, 389, 473, 13, 393, 13, 10919, 7868, 364, 274, 356, 339, 360, 17156, 47595, 437, 1174, 8104, 2468, 279, 41114, 315, 71428, 1174, 323, 374, 264, 1833, 5352, 311, 15268, 540, 15988, 364, 6931, 25284, 315, 279, 99198, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "301", "dataset": "crossner_music", "split": "dev", "prediction": "He(O) was(O) the(O) direct(O) inspiration(O) for(O) three(O) Beatles(O) '(O) songs(O) :(O) Lucy(B-song) in(I-song) the(I-song) Sky(I-song) with(I-song) Diamonds(I-song) ((O) 1967(O) )(O),(O) Hey(B-song) Jude(I-song) ((O) 1968(O) )(O),(O) and(O) Good(B-song) Night(I-song) ((O) 1968(O) )(O).(O)", "instance": {"id": "301", "words": ["He", "was", "the", "direct", "inspiration", "for", "three", "Beatles", "'", "songs", ":", "Lucy", "in", "the", "Sky", "with", "Diamonds", "(", "1967", ")", ",", "Hey", "Jude", "(", "1968", ")", ",", "and", "Good", "Night", "(", "1968", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-band", "O", "O", "O", "B-song", "I-song", "I-song", "I-song", "I-song", "I-song", "O", "O", "O", "O", "B-song", "I-song", "O", "O", "O", "O", "O", "B-song", "I-song", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, person, award, album, musical artist, location, event, country, band, song, music genre, musical instrument and O.\nSentence: He was the direct inspiration for three Beatles ' songs : Lucy in the Sky with Diamonds ( 1967 ) , Hey Jude ( 1968 ) , and Good Night ( 1968 ) .", "prompt_labels": "He(O) was(O) the(O) direct(O) inspiration(O) for(O) three(O) Beatles(B-band) '(O) songs(O) :(O) Lucy(B-song) in(I-song) the(I-song) Sky(I-song) with(I-song) Diamonds(I-song) ((O) 1967(O) )(O) ,(O) Hey(B-song) Jude(I-song) ((O) 1968(O) )(O) ,(O) and(O) Good(B-song) Night(I-song) ((O) 1968(O) )(O) .(O)"}, "label_list": ["organization", "person", "award", "album", "musical artist", "location", "event", "country", "band", "song", "music genre", "musical instrument"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 1732, 11, 10292, 11, 8176, 11, 18273, 10255, 11, 3813, 11, 1567, 11, 3224, 11, 7200, 11, 5609, 11, 4731, 17779, 11, 18273, 14473, 323, 507, 627, 85664, 25, 1283, 574, 279, 2167, 20343, 369, 2380, 55957, 364, 11936, 551, 45170, 304, 279, 15064, 449, 91210, 320, 220, 5162, 22, 883, 1174, 28653, 62734, 320, 220, 5162, 23, 883, 1174, 323, 7839, 13120, 320, 220, 5162, 23, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "80", "dataset": "crossner_politics", "split": "dev", "prediction": "In(O) 1997(B-election) Canadian(I-election) federal(I-election) election(I-election) and(O) again(O) in(O) 2000(B-election) Canadian(I-election) federal(I-election) election(I-election) Timbrell(B-politician) campaigned(O) for(O) a(O) seat(O) in(O) the(O) House(B-organization) of(I-organization) Commons(I-organization) of(I-organization) Canada(I-organization) as(O) the(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) of(I-political party) Canada(I-political party) candidate(O) in(O) the(O) eastern(O) Ontario(O) riding(O) of(O) Prince(B-location) Edward(I-location) -(I-location) Hastings(I-location) In(O) the(O) 1997(B-election) federal(I-election) election(I-election),(O) Timbrell(B-politician) placed(O) second(O) to(O) Liberal(O) Lyle(B-politician) Vanclief(I-politician),(O) with(O) 21.5(O) %(O) of(O) the(O) vote(O).(O)", "instance": {"id": "80", "words": ["In", "1997", "Canadian", "federal", "election", "and", "again", "in", "2000", "Canadian", "federal", "election", "Timbrell", "campaigned", "for", "a", "seat", "in", "the", "House", "of", "Commons", "of", "Canada", "as", "the", "Progressive", "Conservative", "Party", "of", "Canada", "candidate", "in", "the", "eastern", "Ontario", "riding", "of", "Prince", "Edward", "-", "Hastings", "In", "the", "1997", "federal", "election", ",", "Timbrell", "placed", "second", "to", "Liberal", "Lyle", "Vanclief", ",", "with", "21.5", "%", "of", "the", "vote", "."], "labels": ["O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "B-politician", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "I-location", "I-location", "O", "O", "O", "O", "O", "O", "B-politician", "O", "O", "O", "O", "B-politician", "I-politician", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, country, political party, politician, person, location, event, election and O.\nSentence: In 1997 Canadian federal election and again in 2000 Canadian federal election Timbrell campaigned for a seat in the House of Commons of Canada as the Progressive Conservative Party of Canada candidate in the eastern Ontario riding of Prince Edward - Hastings In the 1997 federal election , Timbrell placed second to Liberal Lyle Vanclief , with 21.5 % of the vote .", "prompt_labels": "In(O) 1997(B-election) Canadian(I-election) federal(I-election) election(I-election) and(O) again(O) in(O) 2000(B-election) Canadian(I-election) federal(I-election) election(I-election) Timbrell(B-politician) campaigned(O) for(O) a(O) seat(O) in(O) the(O) House(B-organization) of(I-organization) Commons(I-organization) of(I-organization) Canada(I-organization) as(O) the(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) of(I-political party) Canada(I-political party) candidate(O) in(O) the(O) eastern(O) Ontario(O) riding(O) of(O) Prince(B-location) Edward(I-location) -(I-location) Hastings(I-location) In(O) the(O) 1997(O) federal(O) election(O) ,(O) Timbrell(B-politician) placed(O) second(O) to(O) Liberal(O) Lyle(B-politician) Vanclief(I-politician) ,(O) with(O) 21.5(O) %(O) of(O) the(O) vote(O) .(O)"}, "label_list": ["organization", "country", "political party", "politician", "person", "location", "event", "election"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 3224, 11, 5054, 4717, 11, 37038, 11, 1732, 11, 3813, 11, 1567, 11, 6355, 323, 507, 627, 85664, 25, 763, 220, 2550, 22, 12152, 6918, 6355, 323, 1578, 304, 220, 1049, 15, 12152, 6918, 6355, 9538, 65, 16684, 87296, 369, 264, 10954, 304, 279, 4783, 315, 26667, 315, 7008, 439, 279, 52870, 30071, 8722, 315, 7008, 9322, 304, 279, 24024, 21193, 20427, 315, 19912, 22653, 482, 79844, 763, 279, 220, 2550, 22, 6918, 6355, 1174, 9538, 65, 16684, 9277, 2132, 311, 31158, 445, 982, 13000, 566, 4843, 1174, 449, 220, 1691, 13, 20, 1034, 315, 279, 7055, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "254", "dataset": "crossner_music", "split": "dev", "prediction": "He(O) is(O) the(O) only(O) person(O) ever(O) to(O) have(O) won(O) Academy(B-award) Awards(I-award),(O) Emmy(B-award) Award(I-award),(O) and(O) Tony(B-award) Award(I-award) awards(O) in(O) the(O) same(O) year(O) ((O) 1973(O) )(O).(O)", "instance": {"id": "254", "words": ["He", "is", "the", "only", "person", "ever", "to", "have", "won", "Academy", "Awards", ",", "Emmy", "Award", ",", "and", "Tony", "Award", "awards", "in", "the", "same", "year", "(", "1973", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "O", "B-award", "I-award", "O", "O", "B-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, music genre, album, person, musical artist, band, location, country, event, organization, award, musical instrument and O.\nSentence: He is the only person ever to have won Academy Awards , Emmy Award , and Tony Award awards in the same year ( 1973 ) .", "prompt_labels": "He(O) is(O) the(O) only(O) person(O) ever(O) to(O) have(O) won(O) Academy(B-award) Awards(I-award) ,(O) Emmy(B-award) Award(I-award) ,(O) and(O) Tony(B-award) Award(I-award) awards(O) in(O) the(O) same(O) year(O) ((O) 1973(O) )(O) .(O)"}, "label_list": ["song", "music genre", "album", "person", "musical artist", "band", "location", "country", "event", "organization", "award", "musical instrument"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 4731, 17779, 11, 8176, 11, 1732, 11, 18273, 10255, 11, 7200, 11, 3813, 11, 3224, 11, 1567, 11, 7471, 11, 10292, 11, 18273, 14473, 323, 507, 627, 85664, 25, 1283, 374, 279, 1193, 1732, 3596, 311, 617, 2834, 16192, 23488, 1174, 67112, 17768, 1174, 323, 19036, 17768, 23146, 304, 279, 1890, 1060, 320, 220, 4468, 18, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "10", "dataset": "crossner_science", "split": "dev", "prediction": "He(O) is(O) currently(O) Director(O) of(O) the(O) Yale(B-organization) Center(I-organization) for(I-organization) the(I-organization) Study(I-organization) of(I-organization) Globalization(I-organization) at(O) Yale(B-university) University(I-university),(O) is(O) the(O) Latin(B-event) American(I-event) co-chair(I-event) of(I-event) the(I-event) Inter-American(I-event) Dialogue(I-event),(O) and(O) is(O) on(O) the(O) board(O) of(O) directors(O) of(O) Citigroup(B-organization).(O)", "instance": {"id": "10", "words": ["He", "is", "currently", "Director", "of", "the", "Yale", "Center", "for", "the", "Study", "of", "Globalization", "at", "Yale", "University", ",", "is", "the", "Latin", "American", "co-chair", "of", "the", "Inter-American", "Dialogue", ",", "and", "is", "on", "the", "board", "of", "directors", "of", "Citigroup", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "B-university", "I-university", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, location, protein, event, organization, theory, country, scientist, award, enzyme, discipline, chemical element, person, university, academic journal, astronomical object and O.\nSentence: He is currently Director of the Yale Center for the Study of Globalization at Yale University , is the Latin American co-chair of the Inter-American Dialogue , and is on the board of directors of Citigroup .", "prompt_labels": "He(O) is(O) currently(O) Director(O) of(O) the(O) Yale(B-organization) Center(I-organization) for(I-organization) the(I-organization) Study(I-organization) of(I-organization) Globalization(I-organization) at(O) Yale(B-university) University(I-university) ,(O) is(O) the(O) Latin(O) American(O) co-chair(O) of(O) the(O) Inter-American(B-organization) Dialogue(I-organization) ,(O) and(O) is(O) on(O) the(O) board(O) of(O) directors(O) of(O) Citigroup(B-organization) .(O)"}, "label_list": ["chemical compound", "location", "protein", "event", "organization", "theory", "country", "scientist", "award", "enzyme", "discipline", "chemical element", "person", "university", "academic journal", "astronomical object"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 11742, 24549, 11, 3813, 11, 13128, 11, 1567, 11, 7471, 11, 10334, 11, 3224, 11, 28568, 11, 10292, 11, 49242, 11, 26434, 11, 11742, 2449, 11, 1732, 11, 12374, 11, 14584, 8486, 11, 87283, 1665, 323, 507, 627, 85664, 25, 1283, 374, 5131, 10783, 315, 279, 44552, 5955, 369, 279, 19723, 315, 8121, 2065, 520, 44552, 3907, 1174, 374, 279, 20023, 3778, 1080, 79781, 315, 279, 5783, 24145, 70589, 1174, 323, 374, 389, 279, 4580, 315, 28454, 315, 18002, 75758, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2136", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movie(O) does(O) kenneth(B-actor) branagh(I-actor) star(O) in(O) that(O) was(O) made(O) in(O) the(O) 1940(B-year) s(I-year) with(O) a(O) megacorporation(B-plot) plot(O) that(O) was(O) liked(B-average ratings) by(I-average ratings) many(I-average ratings)", "instance": {"id": "2136", "words": ["what", "movie", "does", "kenneth", "branagh", "star", "in", "that", "was", "made", "in", "the", "1940", "s", "with", "a", "megacorporation", "plot", "that", "was", "liked", "by", "many"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O", "O", "O", "O", "O", "O", "O", "B-year", "I-year", "O", "O", "B-plot", "O", "O", "O", "B-average ratings", "I-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, trailer, character, year, actor, review, average ratings, plot, song, title, genre, director and O.\nSentence: what movie does kenneth branagh star in that was made in the 1940 s with a megacorporation plot that was liked by many", "prompt_labels": "what(O) movie(O) does(O) kenneth(B-actor) branagh(I-actor) star(O) in(O) that(O) was(O) made(O) in(O) the(O) 1940(B-year) s(I-year) with(O) a(O) megacorporation(B-plot) plot(O) that(O) was(O) liked(B-average ratings) by(I-average ratings) many(I-average ratings)"}, "label_list": ["rating", "trailer", "character", "year", "actor", "review", "average ratings", "plot", "song", "title", "genre", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 19809, 11, 3752, 11, 1060, 11, 12360, 11, 3477, 11, 5578, 18594, 11, 7234, 11, 5609, 11, 2316, 11, 17779, 11, 7690, 323, 507, 627, 85664, 25, 1148, 5818, 1587, 75361, 774, 53358, 34856, 6917, 304, 430, 574, 1903, 304, 279, 220, 6393, 15, 274, 449, 264, 19262, 582, 39382, 367, 7234, 430, 574, 15262, 555, 1690, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1987", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) wall(B-title) e(I-title) about(O)", "instance": {"id": "1987", "words": ["what", "is", "wall", "e", "about"], "labels": ["O", "O", "B-title", "I-title", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, average ratings, plot, character, review, director, genre, actor, year, rating, title, trailer and O.\nSentence: what is wall e about", "prompt_labels": "what(O) is(O) wall(B-title) e(I-title) about(O)"}, "label_list": ["song", "average ratings", "plot", "character", "review", "director", "genre", "actor", "year", "rating", "title", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 5578, 18594, 11, 7234, 11, 3752, 11, 3477, 11, 7690, 11, 17779, 11, 12360, 11, 1060, 11, 10959, 11, 2316, 11, 19809, 323, 507, 627, 85664, 25, 1148, 374, 7147, 384, 922, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "34", "dataset": "crossner_science", "split": "dev", "prediction": "Helicase(O) s(O) unwind(O) the(O) strands(O) to(O) facilitate(O) the(O) advance(O) of(O) sequence-reading(O) enzymes(O) such(O) as(O) DNA(B-enzyme) polymerase(I-enzyme).(O)", "instance": {"id": "34", "words": ["Helicase", "s", "unwind", "the", "strands", "to", "facilitate", "the", "advance", "of", "sequence-reading", "enzymes", "such", "as", "DNA", "polymerase", "."], "labels": ["B-enzyme", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-enzyme", "I-enzyme", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, country, event, person, scientist, organization, location, academic journal, discipline, university, theory, protein, astronomical object, chemical element, enzyme, award and O.\nSentence: Helicase s unwind the strands to facilitate the advance of sequence-reading enzymes such as DNA polymerase .", "prompt_labels": "Helicase(B-enzyme) s(O) unwind(O) the(O) strands(O) to(O) facilitate(O) the(O) advance(O) of(O) sequence-reading(O) enzymes(O) such(O) as(O) DNA(B-enzyme) polymerase(I-enzyme) .(O)"}, "label_list": ["chemical compound", "country", "event", "person", "scientist", "organization", "location", "academic journal", "discipline", "university", "theory", "protein", "astronomical object", "chemical element", "enzyme", "award"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 11742, 24549, 11, 3224, 11, 1567, 11, 1732, 11, 28568, 11, 7471, 11, 3813, 11, 14584, 8486, 11, 26434, 11, 12374, 11, 10334, 11, 13128, 11, 87283, 1665, 11, 11742, 2449, 11, 49242, 11, 10292, 323, 507, 627, 85664, 25, 16183, 292, 521, 274, 82610, 279, 69864, 311, 28696, 279, 12178, 315, 8668, 12, 6285, 56067, 1778, 439, 15922, 47393, 521, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "76", "dataset": "crossner_music", "split": "dev", "prediction": "It(O) comprises(O) the(O) music(O) of(O) Bosnia(B-country) and(I-country) Herzegovina(I-country),(O) Bulgaria(B-country),(O) Croatia(B-country),(O) Music(B-music genre) of(I-music genre) Greece(I-music genre),(O) Montenegro(B-country),(O) Serbia(B-country),(O) Romania(B-country),(O) Republic(B-country) of(I-country) Macedonia(I-country),(O) Albania(B-country),(O) some(O) of(O) the(O) historical(O) states(O) of(O) Yugoslavia(B-country) or(O) the(O) State(B-country) Union(I-country) of(I-country) Serbia(I-country) and(I-country) Montenegro(I-country) and(O) geographical(O) regions(O) such(O) as(O) Thrace(B-location).(O)", "instance": {"id": "76", "words": ["It", "comprises", "the", "music", "of", "Bosnia", "and", "Herzegovina", ",", "Bulgaria", ",", "Croatia", ",", "Music", "of", "Greece", ",", "Montenegro", ",", "Serbia", ",", "Romania", ",", "Republic", "of", "Macedonia", ",", "Albania", ",", "some", "of", "the", "historical", "states", "of", "Yugoslavia", "or", "the", "State", "Union", "of", "Serbia", "and", "Montenegro", "and", "geographical", "regions", "such", "as", "Thrace", "."], "labels": ["O", "O", "O", "B-music genre", "I-music genre", "I-music genre", "I-music genre", "I-music genre", "O", "B-country", "O", "B-country", "O", "B-music genre", "I-music genre", "I-music genre", "O", "B-country", "O", "B-country", "O", "B-country", "O", "B-country", "I-country", "I-country", "O", "B-country", "O", "O", "O", "O", "O", "O", "O", "B-country", "O", "O", "B-country", "I-country", "I-country", "I-country", "I-country", "I-country", "O", "O", "O", "O", "O", "B-location", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, award, country, organization, musical artist, song, musical instrument, album, music genre, location, band, person and O.\nSentence: It comprises the music of Bosnia and Herzegovina , Bulgaria , Croatia , Music of Greece , Montenegro , Serbia , Romania , Republic of Macedonia , Albania , some of the historical states of Yugoslavia or the State Union of Serbia and Montenegro and geographical regions such as Thrace .", "prompt_labels": "It(O) comprises(O) the(O) music(B-music genre) of(I-music genre) Bosnia(I-music genre) and(I-music genre) Herzegovina(I-music genre) ,(O) Bulgaria(B-country) ,(O) Croatia(B-country) ,(O) Music(B-music genre) of(I-music genre) Greece(I-music genre) ,(O) Montenegro(B-country) ,(O) Serbia(B-country) ,(O) Romania(B-country) ,(O) Republic(B-country) of(I-country) Macedonia(I-country) ,(O) Albania(B-country) ,(O) some(O) of(O) the(O) historical(O) states(O) of(O) Yugoslavia(B-country) or(O) the(O) State(B-country) Union(I-country) of(I-country) Serbia(I-country) and(I-country) Montenegro(I-country) and(O) geographical(O) regions(O) such(O) as(O) Thrace(B-location) .(O)"}, "label_list": ["event", "award", "country", "organization", "musical artist", "song", "musical instrument", "album", "music genre", "location", "band", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 10292, 11, 3224, 11, 7471, 11, 18273, 10255, 11, 5609, 11, 18273, 14473, 11, 8176, 11, 4731, 17779, 11, 3813, 11, 7200, 11, 1732, 323, 507, 627, 85664, 25, 1102, 41095, 279, 4731, 315, 77428, 323, 53739, 75287, 2259, 1174, 59819, 1174, 58311, 1174, 10948, 315, 25431, 1174, 9995, 88921, 1174, 59814, 1174, 47149, 1174, 5545, 315, 77509, 1174, 95733, 1174, 1063, 315, 279, 13970, 5415, 315, 97877, 477, 279, 3314, 9323, 315, 59814, 323, 9995, 88921, 323, 54001, 13918, 1778, 439, 30665, 580, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "298", "dataset": "crossner_literature", "split": "dev", "prediction": "In(O) Vertigo(B-title) ((O) 1958(O) )(O) and(O) North(B-title) by(I-title) Northwest(I-title) ((O) 1959(O) )(O) respectively(O),(O) Kim(B-actor) Novak(I-actor) and(O) Eva(B-actor) Marie(I-actor) Saint(I-actor) play(O) the(O) blonde(O) heroines(O).(O)", "instance": {"id": "298", "words": ["In", "Vertigo", "(", "1958", ")", "and", "North", "by", "Northwest", "(", "1959", ")", "respectively", ",", "Kim", "Novak", "and", "Eva", "Marie", "Saint", "play", "the", "blonde", "heroines", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "B-person", "I-person", "I-person", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, person, magazine, country, poem, writer, organization, book, event, location, award and O.\nSentence: In Vertigo ( 1958 ) and North by Northwest ( 1959 ) respectively , Kim Novak and Eva Marie Saint play the blonde heroines .", "prompt_labels": "In(O) Vertigo(O) ((O) 1958(O) )(O) and(O) North(O) by(O) Northwest(O) ((O) 1959(O) )(O) respectively(O) ,(O) Kim(B-person) Novak(I-person) and(O) Eva(B-person) Marie(I-person) Saint(I-person) play(O) the(O) blonde(O) heroines(O) .(O)"}, "label_list": ["literary genre", "person", "magazine", "country", "poem", "writer", "organization", "book", "event", "location", "award"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 32465, 17779, 11, 1732, 11, 14756, 11, 3224, 11, 33894, 11, 7061, 11, 7471, 11, 2363, 11, 1567, 11, 3813, 11, 10292, 323, 507, 627, 85664, 25, 763, 15408, 7992, 320, 220, 6280, 23, 883, 323, 4892, 555, 40505, 320, 220, 6280, 24, 883, 15947, 1174, 13818, 4723, 587, 323, 55492, 33116, 14539, 1514, 279, 27117, 12084, 1572, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2112", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) rated(O) r(B-rating) movie(O) that(O) marleen(B-director) gorris(I-director) directed(O) with(O) the(O) emotional(B-genre) decision(O) aspect(O) to(O) it(O) receiving(O) an(O) average(B-average ratings) rating(O)", "instance": {"id": "2112", "words": ["what", "is", "the", "rated", "r", "movie", "that", "marleen", "gorris", "directed", "with", "the", "emotional", "decision", "aspect", "to", "it", "receiving", "an", "average", "rating"], "labels": ["O", "O", "O", "O", "B-rating", "O", "O", "B-director", "I-director", "O", "O", "O", "B-genre", "B-plot", "O", "O", "O", "O", "O", "B-average ratings", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, genre, character, actor, year, song, plot, review, title, director, rating, average ratings and O.\nSentence: what is the rated r movie that marleen gorris directed with the emotional decision aspect to it receiving an average rating", "prompt_labels": "what(O) is(O) the(O) rated(O) r(B-rating) movie(O) that(O) marleen(B-director) gorris(I-director) directed(O) with(O) the(O) emotional(B-genre) decision(B-plot) aspect(O) to(O) it(O) receiving(O) an(O) average(B-average ratings) rating(O)"}, "label_list": ["trailer", "genre", "character", "actor", "year", "song", "plot", "review", "title", "director", "rating", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 17779, 11, 3752, 11, 12360, 11, 1060, 11, 5609, 11, 7234, 11, 3477, 11, 2316, 11, 7690, 11, 10959, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1148, 374, 279, 22359, 436, 5818, 430, 3678, 40762, 46298, 6091, 15910, 449, 279, 14604, 5597, 13189, 311, 433, 12588, 459, 5578, 10959, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "47", "dataset": "crossner_literature", "split": "dev", "prediction": "In(O) March(O) 2020(O),(O) a(O) third(O) season(O) of(O) Cosmos(B-magazine) named(O) Cosmos(B-book) :(O) Possible(B-book) Worlds(I-book),(O) for(O) which(O) Druyan(B-person) was(O) executive(O) producer(O),(O) writer(O),(O) and(O) director(O) premiered(O) on(O) National(B-magazine) Geographic(I-magazine).(O)", "instance": {"id": "47", "words": ["In", "March", "2020", ",", "a", "third", "season", "of", "Cosmos", "named", "Cosmos", ":", "Possible", "Worlds", ",", "for", "which", "Druyan", "was", "executive", "producer", ",", "writer", ",", "and", "director", "premiered", "on", "National", "Geographic", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-writer", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-magazine", "I-magazine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: book, person, location, organization, magazine, award, literary genre, country, writer, poem, event and O.\nSentence: In March 2020 , a third season of Cosmos named Cosmos : Possible Worlds , for which Druyan was executive producer , writer , and director premiered on National Geographic .", "prompt_labels": "In(O) March(O) 2020(O) ,(O) a(O) third(O) season(O) of(O) Cosmos(O) named(O) Cosmos(O) :(O) Possible(O) Worlds(O) ,(O) for(O) which(O) Druyan(B-writer) was(O) executive(O) producer(O) ,(O) writer(O) ,(O) and(O) director(O) premiered(O) on(O) National(B-magazine) Geographic(I-magazine) .(O)"}, "label_list": ["book", "person", "location", "organization", "magazine", "award", "literary genre", "country", "writer", "poem", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2363, 11, 1732, 11, 3813, 11, 7471, 11, 14756, 11, 10292, 11, 32465, 17779, 11, 3224, 11, 7061, 11, 33894, 11, 1567, 323, 507, 627, 85664, 25, 763, 5587, 220, 2366, 15, 1174, 264, 4948, 3280, 315, 84524, 7086, 84524, 551, 37207, 52947, 1174, 369, 902, 423, 2739, 8503, 574, 11145, 17276, 1174, 7061, 1174, 323, 7690, 85170, 389, 5165, 66542, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1469", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) there(O) a(O) animation(B-genre) pg(B-rating) 13(I-rating) movie(O) with(O) trisha(B-actor) romance(B-genre)", "instance": {"id": "1469", "words": ["is", "there", "a", "animation", "pg", "13", "movie", "with", "trisha", "romance"], "labels": ["O", "O", "O", "B-genre", "B-rating", "I-rating", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, title, rating, director, character, year, review, average ratings, actor, plot, genre, song and O.\nSentence: is there a animation pg 13 movie with trisha romance", "prompt_labels": "is(O) there(O) a(O) animation(B-genre) pg(B-rating) 13(I-rating) movie(O) with(O) trisha(B-actor) romance(I-actor)"}, "label_list": ["trailer", "title", "rating", "director", "character", "year", "review", "average ratings", "actor", "plot", "genre", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 2316, 11, 10959, 11, 7690, 11, 3752, 11, 1060, 11, 3477, 11, 5578, 18594, 11, 12360, 11, 7234, 11, 17779, 11, 5609, 323, 507, 627, 85664, 25, 374, 1070, 264, 10571, 17953, 220, 1032, 5818, 449, 490, 36040, 30363, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "208", "dataset": "crossner_music", "split": "dev", "prediction": "The(O) song(O)'s(O) popularity(O) resulted(O) in(O) its(O) being(O) covered(O) by(O) other(O) musicians(O),(O) such(O) as(O) The(B-album) Disposable(I-album) Heroes(I-album) of(I-album) Hiphoprisy(I-album) ((O) who(O) rewrote(O) the(O) lyrics(O) to(O) parody(O) Pete(B-politician) Wilson(I-politician) )(O),(O) John(B-musical artist) Linnell(I-musical artist) of(O) They(B-album) Might(I-album) Be(I-album) Giants(I-album) and(O) Six(B-album) Feet(I-album) Under(I-album) on(O) their(O) Graveyard(O) Classics(O) album(O) of(O) cover(O) versions(O).(O)", "instance": {"id": "208", "words": ["The", "song", "'s", "popularity", "resulted", "in", "its", "being", "covered", "by", "other", "musicians", ",", "such", "as", "The", "Disposable", "Heroes", "of", "Hiphoprisy", "(", "who", "rewrote", "the", "lyrics", "to", "parody", "Pete", "Wilson", ")", ",", "John", "Linnell", "of", "They", "Might", "Be", "Giants", "and", "Six", "Feet", "Under", "on", "their", "Graveyard", "Classics", "album", "of", "cover", "versions", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-band", "I-band", "I-band", "I-band", "I-band", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "O", "B-musical artist", "I-musical artist", "O", "B-band", "I-band", "I-band", "I-band", "O", "B-band", "I-band", "I-band", "O", "O", "B-album", "I-album", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, country, event, person, musical instrument, location, band, musical artist, award, music genre, album, organization and O.\nSentence: The song 's popularity resulted in its being covered by other musicians , such as The Disposable Heroes of Hiphoprisy ( who rewrote the lyrics to parody Pete Wilson ) , John Linnell of They Might Be Giants and Six Feet Under on their Graveyard Classics album of cover versions .", "prompt_labels": "The(O) song(O) 's(O) popularity(O) resulted(O) in(O) its(O) being(O) covered(O) by(O) other(O) musicians(O) ,(O) such(O) as(O) The(B-band) Disposable(I-band) Heroes(I-band) of(I-band) Hiphoprisy(I-band) ((O) who(O) rewrote(O) the(O) lyrics(O) to(O) parody(O) Pete(B-person) Wilson(I-person) )(O) ,(O) John(B-musical artist) Linnell(I-musical artist) of(O) They(B-band) Might(I-band) Be(I-band) Giants(I-band) and(O) Six(B-band) Feet(I-band) Under(I-band) on(O) their(O) Graveyard(B-album) Classics(I-album) album(O) of(O) cover(O) versions(O) .(O)"}, "label_list": ["song", "country", "event", "person", "musical instrument", "location", "band", "musical artist", "award", "music genre", "album", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 3224, 11, 1567, 11, 1732, 11, 18273, 14473, 11, 3813, 11, 7200, 11, 18273, 10255, 11, 10292, 11, 4731, 17779, 11, 8176, 11, 7471, 323, 507, 627, 85664, 25, 578, 5609, 364, 82, 23354, 19543, 304, 1202, 1694, 9960, 555, 1023, 32629, 1174, 1778, 439, 578, 52386, 38099, 315, 473, 15619, 454, 6091, 88, 320, 889, 79722, 5646, 279, 24142, 311, 67265, 37373, 17882, 883, 1174, 3842, 445, 6258, 616, 315, 2435, 34351, 2893, 30835, 323, 19198, 62289, 9636, 389, 872, 74842, 17884, 73415, 8176, 315, 3504, 11028, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1003", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) films(O) use(O) the(O) song(O) zippity(B-song) do(I-song) da(I-song)", "instance": {"id": "1003", "words": ["what", "films", "use", "the", "song", "zippity", "do", "da"], "labels": ["O", "O", "O", "O", "O", "B-song", "I-song", "I-song"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, plot, title, actor, trailer, song, director, year, character, review, genre, rating and O.\nSentence: what films use the song zippity do da", "prompt_labels": "what(O) films(O) use(O) the(O) song(O) zippity(B-song) do(I-song) da(I-song)"}, "label_list": ["average ratings", "plot", "title", "actor", "trailer", "song", "director", "year", "character", "review", "genre", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 7234, 11, 2316, 11, 12360, 11, 19809, 11, 5609, 11, 7690, 11, 1060, 11, 3752, 11, 3477, 11, 17779, 11, 10959, 323, 507, 627, 85664, 25, 1148, 12631, 1005, 279, 5609, 1167, 2877, 488, 656, 3067, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "370", "dataset": "crossner_literature", "split": "dev", "prediction": "Lawrence(B-writer) Hill(I-writer) '(O) s(O) Book(B-book) of(I-book) Negroes(I-book) won(O) the(O) 2008(O) Commonwealth(B-award) Writers(I-award) '(O) Prize(O) Overall(O) Best(O) Book(O) Award(O),(O) while(O) Alice(B-writer) Munro(I-writer) became(O) the(O) first(O) Canadian(O) to(O) win(O) the(O) Nobel(B-award) Prize(I-award) in(I-award) Literature(I-award) in(O) 2013(O).(O)", "instance": {"id": "370", "words": ["Lawrence", "Hill", "'", "s", "Book", "of", "Negroes", "won", "the", "2008", "Commonwealth", "Writers", "'", "Prize", "Overall", "Best", "Book", "Award", ",", "while", "Alice", "Munro", "became", "the", "first", "Canadian", "to", "win", "the", "Nobel", "Prize", "in", "Literature", "in", "2013", "."], "labels": ["B-writer", "I-writer", "O", "O", "B-book", "I-book", "I-book", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O", "O", "B-writer", "I-writer", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, book, writer, magazine, person, organization, country, event, award, poem, literary genre and O.\nSentence: Lawrence Hill ' s Book of Negroes won the 2008 Commonwealth Writers ' Prize Overall Best Book Award , while Alice Munro became the first Canadian to win the Nobel Prize in Literature in 2013 .", "prompt_labels": "Lawrence(B-writer) Hill(I-writer) '(O) s(O) Book(B-book) of(I-book) Negroes(I-book) won(O) the(O) 2008(O) Commonwealth(B-award) Writers(I-award) '(I-award) Prize(I-award) Overall(I-award) Best(I-award) Book(I-award) Award(I-award) ,(O) while(O) Alice(B-writer) Munro(I-writer) became(O) the(O) first(O) Canadian(O) to(O) win(O) the(O) Nobel(B-award) Prize(I-award) in(I-award) Literature(I-award) in(O) 2013(O) .(O)"}, "label_list": ["location", "book", "writer", "magazine", "person", "organization", "country", "event", "award", "poem", "literary genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 2363, 11, 7061, 11, 14756, 11, 1732, 11, 7471, 11, 3224, 11, 1567, 11, 10292, 11, 33894, 11, 32465, 17779, 323, 507, 627, 85664, 25, 28574, 8270, 364, 274, 6017, 315, 57147, 288, 2834, 279, 220, 1049, 23, 38298, 59798, 364, 32293, 28993, 7252, 6017, 17768, 1174, 1418, 30505, 28982, 299, 6244, 279, 1176, 12152, 311, 3243, 279, 48078, 32293, 304, 47470, 304, 220, 679, 18, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "317", "dataset": "crossner_literature", "split": "dev", "prediction": "The(B-book) Ghost(I-book) Writer(I-book),(O) a(O) thriller(B-literary genre) focusing(O) on(O) a(O) ghostwriter(B-literary genre) working(O) on(O) the(O) memoirs(B-literary genre) of(O) a(O) character(O) based(O) loosely(O) on(O) former(O) British(O) prime(O) minister(O) Tony(B-person) Blair(I-person),(O) swept(O) the(O) European(B-award) Film(I-award) Awards(I-award) in(O) 2010(O),(O) winning(O) six(O) awards(O),(O) including(O) best(O) movie(O),(O) director(O),(O) actor(O) and(O) screenplay(O).(O)", "instance": {"id": "317", "words": ["The", "Ghost", "Writer", ",", "a", "thriller", "focusing", "on", "a", "ghostwriter", "working", "on", "the", "memoirs", "of", "a", "character", "based", "loosely", "on", "former", "British", "prime", "minister", "Tony", "Blair", ",", "swept", "the", "European", "Film", "Awards", "in", "2010", ",", "winning", "six", "awards", ",", "including", "best", "movie", ",", "director", ",", "actor", "and", "screenplay", "."], "labels": ["B-book", "I-book", "I-book", "O", "O", "B-literary genre", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "O", "O", "B-award", "I-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, award, country, literary genre, writer, event, person, book, poem, location, magazine and O.\nSentence: The Ghost Writer , a thriller focusing on a ghostwriter working on the memoirs of a character based loosely on former British prime minister Tony Blair , swept the European Film Awards in 2010 , winning six awards , including best movie , director , actor and screenplay .", "prompt_labels": "The(B-book) Ghost(I-book) Writer(I-book) ,(O) a(O) thriller(B-literary genre) focusing(O) on(O) a(O) ghostwriter(O) working(O) on(O) the(O) memoirs(O) of(O) a(O) character(O) based(O) loosely(O) on(O) former(O) British(O) prime(O) minister(O) Tony(B-person) Blair(I-person) ,(O) swept(O) the(O) European(B-award) Film(I-award) Awards(I-award) in(O) 2010(O) ,(O) winning(O) six(O) awards(O) ,(O) including(O) best(O) movie(O) ,(O) director(O) ,(O) actor(O) and(O) screenplay(O) .(O)"}, "label_list": ["organization", "award", "country", "literary genre", "writer", "event", "person", "book", "poem", "location", "magazine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 10292, 11, 3224, 11, 32465, 17779, 11, 7061, 11, 1567, 11, 1732, 11, 2363, 11, 33894, 11, 3813, 11, 14756, 323, 507, 627, 85664, 25, 578, 26099, 30504, 1174, 264, 54461, 21760, 389, 264, 20457, 18688, 3318, 389, 279, 51342, 82, 315, 264, 3752, 3196, 63557, 389, 4846, 8013, 10461, 13015, 19036, 42969, 1174, 41323, 279, 7665, 17042, 23488, 304, 220, 679, 15, 1174, 11230, 4848, 23146, 1174, 2737, 1888, 5818, 1174, 7690, 1174, 12360, 323, 85875, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2069", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) last(O) rated(O) r(B-rating) fantasy(B-genre) movie(O) that(O) came(O) out(O)", "instance": {"id": "2069", "words": ["what", "is", "the", "last", "rated", "r", "fantasy", "movie", "that", "came", "out"], "labels": ["O", "O", "O", "O", "O", "B-rating", "B-genre", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, genre, review, title, character, year, plot, song, actor, trailer, director, rating and O.\nSentence: what is the last rated r fantasy movie that came out", "prompt_labels": "what(O) is(O) the(O) last(O) rated(O) r(B-rating) fantasy(B-genre) movie(O) that(O) came(O) out(O)"}, "label_list": ["average ratings", "genre", "review", "title", "character", "year", "plot", "song", "actor", "trailer", "director", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 17779, 11, 3477, 11, 2316, 11, 3752, 11, 1060, 11, 7234, 11, 5609, 11, 12360, 11, 19809, 11, 7690, 11, 10959, 323, 507, 627, 85664, 25, 1148, 374, 279, 1566, 22359, 436, 18884, 5818, 430, 3782, 704, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2094", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) name(O) of(O) an(O) animated(B-genre) film(O) from(O) the(O) 1990(B-year) s(I-year) directed(O) by(O) fritz(B-director) lang(I-director)", "instance": {"id": "2094", "words": ["what", "is", "the", "name", "of", "an", "animated", "film", "from", "the", "1990", "s", "directed", "by", "fritz", "lang"], "labels": ["O", "O", "O", "O", "O", "O", "B-genre", "O", "O", "O", "B-year", "I-year", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, actor, plot, review, genre, title, song, character, trailer, year, rating, average ratings and O.\nSentence: what is the name of an animated film from the 1990 s directed by fritz lang", "prompt_labels": "what(O) is(O) the(O) name(O) of(O) an(O) animated(B-genre) film(O) from(O) the(O) 1990(B-year) s(I-year) directed(O) by(O) fritz(B-director) lang(I-director)"}, "label_list": ["director", "actor", "plot", "review", "genre", "title", "song", "character", "trailer", "year", "rating", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 12360, 11, 7234, 11, 3477, 11, 17779, 11, 2316, 11, 5609, 11, 3752, 11, 19809, 11, 1060, 11, 10959, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1148, 374, 279, 836, 315, 459, 11625, 4632, 505, 279, 220, 2550, 15, 274, 15910, 555, 282, 57821, 8859, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "509", "dataset": "crossner_politics", "split": "dev", "prediction": "The(O) party(O) seeks(O) the(O) removal(O) of(O) Northern(B-location) Ireland(I-location) from(O) the(O) United(B-country) Kingdom(I-country),(O) the(O) Right2Water(B-event) Campaign(I-event),(O) the(O) campaign(O) to(O) Repeal(O) The(O) 8th(O) Amendment(O),(O) and(O) their(O) Public(B-event) Housing(I-event) For(O) all(O) campaign(O),(O) which(O) calls(O) for(O) the(O) state(O) to(O) introduce(O) a(O) housing(O) system(O) where(O) all(O) citizens(O) have(O) the(O) legal(O) right(O) to(O) rent(O) a(O) high-quality(O),(O) affordable(O) home(O) regardless(O) of(O) their(O) income(O).(O)", "instance": {"id": "509", "words": ["The", "party", "seeks", "the", "removal", "of", "Northern", "Ireland", "from", "the", "United", "Kingdom", ",", "the", "Right2Water", "Campaign", ",", "the", "campaign", "to", "Repeal", "The", "8th", "Amendment", ",", "and", "their", "Public", "Housing", "For", "all", "campaign", ",", "which", "calls", "for", "the", "state", "to", "introduce", "a", "housing", "system", "where", "all", "citizens", "have", "the", "legal", "right", "to", "rent", "a", "high-quality", ",", "affordable", "home", "regardless", "of", "their", "income", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-country", "I-country", "O", "O", "B-country", "I-country", "O", "O", "B-event", "I-event", "O", "O", "B-event", "I-event", "I-event", "I-event", "I-event", "I-event", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, organization, event, election, location, country, person, politician and O.\nSentence: The party seeks the removal of Northern Ireland from the United Kingdom , the Right2Water Campaign , the campaign to Repeal The 8th Amendment , and their Public Housing For all campaign , which calls for the state to introduce a housing system where all citizens have the legal right to rent a high-quality , affordable home regardless of their income .", "prompt_labels": "The(O) party(O) seeks(O) the(O) removal(O) of(O) Northern(B-country) Ireland(I-country) from(O) the(O) United(B-country) Kingdom(I-country) ,(O) the(O) Right2Water(B-event) Campaign(I-event) ,(O) the(O) campaign(B-event) to(I-event) Repeal(I-event) The(I-event) 8th(I-event) Amendment(I-event) ,(O) and(O) their(O) Public(O) Housing(O) For(O) all(O) campaign(O) ,(O) which(O) calls(O) for(O) the(O) state(O) to(O) introduce(O) a(O) housing(O) system(O) where(O) all(O) citizens(O) have(O) the(O) legal(O) right(O) to(O) rent(O) a(O) high-quality(O) ,(O) affordable(O) home(O) regardless(O) of(O) their(O) income(O) .(O)"}, "label_list": ["political party", "organization", "event", "election", "location", "country", "person", "politician"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5054, 4717, 11, 7471, 11, 1567, 11, 6355, 11, 3813, 11, 3224, 11, 1732, 11, 37038, 323, 507, 627, 85664, 25, 578, 4717, 26737, 279, 17065, 315, 17355, 14990, 505, 279, 3723, 15422, 1174, 279, 10291, 17, 29353, 27643, 1174, 279, 4901, 311, 1050, 375, 278, 578, 220, 23, 339, 22454, 1174, 323, 872, 3142, 31433, 1789, 682, 4901, 1174, 902, 6880, 369, 279, 1614, 311, 19678, 264, 11983, 1887, 1405, 682, 10495, 617, 279, 5897, 1314, 311, 8175, 264, 1579, 22867, 1174, 17049, 2162, 15851, 315, 872, 8070, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1730", "dataset": "mit-movie", "split": "dev", "prediction": "name(O) a(O) musical(B-genre) that(O) was(O) directed(O) by(O) billy(B-director) wilder(I-director)", "instance": {"id": "1730", "words": ["name", "a", "musical", "that", "was", "directed", "by", "billy", "wilder"], "labels": ["O", "O", "B-genre", "O", "O", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, genre, plot, title, rating, trailer, character, review, song, year, director, average ratings and O.\nSentence: name a musical that was directed by billy wilder", "prompt_labels": "name(O) a(O) musical(B-genre) that(O) was(O) directed(O) by(O) billy(B-director) wilder(I-director)"}, "label_list": ["actor", "genre", "plot", "title", "rating", "trailer", "character", "review", "song", "year", "director", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 17779, 11, 7234, 11, 2316, 11, 10959, 11, 19809, 11, 3752, 11, 3477, 11, 5609, 11, 1060, 11, 7690, 11, 5578, 18594, 323, 507, 627, 85664, 25, 836, 264, 18273, 430, 574, 15910, 555, 293, 14722, 8545, 261, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1118", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) is(O) the(O) best(B-Rating) coffee(B-Cuisine) house(I-Cuisine) near(B-Location) here(I-Location)", "instance": {"id": "1118", "words": ["what", "is", "the", "best", "coffee", "house", "near", "here"], "labels": ["O", "O", "O", "B-Rating", "B-Cuisine", "I-Cuisine", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Cuisine, Price, Restaurant Name, Dish, Hours, Rating, Amenity and O.\nSentence: what is the best coffee house near here", "prompt_labels": "what(O) is(O) the(O) best(B-Rating) coffee(B-Cuisine) house(I-Cuisine) near(B-Location) here(I-Location)"}, "label_list": ["Location", "Cuisine", "Price", "Restaurant Name", "Dish", "Hours", "Rating", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 81961, 11, 8650, 11, 26568, 4076, 11, 49268, 11, 30192, 11, 19767, 11, 3383, 56685, 323, 507, 627, 85664, 25, 1148, 374, 279, 1888, 11033, 3838, 3221, 1618, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "511", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) year(O) did(O) star(B-title) wars(I-title) a(I-title) new(I-title) hope(I-title) come(O) out(O)", "instance": {"id": "511", "words": ["what", "year", "did", "star", "wars", "a", "new", "hope", "come", "out"], "labels": ["O", "O", "O", "B-title", "I-title", "I-title", "I-title", "I-title", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, actor, character, trailer, genre, average ratings, year, rating, song, plot, title, director and O.\nSentence: what year did star wars a new hope come out", "prompt_labels": "what(O) year(O) did(O) star(B-title) wars(I-title) a(I-title) new(I-title) hope(I-title) come(O) out(O)"}, "label_list": ["review", "actor", "character", "trailer", "genre", "average ratings", "year", "rating", "song", "plot", "title", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 12360, 11, 3752, 11, 19809, 11, 17779, 11, 5578, 18594, 11, 1060, 11, 10959, 11, 5609, 11, 7234, 11, 2316, 11, 7690, 323, 507, 627, 85664, 25, 1148, 1060, 1550, 6917, 25981, 264, 502, 3987, 2586, 704, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "356", "dataset": "crossner_literature", "split": "dev", "prediction": "Only(O) The(B-book) Graveyard(I-book) Book(I-book) by(O) Neil(B-writer) Gaiman(I-writer) ((O) 2009(O) )(O) has(O) won(O) both(O) the(O) Carnegie(B-award) Medal(I-award) and(O) the(O) equivalent(O) American(O) award(O),(O) the(O) Newbery(B-award) Medal(I-award).(O)", "instance": {"id": "356", "words": ["Only", "The", "Graveyard", "Book", "by", "Neil", "Gaiman", "(", "2009", ")", "has", "won", "both", "the", "Carnegie", "Medal", "and", "the", "equivalent", "American", "award", ",", "the", "Newbery", "Medal", "."], "labels": ["O", "B-book", "I-book", "I-book", "O", "B-writer", "I-writer", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, person, location, organization, writer, literary genre, award, country, poem, book, magazine and O.\nSentence: Only The Graveyard Book by Neil Gaiman ( 2009 ) has won both the Carnegie Medal and the equivalent American award , the Newbery Medal .", "prompt_labels": "Only(O) The(B-book) Graveyard(I-book) Book(I-book) by(O) Neil(B-writer) Gaiman(I-writer) ((O) 2009(O) )(O) has(O) won(O) both(O) the(O) Carnegie(B-award) Medal(I-award) and(O) the(O) equivalent(O) American(O) award(O) ,(O) the(O) Newbery(B-award) Medal(I-award) .(O)"}, "label_list": ["event", "person", "location", "organization", "writer", "literary genre", "award", "country", "poem", "book", "magazine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 1732, 11, 3813, 11, 7471, 11, 7061, 11, 32465, 17779, 11, 10292, 11, 3224, 11, 33894, 11, 2363, 11, 14756, 323, 507, 627, 85664, 25, 8442, 578, 74842, 17884, 6017, 555, 34221, 480, 2706, 276, 320, 220, 1049, 24, 883, 706, 2834, 2225, 279, 64373, 17867, 323, 279, 13890, 3778, 10292, 1174, 279, 1561, 31304, 17867, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "359", "dataset": "mit-restaurant", "split": "dev", "prediction": "find(O) me(O) a(O) cheap(B-Price) restaurant(O) with(O) a(O) no(B-Amenity) smoking(I-Amenity) area(I-Amenity)", "instance": {"id": "359", "words": ["find", "me", "a", "cheap", "restaurant", "with", "a", "no", "smoking", "area"], "labels": ["O", "O", "O", "B-Price", "O", "O", "O", "B-Amenity", "I-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Price, Hours, Amenity, Dish, Rating, Cuisine, Location and O.\nSentence: find me a cheap restaurant with a no smoking area", "prompt_labels": "find(O) me(O) a(O) cheap(B-Price) restaurant(O) with(O) a(O) no(B-Amenity) smoking(I-Amenity) area(I-Amenity)"}, "label_list": ["Restaurant Name", "Price", "Hours", "Amenity", "Dish", "Rating", "Cuisine", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 8650, 11, 30192, 11, 3383, 56685, 11, 49268, 11, 19767, 11, 81961, 11, 10067, 323, 507, 627, 85664, 25, 1505, 757, 264, 12136, 10960, 449, 264, 912, 20149, 3158, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "23", "dataset": "crossner_music", "split": "dev", "prediction": "She(O) rose(O) to(O) stardom(O) in(O) the(O) romantic(B-genre) comedy(I-genre) Roman(B-title) Holiday(I-title) ((O) 1953(O) )(O),(O) alongside(O) Gregory(B-musical artist) Peck(I-musical artist),(O) for(O) which(O) she(O) was(O) the(O) first(O) actress(O) to(O) win(O) an(O) Academy(B-award) Awards(I-award),(O) a(O) Golden(B-award) Globe(I-award) Awards(I-award),(O) and(O) a(O) British(B-award) Academy(I-award) Film(I-award) Awards(I-award) for(O) a(O) single(O) performance(O).(O)", "instance": {"id": "23", "words": ["She", "rose", "to", "stardom", "in", "the", "romantic", "comedy", "Roman", "Holiday", "(", "1953", ")", ",", "alongside", "Gregory", "Peck", ",", "for", "which", "she", "was", "the", "first", "actress", "to", "win", "an", "Academy", "Awards", ",", "a", "Golden", "Globe", "Awards", ",", "and", "a", "British", "Academy", "Film", "Awards", "for", "a", "single", "performance", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "O", "O", "B-award", "I-award", "I-award", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, location, album, song, band, country, award, organization, musical artist, event, musical instrument, music genre and O.\nSentence: She rose to stardom in the romantic comedy Roman Holiday ( 1953 ) , alongside Gregory Peck , for which she was the first actress to win an Academy Awards , a Golden Globe Awards , and a British Academy Film Awards for a single performance .", "prompt_labels": "She(O) rose(O) to(O) stardom(O) in(O) the(O) romantic(O) comedy(O) Roman(O) Holiday(O) ((O) 1953(O) )(O) ,(O) alongside(O) Gregory(B-person) Peck(I-person) ,(O) for(O) which(O) she(O) was(O) the(O) first(O) actress(O) to(O) win(O) an(O) Academy(B-award) Awards(I-award) ,(O) a(O) Golden(B-award) Globe(I-award) Awards(I-award) ,(O) and(O) a(O) British(B-award) Academy(I-award) Film(I-award) Awards(I-award) for(O) a(O) single(O) performance(O) .(O)"}, "label_list": ["person", "location", "album", "song", "band", "country", "award", "organization", "musical artist", "event", "musical instrument", "music genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 3813, 11, 8176, 11, 5609, 11, 7200, 11, 3224, 11, 10292, 11, 7471, 11, 18273, 10255, 11, 1567, 11, 18273, 14473, 11, 4731, 17779, 323, 507, 627, 85664, 25, 3005, 16392, 311, 357, 569, 316, 304, 279, 24364, 23160, 13041, 32769, 320, 220, 6280, 18, 883, 1174, 16662, 44069, 5250, 377, 1174, 369, 902, 1364, 574, 279, 1176, 24577, 311, 3243, 459, 16192, 23488, 1174, 264, 18288, 41910, 23488, 1174, 323, 264, 8013, 16192, 17042, 23488, 369, 264, 3254, 5178, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "29", "dataset": "crossner_music", "split": "dev", "prediction": "In(O) central(B-location) Europe(I-location),(O) Italo(B-music genre) disco(I-music genre) ((O) a.k.a.(O) 1980s(B-music genre) Euro(I-music genre) disco(I-music genre) )(O) and(O) Euro(B-music genre) house(I-music genre) were(O) the(O) predominant(O) attempts(O) by(O) young(O) musicians(O) to(O) have(O) a(O) hit(O) record(O) in(O) and(O) beyond(O) the(O) borders(O) of(O) their(O) own(O) country(O).(O)", "instance": {"id": "29", "words": ["In", "central", "Europe", ",", "Italo", "disco", "(", "a.k.a.", "1980s", "Euro", "disco", ")", "and", "Euro", "house", "were", "the", "predominant", "attempts", "by", "young", "musicians", "to", "have", "a", "hit", "record", "in", "and", "beyond", "the", "borders", "of", "their", "own", "country", "."], "labels": ["O", "B-location", "I-location", "O", "B-music genre", "I-music genre", "O", "O", "O", "B-music genre", "I-music genre", "O", "O", "B-music genre", "I-music genre", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, musical instrument, award, person, location, country, album, music genre, event, organization, band, song and O.\nSentence: In central Europe , Italo disco ( a.k.a. 1980s Euro disco ) and Euro house were the predominant attempts by young musicians to have a hit record in and beyond the borders of their own country .", "prompt_labels": "In(O) central(B-location) Europe(I-location) ,(O) Italo(B-music genre) disco(I-music genre) ((O) a.k.a.(O) 1980s(O) Euro(B-music genre) disco(I-music genre) )(O) and(O) Euro(B-music genre) house(I-music genre) were(O) the(O) predominant(O) attempts(O) by(O) young(O) musicians(O) to(O) have(O) a(O) hit(O) record(O) in(O) and(O) beyond(O) the(O) borders(O) of(O) their(O) own(O) country(O) .(O)"}, "label_list": ["musical artist", "musical instrument", "award", "person", "location", "country", "album", "music genre", "event", "organization", "band", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18273, 10255, 11, 18273, 14473, 11, 10292, 11, 1732, 11, 3813, 11, 3224, 11, 8176, 11, 4731, 17779, 11, 1567, 11, 7471, 11, 7200, 11, 5609, 323, 507, 627, 85664, 25, 763, 8792, 4606, 1174, 1102, 12812, 54969, 320, 264, 5314, 5973, 13, 220, 3753, 15, 82, 20026, 54969, 883, 323, 20026, 3838, 1051, 279, 96531, 13865, 555, 3995, 32629, 311, 617, 264, 4295, 3335, 304, 323, 7953, 279, 24743, 315, 872, 1866, 3224, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "95", "dataset": "mit-restaurant", "split": "dev", "prediction": "are(O) there(O) any(O) vegan(B-Cuisine) spots(O) that(O) are(O) open(B-Hours) after(I-Hours) 11(I-Hours) at(I-Hours) night(I-Hours)", "instance": {"id": "95", "words": ["are", "there", "any", "vegan", "spots", "that", "are", "open", "after", "11", "at", "night"], "labels": ["O", "O", "O", "B-Cuisine", "I-Cuisine", "O", "O", "B-Hours", "I-Hours", "I-Hours", "I-Hours", "I-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Dish, Hours, Cuisine, Price, Restaurant Name, Rating, Amenity and O.\nSentence: are there any vegan spots that are open after 11 at night", "prompt_labels": "are(O) there(O) any(O) vegan(B-Cuisine) spots(I-Cuisine) that(O) are(O) open(B-Hours) after(I-Hours) 11(I-Hours) at(I-Hours) night(I-Hours)"}, "label_list": ["Location", "Dish", "Hours", "Cuisine", "Price", "Restaurant Name", "Rating", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 49268, 11, 30192, 11, 81961, 11, 8650, 11, 26568, 4076, 11, 19767, 11, 3383, 56685, 323, 507, 627, 85664, 25, 527, 1070, 904, 30249, 19300, 430, 527, 1825, 1306, 220, 806, 520, 3814, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1773", "dataset": "mit-movie", "split": "dev", "prediction": "that(O) comedy(B-genre) was(O) so(O) funny(O) that(O) id(O) give(O) it(O) ten(B-average ratings) stars(I-average ratings)", "instance": {"id": "1773", "words": ["that", "comedy", "was", "so", "funny", "that", "id", "give", "it", "ten", "stars"], "labels": ["O", "O", "O", "O", "B-genre", "O", "O", "O", "O", "B-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, review, song, trailer, director, year, actor, average ratings, rating, plot, character, title and O.\nSentence: that comedy was so funny that id give it ten stars", "prompt_labels": "that(O) comedy(O) was(O) so(O) funny(B-genre) that(O) id(O) give(O) it(O) ten(B-average ratings) stars(I-average ratings)"}, "label_list": ["genre", "review", "song", "trailer", "director", "year", "actor", "average ratings", "rating", "plot", "character", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 3477, 11, 5609, 11, 19809, 11, 7690, 11, 1060, 11, 12360, 11, 5578, 18594, 11, 10959, 11, 7234, 11, 3752, 11, 2316, 323, 507, 627, 85664, 25, 430, 23160, 574, 779, 15526, 430, 887, 3041, 433, 5899, 9958, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "293", "dataset": "crossner_ai", "split": "dev", "prediction": "In(O) the(O) United(B-country) States(I-country) he(O) is(O) a(O) Member(O) of(O) the(O) National(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization),(O) the(O) American(B-organization) Academy(I-organization) of(I-organization) Arts(I-organization) and(I-organization) Sciences(I-organization),(O) the(O) Linguistic(B-organization) Society(I-organization) of(I-organization) America(I-organization),(O) the(O) American(B-organization) Philosophical(I-organization) Association(I-organization),(O) and(O) the(O) American(B-organization) Association(I-organization) for(I-organization) the(I-organization) Advancement(I-organization) of(I-organization) Science(I-organization).(O)", "instance": {"id": "293", "words": ["In", "the", "United", "States", "he", "is", "a", "Member", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "Linguistic", "Society", "of", "America", ",", "the", "American", "Philosophical", "Association", ",", "and", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "labels": ["O", "O", "B-country", "I-country", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, location, person, metric, algorithm, field, organization, product, researcher, country, conference, programming language, task and O.\nSentence: In the United States he is a Member of the National Academy of Sciences , the American Academy of Arts and Sciences , the Linguistic Society of America , the American Philosophical Association , and the American Association for the Advancement of Science .", "prompt_labels": "In(O) the(O) United(B-country) States(I-country) he(O) is(O) a(O) Member(O) of(O) the(O) National(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) ,(O) the(O) American(B-organization) Academy(I-organization) of(I-organization) Arts(I-organization) and(I-organization) Sciences(I-organization) ,(O) the(O) Linguistic(B-organization) Society(I-organization) of(I-organization) America(I-organization) ,(O) the(O) American(B-organization) Philosophical(I-organization) Association(I-organization) ,(O) and(O) the(O) American(B-organization) Association(I-organization) for(I-organization) the(I-organization) Advancement(I-organization) of(I-organization) Science(I-organization) .(O)"}, "label_list": ["university", "location", "person", "metric", "algorithm", "field", "organization", "product", "researcher", "country", "conference", "programming language", "task"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12374, 11, 3813, 11, 1732, 11, 18767, 11, 12384, 11, 2115, 11, 7471, 11, 2027, 11, 32185, 11, 3224, 11, 10017, 11, 15840, 4221, 11, 3465, 323, 507, 627, 85664, 25, 763, 279, 3723, 4273, 568, 374, 264, 12308, 315, 279, 5165, 16192, 315, 23199, 1174, 279, 3778, 16192, 315, 17979, 323, 23199, 1174, 279, 89333, 4633, 13581, 315, 5270, 1174, 279, 3778, 38356, 950, 10229, 1174, 323, 279, 3778, 10229, 369, 279, 12605, 16887, 315, 10170, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "639", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) want(O) something(O) full(B-Dish) of(I-Dish) grease(I-Dish)", "instance": {"id": "639", "words": ["i", "want", "something", "full", "of", "grease"], "labels": ["O", "O", "O", "O", "O", "B-Cuisine"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Rating, Dish, Hours, Location, Restaurant Name, Price, Amenity and O.\nSentence: i want something full of grease", "prompt_labels": "i(O) want(O) something(O) full(O) of(O) grease(B-Cuisine)"}, "label_list": ["Cuisine", "Rating", "Dish", "Hours", "Location", "Restaurant Name", "Price", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 19767, 11, 49268, 11, 30192, 11, 10067, 11, 26568, 4076, 11, 8650, 11, 3383, 56685, 323, 507, 627, 85664, 25, 602, 1390, 2555, 2539, 315, 63471, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1414", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) is(O) the(O) closest(B-Location) jimmie(B-Restaurant Name) johns(I-Restaurant Name)", "instance": {"id": "1414", "words": ["where", "is", "the", "closest", "jimmie", "johns"], "labels": ["O", "O", "O", "B-Location", "B-Restaurant Name", "I-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Rating, Dish, Restaurant Name, Location, Cuisine, Hours, Price and O.\nSentence: where is the closest jimmie johns", "prompt_labels": "where(O) is(O) the(O) closest(B-Location) jimmie(B-Restaurant Name) johns(I-Restaurant Name)"}, "label_list": ["Amenity", "Rating", "Dish", "Restaurant Name", "Location", "Cuisine", "Hours", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 19767, 11, 49268, 11, 26568, 4076, 11, 10067, 11, 81961, 11, 30192, 11, 8650, 323, 507, 627, 85664, 25, 1405, 374, 279, 18585, 503, 12828, 648, 40742, 82, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "194", "dataset": "crossner_music", "split": "dev", "prediction": "He(O) was(O) the(O) guitarist(O) for(O) the(O) 1980s(O) Hi-NRG(B-music genre),(O) Synth-pop(B-music genre) band(O),(O) Frankie(B-band) Goes(I-band) to(I-band) Hollywood(I-band).(O)", "instance": {"id": "194", "words": ["He", "was", "the", "guitarist", "for", "the", "1980s", "Hi-NRG", ",", "Synth-pop", "band", ",", "Frankie", "Goes", "to", "Hollywood", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-music genre", "O", "B-music genre", "O", "O", "B-band", "I-band", "I-band", "I-band", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, country, location, musical artist, album, song, event, award, band, person, musical instrument, music genre and O.\nSentence: He was the guitarist for the 1980s Hi-NRG , Synth-pop band , Frankie Goes to Hollywood .", "prompt_labels": "He(O) was(O) the(O) guitarist(O) for(O) the(O) 1980s(O) Hi-NRG(B-music genre) ,(O) Synth-pop(B-music genre) band(O) ,(O) Frankie(B-band) Goes(I-band) to(I-band) Hollywood(I-band) .(O)"}, "label_list": ["organization", "country", "location", "musical artist", "album", "song", "event", "award", "band", "person", "musical instrument", "music genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 3224, 11, 3813, 11, 18273, 10255, 11, 8176, 11, 5609, 11, 1567, 11, 10292, 11, 7200, 11, 1732, 11, 18273, 14473, 11, 4731, 17779, 323, 507, 627, 85664, 25, 1283, 574, 279, 62740, 369, 279, 220, 3753, 15, 82, 21694, 11500, 33460, 1174, 24028, 339, 41352, 7200, 1174, 94545, 61261, 311, 17681, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1442", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) robert(B-actor) de(I-actor) niro(I-actor) in(O) any(O) disaster(B-genre) movies(O)", "instance": {"id": "1442", "words": ["is", "robert", "de", "niro", "in", "any", "disaster", "movies"], "labels": ["O", "B-actor", "I-actor", "I-actor", "O", "O", "B-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, title, genre, review, average ratings, rating, character, actor, year, plot, director, song and O.\nSentence: is robert de niro in any disaster movies", "prompt_labels": "is(O) robert(B-actor) de(I-actor) niro(I-actor) in(O) any(O) disaster(B-genre) movies(O)"}, "label_list": ["trailer", "title", "genre", "review", "average ratings", "rating", "character", "actor", "year", "plot", "director", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 2316, 11, 17779, 11, 3477, 11, 5578, 18594, 11, 10959, 11, 3752, 11, 12360, 11, 1060, 11, 7234, 11, 7690, 11, 5609, 323, 507, 627, 85664, 25, 374, 89993, 409, 308, 8869, 304, 904, 21426, 9698, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "44", "dataset": "crossner_literature", "split": "dev", "prediction": "Hesser(B-person) lives(O) in(O) Brooklyn(B-location) Heights(I-location) with(O) her(O) husband(O),(O) Tad(B-writer) Friend(I-writer),(O) a(O) staff(O) writer(O) for(O) The(B-magazine) New(I-magazine) Yorker(I-magazine),(O) and(O) their(O) two(O) children(O).(O)", "instance": {"id": "44", "words": ["Hesser", "lives", "in", "Brooklyn", "Heights", "with", "her", "husband", ",", "Tad", "Friend", ",", "a", "staff", "writer", "for", "The", "New", "Yorker", ",", "and", "their", "two", "children", "."], "labels": ["B-writer", "O", "O", "B-location", "I-location", "O", "O", "O", "O", "B-writer", "I-writer", "O", "O", "O", "O", "O", "B-magazine", "I-magazine", "I-magazine", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, location, country, magazine, writer, poem, book, person, event, literary genre, organization and O.\nSentence: Hesser lives in Brooklyn Heights with her husband , Tad Friend , a staff writer for The New Yorker , and their two children .", "prompt_labels": "Hesser(B-writer) lives(O) in(O) Brooklyn(B-location) Heights(I-location) with(O) her(O) husband(O) ,(O) Tad(B-writer) Friend(I-writer) ,(O) a(O) staff(O) writer(O) for(O) The(B-magazine) New(I-magazine) Yorker(I-magazine) ,(O) and(O) their(O) two(O) children(O) .(O)"}, "label_list": ["award", "location", "country", "magazine", "writer", "poem", "book", "person", "event", "literary genre", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10292, 11, 3813, 11, 3224, 11, 14756, 11, 7061, 11, 33894, 11, 2363, 11, 1732, 11, 1567, 11, 32465, 17779, 11, 7471, 323, 507, 627, 85664, 25, 473, 37470, 6439, 304, 26832, 40503, 449, 1077, 10177, 1174, 350, 329, 11848, 1174, 264, 5687, 7061, 369, 578, 1561, 64874, 1174, 323, 872, 1403, 2911, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "115", "dataset": "crossner_literature", "split": "dev", "prediction": "He(O) particularly(O) revered(O) Johann(B-writer) Wolfgang(I-writer) von(I-writer) Goethe(I-writer),(O) Petrarch(B-writer),(O) Pedro(B-writer) Calder\u00f3n(I-writer) de(I-writer) la(I-writer) Barca(I-writer) and(O) William(B-writer) Shakespeare(I-writer).(O)", "instance": {"id": "115", "words": ["He", "particularly", "revered", "Johann", "Wolfgang", "von", "Goethe", ",", "Petrarch", ",", "Pedro", "Calder\u00f3n", "de", "la", "Barca", "and", "William", "Shakespeare", "."], "labels": ["O", "O", "O", "B-writer", "I-writer", "I-writer", "I-writer", "O", "B-writer", "O", "B-writer", "I-writer", "I-writer", "I-writer", "I-writer", "O", "B-writer", "I-writer", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, poem, organization, award, person, event, literary genre, book, location, magazine, writer and O.\nSentence: He particularly revered Johann Wolfgang von Goethe , Petrarch , Pedro Calder\u00f3n de la Barca and William Shakespeare .", "prompt_labels": "He(O) particularly(O) revered(O) Johann(B-writer) Wolfgang(I-writer) von(I-writer) Goethe(I-writer) ,(O) Petrarch(B-writer) ,(O) Pedro(B-writer) Calder\u00f3n(I-writer) de(I-writer) la(I-writer) Barca(I-writer) and(O) William(B-writer) Shakespeare(I-writer) .(O)"}, "label_list": ["country", "poem", "organization", "award", "person", "event", "literary genre", "book", "location", "magazine", "writer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 33894, 11, 7471, 11, 10292, 11, 1732, 11, 1567, 11, 32465, 17779, 11, 2363, 11, 3813, 11, 14756, 11, 7061, 323, 507, 627, 85664, 25, 1283, 8104, 85761, 88964, 87598, 6675, 6122, 19030, 1174, 96876, 1132, 1174, 43582, 76400, 3244, 409, 1208, 4821, 936, 323, 12656, 42482, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1127", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) bette(B-actor) davis(I-actor) ever(O) star(O) in(O) a(O) movie(O) directed(O) by(O) martin(B-director) scorsese(I-director)", "instance": {"id": "1127", "words": ["did", "bette", "davis", "ever", "star", "in", "a", "movie", "directed", "by", "martin", "scorsese"], "labels": ["O", "B-actor", "I-actor", "O", "O", "O", "O", "O", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, review, genre, character, title, plot, year, director, song, rating, trailer, actor and O.\nSentence: did bette davis ever star in a movie directed by martin scorsese", "prompt_labels": "did(O) bette(B-actor) davis(I-actor) ever(O) star(O) in(O) a(O) movie(O) directed(O) by(O) martin(B-director) scorsese(I-director)"}, "label_list": ["average ratings", "review", "genre", "character", "title", "plot", "year", "director", "song", "rating", "trailer", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 3477, 11, 17779, 11, 3752, 11, 2316, 11, 7234, 11, 1060, 11, 7690, 11, 5609, 11, 10959, 11, 19809, 11, 12360, 323, 507, 627, 85664, 25, 1550, 1297, 668, 294, 23156, 3596, 6917, 304, 264, 5818, 15910, 555, 96016, 1156, 1105, 2423, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "494", "dataset": "crossner_politics", "split": "dev", "prediction": "Once(O) the(O) Armistice(O) of(O) Mudanya(O) was(O) signed(O),(O) replacing(O) the(O) Armistice(O) of(O) Mundros(O) ((O) signed(O) by(O) the(O) Ottoman(B-country) Empire(I-country) in(O) 1918(O) at(O) the(O) end(O) of(O) World(B-event) War(I-event) I(I-event) during(O) the(O) occupation(O) of(O) Turkey(B-country).(O)", "instance": {"id": "494", "words": ["Once", "the", "Armistice", "of", "Mudanya", "was", "signed", ",", "replacing", "the", "Armistice", "of", "Mundros", "(", "signed", "by", "the", "Ottoman", "Empire", "in", "1918", "at", "the", "end", "of", "World", "War", "I", ")", "and", "ending", "the", "Turkish", "War", "of", "Independence", ",", "the", "GNA", "abolished", "the", "imperial", "Sultanate", ",", "which", "was", "accused", "of", "collaborating", "with", "the", "Allies", "of", "World", "War", "I", "during", "the", "occupation", "of", "Turkey", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-country", "I-country", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "O", "O", "O", "O", "B-event", "I-event", "I-event", "I-event", "O", "O", "B-organization", "O", "O", "O", "B-country", "O", "O", "O", "O", "O", "O", "O", "O", "B-country", "O", "B-event", "I-event", "I-event", "O", "O", "O", "O", "B-country", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, organization, location, person, political party, politician, election, country and O.\nSentence: Once the Armistice of Mudanya was signed , replacing the Armistice of Mundros ( signed by the Ottoman Empire in 1918 at the end of World War I ) and ending the Turkish War of Independence , the GNA abolished the imperial Sultanate , which was accused of collaborating with the Allies of World War I during the occupation of Turkey .", "prompt_labels": "Once(O) the(O) Armistice(O) of(O) Mudanya(O) was(O) signed(O) ,(O) replacing(O) the(O) Armistice(O) of(O) Mundros(O) ((O) signed(O) by(O) the(O) Ottoman(B-country) Empire(I-country) in(O) 1918(O) at(O) the(O) end(O) of(O) World(B-event) War(I-event) I(I-event) )(O) and(O) ending(O) the(O) Turkish(B-event) War(I-event) of(I-event) Independence(I-event) ,(O) the(O) GNA(B-organization) abolished(O) the(O) imperial(O) Sultanate(B-country) ,(O) which(O) was(O) accused(O) of(O) collaborating(O) with(O) the(O) Allies(B-country) of(O) World(B-event) War(I-event) I(I-event) during(O) the(O) occupation(O) of(O) Turkey(B-country) .(O)"}, "label_list": ["event", "organization", "location", "person", "political party", "politician", "election", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 7471, 11, 3813, 11, 1732, 11, 5054, 4717, 11, 37038, 11, 6355, 11, 3224, 323, 507, 627, 85664, 25, 9843, 279, 13287, 380, 560, 315, 69440, 25041, 574, 8667, 1174, 25935, 279, 13287, 380, 560, 315, 67661, 3714, 320, 8667, 555, 279, 70110, 21080, 304, 220, 7529, 23, 520, 279, 842, 315, 4435, 5111, 358, 883, 323, 13696, 279, 24666, 5111, 315, 44177, 1174, 279, 480, 7476, 81081, 279, 35379, 76086, 349, 1174, 902, 574, 13487, 315, 73301, 449, 279, 81774, 315, 4435, 5111, 358, 2391, 279, 30747, 315, 17442, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "111", "dataset": "crossner_music", "split": "dev", "prediction": "British genres(O) such(O) as(O) Lovers(B-music genre) rock(I-music genre),(O) Ragga(B-music genre) jungle(I-music genre) and(O) grime(B-music genre) are(O) also(O) influenced(O) by(O) Jamaican(O) music(O).(O)", "instance": {"id": "111", "words": ["British", "genres", "such", "as", "Lovers", "rock", ",", "Ragga", "jungle", "and", "grime", "are", "also", "influenced", "by", "Jamaican", "music", "."], "labels": ["O", "O", "O", "O", "B-music genre", "I-music genre", "O", "B-music genre", "I-music genre", "O", "B-music genre", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, person, music genre, location, band, country, award, event, album, song, organization, musical instrument and O.\nSentence: British genres such as Lovers rock , Ragga jungle and grime are also influenced by Jamaican music .", "prompt_labels": "British(O) genres(O) such(O) as(O) Lovers(B-music genre) rock(I-music genre) ,(O) Ragga(B-music genre) jungle(I-music genre) and(O) grime(B-music genre) are(O) also(O) influenced(O) by(O) Jamaican(O) music(O) .(O)"}, "label_list": ["musical artist", "person", "music genre", "location", "band", "country", "award", "event", "album", "song", "organization", "musical instrument"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18273, 10255, 11, 1732, 11, 4731, 17779, 11, 3813, 11, 7200, 11, 3224, 11, 10292, 11, 1567, 11, 8176, 11, 5609, 11, 7471, 11, 18273, 14473, 323, 507, 627, 85664, 25, 8013, 36744, 1778, 439, 445, 9146, 7091, 1174, 51359, 6885, 45520, 323, 1099, 547, 527, 1101, 28160, 555, 41259, 7210, 4731, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "340", "dataset": "crossner_science", "split": "dev", "prediction": "At(O) the(O) end(O) of(O) 2012(O) the(O) journal(O) was(O) split(O) into(O) three(O) independent(O) journals(O) :(O) Journal(B-academic journal) of(I-academic journal) Materials(I-academic journal) Chemistry(I-academic journal) A(I-academic journal) ((O) energy(B-discipline) and(I-discipline) sustainability(I-discipline) )(O),(O) Journal(B-academic journal) of(I-academic journal) Materials(I-academic journal) Chemistry(I-academic journal) B(I-academic journal) ((O) biology(B-discipline) and(I-discipline) medicine(I-discipline) )(O) and(O) Journal(B-academic journal) of(I-academic journal) Materials(I-academic journal) Chemistry(I-academic journal) C(I-academic journal) ((O) optical(B-discipline),(O) magnetic(B-discipline) and(O) electronic(B-discipline) devices(I-discipline) )(O).(O)", "instance": {"id": "340", "words": ["At", "the", "end", "of", "2012", "the", "journal", "was", "split", "into", "three", "independent", "journals", ":", "Journal", "of", "Materials", "Chemistry", "A", "(", "energy", "and", "sustainability", ")", ",", "Journal", "of", "Materials", "Chemistry", "B", "(", "biology", "and", "medicine", ")", "and", "Journal", "of", "Materials", "Chemistry", "C", "(", "optical", ",", "magnetic", "and", "electronic", "devices", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O", "B-discipline", "I-discipline", "I-discipline", "O", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O", "B-discipline", "O", "B-discipline", "O", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, organization, country, academic journal, university, theory, protein, chemical element, event, location, enzyme, chemical compound, astronomical object, award, scientist, discipline and O.\nSentence: At the end of 2012 the journal was split into three independent journals : Journal of Materials Chemistry A ( energy and sustainability ) , Journal of Materials Chemistry B ( biology and medicine ) and Journal of Materials Chemistry C ( optical , magnetic and electronic devices ) .", "prompt_labels": "At(O) the(O) end(O) of(O) 2012(O) the(O) journal(O) was(O) split(O) into(O) three(O) independent(O) journals(O) :(O) Journal(B-academic journal) of(I-academic journal) Materials(I-academic journal) Chemistry(I-academic journal) A(I-academic journal) ((O) energy(B-discipline) and(I-discipline) sustainability(I-discipline) )(O) ,(O) Journal(B-academic journal) of(I-academic journal) Materials(I-academic journal) Chemistry(I-academic journal) B(I-academic journal) ((O) biology(B-discipline) and(O) medicine(B-discipline) )(O) and(O) Journal(B-academic journal) of(I-academic journal) Materials(I-academic journal) Chemistry(I-academic journal) C(I-academic journal) ((O) optical(O) ,(O) magnetic(O) and(O) electronic(O) devices(O) )(O) .(O)"}, "label_list": ["person", "organization", "country", "academic journal", "university", "theory", "protein", "chemical element", "event", "location", "enzyme", "chemical compound", "astronomical object", "award", "scientist", "discipline"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 7471, 11, 3224, 11, 14584, 8486, 11, 12374, 11, 10334, 11, 13128, 11, 11742, 2449, 11, 1567, 11, 3813, 11, 49242, 11, 11742, 24549, 11, 87283, 1665, 11, 10292, 11, 28568, 11, 26434, 323, 507, 627, 85664, 25, 2468, 279, 842, 315, 220, 679, 17, 279, 8486, 574, 6859, 1139, 2380, 9678, 42780, 551, 10139, 315, 32009, 42846, 362, 320, 4907, 323, 41329, 883, 1174, 10139, 315, 32009, 42846, 426, 320, 34458, 323, 16088, 883, 323, 10139, 315, 32009, 42846, 356, 320, 29393, 1174, 24924, 323, 14683, 7766, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "305", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movies(O) got(O) a(O) great(B-average ratings) review(I-average ratings) by(O) roger(O) ebert(O) in(O) 2011(B-year)", "instance": {"id": "305", "words": ["what", "movies", "got", "a", "great", "review", "by", "roger", "ebert", "in", "2011"], "labels": ["O", "O", "O", "O", "B-average ratings", "I-average ratings", "O", "O", "O", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, character, plot, rating, average ratings, year, song, genre, actor, title, trailer, director and O.\nSentence: what movies got a great review by roger ebert in 2011", "prompt_labels": "what(O) movies(O) got(O) a(O) great(B-average ratings) review(I-average ratings) by(O) roger(O) ebert(O) in(O) 2011(B-year)"}, "label_list": ["review", "character", "plot", "rating", "average ratings", "year", "song", "genre", "actor", "title", "trailer", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 3752, 11, 7234, 11, 10959, 11, 5578, 18594, 11, 1060, 11, 5609, 11, 17779, 11, 12360, 11, 2316, 11, 19809, 11, 7690, 323, 507, 627, 85664, 25, 1148, 9698, 2751, 264, 2294, 3477, 555, 938, 1414, 384, 9339, 304, 220, 679, 16, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2146", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movies(O) did(O) steve(B-actor) mcqueen(I-actor) have(O) a(O) role(O) in(O)", "instance": {"id": "2146", "words": ["what", "movies", "did", "steve", "mcqueen", "have", "a", "role", "in"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, plot, average ratings, review, director, actor, genre, year, rating, song, title, trailer and O.\nSentence: what movies did steve mcqueen have a role in", "prompt_labels": "what(O) movies(O) did(O) steve(B-actor) mcqueen(I-actor) have(O) a(O) role(O) in(O)"}, "label_list": ["character", "plot", "average ratings", "review", "director", "actor", "genre", "year", "rating", "song", "title", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 7234, 11, 5578, 18594, 11, 3477, 11, 7690, 11, 12360, 11, 17779, 11, 1060, 11, 10959, 11, 5609, 11, 2316, 11, 19809, 323, 507, 627, 85664, 25, 1148, 9698, 1550, 4179, 588, 19777, 94214, 617, 264, 3560, 304, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "279", "dataset": "mit-restaurant", "split": "dev", "prediction": "does(O) caribe(B-Restaurant Name) have(O) a(O) smoking(B-Amenity) area(I-Amenity)", "instance": {"id": "279", "words": ["does", "caribe", "have", "a", "smoking", "area"], "labels": ["O", "B-Restaurant Name", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Price, Rating, Location, Dish, Amenity, Restaurant Name, Hours and O.\nSentence: does caribe have a smoking area", "prompt_labels": "does(O) caribe(B-Restaurant Name) have(O) a(O) smoking(B-Amenity) area(I-Amenity)"}, "label_list": ["Cuisine", "Price", "Rating", "Location", "Dish", "Amenity", "Restaurant Name", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 8650, 11, 19767, 11, 10067, 11, 49268, 11, 3383, 56685, 11, 26568, 4076, 11, 30192, 323, 507, 627, 85664, 25, 1587, 1841, 24459, 617, 264, 20149, 3158, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "286", "dataset": "mit-restaurant", "split": "dev", "prediction": "does(O) jaimes(B-Restaurant Name) bakery(I-Restaurant Name) have(O) a(O) great(B-Amenity) decor(I-Amenity)", "instance": {"id": "286", "words": ["does", "jaimes", "bakery", "have", "a", "great", "decor"], "labels": ["O", "B-Restaurant Name", "I-Restaurant Name", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Amenity, Location, Hours, Rating, Price, Restaurant Name, Cuisine and O.\nSentence: does jaimes bakery have a great decor", "prompt_labels": "does(O) jaimes(B-Restaurant Name) bakery(I-Restaurant Name) have(O) a(O) great(B-Amenity) decor(I-Amenity)"}, "label_list": ["Dish", "Amenity", "Location", "Hours", "Rating", "Price", "Restaurant Name", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 3383, 56685, 11, 10067, 11, 30192, 11, 19767, 11, 8650, 11, 26568, 4076, 11, 81961, 323, 507, 627, 85664, 25, 1587, 12203, 1769, 66244, 617, 264, 2294, 10799, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "877", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) a(O) taco(B-Cuisine) joint(I-Cuisine) near(B-Location) the(I-Location) college(I-Location)", "instance": {"id": "877", "words": ["is", "there", "a", "taco", "joint", "near", "the", "college"], "labels": ["O", "O", "O", "B-Cuisine", "I-Cuisine", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Hours, Restaurant Name, Rating, Cuisine, Location, Amenity, Price and O.\nSentence: is there a taco joint near the college", "prompt_labels": "is(O) there(O) a(O) taco(B-Cuisine) joint(I-Cuisine) near(B-Location) the(I-Location) college(I-Location)"}, "label_list": ["Dish", "Hours", "Restaurant Name", "Rating", "Cuisine", "Location", "Amenity", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 30192, 11, 26568, 4076, 11, 19767, 11, 81961, 11, 10067, 11, 3383, 56685, 11, 8650, 323, 507, 627, 85664, 25, 374, 1070, 264, 91941, 10496, 3221, 279, 7926, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1120", "dataset": "mit-movie", "split": "dev", "prediction": "could(O) you(O) help(O) me(O) find(O) a(O) movie(O) starring(O) larenz(B-actor) tate(I-actor) that(O) was(O) made(O) in(O) the(O) past(B-year) eight(I-year) years(I-year) that(O) was(O) rated(B-average ratings) well(I-average ratings)", "instance": {"id": "1120", "words": ["could", "you", "help", "me", "find", "a", "movie", "starring", "larenz", "tate", "that", "was", "made", "in", "the", "past", "eight", "years", "that", "was", "rated", "well"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-actor", "I-actor", "O", "O", "O", "O", "O", "B-year", "I-year", "I-year", "O", "O", "B-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, title, song, average ratings, actor, genre, year, rating, character, plot, director, review and O.\nSentence: could you help me find a movie starring larenz tate that was made in the past eight years that was rated well", "prompt_labels": "could(O) you(O) help(O) me(O) find(O) a(O) movie(O) starring(O) larenz(B-actor) tate(I-actor) that(O) was(O) made(O) in(O) the(O) past(B-year) eight(I-year) years(I-year) that(O) was(O) rated(B-average ratings) well(I-average ratings)"}, "label_list": ["trailer", "title", "song", "average ratings", "actor", "genre", "year", "rating", "character", "plot", "director", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 2316, 11, 5609, 11, 5578, 18594, 11, 12360, 11, 17779, 11, 1060, 11, 10959, 11, 3752, 11, 7234, 11, 7690, 11, 3477, 323, 507, 627, 85664, 25, 1436, 499, 1520, 757, 1505, 264, 5818, 40500, 326, 9329, 89, 259, 349, 430, 574, 1903, 304, 279, 3347, 8223, 1667, 430, 574, 22359, 1664, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "759", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) a(O) movie(O) with(O) lots(B-plot) of(I-plot) sky(I-plot) diving(I-plot) in(O) it(O)", "instance": {"id": "759", "words": ["show", "me", "a", "movie", "with", "lots", "of", "sky", "diving", "in", "it"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-plot", "I-plot", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, review, song, character, title, average ratings, genre, year, rating, actor, director, trailer and O.\nSentence: show me a movie with lots of sky diving in it", "prompt_labels": "show(O) me(O) a(O) movie(O) with(O) lots(O) of(O) sky(B-plot) diving(I-plot) in(O) it(O)"}, "label_list": ["plot", "review", "song", "character", "title", "average ratings", "genre", "year", "rating", "actor", "director", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 3477, 11, 5609, 11, 3752, 11, 2316, 11, 5578, 18594, 11, 17779, 11, 1060, 11, 10959, 11, 12360, 11, 7690, 11, 19809, 323, 507, 627, 85664, 25, 1501, 757, 264, 5818, 449, 10283, 315, 13180, 43515, 304, 433, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "623", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) zombie(B-plot) movie(I-plot) features(I-plot) a(I-plot) zombie(I-plot) tiger(I-plot)", "instance": {"id": "623", "words": ["what", "zombie", "movie", "features", "a", "zombie", "tiger"], "labels": ["O", "B-genre", "I-genre", "O", "O", "B-character", "I-character"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, character, title, song, trailer, rating, review, year, director, average ratings, plot, genre and O.\nSentence: what zombie movie features a zombie tiger", "prompt_labels": "what(O) zombie(B-genre) movie(I-genre) features(O) a(O) zombie(B-character) tiger(I-character)"}, "label_list": ["actor", "character", "title", "song", "trailer", "rating", "review", "year", "director", "average ratings", "plot", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 3752, 11, 2316, 11, 5609, 11, 19809, 11, 10959, 11, 3477, 11, 1060, 11, 7690, 11, 5578, 18594, 11, 7234, 11, 17779, 323, 507, 627, 85664, 25, 1148, 38836, 5818, 4519, 264, 38836, 52835, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1335", "dataset": "mit-movie", "split": "dev", "prediction": "i(O) would(O) like(O) a(O) war(B-genre) movie(O) directed(O) by(O) harry(B-director) elfont(I-director) from(O) last(B-year) year(I-year) rated(O) pg(B-rating) 13(I-rating)", "instance": {"id": "1335", "words": ["i", "would", "like", "a", "war", "movie", "directed", "by", "harry", "elfont", "from", "last", "year", "rated", "pg", "13"], "labels": ["O", "O", "O", "O", "B-plot", "O", "O", "O", "B-director", "I-director", "O", "B-year", "I-year", "O", "B-rating", "I-rating"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, average ratings, song, director, year, title, character, genre, rating, plot, trailer, actor and O.\nSentence: i would like a war movie directed by harry elfont from last year rated pg 13", "prompt_labels": "i(O) would(O) like(O) a(O) war(B-plot) movie(O) directed(O) by(O) harry(B-director) elfont(I-director) from(O) last(B-year) year(I-year) rated(O) pg(B-rating) 13(I-rating)"}, "label_list": ["review", "average ratings", "song", "director", "year", "title", "character", "genre", "rating", "plot", "trailer", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 5578, 18594, 11, 5609, 11, 7690, 11, 1060, 11, 2316, 11, 3752, 11, 17779, 11, 10959, 11, 7234, 11, 19809, 11, 12360, 323, 507, 627, 85664, 25, 602, 1053, 1093, 264, 4208, 5818, 15910, 555, 4960, 894, 41845, 546, 505, 1566, 1060, 22359, 17953, 220, 1032, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "313", "dataset": "crossner_ai", "split": "dev", "prediction": "They(O) presented(O) their(O) method(O) and(O) results(O) in(O) SIGGRAPH(B-conference) 2000(I-conference).(O)", "instance": {"id": "313", "words": ["They", "presented", "their", "method", "and", "results", "in", "SIGGRAPH", "2000", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-conference", "I-conference", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, programming language, university, product, researcher, task, location, organization, algorithm, field, conference, country, metric and O.\nSentence: They presented their method and results in SIGGRAPH 2000 .", "prompt_labels": "They(O) presented(O) their(O) method(O) and(O) results(O) in(O) SIGGRAPH(B-conference) 2000(I-conference) .(O)"}, "label_list": ["person", "programming language", "university", "product", "researcher", "task", "location", "organization", "algorithm", "field", "conference", "country", "metric"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 15840, 4221, 11, 12374, 11, 2027, 11, 32185, 11, 3465, 11, 3813, 11, 7471, 11, 12384, 11, 2115, 11, 10017, 11, 3224, 11, 18767, 323, 507, 627, 85664, 25, 2435, 10666, 872, 1749, 323, 3135, 304, 26093, 41084, 220, 1049, 15, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "47", "dataset": "mit-restaurant", "split": "dev", "prediction": "are(O) there(O) any(O) hamburger(B-Cuisine) restaurants(O) close(B-Location) by(I-Location)", "instance": {"id": "47", "words": ["are", "there", "any", "hamburger", "restaurants", "close", "by"], "labels": ["O", "O", "O", "B-Cuisine", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Price, Rating, Hours, Amenity, Cuisine, Dish, Location and O.\nSentence: are there any hamburger restaurants close by", "prompt_labels": "are(O) there(O) any(O) hamburger(B-Cuisine) restaurants(O) close(B-Location) by(I-Location)"}, "label_list": ["Restaurant Name", "Price", "Rating", "Hours", "Amenity", "Cuisine", "Dish", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 8650, 11, 19767, 11, 30192, 11, 3383, 56685, 11, 81961, 11, 49268, 11, 10067, 323, 507, 627, 85664, 25, 527, 1070, 904, 89847, 15926, 3345, 555, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2142", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movie(O) stared(O) terry(B-actor) farrell(I-actor) as(O) a(O) cowboy(B-genre) in(O) mexico(B-plot)", "instance": {"id": "2142", "words": ["what", "movie", "stared", "terry", "farrell", "as", "a", "cowboy", "in", "mexico"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O", "O", "B-genre", "O", "B-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, director, average ratings, genre, trailer, actor, plot, year, title, rating, character, song and O.\nSentence: what movie stared terry farrell as a cowboy in mexico", "prompt_labels": "what(O) movie(O) stared(O) terry(B-actor) farrell(I-actor) as(O) a(O) cowboy(B-genre) in(O) mexico(B-plot)"}, "label_list": ["review", "director", "average ratings", "genre", "trailer", "actor", "plot", "year", "title", "rating", "character", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 7690, 11, 5578, 18594, 11, 17779, 11, 19809, 11, 12360, 11, 7234, 11, 1060, 11, 2316, 11, 10959, 11, 3752, 11, 5609, 323, 507, 627, 85664, 25, 1148, 5818, 45135, 259, 5515, 3117, 16684, 439, 264, 81272, 304, 77476, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "216", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) directed(O) the(O) film(O) the(B-title) lorax(I-title)", "instance": {"id": "216", "words": ["who", "directed", "the", "film", "the", "lorax"], "labels": ["O", "O", "O", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, plot, actor, average ratings, genre, rating, title, director, year, character, song, trailer and O.\nSentence: who directed the film the lorax", "prompt_labels": "who(O) directed(O) the(O) film(O) the(B-title) lorax(I-title)"}, "label_list": ["review", "plot", "actor", "average ratings", "genre", "rating", "title", "director", "year", "character", "song", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 7234, 11, 12360, 11, 5578, 18594, 11, 17779, 11, 10959, 11, 2316, 11, 7690, 11, 1060, 11, 3752, 11, 5609, 11, 19809, 323, 507, 627, 85664, 25, 889, 15910, 279, 4632, 279, 67311, 710, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "554", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) am(O) looking(O) for(O) lunch(B-Amenity) buffets(I-Amenity) within(B-Location) 15(I-Location) minutes(I-Location) driving(I-Location) distance(I-Location)", "instance": {"id": "554", "words": ["i", "am", "looking", "for", "lunch", "buffets", "within", "15", "minutes", "driving", "distance"], "labels": ["O", "O", "O", "O", "B-Hours", "B-Amenity", "B-Location", "I-Location", "I-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Rating, Cuisine, Location, Restaurant Name, Price, Hours, Dish and O.\nSentence: i am looking for lunch buffets within 15 minutes driving distance", "prompt_labels": "i(O) am(O) looking(O) for(O) lunch(B-Hours) buffets(B-Amenity) within(B-Location) 15(I-Location) minutes(I-Location) driving(I-Location) distance(I-Location)"}, "label_list": ["Amenity", "Rating", "Cuisine", "Location", "Restaurant Name", "Price", "Hours", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 19767, 11, 81961, 11, 10067, 11, 26568, 4076, 11, 8650, 11, 30192, 11, 49268, 323, 507, 627, 85664, 25, 602, 1097, 3411, 369, 16163, 11783, 1441, 2949, 220, 868, 4520, 10043, 6138, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "171", "dataset": "crossner_music", "split": "dev", "prediction": "Juliana(B-musical artist) Hatfield(I-musical artist) is(O) an(O) American(O) musician(O) and(O) singer-songwriter(O) from(O) the(O) Boston(B-location) area(I-location),(O) formerly(O) of(O) the(O) indie(B-music genre) rock(I-music genre) bands(O) Blake(B-band) Babies(I-band),(O) Some(B-band) Girls(I-band),(O) and(O) The(B-band) Lemonheads(I-band).(O)", "instance": {"id": "171", "words": ["Juliana", "Hatfield", "is", "an", "American", "musician", "and", "singer-songwriter", "from", "the", "Boston", "area", ",", "formerly", "of", "the", "indie", "rock", "bands", "Blake", "Babies", ",", "Some", "Girls", ",", "and", "The", "Lemonheads", "."], "labels": ["B-musical artist", "I-musical artist", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "O", "O", "O", "O", "O", "B-music genre", "O", "B-band", "I-band", "O", "B-band", "I-band", "O", "O", "B-band", "I-band", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, country, person, music genre, album, organization, musical artist, musical instrument, event, award, location, band and O.\nSentence: Juliana Hatfield is an American musician and singer-songwriter from the Boston area , formerly of the indie rock bands Blake Babies , Some Girls , and The Lemonheads .", "prompt_labels": "Juliana(B-musical artist) Hatfield(I-musical artist) is(O) an(O) American(O) musician(O) and(O) singer-songwriter(O) from(O) the(O) Boston(B-location) area(I-location) ,(O) formerly(O) of(O) the(O) indie(O) rock(B-music genre) bands(O) Blake(B-band) Babies(I-band) ,(O) Some(B-band) Girls(I-band) ,(O) and(O) The(B-band) Lemonheads(I-band) .(O)"}, "label_list": ["song", "country", "person", "music genre", "album", "organization", "musical artist", "musical instrument", "event", "award", "location", "band"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 3224, 11, 1732, 11, 4731, 17779, 11, 8176, 11, 7471, 11, 18273, 10255, 11, 18273, 14473, 11, 1567, 11, 10292, 11, 3813, 11, 7200, 323, 507, 627, 85664, 25, 10263, 12699, 22050, 2630, 374, 459, 3778, 39844, 323, 23597, 77740, 18688, 505, 279, 10406, 3158, 1174, 34833, 315, 279, 44578, 7091, 21562, 31994, 93792, 1174, 4427, 20666, 1174, 323, 578, 52310, 36910, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "164", "dataset": "crossner_politics", "split": "dev", "prediction": "The(B-political party) Socialist(I-political party) Party(I-political party) of(I-political party) the(I-political party) United(I-political party) States(I-political party) ((O) SPUS(B-political party) )(O) -(O) its(O) name(O) inspired(O) by(O) co-thinkers(O) in(O) the(O) Socialist(B-political party) Party(I-political party) of(I-political party) Great(I-political party) Britain(I-political party) ((O) SPGB(B-political party) )(O) and(O) the(O) original(O) ((O) non-WSM(O) )(O) Socialist(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) ((O) SPC(B-political party) )(O) -(O) was(O) established(O) on(O) July(O) 7(O),(O) 1916(O) by(O) 42(O) defecting(O) members(O) of(O) Local(O) Detroit(O) of(O) the(O) Socialist(B-political party) Party(I-political party) of(I-political party) America(I-political party) ((O) SPA(B-political party) )(O).(O)", "instance": {"id": "164", "words": ["The", "Socialist", "Party", "of", "the", "United", "States", "(", "SPUS", ")", "-", "its", "name", "inspired", "by", "co-thinkers", "in", "the", "Socialist", "Party", "of", "Great", "Britain", "(", "SPGB", ")", "and", "the", "original", "(", "non-WSM", ")", "Socialist", "Party", "of", "Canada", "(", "SPC", ")", "-", "was", "established", "on", "July", "7", ",", "1916", "by", "42", "defecting", "members", "of", "Local", "Detroit", "of", "the", "Socialist", "Party", "of", "America", "(", "SPA", ")", "."], "labels": ["O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "B-political party", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "B-political party", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "B-political party", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "B-political party", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, event, location, election, country, political party, person, politician and O.\nSentence: The Socialist Party of the United States ( SPUS ) - its name inspired by co-thinkers in the Socialist Party of Great Britain ( SPGB ) and the original ( non-WSM ) Socialist Party of Canada ( SPC ) - was established on July 7 , 1916 by 42 defecting members of Local Detroit of the Socialist Party of America ( SPA ) .", "prompt_labels": "The(O) Socialist(B-political party) Party(I-political party) of(I-political party) the(I-political party) United(I-political party) States(I-political party) ((O) SPUS(B-political party) )(O) -(O) its(O) name(O) inspired(O) by(O) co-thinkers(O) in(O) the(O) Socialist(B-political party) Party(I-political party) of(I-political party) Great(I-political party) Britain(I-political party) ((O) SPGB(B-political party) )(O) and(O) the(O) original(O) ((O) non-WSM(O) )(O) Socialist(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) ((O) SPC(B-political party) )(O) -(O) was(O) established(O) on(O) July(O) 7(O) ,(O) 1916(O) by(O) 42(O) defecting(O) members(O) of(O) Local(B-location) Detroit(I-location) of(O) the(O) Socialist(B-political party) Party(I-political party) of(I-political party) America(I-political party) ((O) SPA(B-political party) )(O) .(O)"}, "label_list": ["organization", "event", "location", "election", "country", "political party", "person", "politician"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 1567, 11, 3813, 11, 6355, 11, 3224, 11, 5054, 4717, 11, 1732, 11, 37038, 323, 507, 627, 85664, 25, 578, 57210, 8722, 315, 279, 3723, 4273, 320, 9440, 2078, 883, 482, 1202, 836, 14948, 555, 1080, 7716, 771, 388, 304, 279, 57210, 8722, 315, 8681, 13527, 320, 9440, 5494, 883, 323, 279, 4113, 320, 2536, 12, 7585, 44, 883, 57210, 8722, 315, 7008, 320, 328, 4977, 883, 482, 574, 9749, 389, 5887, 220, 22, 1174, 220, 7529, 21, 555, 220, 2983, 23011, 287, 3697, 315, 8949, 20344, 315, 279, 57210, 8722, 315, 5270, 320, 77508, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "289", "dataset": "mit-restaurant", "split": "dev", "prediction": "does(O) mcdonalds(B-Restaurant Name) serve(O) ice(B-Dish) cream(I-Dish) during(O) breakfast(B-Hours) hours(I-Hours)", "instance": {"id": "289", "words": ["does", "mcdonalds", "serve", "ice", "cream", "during", "breakfast", "hours"], "labels": ["O", "B-Restaurant Name", "O", "B-Dish", "I-Dish", "I-Dish", "B-Hours", "I-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Price, Location, Cuisine, Hours, Restaurant Name, Amenity, Dish and O.\nSentence: does mcdonalds serve ice cream during breakfast hours", "prompt_labels": "does(O) mcdonalds(B-Restaurant Name) serve(O) ice(B-Dish) cream(I-Dish) during(I-Dish) breakfast(B-Hours) hours(I-Hours)"}, "label_list": ["Rating", "Price", "Location", "Cuisine", "Hours", "Restaurant Name", "Amenity", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 8650, 11, 10067, 11, 81961, 11, 30192, 11, 26568, 4076, 11, 3383, 56685, 11, 49268, 323, 507, 627, 85664, 25, 1587, 296, 4484, 80794, 82, 8854, 10054, 12932, 2391, 17954, 4207, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1870", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) r(B-rating) rated(O) movie(O) was(O) released(O) this(B-year) year(I-year) about(O) the(O) 1960(B-plot) s(I-plot) that(O) has(O) an(O) eight(B-average ratings) star(I-average ratings) rating(O)", "instance": {"id": "1870", "words": ["what", "r", "rated", "movie", "was", "released", "this", "year", "about", "the", "1960", "s", "that", "has", "an", "eight", "star", "rating"], "labels": ["O", "B-rating", "O", "O", "O", "O", "B-year", "I-year", "O", "O", "B-plot", "I-plot", "O", "O", "O", "B-average ratings", "I-average ratings", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, title, director, rating, song, trailer, average ratings, actor, year, review, genre, character and O.\nSentence: what r rated movie was released this year about the 1960 s that has an eight star rating", "prompt_labels": "what(O) r(B-rating) rated(O) movie(O) was(O) released(O) this(B-year) year(I-year) about(O) the(O) 1960(B-plot) s(I-plot) that(O) has(O) an(O) eight(B-average ratings) star(I-average ratings) rating(O)"}, "label_list": ["plot", "title", "director", "rating", "song", "trailer", "average ratings", "actor", "year", "review", "genre", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 2316, 11, 7690, 11, 10959, 11, 5609, 11, 19809, 11, 5578, 18594, 11, 12360, 11, 1060, 11, 3477, 11, 17779, 11, 3752, 323, 507, 627, 85664, 25, 1148, 436, 22359, 5818, 574, 6004, 420, 1060, 922, 279, 220, 5162, 15, 274, 430, 706, 459, 8223, 6917, 10959, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1044", "dataset": "mit-restaurant", "split": "dev", "prediction": "red(B-Restaurant Name) robins(I-Restaurant Name) restaurant(O)", "instance": {"id": "1044", "words": ["red", "robins", "restaurant"], "labels": ["B-Restaurant Name", "I-Restaurant Name", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Location, Rating, Dish, Cuisine, Price, Amenity, Restaurant Name and O.\nSentence: red robins restaurant", "prompt_labels": "red(B-Restaurant Name) robins(I-Restaurant Name) restaurant(O)"}, "label_list": ["Hours", "Location", "Rating", "Dish", "Cuisine", "Price", "Amenity", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 10067, 11, 19767, 11, 49268, 11, 81961, 11, 8650, 11, 3383, 56685, 11, 26568, 4076, 323, 507, 627, 85664, 25, 2579, 10773, 1354, 10960, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "128", "dataset": "crossner_music", "split": "dev", "prediction": "They(O) restarted(O) to(O) perform(O) live(O) regularly(O),(O) touring(O) the(O) world(O) with(O) rapturous(O) feedbacks(O) :(O) they(O) brought(O) their(O) distinguishable(O) sound(O) in(O) great(O) venues(O) such(O) as(O) the(O) Kings(B-location) Place(I-location) in(O) London(B-location),(O) the(O) Soma(B-event) Festival(I-event) in(O) Belfast(B-location),(O) the(O) Bolshoi(B-location) Theatre(I-location) in(O) Moscow(B-location) and(O) the(O) Star(B-location) Pine(I-location)'s(I-location) cafe(I-location) in(O) Tokyo(B-location).(O)", "instance": {"id": "128", "words": ["They", "restarted", "to", "perform", "live", "regularly", ",", "touring", "the", "world", "with", "rapturous", "feedbacks", ":", "they", "brought", "their", "distinguishable", "sound", "in", "great", "venues", "such", "as", "the", "Kings", "Place", "in", "London", ",", "the", "Soma", "Festival", "in", "Belfast", ",", "the", "Bolshoi", "Theatre", "in", "Moscow", "and", "the", "Star", "Pine", "'s", "cafe", "in", "Tokyo", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "O", "B-location", "O", "O", "B-event", "I-event", "O", "B-location", "O", "O", "B-location", "I-location", "O", "B-location", "O", "O", "B-location", "I-location", "I-location", "I-location", "O", "B-location", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, musical artist, music genre, album, person, organization, award, musical instrument, event, location, song, band and O.\nSentence: They restarted to perform live regularly , touring the world with rapturous feedbacks : they brought their distinguishable sound in great venues such as the Kings Place in London , the Soma Festival in Belfast , the Bolshoi Theatre in Moscow and the Star Pine 's cafe in Tokyo .", "prompt_labels": "They(O) restarted(O) to(O) perform(O) live(O) regularly(O) ,(O) touring(O) the(O) world(O) with(O) rapturous(O) feedbacks(O) :(O) they(O) brought(O) their(O) distinguishable(O) sound(O) in(O) great(O) venues(O) such(O) as(O) the(O) Kings(B-location) Place(I-location) in(O) London(B-location) ,(O) the(O) Soma(B-event) Festival(I-event) in(O) Belfast(B-location) ,(O) the(O) Bolshoi(B-location) Theatre(I-location) in(O) Moscow(B-location) and(O) the(O) Star(B-location) Pine(I-location) 's(I-location) cafe(I-location) in(O) Tokyo(B-location) .(O)"}, "label_list": ["country", "musical artist", "music genre", "album", "person", "organization", "award", "musical instrument", "event", "location", "song", "band"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 18273, 10255, 11, 4731, 17779, 11, 8176, 11, 1732, 11, 7471, 11, 10292, 11, 18273, 14473, 11, 1567, 11, 3813, 11, 5609, 11, 7200, 323, 507, 627, 85664, 25, 2435, 81754, 311, 2804, 3974, 15870, 1174, 48551, 279, 1917, 449, 436, 2756, 55709, 11302, 82, 551, 814, 7263, 872, 33137, 481, 5222, 304, 2294, 37278, 1778, 439, 279, 24980, 11004, 304, 7295, 1174, 279, 328, 7942, 17772, 304, 55339, 1174, 279, 25007, 939, 6870, 27315, 304, 23223, 323, 279, 7834, 42609, 364, 82, 42030, 304, 27286, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "647", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) want(O) to(O) eat(O) hamburgers(B-Dish)", "instance": {"id": "647", "words": ["i", "want", "to", "eat", "hamburgers"], "labels": ["O", "O", "O", "O", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Dish, Price, Cuisine, Location, Hours, Restaurant Name, Rating and O.\nSentence: i want to eat hamburgers", "prompt_labels": "i(O) want(O) to(O) eat(O) hamburgers(B-Dish)"}, "label_list": ["Amenity", "Dish", "Price", "Cuisine", "Location", "Hours", "Restaurant Name", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 49268, 11, 8650, 11, 81961, 11, 10067, 11, 30192, 11, 26568, 4076, 11, 19767, 323, 507, 627, 85664, 25, 602, 1390, 311, 8343, 57947, 388, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "998", "dataset": "mit-restaurant", "split": "dev", "prediction": "may(O) i(O) have(O) the(O) business(B-Hours) hours(I-Hours) for(O) the(O) nearest(B-Location) red(B-Restaurant Name) lobster(I-Restaurant Name)", "instance": {"id": "998", "words": ["may", "i", "have", "the", "business", "hours", "for", "the", "nearest", "red", "lobster"], "labels": ["O", "O", "O", "O", "B-Hours", "O", "O", "O", "B-Location", "B-Restaurant Name", "I-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Price, Restaurant Name, Location, Rating, Cuisine, Amenity, Hours and O.\nSentence: may i have the business hours for the nearest red lobster", "prompt_labels": "may(O) i(O) have(O) the(O) business(B-Hours) hours(O) for(O) the(O) nearest(B-Location) red(B-Restaurant Name) lobster(I-Restaurant Name)"}, "label_list": ["Dish", "Price", "Restaurant Name", "Location", "Rating", "Cuisine", "Amenity", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 8650, 11, 26568, 4076, 11, 10067, 11, 19767, 11, 81961, 11, 3383, 56685, 11, 30192, 323, 507, 627, 85664, 25, 1253, 602, 617, 279, 2626, 4207, 369, 279, 24379, 2579, 80815, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "479", "dataset": "mit-restaurant", "split": "dev", "prediction": "help(O) me(O) find(O) a(O) good(B-Rating) place(O) to(O) eat(O)", "instance": {"id": "479", "words": ["help", "me", "find", "a", "good", "place", "to", "eat"], "labels": ["O", "O", "O", "O", "B-Rating", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Restaurant Name, Rating, Dish, Price, Amenity, Hours, Location and O.\nSentence: help me find a good place to eat", "prompt_labels": "help(O) me(O) find(O) a(O) good(B-Rating) place(O) to(O) eat(O)"}, "label_list": ["Cuisine", "Restaurant Name", "Rating", "Dish", "Price", "Amenity", "Hours", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 26568, 4076, 11, 19767, 11, 49268, 11, 8650, 11, 3383, 56685, 11, 30192, 11, 10067, 323, 507, 627, 85664, 25, 1520, 757, 1505, 264, 1695, 2035, 311, 8343, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "194", "dataset": "mit-movie", "split": "dev", "prediction": "when(O) did(O) runaway(B-title) jury(I-title) come(O) out(O)", "instance": {"id": "194", "words": ["when", "did", "runaway", "jury", "come", "out"], "labels": ["O", "O", "B-title", "I-title", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, title, average ratings, trailer, plot, genre, song, review, actor, character, director, year and O.\nSentence: when did runaway jury come out", "prompt_labels": "when(O) did(O) runaway(B-title) jury(I-title) come(O) out(O)"}, "label_list": ["rating", "title", "average ratings", "trailer", "plot", "genre", "song", "review", "actor", "character", "director", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 2316, 11, 5578, 18594, 11, 19809, 11, 7234, 11, 17779, 11, 5609, 11, 3477, 11, 12360, 11, 3752, 11, 7690, 11, 1060, 323, 507, 627, 85664, 25, 994, 1550, 91740, 21928, 2586, 704, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "77", "dataset": "crossner_politics", "split": "dev", "prediction": "In(O) recent(O) years(O),(O) the(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) of(I-political party) Canada(I-political party) has(O) had(O) the(O) most(O) success(O) in(O) the(O) city(O) :(O) its(O) members(O) were(O) elected(O) in(O) all(O) but(O) four(O) elections(O) since(O) 1953(O) :(O) 1974(B-election) Canadian(I-election) federal(I-election) election(I-election),(O) 1980(B-election) Canadian(I-election) federal(I-election) election(I-election),(O) 2004(B-election) Canadian(I-election) federal(I-election) election(I-election),(O) and(O) 2006(B-election) Canadian(I-election) federal(I-election) election(I-election).(O)", "instance": {"id": "77", "words": ["In", "recent", "years", ",", "the", "Progressive", "Conservative", "Party", "of", "Canada", "has", "had", "the", "most", "success", "in", "the", "city", ":", "its", "members", "were", "elected", "in", "all", "but", "four", "elections", "since", "1953", ":", "1974", "Canadian", "federal", "election", ",", "1980", "Canadian", "federal", "election", ",", "2004", "Canadian", "federal", "election", ",", "and", "2006", "Canadian", "federal", "election", "."], "labels": ["O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, country, organization, person, location, political party, election, event and O.\nSentence: In recent years , the Progressive Conservative Party of Canada has had the most success in the city : its members were elected in all but four elections since 1953 : 1974 Canadian federal election , 1980 Canadian federal election , 2004 Canadian federal election , and 2006 Canadian federal election .", "prompt_labels": "In(O) recent(O) years(O) ,(O) the(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) of(I-political party) Canada(I-political party) has(O) had(O) the(O) most(O) success(O) in(O) the(O) city(O) :(O) its(O) members(O) were(O) elected(O) in(O) all(O) but(O) four(O) elections(O) since(O) 1953(O) :(O) 1974(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) 1980(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) 2004(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) and(O) 2006(B-election) Canadian(I-election) federal(I-election) election(I-election) .(O)"}, "label_list": ["politician", "country", "organization", "person", "location", "political party", "election", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 37038, 11, 3224, 11, 7471, 11, 1732, 11, 3813, 11, 5054, 4717, 11, 6355, 11, 1567, 323, 507, 627, 85664, 25, 763, 3293, 1667, 1174, 279, 52870, 30071, 8722, 315, 7008, 706, 1047, 279, 1455, 2450, 304, 279, 3363, 551, 1202, 3697, 1051, 16689, 304, 682, 719, 3116, 16374, 2533, 220, 6280, 18, 551, 220, 4468, 19, 12152, 6918, 6355, 1174, 220, 3753, 15, 12152, 6918, 6355, 1174, 220, 1049, 19, 12152, 6918, 6355, 1174, 323, 220, 1049, 21, 12152, 6918, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "52", "dataset": "mit-restaurant", "split": "dev", "prediction": "are(O) there(O) any(O) japanese(B-Cuisine) restaurants(O) in(B-Location) town(I-Location) that(O) do(O) discounts(B-Amenity) for(O) bulk(B-Amenity) orders(I-Amenity) of(O) sushi(B-Dish)", "instance": {"id": "52", "words": ["are", "there", "any", "japanese", "restaurants", "in", "town", "that", "do", "discounts", "for", "bulk", "orders", "of", "sushi"], "labels": ["O", "O", "O", "B-Cuisine", "O", "B-Location", "I-Location", "O", "O", "B-Amenity", "I-Amenity", "I-Amenity", "I-Amenity", "O", "B-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Dish, Location, Restaurant Name, Rating, Price, Hours, Amenity and O.\nSentence: are there any japanese restaurants in town that do discounts for bulk orders of sushi", "prompt_labels": "are(O) there(O) any(O) japanese(B-Cuisine) restaurants(O) in(B-Location) town(I-Location) that(O) do(O) discounts(B-Amenity) for(I-Amenity) bulk(I-Amenity) orders(I-Amenity) of(O) sushi(B-Amenity)"}, "label_list": ["Cuisine", "Dish", "Location", "Restaurant Name", "Rating", "Price", "Hours", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 49268, 11, 10067, 11, 26568, 4076, 11, 19767, 11, 8650, 11, 30192, 11, 3383, 56685, 323, 507, 627, 85664, 25, 527, 1070, 904, 54048, 15926, 304, 6424, 430, 656, 32162, 369, 20155, 10373, 315, 67322, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1242", "dataset": "mit-restaurant", "split": "dev", "prediction": "whats(O) the(O) phone(O) number(O) for(O) that(O) family(B-Amenity) owned(I-Amenity) thai(B-Cuisine) restaurant(O) on(O) the(O) north(B-Location) side(I-Location)", "instance": {"id": "1242", "words": ["whats", "the", "phone", "number", "for", "that", "family", "owned", "thai", "restaurant", "on", "the", "north", "side"], "labels": ["O", "O", "O", "O", "O", "O", "B-Amenity", "I-Amenity", "B-Cuisine", "O", "O", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Cuisine, Location, Restaurant Name, Amenity, Dish, Rating, Hours and O.\nSentence: whats the phone number for that family owned thai restaurant on the north side", "prompt_labels": "whats(O) the(O) phone(O) number(O) for(O) that(O) family(B-Amenity) owned(I-Amenity) thai(B-Cuisine) restaurant(O) on(O) the(O) north(B-Location) side(I-Location)"}, "label_list": ["Price", "Cuisine", "Location", "Restaurant Name", "Amenity", "Dish", "Rating", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 81961, 11, 10067, 11, 26568, 4076, 11, 3383, 56685, 11, 49268, 11, 19767, 11, 30192, 323, 507, 627, 85664, 25, 41209, 279, 4641, 1396, 369, 430, 3070, 13234, 18420, 10960, 389, 279, 10411, 3185, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1169", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) stephen(B-actor) j(I-actor) anderson(I-actor) star(O) in(O) any(O) sci(B-genre) fi(I-genre) movie(O) during(O) the(O) 1950(B-year) s(I-year)", "instance": {"id": "1169", "words": ["did", "stephen", "j", "anderson", "star", "in", "any", "sci", "fi", "movie", "during", "the", "1950", "s"], "labels": ["O", "B-director", "I-director", "I-director", "O", "O", "O", "B-genre", "I-genre", "O", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, director, year, plot, character, song, genre, actor, title, rating, trailer, average ratings and O.\nSentence: did stephen j anderson star in any sci fi movie during the 1950 s", "prompt_labels": "did(O) stephen(B-director) j(I-director) anderson(I-director) star(O) in(O) any(O) sci(B-genre) fi(I-genre) movie(O) during(O) the(O) 1950(B-year) s(I-year)"}, "label_list": ["review", "director", "year", "plot", "character", "song", "genre", "actor", "title", "rating", "trailer", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 7690, 11, 1060, 11, 7234, 11, 3752, 11, 5609, 11, 17779, 11, 12360, 11, 2316, 11, 10959, 11, 19809, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1550, 3094, 12301, 503, 323, 1293, 6917, 304, 904, 39074, 9314, 5818, 2391, 279, 220, 6280, 15, 274, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2062", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) best(B-review) horror(B-genre) movies(O) made(O) in(O) 1977(B-year)", "instance": {"id": "2062", "words": ["what", "is", "the", "best", "horror", "movies", "made", "in", "1977"], "labels": ["O", "O", "O", "O", "B-genre", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, average ratings, character, review, song, actor, title, rating, plot, year, director, trailer and O.\nSentence: what is the best horror movies made in 1977", "prompt_labels": "what(O) is(O) the(O) best(O) horror(B-genre) movies(O) made(O) in(O) 1977(O)"}, "label_list": ["genre", "average ratings", "character", "review", "song", "actor", "title", "rating", "plot", "year", "director", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 5578, 18594, 11, 3752, 11, 3477, 11, 5609, 11, 12360, 11, 2316, 11, 10959, 11, 7234, 11, 1060, 11, 7690, 11, 19809, 323, 507, 627, 85664, 25, 1148, 374, 279, 1888, 22169, 9698, 1903, 304, 220, 4468, 22, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1447", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) is(O) the(O) nearest(B-Location) sushi(B-Cuisine) bar(I-Cuisine)", "instance": {"id": "1447", "words": ["where", "is", "the", "nearest", "sushi", "bar"], "labels": ["O", "O", "O", "B-Location", "B-Cuisine", "I-Cuisine"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Amenity, Hours, Restaurant Name, Rating, Price, Location, Cuisine and O.\nSentence: where is the nearest sushi bar", "prompt_labels": "where(O) is(O) the(O) nearest(B-Location) sushi(B-Cuisine) bar(I-Cuisine)"}, "label_list": ["Dish", "Amenity", "Hours", "Restaurant Name", "Rating", "Price", "Location", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 3383, 56685, 11, 30192, 11, 26568, 4076, 11, 19767, 11, 8650, 11, 10067, 11, 81961, 323, 507, 627, 85664, 25, 1405, 374, 279, 24379, 67322, 3703, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "547", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) was(O) the(O) name(O) of(O) ariels(B-actor) prince(I-actor) in(O) the(O) little(B-title) mermaid(I-title)", "instance": {"id": "547", "words": ["what", "was", "the", "name", "of", "ariels", "prince", "in", "the", "little", "mermaid"], "labels": ["O", "O", "O", "O", "O", "B-character", "O", "O", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, year, song, review, director, character, actor, average ratings, title, trailer, genre, rating and O.\nSentence: what was the name of ariels prince in the little mermaid", "prompt_labels": "what(O) was(O) the(O) name(O) of(O) ariels(B-character) prince(O) in(O) the(O) little(B-title) mermaid(I-title)"}, "label_list": ["plot", "year", "song", "review", "director", "character", "actor", "average ratings", "title", "trailer", "genre", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 1060, 11, 5609, 11, 3477, 11, 7690, 11, 3752, 11, 12360, 11, 5578, 18594, 11, 2316, 11, 19809, 11, 17779, 11, 10959, 323, 507, 627, 85664, 25, 1148, 574, 279, 836, 315, 264, 462, 2053, 42826, 304, 279, 2697, 4809, 46342, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "490", "dataset": "mit-restaurant", "split": "dev", "prediction": "hi(O) i(O) would(O) like(O) some(O) thai(B-Cuisine) food(O) is(O) there(O) any(O) nearby(B-Location)", "instance": {"id": "490", "words": ["hi", "i", "would", "like", "some", "thai", "food", "is", "there", "any", "nearby"], "labels": ["O", "O", "O", "O", "O", "B-Cuisine", "O", "O", "O", "O", "B-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Location, Amenity, Price, Dish, Rating, Hours, Cuisine and O.\nSentence: hi i would like some thai food is there any nearby", "prompt_labels": "hi(O) i(O) would(O) like(O) some(O) thai(B-Cuisine) food(O) is(O) there(O) any(O) nearby(B-Location)"}, "label_list": ["Restaurant Name", "Location", "Amenity", "Price", "Dish", "Rating", "Hours", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 10067, 11, 3383, 56685, 11, 8650, 11, 49268, 11, 19767, 11, 30192, 11, 81961, 323, 507, 627, 85664, 25, 15960, 602, 1053, 1093, 1063, 18420, 3691, 374, 1070, 904, 14373, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2122", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) title(O) of(O) the(O) mystery(B-genre) film(O) with(O) paul(B-actor) reiser(I-actor) that(O) was(O) rated(O) an(O) eight(B-average ratings)", "instance": {"id": "2122", "words": ["what", "is", "the", "title", "of", "the", "mystery", "film", "with", "paul", "reiser", "that", "was", "rated", "an", "eight"], "labels": ["O", "O", "O", "O", "O", "O", "B-genre", "O", "O", "B-actor", "I-actor", "O", "O", "O", "O", "B-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, song, year, character, rating, genre, actor, director, plot, title, review, average ratings and O.\nSentence: what is the title of the mystery film with paul reiser that was rated an eight", "prompt_labels": "what(O) is(O) the(O) title(O) of(O) the(O) mystery(B-genre) film(O) with(O) paul(B-actor) reiser(I-actor) that(O) was(O) rated(O) an(O) eight(B-average ratings)"}, "label_list": ["trailer", "song", "year", "character", "rating", "genre", "actor", "director", "plot", "title", "review", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 5609, 11, 1060, 11, 3752, 11, 10959, 11, 17779, 11, 12360, 11, 7690, 11, 7234, 11, 2316, 11, 3477, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1148, 374, 279, 2316, 315, 279, 23347, 4632, 449, 68111, 312, 12329, 430, 574, 22359, 459, 8223, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1050", "dataset": "mit-restaurant", "split": "dev", "prediction": "search(O) for(O) a(O) place(O) that(O) serves(O) meatloaf(B-Dish)", "instance": {"id": "1050", "words": ["search", "for", "a", "place", "that", "serves", "meatloaf"], "labels": ["O", "O", "O", "O", "O", "O", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Restaurant Name, Amenity, Cuisine, Rating, Price, Dish, Location and O.\nSentence: search for a place that serves meatloaf", "prompt_labels": "search(O) for(O) a(O) place(O) that(O) serves(O) meatloaf(B-Dish)"}, "label_list": ["Hours", "Restaurant Name", "Amenity", "Cuisine", "Rating", "Price", "Dish", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 26568, 4076, 11, 3383, 56685, 11, 81961, 11, 19767, 11, 8650, 11, 49268, 11, 10067, 323, 507, 627, 85664, 25, 2778, 369, 264, 2035, 430, 17482, 13339, 385, 2642, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "447", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) action(B-genre) movies(O) starring(O) sylvester(B-actor) stallone(I-actor)", "instance": {"id": "447", "words": ["show", "me", "action", "movies", "starring", "sylvester", "stallone"], "labels": ["O", "O", "B-genre", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, year, rating, director, character, actor, trailer, title, genre, plot, song, review and O.\nSentence: show me action movies starring sylvester stallone", "prompt_labels": "show(O) me(O) action(B-genre) movies(O) starring(O) sylvester(B-actor) stallone(I-actor)"}, "label_list": ["average ratings", "year", "rating", "director", "character", "actor", "trailer", "title", "genre", "plot", "song", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 1060, 11, 10959, 11, 7690, 11, 3752, 11, 12360, 11, 19809, 11, 2316, 11, 17779, 11, 7234, 11, 5609, 11, 3477, 323, 507, 627, 85664, 25, 1501, 757, 1957, 9698, 40500, 274, 15095, 5302, 43793, 606, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1751", "dataset": "mit-movie", "split": "dev", "prediction": "please(O) list(O) some(O) mediocre(B-average ratings) film(B-genre) noir(I-genre) movies(O) released(O) in(O) the(O) past(B-year) two(I-year) decades(I-year) directed(O) by(O) robert(B-director) hiltzik(I-director)", "instance": {"id": "1751", "words": ["please", "list", "some", "mediocre", "film", "noir", "movies", "released", "in", "the", "past", "two", "decades", "directed", "by", "robert", "hiltzik"], "labels": ["O", "O", "O", "B-average ratings", "B-genre", "I-genre", "O", "O", "O", "O", "B-year", "I-year", "I-year", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, song, genre, year, title, rating, plot, director, actor, trailer, review, character and O.\nSentence: please list some mediocre film noir movies released in the past two decades directed by robert hiltzik", "prompt_labels": "please(O) list(O) some(O) mediocre(B-average ratings) film(B-genre) noir(I-genre) movies(O) released(O) in(O) the(O) past(B-year) two(I-year) decades(I-year) directed(O) by(O) robert(B-director) hiltzik(I-director)"}, "label_list": ["average ratings", "song", "genre", "year", "title", "rating", "plot", "director", "actor", "trailer", "review", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 5609, 11, 17779, 11, 1060, 11, 2316, 11, 10959, 11, 7234, 11, 7690, 11, 12360, 11, 19809, 11, 3477, 11, 3752, 323, 507, 627, 85664, 25, 4587, 1160, 1063, 68480, 4632, 56662, 9698, 6004, 304, 279, 3347, 1403, 11026, 15910, 555, 89993, 305, 3036, 76574, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "138", "dataset": "crossner_science", "split": "dev", "prediction": "catalyzed(O) by(O) Phosphoenolpyruvate(B-chemical compound) carboxylase(I-enzyme) ((O) PEPC(B-enzyme) )(O),(O) to(O) carboxylate(O) phosphoenolpyruvate(O) ((O) PEP(O) )(O) to(O) oxaloacetate(O) ((O) OAA(O) )(O) which(O) is(O) a(O) Csub4(O) /(O) sub(O) dicarboxylic(O) acid(O).(O)", "instance": {"id": "138", "words": ["catalyzed", "by", "Phosphoenolpyruvate", "carboxylase", "(", "PEPC", ")", ",", "to", "carboxylate", "phosphoenolpyruvate", "(", "PEP", ")", "to", "oxaloacetate", "(", "OAA", ")", "which", "is", "a", "Csub4", "/", "sub", "dicarboxylic", "acid", "."], "labels": ["O", "O", "B-enzyme", "I-enzyme", "O", "B-enzyme", "O", "O", "O", "B-chemical compound", "I-chemical compound", "O", "B-chemical compound", "O", "O", "B-chemical compound", "O", "B-chemical compound", "O", "O", "O", "O", "B-chemical compound", "I-chemical compound", "I-chemical compound", "I-chemical compound", "I-chemical compound", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: discipline, academic journal, astronomical object, university, protein, theory, country, location, event, chemical compound, person, enzyme, organization, chemical element, award, scientist and O.\nSentence: catalyzed by Phosphoenolpyruvate carboxylase ( PEPC ) , to carboxylate phosphoenolpyruvate ( PEP ) to oxaloacetate ( OAA ) which is a Csub4 / sub dicarboxylic acid .", "prompt_labels": "catalyzed(O) by(O) Phosphoenolpyruvate(B-enzyme) carboxylase(I-enzyme) ((O) PEPC(B-enzyme) )(O) ,(O) to(O) carboxylate(B-chemical compound) phosphoenolpyruvate(I-chemical compound) ((O) PEP(B-chemical compound) )(O) to(O) oxaloacetate(B-chemical compound) ((O) OAA(B-chemical compound) )(O) which(O) is(O) a(O) Csub4(B-chemical compound) /(I-chemical compound) sub(I-chemical compound) dicarboxylic(I-chemical compound) acid(I-chemical compound) .(O)"}, "label_list": ["discipline", "academic journal", "astronomical object", "university", "protein", "theory", "country", "location", "event", "chemical compound", "person", "enzyme", "organization", "chemical element", "award", "scientist"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26434, 11, 14584, 8486, 11, 87283, 1665, 11, 12374, 11, 13128, 11, 10334, 11, 3224, 11, 3813, 11, 1567, 11, 11742, 24549, 11, 1732, 11, 49242, 11, 7471, 11, 11742, 2449, 11, 10292, 11, 28568, 323, 507, 627, 85664, 25, 34454, 88, 16284, 555, 2405, 24527, 16355, 337, 3368, 2739, 85, 349, 1841, 2054, 4010, 521, 320, 22557, 4977, 883, 1174, 311, 1841, 2054, 4010, 349, 33088, 16355, 337, 3368, 2739, 85, 349, 320, 393, 9377, 883, 311, 19488, 12812, 68323, 349, 320, 507, 6157, 883, 902, 374, 264, 356, 2008, 19, 611, 1207, 21945, 277, 2054, 88, 416, 13935, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1275", "dataset": "mit-movie", "split": "dev", "prediction": "has(O) julie(B-actor) andrews(I-actor) ever(O) been(O) a(O) rated(O) r(B-rating) film(B-genre) noir(I-genre) movie(O)", "instance": {"id": "1275", "words": ["has", "julie", "andrews", "ever", "been", "a", "rated", "r", "film", "noir", "movie"], "labels": ["O", "B-actor", "I-actor", "O", "O", "O", "O", "B-rating", "B-genre", "I-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, year, trailer, plot, character, song, average ratings, director, rating, title, review, actor and O.\nSentence: has julie andrews ever been a rated r film noir movie", "prompt_labels": "has(O) julie(B-actor) andrews(I-actor) ever(O) been(O) a(O) rated(O) r(B-rating) film(B-genre) noir(I-genre) movie(O)"}, "label_list": ["genre", "year", "trailer", "plot", "character", "song", "average ratings", "director", "rating", "title", "review", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 1060, 11, 19809, 11, 7234, 11, 3752, 11, 5609, 11, 5578, 18594, 11, 7690, 11, 10959, 11, 2316, 11, 3477, 11, 12360, 323, 507, 627, 85664, 25, 706, 41638, 648, 323, 4361, 82, 3596, 1027, 264, 22359, 436, 4632, 56662, 5818, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1917", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) are(O) some(O) titles(O) of(O) animation(B-genre) films(O) directed(O) by(O) tomm(B-director) coker(I-director) that(O) received(O) average(B-average ratings) ratings(O)", "instance": {"id": "1917", "words": ["what", "are", "some", "titles", "of", "animation", "films", "directed", "by", "tomm", "coker", "that", "received", "average", "ratings"], "labels": ["O", "O", "O", "O", "O", "B-genre", "O", "O", "O", "B-director", "I-director", "O", "O", "B-average ratings", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, title, song, trailer, character, plot, actor, rating, average ratings, genre, year, review and O.\nSentence: what are some titles of animation films directed by tomm coker that received average ratings", "prompt_labels": "what(O) are(O) some(O) titles(O) of(O) animation(B-genre) films(O) directed(O) by(O) tomm(B-director) coker(I-director) that(O) received(O) average(B-average ratings) ratings(O)"}, "label_list": ["director", "title", "song", "trailer", "character", "plot", "actor", "rating", "average ratings", "genre", "year", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 2316, 11, 5609, 11, 19809, 11, 3752, 11, 7234, 11, 12360, 11, 10959, 11, 5578, 18594, 11, 17779, 11, 1060, 11, 3477, 323, 507, 627, 85664, 25, 1148, 527, 1063, 15671, 315, 10571, 12631, 15910, 555, 311, 3906, 272, 10668, 430, 4036, 5578, 18594, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "710", "dataset": "mit-restaurant", "split": "dev", "prediction": "id(O) like(O) to(O) find(O) a(O) chinese(B-Cuisine) restaurant(O) nearby(B-Location)", "instance": {"id": "710", "words": ["id", "like", "to", "find", "a", "chinese", "restaurant", "nearby"], "labels": ["O", "O", "O", "O", "O", "B-Cuisine", "O", "B-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Hours, Dish, Location, Cuisine, Rating, Amenity, Restaurant Name and O.\nSentence: id like to find a chinese restaurant nearby", "prompt_labels": "id(O) like(O) to(O) find(O) a(O) chinese(B-Cuisine) restaurant(O) nearby(B-Location)"}, "label_list": ["Price", "Hours", "Dish", "Location", "Cuisine", "Rating", "Amenity", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 30192, 11, 49268, 11, 10067, 11, 81961, 11, 19767, 11, 3383, 56685, 11, 26568, 4076, 323, 507, 627, 85664, 25, 887, 1093, 311, 1505, 264, 57487, 10960, 14373, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "417", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) worst(O) viewer(O) rated(O) vampire(B-plot) film(O)", "instance": {"id": "417", "words": ["what", "is", "the", "worst", "viewer", "rated", "vampire", "film"], "labels": ["O", "O", "O", "B-average ratings", "I-average ratings", "I-average ratings", "B-plot", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, genre, character, plot, title, year, actor, rating, director, song, average ratings, review and O.\nSentence: what is the worst viewer rated vampire film", "prompt_labels": "what(O) is(O) the(O) worst(B-average ratings) viewer(I-average ratings) rated(I-average ratings) vampire(B-plot) film(O)"}, "label_list": ["trailer", "genre", "character", "plot", "title", "year", "actor", "rating", "director", "song", "average ratings", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 17779, 11, 3752, 11, 7234, 11, 2316, 11, 1060, 11, 12360, 11, 10959, 11, 7690, 11, 5609, 11, 5578, 18594, 11, 3477, 323, 507, 627, 85664, 25, 1148, 374, 279, 12047, 26792, 22359, 51587, 4632, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "290", "dataset": "crossner_politics", "split": "dev", "prediction": "After(O) the(O) April(B-election) 2009(I-election) Moldovan(I-election) parliamentary(I-election) election(I-election),(O) the(O) 2009(B-election) Moldova(I-election) civil(I-election) unrest(I-election),(O) the(O) July(B-election) 2009(I-election) Moldovan(I-election) parliamentary(I-election) election(I-election) and(O) the(O) creation(O) of(O) the(O) governing(O) Alliance(B-political party) for(I-political party) European(I-political party) Integration(I-political party),(O) a(O) new(O) wave(O) of(O) speculations(O) about(O) the(O) union(O) followed(O).(O)", "instance": {"id": "290", "words": ["After", "the", "April", "2009", "Moldovan", "parliamentary", "election", ",", "the", "2009", "Moldova", "civil", "unrest", ",", "the", "July", "2009", "Moldovan", "parliamentary", "election", "and", "the", "creation", "of", "the", "governing", "Alliance", "for", "European", "Integration", ",", "a", "new", "wave", "of", "speculations", "about", "the", "union", "followed", "."], "labels": ["O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-event", "I-event", "I-event", "I-event", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, location, country, organization, event, politician, political party, election and O.\nSentence: After the April 2009 Moldovan parliamentary election , the 2009 Moldova civil unrest , the July 2009 Moldovan parliamentary election and the creation of the governing Alliance for European Integration , a new wave of speculations about the union followed .", "prompt_labels": "After(O) the(O) April(B-election) 2009(I-election) Moldovan(I-election) parliamentary(I-election) election(I-election) ,(O) the(O) 2009(B-event) Moldova(I-event) civil(I-event) unrest(I-event) ,(O) the(O) July(B-election) 2009(I-election) Moldovan(I-election) parliamentary(I-election) election(I-election) and(O) the(O) creation(O) of(O) the(O) governing(O) Alliance(B-organization) for(I-organization) European(I-organization) Integration(I-organization) ,(O) a(O) new(O) wave(O) of(O) speculations(O) about(O) the(O) union(O) followed(O) .(O)"}, "label_list": ["person", "location", "country", "organization", "event", "politician", "political party", "election"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 3813, 11, 3224, 11, 7471, 11, 1567, 11, 37038, 11, 5054, 4717, 11, 6355, 323, 507, 627, 85664, 25, 4740, 279, 5936, 220, 1049, 24, 55263, 43757, 44250, 6355, 1174, 279, 220, 1049, 24, 55263, 12949, 8431, 59322, 1174, 279, 5887, 220, 1049, 24, 55263, 43757, 44250, 6355, 323, 279, 9886, 315, 279, 10217, 23590, 369, 7665, 41169, 1174, 264, 502, 12330, 315, 1424, 7607, 922, 279, 11552, 8272, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1652", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) action(B-genre) movies(O) that(O) star(O) satoshi(B-actor) kon(I-actor)", "instance": {"id": "1652", "words": ["list", "action", "movies", "that", "star", "satoshi", "kon"], "labels": ["O", "B-genre", "O", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, director, genre, song, plot, character, year, review, average ratings, rating, actor, trailer and O.\nSentence: list action movies that star satoshi kon", "prompt_labels": "list(O) action(B-genre) movies(O) that(O) star(O) satoshi(B-director) kon(I-director)"}, "label_list": ["title", "director", "genre", "song", "plot", "character", "year", "review", "average ratings", "rating", "actor", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 7690, 11, 17779, 11, 5609, 11, 7234, 11, 3752, 11, 1060, 11, 3477, 11, 5578, 18594, 11, 10959, 11, 12360, 11, 19809, 323, 507, 627, 85664, 25, 1160, 1957, 9698, 430, 6917, 7731, 32945, 16947, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "3", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) science(B-genre) fiction(I-genre) films(O) have(O) come(O) out(O) recently(O)", "instance": {"id": "3", "words": ["what", "science", "fiction", "films", "have", "come", "out", "recently"], "labels": ["O", "B-genre", "I-genre", "O", "O", "O", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, year, genre, director, review, character, rating, average ratings, song, trailer, actor, title and O.\nSentence: what science fiction films have come out recently", "prompt_labels": "what(O) science(B-genre) fiction(I-genre) films(O) have(O) come(O) out(O) recently(B-year)"}, "label_list": ["plot", "year", "genre", "director", "review", "character", "rating", "average ratings", "song", "trailer", "actor", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 1060, 11, 17779, 11, 7690, 11, 3477, 11, 3752, 11, 10959, 11, 5578, 18594, 11, 5609, 11, 19809, 11, 12360, 11, 2316, 323, 507, 627, 85664, 25, 1148, 8198, 17422, 12631, 617, 2586, 704, 6051, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "80", "dataset": "crossner_music", "split": "dev", "prediction": "This(O) is(O) the(O) method(O) used(O) by(O) Bands(B-organization) of(I-organization) America(I-organization),(O) the(O) Indiana(B-organization) State(I-organization) School(I-organization) Music(I-organization) Association(I-organization),(O) Kentucky(B-organization) Music(I-organization) Educators(I-organization) Association(I-organization) and(O) the(O) University(B-organization) Interscholastic(I-organization) League(I-organization).(O)", "instance": {"id": "80", "words": ["This", "is", "the", "method", "used", "by", "Bands", "of", "America", ",", "the", "Indiana", "State", "School", "Music", "Association", ",", "Kentucky", "Music", "Educators", "Association", "and", "the", "University", "Interscholastic", "League", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, location, musical artist, musical instrument, band, country, music genre, organization, event, album, award, person and O.\nSentence: This is the method used by Bands of America , the Indiana State School Music Association , Kentucky Music Educators Association and the University Interscholastic League .", "prompt_labels": "This(O) is(O) the(O) method(O) used(O) by(O) Bands(B-organization) of(I-organization) America(I-organization) ,(O) the(O) Indiana(B-organization) State(I-organization) School(I-organization) Music(I-organization) Association(I-organization) ,(O) Kentucky(B-organization) Music(I-organization) Educators(I-organization) Association(I-organization) and(O) the(O) University(B-organization) Interscholastic(I-organization) League(I-organization) .(O)"}, "label_list": ["song", "location", "musical artist", "musical instrument", "band", "country", "music genre", "organization", "event", "album", "award", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 3813, 11, 18273, 10255, 11, 18273, 14473, 11, 7200, 11, 3224, 11, 4731, 17779, 11, 7471, 11, 1567, 11, 8176, 11, 10292, 11, 1732, 323, 507, 627, 85664, 25, 1115, 374, 279, 1749, 1511, 555, 88402, 315, 5270, 1174, 279, 22319, 3314, 6150, 10948, 10229, 1174, 26036, 10948, 10355, 3046, 10229, 323, 279, 3907, 1357, 388, 331, 337, 5174, 9130, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "997", "dataset": "mit-restaurant", "split": "dev", "prediction": "make(O) me(O) reservations(O) for(O) three(O) people(O) at(O) devitos(B-Restaurant Name) italian(I-Restaurant Name)", "instance": {"id": "997", "words": ["make", "me", "reservations", "for", "three", "people", "at", "devitos", "italian"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-Restaurant Name", "I-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Hours, Dish, Rating, Restaurant Name, Cuisine, Amenity, Price and O.\nSentence: make me reservations for three people at devitos italian", "prompt_labels": "make(O) me(O) reservations(O) for(O) three(O) people(O) at(O) devitos(B-Restaurant Name) italian(I-Restaurant Name)"}, "label_list": ["Location", "Hours", "Dish", "Rating", "Restaurant Name", "Cuisine", "Amenity", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 30192, 11, 49268, 11, 19767, 11, 26568, 4076, 11, 81961, 11, 3383, 56685, 11, 8650, 323, 507, 627, 85664, 25, 1304, 757, 41162, 369, 2380, 1274, 520, 3567, 26675, 29048, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1743", "dataset": "mit-movie", "split": "dev", "prediction": "name(O) the(O) harold(B-director) f(I-director) kress(I-director) unrated(B-rating) film(O) with(O) good(B-average ratings) ratings(O) that(O) centers(O) on(O) a(O) parole(B-plot) hearing(I-plot)", "instance": {"id": "1743", "words": ["name", "the", "harold", "f", "kress", "unrated", "film", "with", "good", "ratings", "that", "centers", "on", "a", "parole", "hearing"], "labels": ["O", "O", "B-director", "I-director", "I-director", "B-rating", "O", "O", "B-average ratings", "O", "O", "O", "O", "O", "B-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, song, actor, review, year, director, average ratings, title, character, plot, trailer, rating and O.\nSentence: name the harold f kress unrated film with good ratings that centers on a parole hearing", "prompt_labels": "name(O) the(O) harold(B-director) f(I-director) kress(I-director) unrated(B-rating) film(O) with(O) good(B-average ratings) ratings(O) that(O) centers(O) on(O) a(O) parole(B-plot) hearing(I-plot)"}, "label_list": ["genre", "song", "actor", "review", "year", "director", "average ratings", "title", "character", "plot", "trailer", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 5609, 11, 12360, 11, 3477, 11, 1060, 11, 7690, 11, 5578, 18594, 11, 2316, 11, 3752, 11, 7234, 11, 19809, 11, 10959, 323, 507, 627, 85664, 25, 836, 279, 4960, 820, 282, 597, 676, 41480, 660, 4632, 449, 1695, 18594, 430, 19169, 389, 264, 49361, 11011, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "453", "dataset": "mit-movie", "split": "dev", "prediction": "whats(O) the(O) highest(B-average ratings) rated(I-average ratings) drama(B-genre) of(O) 1990(B-year)", "instance": {"id": "453", "words": ["whats", "the", "highest", "rated", "drama", "of", "1990"], "labels": ["O", "O", "B-review", "I-review", "B-genre", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, plot, title, average ratings, year, character, actor, genre, song, trailer, rating, review and O.\nSentence: whats the highest rated drama of 1990", "prompt_labels": "whats(O) the(O) highest(B-review) rated(I-review) drama(B-genre) of(O) 1990(B-year)"}, "label_list": ["director", "plot", "title", "average ratings", "year", "character", "actor", "genre", "song", "trailer", "rating", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 7234, 11, 2316, 11, 5578, 18594, 11, 1060, 11, 3752, 11, 12360, 11, 17779, 11, 5609, 11, 19809, 11, 10959, 11, 3477, 323, 507, 627, 85664, 25, 41209, 279, 8592, 22359, 20156, 315, 220, 2550, 15, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1629", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) a(O) musical(B-genre) directed(O) by(O) susan(B-director) muska(I-director)", "instance": {"id": "1629", "words": ["list", "a", "musical", "directed", "by", "susan", "muska"], "labels": ["O", "O", "B-genre", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, character, plot, song, review, director, genre, title, average ratings, trailer, actor, year and O.\nSentence: list a musical directed by susan muska", "prompt_labels": "list(O) a(O) musical(B-genre) directed(O) by(O) susan(B-director) muska(I-director)"}, "label_list": ["rating", "character", "plot", "song", "review", "director", "genre", "title", "average ratings", "trailer", "actor", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 3752, 11, 7234, 11, 5609, 11, 3477, 11, 7690, 11, 17779, 11, 2316, 11, 5578, 18594, 11, 19809, 11, 12360, 11, 1060, 323, 507, 627, 85664, 25, 1160, 264, 18273, 15910, 555, 4582, 276, 3167, 4657, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1849", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) pg(B-rating) movie(O) released(O) within(O) the(O) last(B-year) two(I-year) years(I-year) featured(O) david(B-actor) cassidy(I-actor) and(O) was(O) liked(B-average ratings) by(I-average ratings) many(I-average ratings)", "instance": {"id": "1849", "words": ["what", "pg", "movie", "released", "within", "the", "last", "two", "years", "featured", "david", "cassidy", "and", "was", "liked", "by", "many"], "labels": ["O", "B-rating", "O", "O", "O", "O", "B-year", "I-year", "I-year", "O", "B-actor", "I-actor", "O", "O", "B-average ratings", "I-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, year, genre, actor, plot, song, rating, review, character, title, director, trailer and O.\nSentence: what pg movie released within the last two years featured david cassidy and was liked by many", "prompt_labels": "what(O) pg(B-rating) movie(O) released(O) within(O) the(O) last(B-year) two(I-year) years(I-year) featured(O) david(B-actor) cassidy(I-actor) and(O) was(O) liked(B-average ratings) by(I-average ratings) many(I-average ratings)"}, "label_list": ["average ratings", "year", "genre", "actor", "plot", "song", "rating", "review", "character", "title", "director", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 1060, 11, 17779, 11, 12360, 11, 7234, 11, 5609, 11, 10959, 11, 3477, 11, 3752, 11, 2316, 11, 7690, 11, 19809, 323, 507, 627, 85664, 25, 1148, 17953, 5818, 6004, 2949, 279, 1566, 1403, 1667, 15109, 55046, 45324, 43686, 323, 574, 15262, 555, 1690, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "74", "dataset": "crossner_ai", "split": "dev", "prediction": "In(O) August(O) 2011(O),(O) it(O) was(O) announced(O) that(O) Hitachi(B-organization) would(O) donate(O) an(O) electron(B-field) microscope(I-field) to(O) each(O) of(O) five(O) universities(O) in(O) Indonesia(B-country) ((O) the(O) University(B-university) of(I-university) North(I-university) Sumatra(I-university) in(O) Medan(B-location),(O) the(O) Indonesian(B-university) Christian(I-university) University(I-university) in(O) Jakarta(B-location),(O) Padjadjaran(B-university) University(I-university) in(O) Bandung(B-location),(O) Jenderal(B-university) Soedirman(I-university) University(I-university) in(O) Purwokerto(B-location) and(O) Muhammadiyah(B-university) University(I-university) in(O) Malang(B-location) )(O).(O)", "instance": {"id": "74", "words": ["In", "August", "2011", ",", "it", "was", "announced", "that", "Hitachi", "would", "donate", "an", "electron", "microscope", "to", "each", "of", "five", "universities", "in", "Indonesia", "(", "the", "University", "of", "North", "Sumatra", "in", "Medan", ",", "the", "Indonesian", "Christian", "University", "in", "Jakarta", ",", "Padjadjaran", "University", "in", "Bandung", ",", "Jenderal", "Soedirman", "University", "in", "Purwokerto", "and", "Muhammadiyah", "University", "in", "Malang", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "O", "O", "O", "B-product", "I-product", "O", "O", "O", "O", "O", "O", "B-country", "O", "O", "B-university", "I-university", "I-university", "I-university", "O", "B-location", "O", "O", "B-university", "I-university", "I-university", "O", "B-location", "O", "B-university", "I-university", "O", "B-location", "O", "B-university", "I-university", "I-university", "O", "B-location", "O", "B-university", "I-university", "O", "B-location", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, field, conference, task, country, algorithm, metric, university, location, product, person, researcher, programming language and O.\nSentence: In August 2011 , it was announced that Hitachi would donate an electron microscope to each of five universities in Indonesia ( the University of North Sumatra in Medan , the Indonesian Christian University in Jakarta , Padjadjaran University in Bandung , Jenderal Soedirman University in Purwokerto and Muhammadiyah University in Malang ) .", "prompt_labels": "In(O) August(O) 2011(O) ,(O) it(O) was(O) announced(O) that(O) Hitachi(B-organization) would(O) donate(O) an(O) electron(B-product) microscope(I-product) to(O) each(O) of(O) five(O) universities(O) in(O) Indonesia(B-country) ((O) the(O) University(B-university) of(I-university) North(I-university) Sumatra(I-university) in(O) Medan(B-location) ,(O) the(O) Indonesian(B-university) Christian(I-university) University(I-university) in(O) Jakarta(B-location) ,(O) Padjadjaran(B-university) University(I-university) in(O) Bandung(B-location) ,(O) Jenderal(B-university) Soedirman(I-university) University(I-university) in(O) Purwokerto(B-location) and(O) Muhammadiyah(B-university) University(I-university) in(O) Malang(B-location) )(O) .(O)"}, "label_list": ["organization", "field", "conference", "task", "country", "algorithm", "metric", "university", "location", "product", "person", "researcher", "programming language"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 2115, 11, 10017, 11, 3465, 11, 3224, 11, 12384, 11, 18767, 11, 12374, 11, 3813, 11, 2027, 11, 1732, 11, 32185, 11, 15840, 4221, 323, 507, 627, 85664, 25, 763, 6287, 220, 679, 16, 1174, 433, 574, 7376, 430, 16261, 31464, 1053, 33009, 459, 17130, 73757, 311, 1855, 315, 4330, 23978, 304, 24922, 320, 279, 3907, 315, 4892, 8279, 40658, 304, 3344, 276, 1174, 279, 59929, 9052, 3907, 304, 64133, 1174, 393, 25770, 329, 19571, 276, 3907, 304, 17366, 2234, 1174, 622, 1693, 278, 2100, 101081, 1543, 3907, 304, 14874, 86, 564, 14200, 323, 117970, 76, 2836, 95780, 3907, 304, 8560, 526, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "336", "dataset": "mit-movie", "split": "dev", "prediction": "look(O) for(O) dramas(B-genre) that(O) have(O) denzel(B-actor) washington(I-actor) and(O) are(O) academy(O) award(O) winners(O) or(O) nominees(O)", "instance": {"id": "336", "words": ["look", "for", "dramas", "that", "have", "denzel", "washington", "and", "are", "academy", "award", "winners", "or", "nominees"], "labels": ["O", "O", "B-genre", "O", "O", "B-actor", "I-actor", "O", "O", "B-average ratings", "I-average ratings", "I-average ratings", "I-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, director, genre, year, average ratings, plot, rating, song, review, character, trailer, title and O.\nSentence: look for dramas that have denzel washington and are academy award winners or nominees", "prompt_labels": "look(O) for(O) dramas(B-genre) that(O) have(O) denzel(B-actor) washington(I-actor) and(O) are(O) academy(B-average ratings) award(I-average ratings) winners(I-average ratings) or(I-average ratings) nominees(I-average ratings)"}, "label_list": ["actor", "director", "genre", "year", "average ratings", "plot", "rating", "song", "review", "character", "trailer", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 7690, 11, 17779, 11, 1060, 11, 5578, 18594, 11, 7234, 11, 10959, 11, 5609, 11, 3477, 11, 3752, 11, 19809, 11, 2316, 323, 507, 627, 85664, 25, 1427, 369, 88826, 430, 617, 3453, 28493, 94771, 323, 527, 44445, 10292, 26526, 477, 60142, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "412", "dataset": "mit-restaurant", "split": "dev", "prediction": "find(O) me(O) a(O) tgi(B-Restaurant Name) fridays(I-Restaurant Name) near(B-Location) me(I-Location)", "instance": {"id": "412", "words": ["find", "me", "a", "tgi", "fridays", "near", "me"], "labels": ["O", "O", "O", "B-Restaurant Name", "I-Restaurant Name", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Rating, Price, Location, Cuisine, Restaurant Name, Dish, Amenity and O.\nSentence: find me a tgi fridays near me", "prompt_labels": "find(O) me(O) a(O) tgi(B-Restaurant Name) fridays(I-Restaurant Name) near(B-Location) me(I-Location)"}, "label_list": ["Hours", "Rating", "Price", "Location", "Cuisine", "Restaurant Name", "Dish", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 19767, 11, 8650, 11, 10067, 11, 81961, 11, 26568, 4076, 11, 49268, 11, 3383, 56685, 323, 507, 627, 85664, 25, 1505, 757, 264, 259, 8376, 1448, 307, 954, 3221, 757, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "191", "dataset": "crossner_literature", "split": "dev", "prediction": "Of(B-book) Things(I-book) to(I-book) Come(I-book),(O) The(B-book) New(I-book) York(I-book) Times(I-book) Book(I-book) Review(I-book),(O) October(O) 26(O),(O) 1975(O) Theodore(B-writer) Sturgeon(I-writer) praised(O) The(B-book) Dispossessed(I-book) as(O) a(O) beautifully(O) written(O),(O) beautifully(O) composed(O) book(O),(O) saying(O) it(O) performs(O) one(O) of(O) science(B-literary genre) fiction(I-literary genre)'s(O) prime(O) functions(O),(O) which(O) is(O) to(O) create(O) another(O) kind(O) of(O) social(O) system(O) to(O) see(O) how(O) it(O) would(O) work(O).(O)", "instance": {"id": "191", "words": ["Of", "Things", "to", "Come", ",", "The", "New", "York", "Times", "Book", "Review", ",", "October", "26", ",", "1975", "Theodore", "Sturgeon", "praised", "The", "Dispossessed", "as", "a", "beautifully", "written", ",", "beautifully", "composed", "book", ",", "saying", "it", "performs", "one", "of", "science", "fiction", "'s", "prime", "functions", ",", "which", "is", "to", "create", "another", "kind", "of", "social", "system", "to", "see", "how", "it", "would", "work", "."], "labels": ["O", "O", "O", "O", "O", "B-magazine", "I-magazine", "I-magazine", "I-magazine", "I-magazine", "I-magazine", "O", "O", "O", "O", "O", "B-writer", "I-writer", "O", "B-book", "I-book", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-literary genre", "I-literary genre", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, writer, poem, organization, book, person, literary genre, event, country, award, magazine and O.\nSentence: Of Things to Come , The New York Times Book Review , October 26 , 1975 Theodore Sturgeon praised The Dispossessed as a beautifully written , beautifully composed book , saying it performs one of science fiction 's prime functions , which is to create another kind of social system to see how it would work .", "prompt_labels": "Of(O) Things(O) to(O) Come(O) ,(O) The(B-magazine) New(I-magazine) York(I-magazine) Times(I-magazine) Book(I-magazine) Review(I-magazine) ,(O) October(O) 26(O) ,(O) 1975(O) Theodore(B-writer) Sturgeon(I-writer) praised(O) The(B-book) Dispossessed(I-book) as(O) a(O) beautifully(O) written(O) ,(O) beautifully(O) composed(O) book(O) ,(O) saying(O) it(O) performs(O) one(O) of(O) science(B-literary genre) fiction(I-literary genre) 's(O) prime(O) functions(O) ,(O) which(O) is(O) to(O) create(O) another(O) kind(O) of(O) social(O) system(O) to(O) see(O) how(O) it(O) would(O) work(O) .(O)"}, "label_list": ["location", "writer", "poem", "organization", "book", "person", "literary genre", "event", "country", "award", "magazine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 7061, 11, 33894, 11, 7471, 11, 2363, 11, 1732, 11, 32465, 17779, 11, 1567, 11, 3224, 11, 10292, 11, 14756, 323, 507, 627, 85664, 25, 5046, 20695, 311, 15936, 1174, 578, 1561, 4356, 8691, 6017, 10506, 1174, 6664, 220, 1627, 1174, 220, 4468, 20, 77449, 800, 81562, 37475, 578, 4185, 9007, 22456, 439, 264, 32719, 5439, 1174, 32719, 24306, 2363, 1174, 5605, 433, 27772, 832, 315, 8198, 17422, 364, 82, 10461, 5865, 1174, 902, 374, 311, 1893, 2500, 3169, 315, 3674, 1887, 311, 1518, 1268, 433, 1053, 990, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "324", "dataset": "crossner_politics", "split": "dev", "prediction": "His(O) father(O) Patrick(B-politician) Reynolds(I-politician) was(O) elected(O) as(O) a(O) Cumann(B-political party) na(I-political party) nGaedheal(I-political party) Teachta(I-political party) D\u00e1la(I-political party) ((O) TD(O) )(O) for(O) Leitrim-Sligo(B-location) at(O) the(O) September(B-election) 1927(I-election) Irish(I-election) general(I-election) election(I-election),(O) but(O) was(O) fatally(O) shot(O) during(O) the(O) 1932(B-election) Irish(I-election) general(I-election) election(I-election) campaign(O).(O)", "instance": {"id": "324", "words": ["His", "father", "Patrick", "Reynolds", "was", "elected", "as", "a", "Cumann", "na", "nGaedheal", "Teachta", "D\u00e1la", "(", "TD", ")", "for", "Leitrim-Sligo", "at", "the", "September", "1927", "Irish", "general", "election", ",", "but", "was", "fatally", "shot", "during", "the", "1932", "Irish", "general", "election", "campaign", "."], "labels": ["O", "O", "B-politician", "I-politician", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "B-political party", "O", "O", "B-location", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, event, country, location, election, person, organization, politician and O.\nSentence: His father Patrick Reynolds was elected as a Cumann na nGaedheal Teachta D\u00e1la ( TD ) for Leitrim-Sligo at the September 1927 Irish general election , but was fatally shot during the 1932 Irish general election campaign .", "prompt_labels": "His(O) father(O) Patrick(B-politician) Reynolds(I-politician) was(O) elected(O) as(O) a(O) Cumann(B-political party) na(I-political party) nGaedheal(I-political party) Teachta(I-political party) D\u00e1la(I-political party) ((O) TD(B-political party) )(O) for(O) Leitrim-Sligo(B-location) at(O) the(O) September(B-election) 1927(I-election) Irish(I-election) general(I-election) election(I-election) ,(O) but(O) was(O) fatally(O) shot(O) during(O) the(O) 1932(B-election) Irish(I-election) general(I-election) election(I-election) campaign(O) .(O)"}, "label_list": ["political party", "event", "country", "location", "election", "person", "organization", "politician"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5054, 4717, 11, 1567, 11, 3224, 11, 3813, 11, 6355, 11, 1732, 11, 7471, 11, 37038, 323, 507, 627, 85664, 25, 5414, 7126, 20199, 46172, 574, 16689, 439, 264, 32678, 1036, 4415, 308, 38, 62554, 383, 278, 70377, 2629, 423, 119756, 320, 28816, 883, 369, 2009, 275, 6417, 6354, 7864, 78, 520, 279, 6250, 220, 5926, 22, 18088, 4689, 6355, 1174, 719, 574, 72461, 6689, 2391, 279, 220, 7285, 17, 18088, 4689, 6355, 4901, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "652", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) want(O) to(O) find(O) a(O) burger(B-Dish) that(O) isnt(B-Amenity) fast(B-Cuisine) food(I-Cuisine)", "instance": {"id": "652", "words": ["i", "want", "to", "find", "a", "burger", "that", "isnt", "fast", "food"], "labels": ["O", "O", "O", "O", "O", "B-Dish", "O", "B-Rating", "I-Rating", "I-Rating"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Location, Cuisine, Restaurant Name, Dish, Rating, Hours, Price and O.\nSentence: i want to find a burger that isnt fast food", "prompt_labels": "i(O) want(O) to(O) find(O) a(O) burger(B-Dish) that(O) isnt(B-Rating) fast(I-Rating) food(I-Rating)"}, "label_list": ["Amenity", "Location", "Cuisine", "Restaurant Name", "Dish", "Rating", "Hours", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 10067, 11, 81961, 11, 26568, 4076, 11, 49268, 11, 19767, 11, 30192, 11, 8650, 323, 507, 627, 85664, 25, 602, 1390, 311, 1505, 264, 45723, 430, 70058, 5043, 3691, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2035", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) a(O) really(B-average ratings) good(I-average ratings) scary(B-genre) movie(O) about(O) an(O) axe(B-plot) murder(I-plot)", "instance": {"id": "2035", "words": ["what", "is", "a", "really", "good", "scary", "movie", "about", "an", "axe", "murder"], "labels": ["O", "O", "O", "B-average ratings", "I-average ratings", "B-genre", "O", "O", "O", "B-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, review, genre, year, actor, title, song, character, average ratings, director, trailer, rating and O.\nSentence: what is a really good scary movie about an axe murder", "prompt_labels": "what(O) is(O) a(O) really(B-average ratings) good(I-average ratings) scary(B-genre) movie(O) about(O) an(O) axe(B-plot) murder(I-plot)"}, "label_list": ["plot", "review", "genre", "year", "actor", "title", "song", "character", "average ratings", "director", "trailer", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 3477, 11, 17779, 11, 1060, 11, 12360, 11, 2316, 11, 5609, 11, 3752, 11, 5578, 18594, 11, 7690, 11, 19809, 11, 10959, 323, 507, 627, 85664, 25, 1148, 374, 264, 2216, 1695, 29565, 5818, 922, 459, 51564, 10102, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "375", "dataset": "crossner_music", "split": "dev", "prediction": "Justincase(B-band) was(O) an(O) American(O) Alternative(B-music genre) rock(I-music genre) -(O) Pop(B-music genre) music(I-music genre) band(O) from(O) Charlotte(B-location),(O) North(B-location) Carolina(I-location),(O) best(O) known(O) for(O) their(O) 2002(O) single(O) Don(B-song) 't(I-song) Cry(I-song) for(I-song) Us(I-song),(O) which(O) was(O) co-written(O) by(O) Michelle(B-musical artist) Branch(I-musical artist),(O) who(O) was(O) one(O) of(O) the(O) band(O)'s(O) early(O) champions(O).(O)", "instance": {"id": "375", "words": ["Justincase", "was", "an", "American", "Alternative", "rock", "-", "Pop", "music", "band", "from", "Charlotte", ",", "North", "Carolina", ",", "best", "known", "for", "their", "2002", "single", "Don", "'t", "Cry", "for", "Us", ",", "which", "was", "co-written", "by", "Michelle", "Branch", ",", "who", "was", "one", "of", "the", "band", "'s", "early", "champions", "."], "labels": ["B-band", "O", "O", "O", "B-music genre", "I-music genre", "O", "B-music genre", "I-music genre", "O", "O", "B-location", "O", "B-location", "I-location", "O", "O", "O", "O", "O", "O", "O", "B-song", "I-song", "I-song", "I-song", "I-song", "O", "O", "O", "O", "O", "B-musical artist", "I-musical artist", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, event, musical artist, music genre, location, country, award, musical instrument, band, album, organization, song and O.\nSentence: Justincase was an American Alternative rock - Pop music band from Charlotte , North Carolina , best known for their 2002 single Don 't Cry for Us , which was co-written by Michelle Branch , who was one of the band 's early champions .", "prompt_labels": "Justincase(B-band) was(O) an(O) American(O) Alternative(B-music genre) rock(I-music genre) -(O) Pop(B-music genre) music(I-music genre) band(O) from(O) Charlotte(B-location) ,(O) North(B-location) Carolina(I-location) ,(O) best(O) known(O) for(O) their(O) 2002(O) single(O) Don(B-song) 't(I-song) Cry(I-song) for(I-song) Us(I-song) ,(O) which(O) was(O) co-written(O) by(O) Michelle(B-musical artist) Branch(I-musical artist) ,(O) who(O) was(O) one(O) of(O) the(O) band(O) 's(O) early(O) champions(O) .(O)"}, "label_list": ["person", "event", "musical artist", "music genre", "location", "country", "award", "musical instrument", "band", "album", "organization", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 1567, 11, 18273, 10255, 11, 4731, 17779, 11, 3813, 11, 3224, 11, 10292, 11, 18273, 14473, 11, 7200, 11, 8176, 11, 7471, 11, 5609, 323, 507, 627, 85664, 25, 4702, 2910, 521, 574, 459, 3778, 42209, 7091, 482, 10466, 4731, 7200, 505, 29473, 1174, 4892, 13030, 1174, 1888, 3967, 369, 872, 220, 1049, 17, 3254, 4418, 364, 83, 43805, 369, 4073, 1174, 902, 574, 1080, 67383, 555, 33126, 26176, 1174, 889, 574, 832, 315, 279, 7200, 364, 82, 4216, 34838, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1398", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) is(O) station(B-Restaurant Name) donuts(I-Restaurant Name)", "instance": {"id": "1398", "words": ["where", "is", "station", "donuts"], "labels": ["O", "O", "B-Restaurant Name", "I-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Hours, Amenity, Price, Restaurant Name, Location, Cuisine, Rating and O.\nSentence: where is station donuts", "prompt_labels": "where(O) is(O) station(B-Restaurant Name) donuts(I-Restaurant Name)"}, "label_list": ["Dish", "Hours", "Amenity", "Price", "Restaurant Name", "Location", "Cuisine", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 30192, 11, 3383, 56685, 11, 8650, 11, 26568, 4076, 11, 10067, 11, 81961, 11, 19767, 323, 507, 627, 85664, 25, 1405, 374, 8216, 1541, 6256, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "220", "dataset": "crossner_science", "split": "dev", "prediction": "Pupin(B-scientist) was(O) a(O) founding(O) member(O) of(O) National(B-organization) Advisory(I-organization) Committee(I-organization) for(I-organization) Aeronautics(I-organization) ((O) NACA(B-organization) )(O) on(O) 3(O) March(O) 1915(O),(O) which(O) later(O) became(O) NASA(B-organization),(O) and(O) he(O) participated(O) in(O) the(O) founding(O) of(O) American(B-organization) Mathematical(I-organization) Society(I-organization) and(O) American(B-organization) Physical(I-organization) Society(I-organization).(O)", "instance": {"id": "220", "words": ["Pupin", "was", "a", "founding", "member", "of", "National", "Advisory", "Committee", "for", "Aeronautics", "(", "NACA", ")", "on", "3", "March", "1915", ",", "which", "later", "became", "NASA", ",", "and", "he", "participated", "in", "the", "founding", "of", "American", "Mathematical", "Society", "and", "American", "Physical", "Society", "."], "labels": ["B-scientist", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "B-organization", "I-organization", "I-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: theory, person, award, enzyme, academic journal, country, protein, university, chemical element, location, discipline, organization, astronomical object, event, chemical compound, scientist and O.\nSentence: Pupin was a founding member of National Advisory Committee for Aeronautics ( NACA ) on 3 March 1915 , which later became NASA , and he participated in the founding of American Mathematical Society and American Physical Society .", "prompt_labels": "Pupin(B-scientist) was(O) a(O) founding(O) member(O) of(O) National(B-organization) Advisory(I-organization) Committee(I-organization) for(I-organization) Aeronautics(I-organization) ((O) NACA(B-organization) )(O) on(O) 3(O) March(O) 1915(O) ,(O) which(O) later(O) became(O) NASA(B-organization) ,(O) and(O) he(O) participated(O) in(O) the(O) founding(O) of(O) American(B-organization) Mathematical(I-organization) Society(I-organization) and(O) American(B-organization) Physical(I-organization) Society(I-organization) .(O)"}, "label_list": ["theory", "person", "award", "enzyme", "academic journal", "country", "protein", "university", "chemical element", "location", "discipline", "organization", "astronomical object", "event", "chemical compound", "scientist"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10334, 11, 1732, 11, 10292, 11, 49242, 11, 14584, 8486, 11, 3224, 11, 13128, 11, 12374, 11, 11742, 2449, 11, 3813, 11, 26434, 11, 7471, 11, 87283, 1665, 11, 1567, 11, 11742, 24549, 11, 28568, 323, 507, 627, 85664, 25, 393, 455, 258, 574, 264, 36330, 4562, 315, 5165, 45013, 10554, 369, 362, 20110, 2784, 1233, 320, 452, 63638, 883, 389, 220, 18, 5587, 220, 7529, 20, 1174, 902, 3010, 6244, 22146, 1174, 323, 568, 31408, 304, 279, 36330, 315, 3778, 92102, 13581, 323, 3778, 28479, 13581, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "406", "dataset": "crossner_science", "split": "dev", "prediction": "By(O) being(O) an(O) AMP-activated(B-protein) protein(I-protein) kinase(I-protein) activator(O) like(O) Metformin(B-chemical compound),(O) it(O) acts(O) similar(O),(O) affecting(O) metabolism(O) in(O) a(O) way(O) that(O) may(O) reveal(O) useful(O) applications(O) to(O) treat(O).(O)", "instance": {"id": "406", "words": ["By", "being", "an", "AMP-activated", "protein", "kinase", "activator", "like", "Metformin", ",", "it", "acts", "similar", ",", "affecting", "metabolism", "in", "a", "way", "that", "may", "reveal", "useful", "applications", "to", "treat", "."], "labels": ["O", "O", "O", "B-enzyme", "I-enzyme", "I-enzyme", "O", "O", "B-enzyme", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: theory, university, discipline, astronomical object, scientist, event, person, protein, location, award, country, chemical compound, enzyme, organization, chemical element, academic journal and O.\nSentence: By being an AMP-activated protein kinase activator like Metformin , it acts similar , affecting metabolism in a way that may reveal useful applications to treat .", "prompt_labels": "By(O) being(O) an(O) AMP-activated(B-enzyme) protein(I-enzyme) kinase(I-enzyme) activator(O) like(O) Metformin(B-enzyme) ,(O) it(O) acts(O) similar(O) ,(O) affecting(O) metabolism(O) in(O) a(O) way(O) that(O) may(O) reveal(O) useful(O) applications(O) to(O) treat(O) .(O)"}, "label_list": ["theory", "university", "discipline", "astronomical object", "scientist", "event", "person", "protein", "location", "award", "country", "chemical compound", "enzyme", "organization", "chemical element", "academic journal"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10334, 11, 12374, 11, 26434, 11, 87283, 1665, 11, 28568, 11, 1567, 11, 1732, 11, 13128, 11, 3813, 11, 10292, 11, 3224, 11, 11742, 24549, 11, 49242, 11, 7471, 11, 11742, 2449, 11, 14584, 8486, 323, 507, 627, 85664, 25, 3296, 1694, 459, 64008, 12, 31262, 13128, 82160, 4197, 859, 1093, 6344, 630, 258, 1174, 433, 14385, 4528, 1174, 28987, 39097, 304, 264, 1648, 430, 1253, 16805, 5505, 8522, 311, 4322, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "13", "dataset": "crossner_politics", "split": "dev", "prediction": "In(O) Australia(B-country),(O) a(O) number(O) of(O) single(O) issue(O) parties(O) have(O) been(O) elected(O) to(O) federal(O) and(O) state(O) parliaments(O) such(O) as(O) the(O) Animal(B-political party) Justice(I-political party) Party(I-political party),(O) Dignity(B-political party) for(I-political party) Disability(I-political party),(O) Australian(B-political party) Motoring(I-political party) Enthusiast(I-political party) Party(I-political party) and(O) the(O) Australian(B-political party) Sex(I-political party) Party(I-political party).(O)", "instance": {"id": "13", "words": ["In", "Australia", ",", "a", "number", "of", "single", "issue", "parties", "have", "been", "elected", "to", "federal", "and", "state", "parliaments", "such", "as", "the", "Animal", "Justice", "Party", ",", "Dignity", "for", "Disability", ",", "Australian", "Motoring", "Enthusiast", "Party", "and", "the", "Australian", "Sex", "Party", "."], "labels": ["O", "B-country", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "O", "B-political party", "I-political party", "I-political party", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, event, political party, country, politician, election, organization, person and O.\nSentence: In Australia , a number of single issue parties have been elected to federal and state parliaments such as the Animal Justice Party , Dignity for Disability , Australian Motoring Enthusiast Party and the Australian Sex Party .", "prompt_labels": "In(O) Australia(B-country) ,(O) a(O) number(O) of(O) single(O) issue(O) parties(O) have(O) been(O) elected(O) to(O) federal(O) and(O) state(O) parliaments(O) such(O) as(O) the(O) Animal(B-political party) Justice(I-political party) Party(I-political party) ,(O) Dignity(B-political party) for(I-political party) Disability(I-political party) ,(O) Australian(B-political party) Motoring(I-political party) Enthusiast(I-political party) Party(I-political party) and(O) the(O) Australian(B-political party) Sex(I-political party) Party(I-political party) .(O)"}, "label_list": ["location", "event", "political party", "country", "politician", "election", "organization", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 1567, 11, 5054, 4717, 11, 3224, 11, 37038, 11, 6355, 11, 7471, 11, 1732, 323, 507, 627, 85664, 25, 763, 8494, 1174, 264, 1396, 315, 3254, 4360, 9875, 617, 1027, 16689, 311, 6918, 323, 1614, 1370, 747, 24469, 1778, 439, 279, 21995, 12007, 8722, 1174, 423, 625, 488, 369, 75368, 1174, 13673, 19514, 5620, 2998, 34232, 72, 561, 8722, 323, 279, 13673, 6834, 8722, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "288", "dataset": "crossner_ai", "split": "dev", "prediction": "The(O) values(O) of(O) sensitivity(B-metric) and(O) specificity(B-metric) are(O) agnostic(O) to(O) the(O) percent(O) of(O) positive(O) cases(O) in(O) the(O) population(O) of(O) interest(O) ((O) as(O) opposed(O) to(O),(O) for(O) example(O),(O) precision(B-metric) )(O).(O)", "instance": {"id": "288", "words": ["The", "values", "of", "sensitivity", "and", "specificity", "are", "agnostic", "to", "the", "percent", "of", "positive", "cases", "in", "the", "population", "of", "interest", "(", "as", "opposed", "to", ",", "for", "example", ",", "precision", ")", "."], "labels": ["O", "O", "O", "B-metric", "O", "B-metric", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-metric", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, country, researcher, programming language, conference, university, task, product, field, person, metric, organization, location and O.\nSentence: The values of sensitivity and specificity are agnostic to the percent of positive cases in the population of interest ( as opposed to , for example , precision ) .", "prompt_labels": "The(O) values(O) of(O) sensitivity(B-metric) and(O) specificity(B-metric) are(O) agnostic(O) to(O) the(O) percent(O) of(O) positive(O) cases(O) in(O) the(O) population(O) of(O) interest(O) ((O) as(O) opposed(O) to(O) ,(O) for(O) example(O) ,(O) precision(B-metric) )(O) .(O)"}, "label_list": ["algorithm", "country", "researcher", "programming language", "conference", "university", "task", "product", "field", "person", "metric", "organization", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12384, 11, 3224, 11, 32185, 11, 15840, 4221, 11, 10017, 11, 12374, 11, 3465, 11, 2027, 11, 2115, 11, 1732, 11, 18767, 11, 7471, 11, 3813, 323, 507, 627, 85664, 25, 578, 2819, 315, 27541, 323, 76041, 527, 945, 87524, 311, 279, 3346, 315, 6928, 5157, 304, 279, 7187, 315, 2802, 320, 439, 16475, 311, 1174, 369, 3187, 1174, 16437, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1240", "dataset": "mit-restaurant", "split": "dev", "prediction": "whats(O) the(O) most(B-Rating) popular(I-Rating) steak(B-Cuisine) house(I-Cuisine) around(B-Location) here(I-Location)", "instance": {"id": "1240", "words": ["whats", "the", "most", "popular", "steak", "house", "around", "here"], "labels": ["O", "O", "O", "B-Rating", "B-Cuisine", "I-Cuisine", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Dish, Restaurant Name, Location, Hours, Price, Amenity, Rating and O.\nSentence: whats the most popular steak house around here", "prompt_labels": "whats(O) the(O) most(O) popular(B-Rating) steak(B-Cuisine) house(I-Cuisine) around(B-Location) here(I-Location)"}, "label_list": ["Cuisine", "Dish", "Restaurant Name", "Location", "Hours", "Price", "Amenity", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 49268, 11, 26568, 4076, 11, 10067, 11, 30192, 11, 8650, 11, 3383, 56685, 11, 19767, 323, 507, 627, 85664, 25, 41209, 279, 1455, 5526, 50059, 3838, 2212, 1618, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1937", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) biography(B-genre) movies(O) are(O) about(O) warsaw(B-plot) poland(I-plot)", "instance": {"id": "1937", "words": ["what", "biography", "movies", "are", "about", "warsaw", "poland"], "labels": ["O", "B-genre", "O", "O", "O", "B-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, plot, director, average ratings, review, genre, rating, title, trailer, actor, year, song and O.\nSentence: what biography movies are about warsaw poland", "prompt_labels": "what(O) biography(B-genre) movies(O) are(O) about(O) warsaw(B-plot) poland(I-plot)"}, "label_list": ["character", "plot", "director", "average ratings", "review", "genre", "rating", "title", "trailer", "actor", "year", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 7234, 11, 7690, 11, 5578, 18594, 11, 3477, 11, 17779, 11, 10959, 11, 2316, 11, 19809, 11, 12360, 11, 1060, 11, 5609, 323, 507, 627, 85664, 25, 1148, 48345, 9698, 527, 922, 25981, 675, 1499, 438, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1996", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) a(O) pg(B-rating) thriller(B-genre) rated(O) seven(B-average ratings) stars(I-average ratings) directed(O) by(O) hironobu(B-director) sakaguchi(I-director)", "instance": {"id": "1996", "words": ["what", "is", "a", "pg", "thriller", "rated", "seven", "stars", "directed", "by", "hironobu", "sakaguchi"], "labels": ["O", "O", "O", "B-rating", "B-genre", "O", "B-average ratings", "I-average ratings", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, trailer, average ratings, plot, rating, actor, character, review, genre, song, director, title and O.\nSentence: what is a pg thriller rated seven stars directed by hironobu sakaguchi", "prompt_labels": "what(O) is(O) a(O) pg(B-rating) thriller(B-genre) rated(O) seven(B-average ratings) stars(I-average ratings) directed(O) by(O) hironobu(B-director) sakaguchi(I-director)"}, "label_list": ["year", "trailer", "average ratings", "plot", "rating", "actor", "character", "review", "genre", "song", "director", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 19809, 11, 5578, 18594, 11, 7234, 11, 10959, 11, 12360, 11, 3752, 11, 3477, 11, 17779, 11, 5609, 11, 7690, 11, 2316, 323, 507, 627, 85664, 25, 1148, 374, 264, 17953, 54461, 22359, 8254, 9958, 15910, 555, 305, 2534, 677, 84, 78410, 351, 56017, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "729", "dataset": "mit-restaurant", "split": "dev", "prediction": "im(O) in(O) the(O) mood(O) for(O) some(O) texas(B-Dish) chili(I-Dish)", "instance": {"id": "729", "words": ["im", "in", "the", "mood", "for", "some", "texas", "chili"], "labels": ["O", "O", "O", "O", "O", "O", "B-Dish", "I-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Restaurant Name, Location, Rating, Price, Hours, Dish, Amenity and O.\nSentence: im in the mood for some texas chili", "prompt_labels": "im(O) in(O) the(O) mood(O) for(O) some(O) texas(B-Dish) chili(I-Dish)"}, "label_list": ["Cuisine", "Restaurant Name", "Location", "Rating", "Price", "Hours", "Dish", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 26568, 4076, 11, 10067, 11, 19767, 11, 8650, 11, 30192, 11, 49268, 11, 3383, 56685, 323, 507, 627, 85664, 25, 737, 304, 279, 20247, 369, 1063, 60348, 59717, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1087", "dataset": "mit-restaurant", "split": "dev", "prediction": "want(O) to(O) find(O) a(O) restaurant(O) that(O) specilizes(O) in(O) spagetti(B-Dish)", "instance": {"id": "1087", "words": ["want", "to", "find", "a", "restaurant", "that", "specilizes", "in", "spagetti"], "labels": ["O", "O", "O", "O", "O", "O", "B-Amenity", "I-Amenity", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Price, Amenity, Cuisine, Restaurant Name, Hours, Rating, Dish and O.\nSentence: want to find a restaurant that specilizes in spagetti", "prompt_labels": "want(O) to(O) find(O) a(O) restaurant(O) that(O) specilizes(B-Amenity) in(I-Amenity) spagetti(B-Dish)"}, "label_list": ["Location", "Price", "Amenity", "Cuisine", "Restaurant Name", "Hours", "Rating", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 8650, 11, 3383, 56685, 11, 81961, 11, 26568, 4076, 11, 30192, 11, 19767, 11, 49268, 323, 507, 627, 85664, 25, 1390, 311, 1505, 264, 10960, 430, 1424, 321, 4861, 304, 993, 351, 29037, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "349", "dataset": "crossner_music", "split": "dev", "prediction": "In(O) the(O) days(O) following(O) his(O) death(O),(O) tributes(O) were(O) paid(O) by(O) then-President(O) George(B-person) W.(I-person) Bush(I-person),(O) the(O) United(B-country) States(I-country) House(I-country) of(I-country) Representatives(I-country),(O) and(O) many(O) musicians(O) and(O) performers(O),(O) including(O) B.(B-musical artist) B.(I-musical artist) King(I-musical artist),(O) Ronnie(B-musical artist) Hawkins(I-musical artist),(O) Mick(B-musical artist) Jagger(I-musical artist),(O) Ronnie(B-musical artist) Wood(I-musical artist),(O) George(B-musical artist) Thorogood(I-musical artist),(O) Eric(B-musical artist) Clapton(I-musical artist),(O) Tom(B-musical artist) Petty(I-musical artist),(O) Robert(B-musical artist) Plant(I-musical artist),(O) Elvis(B-musical artist) Costello(I-musical artist),(O) Bonnie(B-musical artist) Raitt(I-musical artist),(O) Robert(B-musical artist) Randolph(I-musical artist) and(O) the(B-band) Family(I-band) Band(I-band) and(O) Eric(B-musical artist) Burdon(I-musical artist).(O)", "instance": {"id": "349", "words": ["In", "the", "days", "following", "his", "death", ",", "tributes", "were", "paid", "by", "then-President", "George", "W.", "Bush", ",", "the", "United", "States", "House", "of", "Representatives", ",", "and", "many", "musicians", "and", "performers", ",", "including", "B.", "B.", "King", ",", "Ronnie", "Hawkins", ",", "Mick", "Jagger", ",", "Ronnie", "Wood", ",", "George", "Thorogood", ",", "Eric", "Clapton", ",", "Tom", "Petty", ",", "Robert", "Plant", ",", "Elvis", "Costello", ",", "Bonnie", "Raitt", ",", "Robert", "Randolph", "and", "the", "Family", "Band", "and", "Eric", "Burdon", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "I-person", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-musical artist", "I-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-band", "I-band", "I-band", "I-band", "I-band", "I-band", "O", "B-musical artist", "I-musical artist", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, event, musical artist, album, organization, location, music genre, band, musical instrument, person, award, country and O.\nSentence: In the days following his death , tributes were paid by then-President George W. Bush , the United States House of Representatives , and many musicians and performers , including B. B. King , Ronnie Hawkins , Mick Jagger , Ronnie Wood , George Thorogood , Eric Clapton , Tom Petty , Robert Plant , Elvis Costello , Bonnie Raitt , Robert Randolph and the Family Band and Eric Burdon .", "prompt_labels": "In(O) the(O) days(O) following(O) his(O) death(O) ,(O) tributes(O) were(O) paid(O) by(O) then-President(O) George(B-person) W.(I-person) Bush(I-person) ,(O) the(O) United(O) States(O) House(O) of(O) Representatives(O) ,(O) and(O) many(O) musicians(O) and(O) performers(O) ,(O) including(O) B.(B-musical artist) B.(I-musical artist) King(I-musical artist) ,(O) Ronnie(B-musical artist) Hawkins(I-musical artist) ,(O) Mick(B-musical artist) Jagger(I-musical artist) ,(O) Ronnie(B-musical artist) Wood(I-musical artist) ,(O) George(B-musical artist) Thorogood(I-musical artist) ,(O) Eric(B-musical artist) Clapton(I-musical artist) ,(O) Tom(B-musical artist) Petty(I-musical artist) ,(O) Robert(B-musical artist) Plant(I-musical artist) ,(O) Elvis(B-musical artist) Costello(I-musical artist) ,(O) Bonnie(B-musical artist) Raitt(I-musical artist) ,(O) Robert(B-band) Randolph(I-band) and(I-band) the(I-band) Family(I-band) Band(I-band) and(O) Eric(B-musical artist) Burdon(I-musical artist) .(O)"}, "label_list": ["song", "event", "musical artist", "album", "organization", "location", "music genre", "band", "musical instrument", "person", "award", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 1567, 11, 18273, 10255, 11, 8176, 11, 7471, 11, 3813, 11, 4731, 17779, 11, 7200, 11, 18273, 14473, 11, 1732, 11, 10292, 11, 3224, 323, 507, 627, 85664, 25, 763, 279, 2919, 2768, 813, 4648, 1174, 14121, 2142, 1051, 7318, 555, 1243, 86481, 10058, 468, 13, 14409, 1174, 279, 3723, 4273, 4783, 315, 40845, 1174, 323, 1690, 32629, 323, 45518, 1174, 2737, 426, 13, 426, 13, 6342, 1174, 84805, 70687, 1174, 60333, 622, 10322, 1174, 84805, 12404, 1174, 10058, 29550, 540, 1411, 1174, 16645, 2493, 391, 783, 1174, 8529, 95798, 1174, 8563, 18317, 1174, 67306, 11443, 4896, 1174, 74295, 432, 1339, 83, 1174, 8563, 86852, 323, 279, 12517, 17366, 323, 16645, 12649, 15357, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "105", "dataset": "crossner_music", "split": "dev", "prediction": "The(O) group(O)'s(O) evolution(O) can(O) be(O) traced(O) through(O) the(O) albums(O) The(B-album) John(I-album) Coltrane(I-album) Quartet(I-album) Plays(I-album),(O) Living(B-album) Space(I-album),(O) Transition(B-album),(O) New(B-album) Thing(I-album) at(I-album) Newport(I-album),(O) Sun(B-album) Ship(I-album),(O) and(O) First(B-album) Meditations(I-album).(O)", "instance": {"id": "105", "words": ["The", "group", "'s", "evolution", "can", "be", "traced", "through", "the", "albums", "The", "John", "Coltrane", "Quartet", "Plays", ",", "Living", "Space", ",", "Transition", ",", "New", "Thing", "at", "Newport", ",", "Sun", "Ship", ",", "and", "First", "Meditations", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-album", "I-album", "I-album", "I-album", "I-album", "O", "B-album", "I-album", "O", "B-album", "O", "B-album", "I-album", "I-album", "I-album", "O", "B-album", "I-album", "O", "O", "B-album", "I-album", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, music genre, band, album, organization, person, location, musical artist, award, country, song, musical instrument and O.\nSentence: The group 's evolution can be traced through the albums The John Coltrane Quartet Plays , Living Space , Transition , New Thing at Newport , Sun Ship , and First Meditations .", "prompt_labels": "The(O) group(O) 's(O) evolution(O) can(O) be(O) traced(O) through(O) the(O) albums(O) The(B-album) John(I-album) Coltrane(I-album) Quartet(I-album) Plays(I-album) ,(O) Living(B-album) Space(I-album) ,(O) Transition(B-album) ,(O) New(B-album) Thing(I-album) at(I-album) Newport(I-album) ,(O) Sun(B-album) Ship(I-album) ,(O) and(O) First(B-album) Meditations(I-album) .(O)"}, "label_list": ["event", "music genre", "band", "album", "organization", "person", "location", "musical artist", "award", "country", "song", "musical instrument"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 4731, 17779, 11, 7200, 11, 8176, 11, 7471, 11, 1732, 11, 3813, 11, 18273, 10255, 11, 10292, 11, 3224, 11, 5609, 11, 18273, 14473, 323, 507, 627, 85664, 25, 578, 1912, 364, 82, 15740, 649, 387, 51400, 1555, 279, 28785, 578, 3842, 4349, 376, 2194, 70184, 295, 77265, 1174, 19048, 11746, 1174, 38821, 1174, 1561, 38300, 520, 59900, 1174, 8219, 27901, 1174, 323, 5629, 3344, 31767, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "832", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) a(O) mcdonalds(B-Restaurant Name) nearby(B-Location)", "instance": {"id": "832", "words": ["is", "there", "a", "mcdonalds", "nearby"], "labels": ["O", "O", "O", "B-Restaurant Name", "B-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Price, Dish, Cuisine, Amenity, Location, Restaurant Name, Rating and O.\nSentence: is there a mcdonalds nearby", "prompt_labels": "is(O) there(O) a(O) mcdonalds(B-Restaurant Name) nearby(B-Location)"}, "label_list": ["Hours", "Price", "Dish", "Cuisine", "Amenity", "Location", "Restaurant Name", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 8650, 11, 49268, 11, 81961, 11, 3383, 56685, 11, 10067, 11, 26568, 4076, 11, 19767, 323, 507, 627, 85664, 25, 374, 1070, 264, 296, 4484, 80794, 82, 14373, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1767", "dataset": "mit-movie", "split": "dev", "prediction": "tell(O) me(O) about(O) the(O) movie(O) lemonade(B-title) mouth(I-title)", "instance": {"id": "1767", "words": ["tell", "me", "about", "the", "movie", "lemonade", "mouth"], "labels": ["O", "O", "O", "O", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, plot, genre, year, actor, character, rating, average ratings, song, director, review, title and O.\nSentence: tell me about the movie lemonade mouth", "prompt_labels": "tell(O) me(O) about(O) the(O) movie(O) lemonade(B-title) mouth(I-title)"}, "label_list": ["trailer", "plot", "genre", "year", "actor", "character", "rating", "average ratings", "song", "director", "review", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 7234, 11, 17779, 11, 1060, 11, 12360, 11, 3752, 11, 10959, 11, 5578, 18594, 11, 5609, 11, 7690, 11, 3477, 11, 2316, 323, 507, 627, 85664, 25, 3371, 757, 922, 279, 5818, 30564, 1037, 11013, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "457", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) all(O) of(O) the(O) films(O) directed(O) by(O) clint(B-director) eastwood(I-director)", "instance": {"id": "457", "words": ["show", "me", "all", "of", "the", "films", "directed", "by", "clint", "eastwood"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, character, rating, trailer, plot, genre, title, year, review, actor, average ratings, director and O.\nSentence: show me all of the films directed by clint eastwood", "prompt_labels": "show(O) me(O) all(O) of(O) the(O) films(O) directed(O) by(O) clint(B-director) eastwood(I-director)"}, "label_list": ["song", "character", "rating", "trailer", "plot", "genre", "title", "year", "review", "actor", "average ratings", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 3752, 11, 10959, 11, 19809, 11, 7234, 11, 17779, 11, 2316, 11, 1060, 11, 3477, 11, 12360, 11, 5578, 18594, 11, 7690, 323, 507, 627, 85664, 25, 1501, 757, 682, 315, 279, 12631, 15910, 555, 1206, 396, 11226, 6798, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "224", "dataset": "crossner_science", "split": "dev", "prediction": "He(O) is(O) also(O) a(O) two-time(O) Academy(B-award) Award(I-award) nominee(O),(O) receiving(O) a(O) 2014(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Original(I-award) Song(I-award) nomination(O) for(O) Happy(O) ((O) which(O) was(O) featured(O) in(O) Despicable(B-title) Me(I-title) 2(I-title) )(O) and(O) a(O) 2017(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Picture(I-award) nomination(O) as(O) one(O) of(O) the(O) producers(O) of(O) Hidden(B-title) Figures(I-title).(O)", "instance": {"id": "224", "words": ["He", "is", "also", "a", "two-time", "Academy", "Award", "nominee", ",", "receiving", "a", "2014", "Academy", "Award", "for", "Best", "Original", "Song", "nomination", "for", "Happy", "(", "which", "was", "featured", "in", "Despicable", "Me", "2", ")", "and", "a", "2017", "Academy", "Award", "for", "Best", "Picture", "nomination", "as", "one", "of", "the", "producers", "of", "Hidden", "Figures", "."], "labels": ["O", "O", "O", "O", "O", "B-award", "I-award", "O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical element, organization, academic journal, scientist, university, theory, chemical compound, protein, astronomical object, person, discipline, enzyme, event, award, country, location and O.\nSentence: He is also a two-time Academy Award nominee , receiving a 2014 Academy Award for Best Original Song nomination for Happy ( which was featured in Despicable Me 2 ) and a 2017 Academy Award for Best Picture nomination as one of the producers of Hidden Figures .", "prompt_labels": "He(O) is(O) also(O) a(O) two-time(O) Academy(B-award) Award(I-award) nominee(O) ,(O) receiving(O) a(O) 2014(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Original(I-award) Song(I-award) nomination(O) for(O) Happy(O) ((O) which(O) was(O) featured(O) in(O) Despicable(O) Me(O) 2(O) )(O) and(O) a(O) 2017(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Picture(I-award) nomination(O) as(O) one(O) of(O) the(O) producers(O) of(O) Hidden(O) Figures(O) .(O)"}, "label_list": ["chemical element", "organization", "academic journal", "scientist", "university", "theory", "chemical compound", "protein", "astronomical object", "person", "discipline", "enzyme", "event", "award", "country", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 11742, 2449, 11, 7471, 11, 14584, 8486, 11, 28568, 11, 12374, 11, 10334, 11, 11742, 24549, 11, 13128, 11, 87283, 1665, 11, 1732, 11, 26434, 11, 49242, 11, 1567, 11, 10292, 11, 3224, 11, 3813, 323, 507, 627, 85664, 25, 1283, 374, 1101, 264, 1403, 7394, 16192, 17768, 29311, 1174, 12588, 264, 220, 679, 19, 16192, 17768, 369, 7252, 17674, 19508, 29804, 369, 24241, 320, 902, 574, 15109, 304, 3959, 95118, 2206, 220, 17, 883, 323, 264, 220, 679, 22, 16192, 17768, 369, 7252, 25586, 29804, 439, 832, 315, 279, 24190, 315, 35342, 69356, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "316", "dataset": "crossner_politics", "split": "dev", "prediction": "He(O) was(O) an(O) AKP(B-political party) parliamentary(O) candidate(O) in(O) 2011(B-election) Turkish(I-election) general(I-election) election(I-election) and(O) the(O) leader(O) of(O) the(O) AKP(B-political party) in(O) both(O) the(O) June(B-election) 2015(I-election) Turkish(I-election) general(I-election) election(I-election) and(O) November(B-election) 2015(I-election) Turkish(I-election) general(I-election) election(I-election) general(O) elections(O).(O)", "instance": {"id": "316", "words": ["He", "was", "an", "AKP", "parliamentary", "candidate", "in", "2011", "Turkish", "general", "election", "and", "the", "leader", "of", "the", "AKP", "in", "both", "the", "June", "2015", "Turkish", "general", "election", "and", "November", "2015", "Turkish", "general", "election", "general", "elections", "."], "labels": ["O", "O", "O", "B-political party", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "B-political party", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, organization, country, election, person, location, political party, politician and O.\nSentence: He was an AKP parliamentary candidate in 2011 Turkish general election and the leader of the AKP in both the June 2015 Turkish general election and November 2015 Turkish general election general elections .", "prompt_labels": "He(O) was(O) an(O) AKP(B-political party) parliamentary(O) candidate(O) in(O) 2011(B-election) Turkish(I-election) general(I-election) election(I-election) and(O) the(O) leader(O) of(O) the(O) AKP(B-political party) in(O) both(O) the(O) June(B-election) 2015(I-election) Turkish(I-election) general(I-election) election(I-election) and(O) November(B-election) 2015(I-election) Turkish(I-election) general(I-election) election(I-election) general(O) elections(O) .(O)"}, "label_list": ["event", "organization", "country", "election", "person", "location", "political party", "politician"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 7471, 11, 3224, 11, 6355, 11, 1732, 11, 3813, 11, 5054, 4717, 11, 37038, 323, 507, 627, 85664, 25, 1283, 574, 459, 31672, 47, 44250, 9322, 304, 220, 679, 16, 24666, 4689, 6355, 323, 279, 7808, 315, 279, 31672, 47, 304, 2225, 279, 5651, 220, 679, 20, 24666, 4689, 6355, 323, 6841, 220, 679, 20, 24666, 4689, 6355, 4689, 16374, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "38", "dataset": "crossner_ai", "split": "dev", "prediction": "Image(B-task) segmentation(I-task) using(O) k-means(B-algorithm) clustering(I-algorithm) algorithms(I-algorithm) has(O) long(O) been(O) used(O) for(O) pattern(B-field) recognition(I-field),(O) object(B-task) detection(I-task),(O) and(O) medical(B-field) imaging(I-field).(O)", "instance": {"id": "38", "words": ["Image", "segmentation", "using", "k-means", "clustering", "algorithms", "has", "long", "been", "used", "for", "pattern", "recognition", ",", "object", "detection", ",", "and", "medical", "imaging", "."], "labels": ["B-task", "I-task", "O", "B-algorithm", "I-algorithm", "I-algorithm", "O", "O", "O", "O", "O", "B-field", "I-field", "O", "B-task", "I-task", "O", "O", "B-field", "I-field", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, algorithm, location, field, product, programming language, task, organization, metric, person, country, researcher, university and O.\nSentence: Image segmentation using k-means clustering algorithms has long been used for pattern recognition , object detection , and medical imaging .", "prompt_labels": "Image(B-task) segmentation(I-task) using(O) k-means(B-algorithm) clustering(I-algorithm) algorithms(I-algorithm) has(O) long(O) been(O) used(O) for(O) pattern(B-field) recognition(I-field) ,(O) object(B-task) detection(I-task) ,(O) and(O) medical(B-field) imaging(I-field) .(O)"}, "label_list": ["conference", "algorithm", "location", "field", "product", "programming language", "task", "organization", "metric", "person", "country", "researcher", "university"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10017, 11, 12384, 11, 3813, 11, 2115, 11, 2027, 11, 15840, 4221, 11, 3465, 11, 7471, 11, 18767, 11, 1732, 11, 3224, 11, 32185, 11, 12374, 323, 507, 627, 85664, 25, 4758, 60852, 1701, 597, 35073, 598, 59454, 26249, 706, 1317, 1027, 1511, 369, 5497, 18324, 1174, 1665, 18468, 1174, 323, 6593, 32758, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1134", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) is(O) the(O) favorite(O) type(O) of(O) food(O) people(O) eat(O) out(O) here(O) and(O) where(O) can(O) i(O) get(O) it(O)", "instance": {"id": "1134", "words": ["what", "is", "the", "favorite", "type", "of", "food", "people", "eat", "out", "here", "and", "where", "can", "i", "get", "it"], "labels": ["O", "O", "O", "B-Rating", "O", "O", "O", "O", "O", "B-Location", "I-Location", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Rating, Amenity, Dish, Restaurant Name, Cuisine, Location, Hours and O.\nSentence: what is the favorite type of food people eat out here and where can i get it", "prompt_labels": "what(O) is(O) the(O) favorite(B-Rating) type(O) of(O) food(O) people(O) eat(O) out(B-Location) here(I-Location) and(O) where(O) can(O) i(O) get(O) it(O)"}, "label_list": ["Price", "Rating", "Amenity", "Dish", "Restaurant Name", "Cuisine", "Location", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 19767, 11, 3383, 56685, 11, 49268, 11, 26568, 4076, 11, 81961, 11, 10067, 11, 30192, 323, 507, 627, 85664, 25, 1148, 374, 279, 7075, 955, 315, 3691, 1274, 8343, 704, 1618, 323, 1405, 649, 602, 636, 433, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1039", "dataset": "mit-restaurant", "split": "dev", "prediction": "please(O) take(O) me(O) to(O) a(O) highly(B-Rating) rated(I-Rating) family(B-Amenity) diner(B-Cuisine)", "instance": {"id": "1039", "words": ["please", "take", "me", "to", "a", "highly", "rated", "family", "diner"], "labels": ["O", "O", "O", "O", "O", "B-Rating", "I-Rating", "B-Cuisine", "I-Cuisine"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Restaurant Name, Hours, Rating, Dish, Cuisine, Amenity, Location and O.\nSentence: please take me to a highly rated family diner", "prompt_labels": "please(O) take(O) me(O) to(O) a(O) highly(B-Rating) rated(I-Rating) family(B-Cuisine) diner(I-Cuisine)"}, "label_list": ["Price", "Restaurant Name", "Hours", "Rating", "Dish", "Cuisine", "Amenity", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 26568, 4076, 11, 30192, 11, 19767, 11, 49268, 11, 81961, 11, 3383, 56685, 11, 10067, 323, 507, 627, 85664, 25, 4587, 1935, 757, 311, 264, 7701, 22359, 3070, 89206, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1418", "dataset": "mit-movie", "split": "dev", "prediction": "in(O) the(O) last(B-year) ten(I-year) years(I-year) did(O) gene(B-actor) kelly(I-actor) star(O) in(O) any(O) very(B-average ratings) popular(I-average ratings) fantasy(B-genre) movies(O)", "instance": {"id": "1418", "words": ["in", "the", "last", "ten", "years", "did", "gene", "kelly", "star", "in", "any", "very", "popular", "fantasy", "movies"], "labels": ["O", "O", "B-year", "I-year", "I-year", "O", "B-actor", "I-actor", "O", "O", "O", "B-average ratings", "I-average ratings", "B-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, plot, actor, year, review, character, genre, trailer, title, song, rating, director and O.\nSentence: in the last ten years did gene kelly star in any very popular fantasy movies", "prompt_labels": "in(O) the(O) last(B-year) ten(I-year) years(I-year) did(O) gene(B-actor) kelly(I-actor) star(O) in(O) any(O) very(B-average ratings) popular(I-average ratings) fantasy(B-genre) movies(O)"}, "label_list": ["average ratings", "plot", "actor", "year", "review", "character", "genre", "trailer", "title", "song", "rating", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 7234, 11, 12360, 11, 1060, 11, 3477, 11, 3752, 11, 17779, 11, 19809, 11, 2316, 11, 5609, 11, 10959, 11, 7690, 323, 507, 627, 85664, 25, 304, 279, 1566, 5899, 1667, 1550, 15207, 597, 12160, 6917, 304, 904, 1633, 5526, 18884, 9698, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "944", "dataset": "mit-movie", "split": "dev", "prediction": "i(O) want(O) to(O) find(O) the(O) movies(O) with(O) music(B-song) by(I-song) the(I-song) bee(I-song) gees(I-song)", "instance": {"id": "944", "words": ["i", "want", "to", "find", "the", "movies", "with", "music", "by", "the", "bee", "gees"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-song", "I-song", "I-song", "I-song", "I-song"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, trailer, review, rating, average ratings, actor, year, title, song, director, genre, plot and O.\nSentence: i want to find the movies with music by the bee gees", "prompt_labels": "i(O) want(O) to(O) find(O) the(O) movies(O) with(O) music(B-song) by(I-song) the(I-song) bee(I-song) gees(I-song)"}, "label_list": ["character", "trailer", "review", "rating", "average ratings", "actor", "year", "title", "song", "director", "genre", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 19809, 11, 3477, 11, 10959, 11, 5578, 18594, 11, 12360, 11, 1060, 11, 2316, 11, 5609, 11, 7690, 11, 17779, 11, 7234, 323, 507, 627, 85664, 25, 602, 1390, 311, 1505, 279, 9698, 449, 4731, 555, 279, 38328, 3980, 288, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "196", "dataset": "crossner_politics", "split": "dev", "prediction": "The(O) same(O) boundaries(O) were(O) used(O) in(O) the(O) 1922(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) the(O) 1923(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) the(O) 1924(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) the(O) 1929(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) the(O) 1931(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) the(O) 1935(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) the(O) 1945(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election).(O)", "instance": {"id": "196", "words": ["The", "same", "boundaries", "were", "used", "in", "the", "1922", "United", "Kingdom", "general", "election", ",", "the", "1923", "United", "Kingdom", "general", "election", ",", "the", "1924", "United", "Kingdom", "general", "election", ",", "the", "1929", "United", "Kingdom", "general", "election", ",", "the", "1931", "United", "Kingdom", "general", "election", ",", "the", "1935", "United", "Kingdom", "general", "election", "and", "the", "1945", "United", "Kingdom", "general", "election", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, politician, country, election, political party, location, person, event and O.\nSentence: The same boundaries were used in the 1922 United Kingdom general election , the 1923 United Kingdom general election , the 1924 United Kingdom general election , the 1929 United Kingdom general election , the 1931 United Kingdom general election , the 1935 United Kingdom general election and the 1945 United Kingdom general election .", "prompt_labels": "The(O) same(O) boundaries(O) were(O) used(O) in(O) the(O) 1922(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1923(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1924(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1929(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1931(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1935(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) the(O) 1945(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)"}, "label_list": ["organization", "politician", "country", "election", "political party", "location", "person", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 37038, 11, 3224, 11, 6355, 11, 5054, 4717, 11, 3813, 11, 1732, 11, 1567, 323, 507, 627, 85664, 25, 578, 1890, 23546, 1051, 1511, 304, 279, 220, 5926, 17, 3723, 15422, 4689, 6355, 1174, 279, 220, 5926, 18, 3723, 15422, 4689, 6355, 1174, 279, 220, 5926, 19, 3723, 15422, 4689, 6355, 1174, 279, 220, 5926, 24, 3723, 15422, 4689, 6355, 1174, 279, 220, 7285, 16, 3723, 15422, 4689, 6355, 1174, 279, 220, 7285, 20, 3723, 15422, 4689, 6355, 323, 279, 220, 6393, 20, 3723, 15422, 4689, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "379", "dataset": "crossner_politics", "split": "dev", "prediction": "He(O) was(O) elected(O) to(O) the(O) Parliament(O) of(O) Norway(B-country) from(O) Finnmark(B-location) in(O) 1973(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election),(O) and(O) was(O) re-elected(O) in(O) 1977(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election) and(O) 1981(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election).(O)", "instance": {"id": "379", "words": ["He", "was", "elected", "to", "the", "Parliament", "of", "Norway", "from", "Finnmark", "in", "1973", "Norwegian", "parliamentary", "election", ",", "and", "was", "re-elected", "in", "1977", "Norwegian", "parliamentary", "election", "and", "1981", "Norwegian", "parliamentary", "election", "."], "labels": ["O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "B-location", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, country, political party, location, event, organization, person, politician and O.\nSentence: He was elected to the Parliament of Norway from Finnmark in 1973 Norwegian parliamentary election , and was re-elected in 1977 Norwegian parliamentary election and 1981 Norwegian parliamentary election .", "prompt_labels": "He(O) was(O) elected(O) to(O) the(O) Parliament(B-organization) of(I-organization) Norway(I-organization) from(O) Finnmark(B-location) in(O) 1973(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election) ,(O) and(O) was(O) re-elected(O) in(O) 1977(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election) and(O) 1981(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election) .(O)"}, "label_list": ["election", "country", "political party", "location", "event", "organization", "person", "politician"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 6355, 11, 3224, 11, 5054, 4717, 11, 3813, 11, 1567, 11, 7471, 11, 1732, 11, 37038, 323, 507, 627, 85664, 25, 1283, 574, 16689, 311, 279, 20302, 315, 32603, 505, 35162, 4075, 304, 220, 4468, 18, 45721, 44250, 6355, 1174, 323, 574, 312, 96805, 304, 220, 4468, 22, 45721, 44250, 6355, 323, 220, 3753, 16, 45721, 44250, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "314", "dataset": "crossner_ai", "split": "dev", "prediction": "The(O) KDD(B-conference) Conference(I-conference) grew(O) from(O) KDD(B-conference) ((O) Knowledge(B-conference) Discovery(I-conference) and(I-conference) Data(I-conference) Mining(I-conference) )(O) workshops(O) at(O) AAAI(B-conference) conferences(O),(O) which(O) were(O) started(O) by(O) Gregory(B-researcher) I.(I-researcher) Piatetsky-Shapiro(I-researcher) in(O) 1989(O),(O) 1991(O),(O) and(O) 1993(O),(O) and(O) Usama(B-researcher) Fayyad(I-researcher) in(O) 1994(O).(O) Machinery(O) |(O) ACM(O).(O)", "instance": {"id": "314", "words": ["The", "KDD", "Conference", "grew", "from", "KDD", "(", "Knowledge", "Discovery", "and", "Data", "Mining", ")", "workshops", "at", "AAAI", "conferences", ",", "which", "were", "started", "by", "Gregory", "I.", "Piatetsky-Shapiro", "in", "1989", ",", "1991", ",", "and", "1993", ",", "and", "Usama", "Fayyad", "in", "1994", ".", "Machinery", "|", "ACM", "."], "labels": ["O", "B-conference", "I-conference", "O", "O", "B-conference", "O", "B-conference", "I-conference", "I-conference", "I-conference", "I-conference", "O", "O", "O", "B-conference", "I-conference", "O", "O", "O", "O", "O", "B-researcher", "I-researcher", "I-researcher", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-researcher", "I-researcher", "O", "O", "O", "B-conference", "I-conference", "I-conference", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, researcher, metric, location, programming language, university, algorithm, organization, country, product, conference, task, field and O.\nSentence: The KDD Conference grew from KDD ( Knowledge Discovery and Data Mining ) workshops at AAAI conferences , which were started by Gregory I. Piatetsky-Shapiro in 1989 , 1991 , and 1993 , and Usama Fayyad in 1994 . Machinery | ACM .", "prompt_labels": "The(O) KDD(B-conference) Conference(I-conference) grew(O) from(O) KDD(B-conference) ((O) Knowledge(B-conference) Discovery(I-conference) and(I-conference) Data(I-conference) Mining(I-conference) )(O) workshops(O) at(O) AAAI(B-conference) conferences(I-conference) ,(O) which(O) were(O) started(O) by(O) Gregory(B-researcher) I.(I-researcher) Piatetsky-Shapiro(I-researcher) in(O) 1989(O) ,(O) 1991(O) ,(O) and(O) 1993(O) ,(O) and(O) Usama(B-researcher) Fayyad(I-researcher) in(O) 1994(O) .(O) Machinery(B-conference) |(I-conference) ACM(I-conference) .(O)"}, "label_list": ["person", "researcher", "metric", "location", "programming language", "university", "algorithm", "organization", "country", "product", "conference", "task", "field"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 32185, 11, 18767, 11, 3813, 11, 15840, 4221, 11, 12374, 11, 12384, 11, 7471, 11, 3224, 11, 2027, 11, 10017, 11, 3465, 11, 2115, 323, 507, 627, 85664, 25, 578, 735, 4195, 15217, 14264, 505, 735, 4195, 320, 33025, 39193, 323, 2956, 26917, 883, 35936, 520, 48197, 40, 38614, 1174, 902, 1051, 3940, 555, 44069, 358, 13, 393, 10574, 1441, 8050, 31361, 70579, 304, 220, 3753, 24, 1174, 220, 2550, 16, 1174, 323, 220, 2550, 18, 1174, 323, 4073, 3105, 90405, 88, 329, 304, 220, 2550, 19, 662, 45206, 765, 90315, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1015", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) 1960(B-year) horror(B-genre) movies(O) with(O) zombies(B-plot)", "instance": {"id": "1015", "words": ["show", "me", "1960", "horror", "movies", "with", "zombies"], "labels": ["O", "O", "B-year", "B-genre", "I-genre", "O", "B-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, character, average ratings, director, song, title, genre, trailer, actor, year, review, rating and O.\nSentence: show me 1960 horror movies with zombies", "prompt_labels": "show(O) me(O) 1960(B-year) horror(B-genre) movies(I-genre) with(O) zombies(B-plot)"}, "label_list": ["plot", "character", "average ratings", "director", "song", "title", "genre", "trailer", "actor", "year", "review", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 3752, 11, 5578, 18594, 11, 7690, 11, 5609, 11, 2316, 11, 17779, 11, 19809, 11, 12360, 11, 1060, 11, 3477, 11, 10959, 323, 507, 627, 85664, 25, 1501, 757, 220, 5162, 15, 22169, 9698, 449, 48173, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1668", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) an(O) r(B-rating) rated(O) highly(B-average ratings) recommended(I-average ratings) political(B-genre) film(O) from(O) the(O) past(B-year) year(I-year)", "instance": {"id": "1668", "words": ["list", "an", "r", "rated", "highly", "recommended", "political", "film", "from", "the", "past", "year"], "labels": ["O", "O", "B-rating", "O", "B-average ratings", "I-average ratings", "B-genre", "O", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, character, genre, review, actor, trailer, plot, song, year, rating, director, title and O.\nSentence: list an r rated highly recommended political film from the past year", "prompt_labels": "list(O) an(O) r(B-rating) rated(O) highly(B-average ratings) recommended(I-average ratings) political(B-genre) film(O) from(O) the(O) past(B-year) year(I-year)"}, "label_list": ["average ratings", "character", "genre", "review", "actor", "trailer", "plot", "song", "year", "rating", "director", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 3752, 11, 17779, 11, 3477, 11, 12360, 11, 19809, 11, 7234, 11, 5609, 11, 1060, 11, 10959, 11, 7690, 11, 2316, 323, 507, 627, 85664, 25, 1160, 459, 436, 22359, 7701, 11349, 5054, 4632, 505, 279, 3347, 1060, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1230", "dataset": "mit-movie", "split": "dev", "prediction": "eddie(B-actor) cibrian(I-actor) starred(O) in(O) what(O) merit(B-plot) badge(I-plot) tale(B-genre) that(O) people(O) found(O) ok(B-average ratings) made(O) in(O) the(O) past(B-year) four(I-year) years(I-year)", "instance": {"id": "1230", "words": ["eddie", "cibrian", "starred", "in", "what", "merit", "badge", "tale", "that", "people", "found", "ok", "made", "in", "the", "past", "four", "years"], "labels": ["B-actor", "I-actor", "O", "O", "O", "B-plot", "I-plot", "B-genre", "O", "O", "O", "B-average ratings", "O", "O", "O", "B-year", "I-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, trailer, rating, character, song, director, title, actor, average ratings, genre, review, year and O.\nSentence: eddie cibrian starred in what merit badge tale that people found ok made in the past four years", "prompt_labels": "eddie(B-actor) cibrian(I-actor) starred(O) in(O) what(O) merit(B-plot) badge(I-plot) tale(B-genre) that(O) people(O) found(O) ok(B-average ratings) made(O) in(O) the(O) past(B-year) four(I-year) years(I-year)"}, "label_list": ["plot", "trailer", "rating", "character", "song", "director", "title", "actor", "average ratings", "genre", "review", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 19809, 11, 10959, 11, 3752, 11, 5609, 11, 7690, 11, 2316, 11, 12360, 11, 5578, 18594, 11, 17779, 11, 3477, 11, 1060, 323, 507, 627, 85664, 25, 1608, 27591, 272, 581, 7414, 59335, 304, 1148, 38559, 24914, 24162, 430, 1274, 1766, 5509, 1903, 304, 279, 3347, 3116, 1667, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2302", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) directed(O) crimson(B-title) rivers(I-title) 2(I-title) angels(I-title) of(I-title) the(I-title) apocalypse(I-title)", "instance": {"id": "2302", "words": ["who", "directed", "crimson", "rivers", "2", "angels", "of", "the", "apocalypse"], "labels": ["O", "O", "B-title", "I-title", "I-title", "I-title", "I-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, song, rating, character, average ratings, year, director, trailer, review, plot, genre, actor and O.\nSentence: who directed crimson rivers 2 angels of the apocalypse", "prompt_labels": "who(O) directed(O) crimson(B-title) rivers(I-title) 2(I-title) angels(I-title) of(I-title) the(I-title) apocalypse(I-title)"}, "label_list": ["title", "song", "rating", "character", "average ratings", "year", "director", "trailer", "review", "plot", "genre", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 5609, 11, 10959, 11, 3752, 11, 5578, 18594, 11, 1060, 11, 7690, 11, 19809, 11, 3477, 11, 7234, 11, 17779, 11, 12360, 323, 507, 627, 85664, 25, 889, 15910, 97119, 36617, 220, 17, 46968, 315, 279, 88914, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "474", "dataset": "mit-restaurant", "split": "dev", "prediction": "hard(B-Restaurant Name) rock(I-Restaurant Name) hotel(I-Restaurant Name) restaurant(I-Restaurant Name) near(B-Location) me(I-Location)", "instance": {"id": "474", "words": ["hard", "rock", "hotel", "restaurant", "near", "me"], "labels": ["B-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Location, Dish, Rating, Cuisine, Price, Amenity, Restaurant Name and O.\nSentence: hard rock hotel restaurant near me", "prompt_labels": "hard(B-Restaurant Name) rock(I-Restaurant Name) hotel(I-Restaurant Name) restaurant(O) near(B-Location) me(I-Location)"}, "label_list": ["Hours", "Location", "Dish", "Rating", "Cuisine", "Price", "Amenity", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 10067, 11, 49268, 11, 19767, 11, 81961, 11, 8650, 11, 3383, 56685, 11, 26568, 4076, 323, 507, 627, 85664, 25, 2653, 7091, 9689, 10960, 3221, 757, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "374", "dataset": "crossner_music", "split": "dev", "prediction": "The(B-band) Hives(I-band) have(O) released(O) five(O) studio(O) albums(O) :(O) Barely(B-album) Legal(I-album) ((O) 1997(O) )(O),(O) Veni(B-album) Vidi(I-album) Vicious(I-album) ((O) 2000(O) )(O),(O) Tyrannosaurus(B-album) Hives(I-album) ((O) 2004(O) )(O),(O) The(B-album) Black(I-album) and(I-album) White(I-album) Album(I-album) ((O) 2007(O) )(O) and(O) Lex(B-album) Hives(I-album) ((O) 2012(O) )(O).(O)", "instance": {"id": "374", "words": ["The", "Hives", "have", "released", "five", "studio", "albums", ":", "Barely", "Legal", "(", "1997", ")", ",", "Veni", "Vidi", "Vicious", "(", "2000", ")", ",", "Tyrannosaurus", "Hives", "(", "2004", ")", ",", "The", "Black", "and", "White", "Album", "(", "2007", ")", "and", "Lex", "Hives", "(", "2012", ")", "."], "labels": ["B-band", "I-band", "O", "O", "O", "O", "O", "O", "B-album", "I-album", "O", "O", "O", "O", "B-album", "I-album", "I-album", "O", "O", "O", "O", "B-album", "I-album", "O", "O", "O", "O", "B-album", "I-album", "I-album", "I-album", "I-album", "O", "O", "O", "O", "B-album", "I-album", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, award, music genre, organization, musical artist, band, musical instrument, location, person, song, event, album and O.\nSentence: The Hives have released five studio albums : Barely Legal ( 1997 ) , Veni Vidi Vicious ( 2000 ) , Tyrannosaurus Hives ( 2004 ) , The Black and White Album ( 2007 ) and Lex Hives ( 2012 ) .", "prompt_labels": "The(B-band) Hives(I-band) have(O) released(O) five(O) studio(O) albums(O) :(O) Barely(B-album) Legal(I-album) ((O) 1997(O) )(O) ,(O) Veni(B-album) Vidi(I-album) Vicious(I-album) ((O) 2000(O) )(O) ,(O) Tyrannosaurus(B-album) Hives(I-album) ((O) 2004(O) )(O) ,(O) The(B-album) Black(I-album) and(I-album) White(I-album) Album(I-album) ((O) 2007(O) )(O) and(O) Lex(B-album) Hives(I-album) ((O) 2012(O) )(O) .(O)"}, "label_list": ["country", "award", "music genre", "organization", "musical artist", "band", "musical instrument", "location", "person", "song", "event", "album"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 10292, 11, 4731, 17779, 11, 7471, 11, 18273, 10255, 11, 7200, 11, 18273, 14473, 11, 3813, 11, 1732, 11, 5609, 11, 1567, 11, 8176, 323, 507, 627, 85664, 25, 578, 473, 1924, 617, 6004, 4330, 14356, 28785, 551, 61892, 398, 25705, 320, 220, 2550, 22, 883, 1174, 18732, 72, 650, 12558, 650, 9824, 320, 220, 1049, 15, 883, 1174, 50595, 1036, 437, 43613, 473, 1924, 320, 220, 1049, 19, 883, 1174, 578, 5348, 323, 5929, 26749, 320, 220, 1049, 22, 883, 323, 27917, 473, 1924, 320, 220, 679, 17, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "14", "dataset": "crossner_literature", "split": "dev", "prediction": "He(O) is(O) the(O) protagonist(O) of(O) Robert(B-writer) Coover(I-writer) '(O) s(O) short(O) story(O) Charlie(B-book) in(I-book) the(I-book) House(I-book) of(I-book) Rue(I-book) ((O) 1980(O) ;(O) reprinted(O) in(O) Coover(B-writer)'s(O) 1987(O) collection(O) A(B-book) Night(I-book) at(I-book) the(I-book) Movies(I-book) )(O),(O) and(O) of(O) Glen(B-writer) David(I-writer) Gold(I-writer) '(O) s(O) Sunnyside(B-book) ((O) 2009(O) )(O),(O) a(O) historical(O) novel(O) set(O) in(O) the(O) First(B-event) World(I-event) War(I-event) period(O).(O)", "instance": {"id": "14", "words": ["He", "is", "the", "protagonist", "of", "Robert", "Coover", "'", "s", "short", "story", "Charlie", "in", "the", "House", "of", "Rue", "(", "1980", ";", "reprinted", "in", "Coover", "'s", "1987", "collection", "A", "Night", "at", "the", "Movies", ")", ",", "and", "of", "Glen", "David", "Gold", "'", "s", "Sunnyside", "(", "2009", ")", ",", "a", "historical", "novel", "set", "in", "the", "First", "World", "War", "period", "."], "labels": ["O", "O", "O", "O", "O", "B-book", "I-book", "O", "O", "B-literary genre", "I-literary genre", "B-book", "I-book", "I-book", "I-book", "I-book", "I-book", "O", "O", "O", "O", "O", "B-writer", "O", "O", "O", "B-book", "I-book", "I-book", "I-book", "I-book", "O", "O", "O", "O", "B-writer", "I-writer", "I-writer", "O", "O", "B-book", "O", "O", "O", "O", "O", "B-literary genre", "I-literary genre", "O", "O", "O", "B-event", "I-event", "I-event", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, person, event, literary genre, award, book, poem, writer, country, location, magazine and O.\nSentence: He is the protagonist of Robert Coover ' s short story Charlie in the House of Rue ( 1980 ; reprinted in Coover 's 1987 collection A Night at the Movies ) , and of Glen David Gold ' s Sunnyside ( 2009 ) , a historical novel set in the First World War period .", "prompt_labels": "He(O) is(O) the(O) protagonist(O) of(O) Robert(B-book) Coover(I-book) '(O) s(O) short(B-literary genre) story(I-literary genre) Charlie(B-book) in(I-book) the(I-book) House(I-book) of(I-book) Rue(I-book) ((O) 1980(O) ;(O) reprinted(O) in(O) Coover(B-writer) 's(O) 1987(O) collection(O) A(B-book) Night(I-book) at(I-book) the(I-book) Movies(I-book) )(O) ,(O) and(O) of(O) Glen(B-writer) David(I-writer) Gold(I-writer) '(O) s(O) Sunnyside(B-book) ((O) 2009(O) )(O) ,(O) a(O) historical(B-literary genre) novel(I-literary genre) set(O) in(O) the(O) First(B-event) World(I-event) War(I-event) period(O) .(O)"}, "label_list": ["organization", "person", "event", "literary genre", "award", "book", "poem", "writer", "country", "location", "magazine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 1732, 11, 1567, 11, 32465, 17779, 11, 10292, 11, 2363, 11, 33894, 11, 7061, 11, 3224, 11, 3813, 11, 14756, 323, 507, 627, 85664, 25, 1283, 374, 279, 46684, 315, 8563, 3623, 2017, 364, 274, 2875, 3446, 25972, 304, 279, 4783, 315, 79151, 320, 220, 3753, 15, 2652, 312, 53313, 304, 3623, 2017, 364, 82, 220, 3753, 22, 4526, 362, 13120, 520, 279, 27019, 883, 1174, 323, 315, 41061, 6941, 7573, 364, 274, 8219, 77, 1065, 579, 320, 220, 1049, 24, 883, 1174, 264, 13970, 11775, 743, 304, 279, 5629, 4435, 5111, 4261, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "13", "dataset": "crossner_science", "split": "dev", "prediction": "In(O) addition(O) to(O) his(O) steady(O) research(O) output(O),(O) Naqvi(B-scientist) has(O) manifested(O) his(O) commitment(O) to(O) teaching(O) by(O) contributing(O) to(O) journals(O) devoted(O) to(O) didactical(O) aspects(O) of(O) science(O) ((O) American(B-academic journal) Journal(I-academic journal) of(I-academic journal) Physics(I-academic journal),(O) European(B-academic journal) Journal(I-academic journal) of(I-academic journal) Physics(I-academic journal),(O) Journal(B-academic journal) of(I-academic journal) Chemical(I-academic journal) Education(I-academic journal) )(O).(O)", "instance": {"id": "13", "words": ["In", "addition", "to", "his", "steady", "research", "output", ",", "Naqvi", "has", "manifested", "his", "commitment", "to", "teaching", "by", "contributing", "to", "journals", "devoted", "to", "didactical", "aspects", "of", "science", "(", "American", "Journal", "of", "Physics", ",", "European", "Journal", "of", "Physics", ",", "Journal", "of", "Chemical", "Education", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-scientist", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, chemical element, event, academic journal, country, scientist, location, protein, person, astronomical object, award, organization, discipline, chemical compound, enzyme, theory and O.\nSentence: In addition to his steady research output , Naqvi has manifested his commitment to teaching by contributing to journals devoted to didactical aspects of science ( American Journal of Physics , European Journal of Physics , Journal of Chemical Education ) .", "prompt_labels": "In(O) addition(O) to(O) his(O) steady(O) research(O) output(O) ,(O) Naqvi(B-scientist) has(O) manifested(O) his(O) commitment(O) to(O) teaching(O) by(O) contributing(O) to(O) journals(O) devoted(O) to(O) didactical(O) aspects(O) of(O) science(O) ((O) American(B-academic journal) Journal(I-academic journal) of(I-academic journal) Physics(I-academic journal) ,(O) European(B-academic journal) Journal(I-academic journal) of(I-academic journal) Physics(I-academic journal) ,(O) Journal(B-academic journal) of(I-academic journal) Chemical(I-academic journal) Education(I-academic journal) )(O) .(O)"}, "label_list": ["university", "chemical element", "event", "academic journal", "country", "scientist", "location", "protein", "person", "astronomical object", "award", "organization", "discipline", "chemical compound", "enzyme", "theory"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12374, 11, 11742, 2449, 11, 1567, 11, 14584, 8486, 11, 3224, 11, 28568, 11, 3813, 11, 13128, 11, 1732, 11, 87283, 1665, 11, 10292, 11, 7471, 11, 26434, 11, 11742, 24549, 11, 49242, 11, 10334, 323, 507, 627, 85664, 25, 763, 5369, 311, 813, 24981, 3495, 2612, 1174, 13106, 80, 10176, 706, 79754, 813, 15507, 311, 12917, 555, 29820, 311, 42780, 29329, 311, 1550, 37119, 13878, 315, 8198, 320, 3778, 10139, 315, 28415, 1174, 7665, 10139, 315, 28415, 1174, 10139, 315, 36424, 11930, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "842", "dataset": "mit-movie", "split": "dev", "prediction": "find(O) me(O) a(O) film(O) with(O) the(O) song(O) under(B-song) the(I-song) sea(I-song)", "instance": {"id": "842", "words": ["find", "me", "a", "film", "with", "the", "song", "under", "the", "sea"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-song", "I-song", "I-song"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, director, plot, trailer, genre, year, rating, average ratings, song, title, review, character and O.\nSentence: find me a film with the song under the sea", "prompt_labels": "find(O) me(O) a(O) film(O) with(O) the(O) song(O) under(B-song) the(I-song) sea(I-song)"}, "label_list": ["actor", "director", "plot", "trailer", "genre", "year", "rating", "average ratings", "song", "title", "review", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 7690, 11, 7234, 11, 19809, 11, 17779, 11, 1060, 11, 10959, 11, 5578, 18594, 11, 5609, 11, 2316, 11, 3477, 11, 3752, 323, 507, 627, 85664, 25, 1505, 757, 264, 4632, 449, 279, 5609, 1234, 279, 9581, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1092", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) are(O) some(O) of(O) the(O) locally(B-Rating) favourite(I-Rating) restaurants(O)", "instance": {"id": "1092", "words": ["what", "are", "some", "of", "the", "locally", "favourite", "restaurants"], "labels": ["O", "O", "O", "O", "O", "B-Location", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Hours, Restaurant Name, Location, Rating, Amenity, Dish, Price and O.\nSentence: what are some of the locally favourite restaurants", "prompt_labels": "what(O) are(O) some(O) of(O) the(O) locally(B-Location) favourite(O) restaurants(O)"}, "label_list": ["Cuisine", "Hours", "Restaurant Name", "Location", "Rating", "Amenity", "Dish", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 30192, 11, 26568, 4076, 11, 10067, 11, 19767, 11, 3383, 56685, 11, 49268, 11, 8650, 323, 507, 627, 85664, 25, 1148, 527, 1063, 315, 279, 24392, 19214, 15926, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "127", "dataset": "crossner_ai", "split": "dev", "prediction": "Artificial(B-field) intelligence(I-field) has(O) retained(O) the(O) most(O) attention(O) regarding(O) applied(O) ontology(O) in(O) subfields(O) like(O) natural(B-field) language(I-field) processing(I-field) within(O) machine(B-field) and(O) knowledge(B-field) representation(I-field),(O) but(O) ontology(O) editors(O) are(O) being(O) used(O) often(O) in(O) a(O) range(O) of(O) fields(O) like(O) education(B-field) without(O) the(O) intent(O) to(O) contribute(O) to(O) AI(B-field).(O)", "instance": {"id": "127", "words": ["Artificial", "intelligence", "has", "retained", "the", "most", "attention", "regarding", "applied", "ontology", "in", "subfields", "like", "natural", "language", "processing", "within", "machine", "and", "knowledge", "representation", ",", "but", "ontology", "editors", "are", "being", "used", "often", "in", "a", "range", "of", "fields", "like", "education", "without", "the", "intent", "to", "contribute", "to", "AI", "."], "labels": ["B-field", "I-field", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-field", "I-field", "I-field", "O", "B-task", "O", "B-task", "I-task", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-field", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, university, programming language, conference, person, organization, country, algorithm, location, metric, researcher, product, task and O.\nSentence: Artificial intelligence has retained the most attention regarding applied ontology in subfields like natural language processing within machine and knowledge representation , but ontology editors are being used often in a range of fields like education without the intent to contribute to AI .", "prompt_labels": "Artificial(B-field) intelligence(I-field) has(O) retained(O) the(O) most(O) attention(O) regarding(O) applied(O) ontology(O) in(O) subfields(O) like(O) natural(B-field) language(I-field) processing(I-field) within(O) machine(B-task) and(O) knowledge(B-task) representation(I-task) ,(O) but(O) ontology(O) editors(O) are(O) being(O) used(O) often(O) in(O) a(O) range(O) of(O) fields(O) like(O) education(O) without(O) the(O) intent(O) to(O) contribute(O) to(O) AI(B-field) .(O)"}, "label_list": ["field", "university", "programming language", "conference", "person", "organization", "country", "algorithm", "location", "metric", "researcher", "product", "task"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2115, 11, 12374, 11, 15840, 4221, 11, 10017, 11, 1732, 11, 7471, 11, 3224, 11, 12384, 11, 3813, 11, 18767, 11, 32185, 11, 2027, 11, 3465, 323, 507, 627, 85664, 25, 59294, 11478, 706, 35363, 279, 1455, 6666, 9002, 9435, 84369, 304, 1207, 9184, 1093, 5933, 4221, 8863, 2949, 5780, 323, 6677, 13340, 1174, 719, 84369, 29846, 527, 1694, 1511, 3629, 304, 264, 2134, 315, 5151, 1093, 6873, 2085, 279, 7537, 311, 17210, 311, 15592, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2260", "dataset": "mit-movie", "split": "dev", "prediction": "when(O) did(O) alpha(B-title) and(I-title) omega(I-title) come(O) out(O)", "instance": {"id": "2260", "words": ["when", "did", "alpha", "and", "omega", "come", "out"], "labels": ["O", "O", "B-title", "I-title", "I-title", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, actor, song, trailer, year, director, genre, rating, average ratings, review, plot, character and O.\nSentence: when did alpha and omega come out", "prompt_labels": "when(O) did(O) alpha(B-title) and(I-title) omega(I-title) come(O) out(O)"}, "label_list": ["title", "actor", "song", "trailer", "year", "director", "genre", "rating", "average ratings", "review", "plot", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 12360, 11, 5609, 11, 19809, 11, 1060, 11, 7690, 11, 17779, 11, 10959, 11, 5578, 18594, 11, 3477, 11, 7234, 11, 3752, 323, 507, 627, 85664, 25, 994, 1550, 8451, 323, 34998, 2586, 704, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "167", "dataset": "crossner_ai", "split": "dev", "prediction": "During(O) his(O) time(O) at(O) Duke(B-university),(O) he(O) worked(O) on(O) an(O) automated(O) crossword(O) solver(O) PROVERB(B-algorithm),(O) which(O) won(O) an(O) Outstanding(O) Paper(O) Award(O) in(O) 1999(O) from(O) AAAI(B-conference) and(O) competed(O) in(O) the(O) American(B-conference) Crossword(I-conference) Puzzle(I-conference) Tournament(I-conference).(O)", "instance": {"id": "167", "words": ["During", "his", "time", "at", "Duke", ",", "he", "worked", "on", "an", "automated", "crossword", "solver", "PROVERB", ",", "which", "won", "an", "Outstanding", "Paper", "Award", "in", "1999", "from", "AAAI", "and", "competed", "in", "the", "American", "Crossword", "Puzzle", "Tournament", "."], "labels": ["O", "O", "O", "O", "B-university", "O", "O", "O", "O", "O", "O", "O", "O", "B-product", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-conference", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, product, field, university, metric, task, country, algorithm, location, organization, programming language, person, researcher and O.\nSentence: During his time at Duke , he worked on an automated crossword solver PROVERB , which won an Outstanding Paper Award in 1999 from AAAI and competed in the American Crossword Puzzle Tournament .", "prompt_labels": "During(O) his(O) time(O) at(O) Duke(B-university) ,(O) he(O) worked(O) on(O) an(O) automated(O) crossword(O) solver(O) PROVERB(B-product) ,(O) which(O) won(O) an(O) Outstanding(O) Paper(O) Award(O) in(O) 1999(O) from(O) AAAI(B-conference) and(O) competed(O) in(O) the(O) American(O) Crossword(O) Puzzle(O) Tournament(O) .(O)"}, "label_list": ["conference", "product", "field", "university", "metric", "task", "country", "algorithm", "location", "organization", "programming language", "person", "researcher"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10017, 11, 2027, 11, 2115, 11, 12374, 11, 18767, 11, 3465, 11, 3224, 11, 12384, 11, 3813, 11, 7471, 11, 15840, 4221, 11, 1732, 11, 32185, 323, 507, 627, 85664, 25, 12220, 813, 892, 520, 27453, 1174, 568, 6575, 389, 459, 28598, 92496, 30061, 5421, 3848, 33, 1174, 902, 2834, 459, 76441, 18343, 17768, 304, 220, 2550, 24, 505, 48197, 40, 323, 67235, 304, 279, 3778, 11511, 1178, 61112, 18877, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "385", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) a(O) trailer(B-trailer) for(O) an(O) alec(B-actor) guiness(I-actor) flick(O)", "instance": {"id": "385", "words": ["show", "me", "a", "trailer", "for", "an", "alec", "guiness", "flick"], "labels": ["O", "O", "O", "B-trailer", "O", "O", "B-actor", "I-actor", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, plot, character, year, average ratings, title, review, trailer, actor, director, song, rating and O.\nSentence: show me a trailer for an alec guiness flick", "prompt_labels": "show(O) me(O) a(O) trailer(B-trailer) for(O) an(O) alec(B-actor) guiness(I-actor) flick(O)"}, "label_list": ["genre", "plot", "character", "year", "average ratings", "title", "review", "trailer", "actor", "director", "song", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 7234, 11, 3752, 11, 1060, 11, 5578, 18594, 11, 2316, 11, 3477, 11, 19809, 11, 12360, 11, 7690, 11, 5609, 11, 10959, 323, 507, 627, 85664, 25, 1501, 757, 264, 19809, 369, 459, 22180, 66, 1709, 1918, 29447, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1", "dataset": "crossner_music", "split": "dev", "prediction": "Squarepusher(B-album) continues(O) to(O) push(O) new(O) boundaries(O) to(O) this(O) day(O),(O) where(O) he(O) still(O) calls(O) Warp(B-organization) Records(I-organization) his(O) home(O),(O) having(O) released(O) numerous(O) albums(O) to(O) critical(O) acclaim(O) in(O) the(O) years(O) to(O) follow(O),(O) such(O) as(O) Go(B-album) Plastic(I-album),(O) Do(B-album) You(I-album) Know(I-album) Squarepusher(I-album),(O) Ultravisitor(B-album),(O) Hello(B-album) Everything(I-album),(O) Just(B-album) a(I-album) Souvenir(I-album),(O) Solo(B-album) Electric(I-album) Bass(I-album) 1(I-album),(O) Ufabulum(B-album) and(O) Damogen(B-album) Furies(I-album).(O)", "instance": {"id": "1", "words": ["Squarepusher", "continues", "to", "push", "new", "boundaries", "to", "this", "day", ",", "where", "he", "still", "calls", "Warp", "Records", "his", "home", ",", "having", "released", "numerous", "albums", "to", "critical", "acclaim", "in", "the", "years", "to", "follow", ",", "such", "as", "Go", "Plastic", ",", "Do", "You", "Know", "Squarepusher", ",", "Ultravisitor", ",", "Hello", "Everything", ",", "Just", "a", "Souvenir", ",", "Solo", "Electric", "Bass", "1", ",", "Ufabulum", "and", "Damogen", "Furies", "."], "labels": ["B-musical artist", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-album", "I-album", "O", "B-album", "I-album", "I-album", "I-album", "O", "B-album", "O", "B-album", "I-album", "O", "B-album", "I-album", "I-album", "O", "B-album", "I-album", "I-album", "I-album", "O", "B-album", "O", "B-album", "I-album", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, music genre, award, musical instrument, event, musical artist, organization, song, band, person, album, country and O.\nSentence: Squarepusher continues to push new boundaries to this day , where he still calls Warp Records his home , having released numerous albums to critical acclaim in the years to follow , such as Go Plastic , Do You Know Squarepusher , Ultravisitor , Hello Everything , Just a Souvenir , Solo Electric Bass 1 , Ufabulum and Damogen Furies .", "prompt_labels": "Squarepusher(B-musical artist) continues(O) to(O) push(O) new(O) boundaries(O) to(O) this(O) day(O) ,(O) where(O) he(O) still(O) calls(O) Warp(B-organization) Records(I-organization) his(O) home(O) ,(O) having(O) released(O) numerous(O) albums(O) to(O) critical(O) acclaim(O) in(O) the(O) years(O) to(O) follow(O) ,(O) such(O) as(O) Go(B-album) Plastic(I-album) ,(O) Do(B-album) You(I-album) Know(I-album) Squarepusher(I-album) ,(O) Ultravisitor(B-album) ,(O) Hello(B-album) Everything(I-album) ,(O) Just(B-album) a(I-album) Souvenir(I-album) ,(O) Solo(B-album) Electric(I-album) Bass(I-album) 1(I-album) ,(O) Ufabulum(B-album) and(O) Damogen(B-album) Furies(I-album) .(O)"}, "label_list": ["location", "music genre", "award", "musical instrument", "event", "musical artist", "organization", "song", "band", "person", "album", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 4731, 17779, 11, 10292, 11, 18273, 14473, 11, 1567, 11, 18273, 10255, 11, 7471, 11, 5609, 11, 7200, 11, 1732, 11, 8176, 11, 3224, 323, 507, 627, 85664, 25, 15992, 9254, 261, 9731, 311, 4585, 502, 23546, 311, 420, 1938, 1174, 1405, 568, 2103, 6880, 78910, 22293, 813, 2162, 1174, 3515, 6004, 12387, 28785, 311, 9200, 97963, 304, 279, 1667, 311, 1833, 1174, 1778, 439, 6122, 37108, 1174, 3234, 1472, 14521, 15992, 9254, 261, 1174, 67957, 23156, 1960, 1174, 22691, 20696, 1174, 4702, 264, 9424, 43406, 1174, 36223, 21246, 37053, 220, 16, 1174, 549, 37955, 16903, 323, 16758, 11968, 435, 10612, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "434", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movies(O) has(O) ellen(B-actor) page(I-actor) been(O) in(O)", "instance": {"id": "434", "words": ["what", "movies", "has", "ellen", "page", "been", "in"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, title, genre, rating, actor, song, plot, trailer, character, year, review, director and O.\nSentence: what movies has ellen page been in", "prompt_labels": "what(O) movies(O) has(O) ellen(B-actor) page(I-actor) been(O) in(O)"}, "label_list": ["average ratings", "title", "genre", "rating", "actor", "song", "plot", "trailer", "character", "year", "review", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 2316, 11, 17779, 11, 10959, 11, 12360, 11, 5609, 11, 7234, 11, 19809, 11, 3752, 11, 1060, 11, 3477, 11, 7690, 323, 507, 627, 85664, 25, 1148, 9698, 706, 220, 16046, 2199, 1027, 304, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "109", "dataset": "crossner_science", "split": "dev", "prediction": "He(O) has(O) received(O) Academy(B-award) Awards(I-award),(O) Grammy(B-award) Award(I-award),(O) and(O) Golden(B-award) Globe(I-award) Award(I-award) s(O),(O) and(O) he(O) is(O) an(O) inductee(O) to(O) the(O) Rock(B-award) and(I-award) Roll(I-award) Hall(I-award) of(I-award) Fame(I-award).(O)", "instance": {"id": "109", "words": ["He", "has", "received", "Academy", "Awards", ",", "Grammy", "Award", ",", "and", "Golden", "Globe", "Award", "s", ",", "and", "he", "is", "an", "inductee", "to", "the", "Rock", "and", "Roll", "Hall", "of", "Fame", "."], "labels": ["O", "O", "O", "B-award", "I-award", "O", "B-award", "I-award", "O", "O", "B-award", "I-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, award, protein, location, theory, enzyme, chemical compound, chemical element, country, astronomical object, person, university, academic journal, organization, scientist, discipline and O.\nSentence: He has received Academy Awards , Grammy Award , and Golden Globe Award s , and he is an inductee to the Rock and Roll Hall of Fame .", "prompt_labels": "He(O) has(O) received(O) Academy(B-award) Awards(I-award) ,(O) Grammy(B-award) Award(I-award) ,(O) and(O) Golden(B-award) Globe(I-award) Award(I-award) s(O) ,(O) and(O) he(O) is(O) an(O) inductee(O) to(O) the(O) Rock(B-organization) and(I-organization) Roll(I-organization) Hall(I-organization) of(I-organization) Fame(I-organization) .(O)"}, "label_list": ["event", "award", "protein", "location", "theory", "enzyme", "chemical compound", "chemical element", "country", "astronomical object", "person", "university", "academic journal", "organization", "scientist", "discipline"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 10292, 11, 13128, 11, 3813, 11, 10334, 11, 49242, 11, 11742, 24549, 11, 11742, 2449, 11, 3224, 11, 87283, 1665, 11, 1732, 11, 12374, 11, 14584, 8486, 11, 7471, 11, 28568, 11, 26434, 323, 507, 627, 85664, 25, 1283, 706, 4036, 16192, 23488, 1174, 74679, 17768, 1174, 323, 18288, 41910, 17768, 274, 1174, 323, 568, 374, 459, 304, 1076, 2176, 311, 279, 9305, 323, 15028, 11166, 315, 39627, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "244", "dataset": "mit-movie", "split": "dev", "prediction": "when(O) did(O) the(O) game(O) come(O) out(O)", "instance": {"id": "244", "words": ["when", "did", "the", "game", "come", "out"], "labels": ["O", "O", "B-title", "I-title", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, actor, trailer, genre, rating, year, character, average ratings, song, title, director, review and O.\nSentence: when did the game come out", "prompt_labels": "when(O) did(O) the(B-title) game(I-title) come(O) out(O)"}, "label_list": ["plot", "actor", "trailer", "genre", "rating", "year", "character", "average ratings", "song", "title", "director", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 12360, 11, 19809, 11, 17779, 11, 10959, 11, 1060, 11, 3752, 11, 5578, 18594, 11, 5609, 11, 2316, 11, 7690, 11, 3477, 323, 507, 627, 85664, 25, 994, 1550, 279, 1847, 2586, 704, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "155", "dataset": "crossner_music", "split": "dev", "prediction": "It(O) also(O) produced(O) the(O) Top(O) 5(O) single(O) Rage(B-song) Hard(I-song) ((O) #(O) 1(O) in(O) Germany(B-country) )(O),(O) Top(O) 20(O) single(O) Warriors(B-song) of(I-song) the(I-song) Wasteland(I-song) and(O) Top(O) 30(O) single(O) Watching(B-song) the(I-song) Wildlife(I-song).(O)", "instance": {"id": "155", "words": ["It", "also", "produced", "the", "Top", "5", "single", "Rage", "Hard", "(", "#", "1", "in", "Germany", ")", ",", "Top", "20", "single", "Warriors", "of", "the", "Wasteland", "and", "Top", "30", "single", "Watching", "the", "Wildlife", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-song", "I-song", "O", "O", "O", "O", "B-country", "O", "O", "O", "O", "O", "B-song", "I-song", "I-song", "I-song", "O", "O", "O", "O", "B-song", "I-song", "I-song", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, musical artist, person, song, music genre, organization, location, album, musical instrument, event, award, band and O.\nSentence: It also produced the Top 5 single Rage Hard ( # 1 in Germany ) , Top 20 single Warriors of the Wasteland and Top 30 single Watching the Wildlife .", "prompt_labels": "It(O) also(O) produced(O) the(O) Top(O) 5(O) single(O) Rage(B-song) Hard(I-song) ((O) #(O) 1(O) in(O) Germany(B-country) )(O) ,(O) Top(O) 20(O) single(O) Warriors(B-song) of(I-song) the(I-song) Wasteland(I-song) and(O) Top(O) 30(O) single(O) Watching(B-song) the(I-song) Wildlife(I-song) .(O)"}, "label_list": ["country", "musical artist", "person", "song", "music genre", "organization", "location", "album", "musical instrument", "event", "award", "band"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 18273, 10255, 11, 1732, 11, 5609, 11, 4731, 17779, 11, 7471, 11, 3813, 11, 8176, 11, 18273, 14473, 11, 1567, 11, 10292, 11, 7200, 323, 507, 627, 85664, 25, 1102, 1101, 9124, 279, 7054, 220, 20, 3254, 66567, 11481, 320, 674, 220, 16, 304, 10057, 883, 1174, 7054, 220, 508, 3254, 32987, 315, 279, 468, 561, 18615, 323, 7054, 220, 966, 3254, 69676, 279, 42649, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "429", "dataset": "crossner_politics", "split": "dev", "prediction": "The(B-title) Front(I-title) Runner(I-title) is(O) a(O) 2018(B-year) American(O) political(O) drama(B-genre) film(O) directed(O) by(O) Jason(B-director) Reitman(I-director),(O) based(O) on(O) the(O) 2014(O) book(O) All(B-book) the(I-book) Truth(I-book) Is(I-book) Out(I-book) :(O) The(B-book) Week(I-book) Politics(I-book) Went(I-book) Tabloid(I-book) by(O) Matt(B-politician) Bai(I-politician),(O) who(O) co-wrote(O) the(O) screenplay(O) with(O) Reitman(B-director) and(O) Jay(B-politician) Carson(I-politician).(O)", "instance": {"id": "429", "words": ["The", "Front", "Runner", "is", "a", "2018", "American", "political", "drama", "film", "directed", "by", "Jason", "Reitman", ",", "based", "on", "the", "2014", "book", "All", "the", "Truth", "Is", "Out", ":", "The", "Week", "Politics", "Went", "Tabloid", "by", "Matt", "Bai", ",", "who", "co-wrote", "the", "screenplay", "with", "Reitman", "and", "Jay", "Carson", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "O", "O", "O", "O", "O", "B-person", "O", "B-person", "I-person", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, organization, event, politician, country, person, location, political party and O.\nSentence: The Front Runner is a 2018 American political drama film directed by Jason Reitman , based on the 2014 book All the Truth Is Out : The Week Politics Went Tabloid by Matt Bai , who co-wrote the screenplay with Reitman and Jay Carson .", "prompt_labels": "The(O) Front(O) Runner(O) is(O) a(O) 2018(O) American(O) political(O) drama(O) film(O) directed(O) by(O) Jason(B-person) Reitman(I-person) ,(O) based(O) on(O) the(O) 2014(O) book(O) All(O) the(O) Truth(O) Is(O) Out(O) :(O) The(O) Week(O) Politics(O) Went(O) Tabloid(O) by(O) Matt(B-person) Bai(I-person) ,(O) who(O) co-wrote(O) the(O) screenplay(O) with(O) Reitman(B-person) and(O) Jay(B-person) Carson(I-person) .(O)"}, "label_list": ["election", "organization", "event", "politician", "country", "person", "location", "political party"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 6355, 11, 7471, 11, 1567, 11, 37038, 11, 3224, 11, 1732, 11, 3813, 11, 5054, 4717, 323, 507, 627, 85664, 25, 578, 15248, 46046, 374, 264, 220, 679, 23, 3778, 5054, 20156, 4632, 15910, 555, 18984, 1050, 275, 1543, 1174, 3196, 389, 279, 220, 679, 19, 2363, 2052, 279, 30198, 2209, 4470, 551, 578, 10563, 35979, 54859, 15490, 52196, 555, 13678, 86008, 1174, 889, 1080, 2695, 5646, 279, 85875, 449, 1050, 275, 1543, 323, 19455, 41276, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2188", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) short(B-genre) films(O) by(O) bob(B-director) gray(I-director) received(O) excellent(B-average ratings) ratings(I-average ratings)", "instance": {"id": "2188", "words": ["what", "short", "films", "by", "bob", "gray", "received", "excellent", "ratings"], "labels": ["O", "B-genre", "O", "O", "B-director", "I-director", "O", "B-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, average ratings, genre, rating, plot, review, title, year, director, character, song, trailer and O.\nSentence: what short films by bob gray received excellent ratings", "prompt_labels": "what(O) short(B-genre) films(O) by(O) bob(B-director) gray(I-director) received(O) excellent(B-average ratings) ratings(I-average ratings)"}, "label_list": ["actor", "average ratings", "genre", "rating", "plot", "review", "title", "year", "director", "character", "song", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 5578, 18594, 11, 17779, 11, 10959, 11, 7234, 11, 3477, 11, 2316, 11, 1060, 11, 7690, 11, 3752, 11, 5609, 11, 19809, 323, 507, 627, 85664, 25, 1148, 2875, 12631, 555, 36292, 18004, 4036, 9250, 18594, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1919", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) are(O) some(O) titles(O) of(O) crime(B-genre) films(O) from(O) the(O) 1950(B-year) s(I-year)", "instance": {"id": "1919", "words": ["what", "are", "some", "titles", "of", "crime", "films", "from", "the", "1950", "s"], "labels": ["O", "O", "O", "O", "O", "B-genre", "O", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, director, plot, average ratings, trailer, title, year, rating, review, character, actor, song and O.\nSentence: what are some titles of crime films from the 1950 s", "prompt_labels": "what(O) are(O) some(O) titles(O) of(O) crime(B-genre) films(O) from(O) the(O) 1950(B-year) s(I-year)"}, "label_list": ["genre", "director", "plot", "average ratings", "trailer", "title", "year", "rating", "review", "character", "actor", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 7690, 11, 7234, 11, 5578, 18594, 11, 19809, 11, 2316, 11, 1060, 11, 10959, 11, 3477, 11, 3752, 11, 12360, 11, 5609, 323, 507, 627, 85664, 25, 1148, 527, 1063, 15671, 315, 9977, 12631, 505, 279, 220, 6280, 15, 274, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "261", "dataset": "crossner_politics", "split": "dev", "prediction": "Since(O) 2008(O) it(O) was(O) part(O) of(O) the(O) Sammarinese(B-political party) Union(I-political party) of(I-political party) Moderates(I-political party) together(O) with(O) Sammarinese(B-political party) Populars(I-political party) and(O) stood(O) in(O) opposition(O) to(O) the(O) 2006-2008(O) coalition(O) government(O) consisting(O) of(O) the(O) Party(B-political party) of(I-political party) Socialists(I-political party) and(I-political party) Democrats(I-political party),(O) the(O) Popular(B-political party) Alliance(I-political party) and(O) the(O) United(B-political party) Left(I-political party).(O)", "instance": {"id": "261", "words": ["Since", "2008", "it", "was", "part", "of", "the", "Sammarinese", "Union", "of", "Moderates", "together", "with", "Sammarinese", "Populars", "and", "stood", "in", "opposition", "to", "the", "2006-2008", "coalition", "government", "consisting", "of", "the", "Party", "of", "Socialists", "and", "Democrats", ",", "the", "Popular", "Alliance", "and", "the", "United", "Left", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "O", "O", "B-organization", "I-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, political party, organization, location, event, politician, election, person and O.\nSentence: Since 2008 it was part of the Sammarinese Union of Moderates together with Sammarinese Populars and stood in opposition to the 2006-2008 coalition government consisting of the Party of Socialists and Democrats , the Popular Alliance and the United Left .", "prompt_labels": "Since(O) 2008(O) it(O) was(O) part(O) of(O) the(O) Sammarinese(B-political party) Union(I-political party) of(I-political party) Moderates(I-political party) together(O) with(O) Sammarinese(B-political party) Populars(I-political party) and(O) stood(O) in(O) opposition(O) to(O) the(O) 2006-2008(O) coalition(O) government(O) consisting(O) of(O) the(O) Party(B-political party) of(I-political party) Socialists(I-political party) and(I-political party) Democrats(I-political party) ,(O) the(O) Popular(B-political party) Alliance(I-political party) and(O) the(O) United(B-organization) Left(I-organization) .(O)"}, "label_list": ["country", "political party", "organization", "location", "event", "politician", "election", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 5054, 4717, 11, 7471, 11, 3813, 11, 1567, 11, 37038, 11, 6355, 11, 1732, 323, 507, 627, 85664, 25, 8876, 220, 1049, 23, 433, 574, 961, 315, 279, 8388, 5730, 7496, 9323, 315, 44527, 988, 3871, 449, 8388, 5730, 7496, 32495, 82, 323, 14980, 304, 14076, 311, 279, 220, 1049, 21, 12, 1049, 23, 26283, 3109, 31706, 315, 279, 8722, 315, 9983, 1705, 323, 12643, 1174, 279, 32495, 23590, 323, 279, 3723, 14043, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1205", "dataset": "mit-movie", "split": "dev", "prediction": "do(O) you(O) have(O) the(O) pg(B-rating) 13(I-rating) movie(O) from(O) 1970(B-year) about(O) a(O) road(B-plot) trip(I-plot) directed(O) by(O) karen(B-director) harley(I-director) thats(O) good(B-average ratings) for(O) a(O) laugh(B-genre)", "instance": {"id": "1205", "words": ["do", "you", "have", "the", "pg", "13", "movie", "from", "1970", "about", "a", "road", "trip", "directed", "by", "karen", "harley", "thats", "good", "for", "a", "laugh"], "labels": ["O", "O", "O", "O", "B-rating", "I-rating", "O", "O", "B-year", "O", "O", "B-plot", "I-plot", "O", "O", "B-director", "I-director", "O", "O", "O", "O", "B-genre"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, review, plot, director, actor, rating, song, character, title, average ratings, year, genre and O.\nSentence: do you have the pg 13 movie from 1970 about a road trip directed by karen harley thats good for a laugh", "prompt_labels": "do(O) you(O) have(O) the(O) pg(B-rating) 13(I-rating) movie(O) from(O) 1970(B-year) about(O) a(O) road(B-plot) trip(I-plot) directed(O) by(O) karen(B-director) harley(I-director) thats(O) good(O) for(O) a(O) laugh(B-genre)"}, "label_list": ["trailer", "review", "plot", "director", "actor", "rating", "song", "character", "title", "average ratings", "year", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 3477, 11, 7234, 11, 7690, 11, 12360, 11, 10959, 11, 5609, 11, 3752, 11, 2316, 11, 5578, 18594, 11, 1060, 11, 17779, 323, 507, 627, 85664, 25, 656, 499, 617, 279, 17953, 220, 1032, 5818, 505, 220, 4468, 15, 922, 264, 5754, 8577, 15910, 555, 597, 9329, 4960, 3258, 41136, 1695, 369, 264, 12835, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1074", "dataset": "mit-movie", "split": "dev", "prediction": "any(O) highly(B-average ratings) recommended(I-average ratings) movies(O) for(O) the(O) 1980(B-year) s(I-year) about(O) military(B-genre) guerrilla(B-plot) warfare(I-plot)", "instance": {"id": "1074", "words": ["any", "highly", "recommended", "movies", "for", "the", "1980", "s", "about", "military", "guerrilla", "warfare"], "labels": ["O", "B-average ratings", "I-average ratings", "O", "O", "O", "B-year", "I-year", "O", "B-genre", "B-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, song, plot, year, title, review, character, director, genre, average ratings, actor, rating and O.\nSentence: any highly recommended movies for the 1980 s about military guerrilla warfare", "prompt_labels": "any(O) highly(B-average ratings) recommended(I-average ratings) movies(O) for(O) the(O) 1980(B-year) s(I-year) about(O) military(B-genre) guerrilla(B-plot) warfare(I-plot)"}, "label_list": ["trailer", "song", "plot", "year", "title", "review", "character", "director", "genre", "average ratings", "actor", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 5609, 11, 7234, 11, 1060, 11, 2316, 11, 3477, 11, 3752, 11, 7690, 11, 17779, 11, 5578, 18594, 11, 12360, 11, 10959, 323, 507, 627, 85664, 25, 904, 7701, 11349, 9698, 369, 279, 220, 3753, 15, 274, 922, 6411, 76270, 6374, 39307, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1488", "dataset": "mit-restaurant", "split": "dev", "prediction": "which(O) places(O) serve(O) large(B-Amenity) portions(I-Amenity)", "instance": {"id": "1488", "words": ["which", "places", "serve", "large", "portions"], "labels": ["O", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Hours, Restaurant Name, Amenity, Cuisine, Dish, Price, Location and O.\nSentence: which places serve large portions", "prompt_labels": "which(O) places(O) serve(O) large(B-Amenity) portions(I-Amenity)"}, "label_list": ["Rating", "Hours", "Restaurant Name", "Amenity", "Cuisine", "Dish", "Price", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 30192, 11, 26568, 4076, 11, 3383, 56685, 11, 81961, 11, 49268, 11, 8650, 11, 10067, 323, 507, 627, 85664, 25, 902, 7634, 8854, 3544, 19885, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "364", "dataset": "crossner_science", "split": "dev", "prediction": "Max(B-scientist) Volmer(I-scientist) and(O) Robert(B-scientist) D\u00f6pel(I-scientist) were(O) assigned(O) to(O) this(O) facility(O).(O)", "instance": {"id": "364", "words": ["Max", "Volmer", "and", "Robert", "D\u00f6pel", "were", "assigned", "to", "this", "facility", "."], "labels": ["B-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, enzyme, person, event, university, chemical compound, chemical element, academic journal, theory, discipline, award, country, protein, scientist, astronomical object, location and O.\nSentence: Max Volmer and Robert D\u00f6pel were assigned to this facility .", "prompt_labels": "Max(B-scientist) Volmer(I-scientist) and(O) Robert(B-scientist) D\u00f6pel(I-scientist) were(O) assigned(O) to(O) this(O) facility(O) .(O)"}, "label_list": ["organization", "enzyme", "person", "event", "university", "chemical compound", "chemical element", "academic journal", "theory", "discipline", "award", "country", "protein", "scientist", "astronomical object", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 49242, 11, 1732, 11, 1567, 11, 12374, 11, 11742, 24549, 11, 11742, 2449, 11, 14584, 8486, 11, 10334, 11, 26434, 11, 10292, 11, 3224, 11, 13128, 11, 28568, 11, 87283, 1665, 11, 3813, 323, 507, 627, 85664, 25, 7639, 11119, 1195, 323, 8563, 423, 3029, 48624, 1051, 12893, 311, 420, 12764, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2268", "dataset": "mit-movie", "split": "dev", "prediction": "when(O) is(O) a(O) good(O) romantic(B-genre) comedy(I-genre) based(O) on(O) a(O) book(O) coming(O) out(O)", "instance": {"id": "2268", "words": ["when", "is", "a", "good", "romantic", "comedy", "based", "on", "a", "book", "coming", "out"], "labels": ["O", "O", "O", "O", "B-genre", "I-genre", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, director, plot, average ratings, actor, character, year, rating, genre, review, song, title and O.\nSentence: when is a good romantic comedy based on a book coming out", "prompt_labels": "when(O) is(O) a(O) good(O) romantic(B-genre) comedy(I-genre) based(O) on(O) a(O) book(O) coming(O) out(O)"}, "label_list": ["trailer", "director", "plot", "average ratings", "actor", "character", "year", "rating", "genre", "review", "song", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 7690, 11, 7234, 11, 5578, 18594, 11, 12360, 11, 3752, 11, 1060, 11, 10959, 11, 17779, 11, 3477, 11, 5609, 11, 2316, 323, 507, 627, 85664, 25, 994, 374, 264, 1695, 24364, 23160, 3196, 389, 264, 2363, 5108, 704, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "230", "dataset": "crossner_ai", "split": "dev", "prediction": "At(O) UCSD(B-university),(O) Norman(B-researcher) was(O) a(O) founder(O) of(O) the(O) Institute(B-organization) for(I-organization) Cognitive(I-organization) Science(I-organization) and(O) one(O) of(O) the(O) organizers(O) of(O) the(O) Cognitive(B-conference) Science(I-conference) Society(I-conference) ((O) along(O) with(O) Roger(B-researcher) Schank(I-researcher),(O) Allan(B-researcher) M.(I-researcher) Collins(I-researcher),(O) and(O) others(O) )(O),(O) which(O) held(O) its(O) first(O) meeting(O) at(O) the(O) UCSD(B-university) campus(O) in(O) 1979(O).(O)", "instance": {"id": "230", "words": ["At", "UCSD", ",", "Norman", "was", "a", "founder", "of", "the", "Institute", "for", "Cognitive", "Science", "and", "one", "of", "the", "organizers", "of", "the", "Cognitive", "Science", "Society", "(", "along", "with", "Roger", "Schank", ",", "Allan", "M.", "Collins", ",", "and", "others", ")", ",", "which", "held", "its", "first", "meeting", "at", "the", "UCSD", "campus", "in", "1979", "."], "labels": ["O", "B-university", "O", "B-researcher", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "O", "B-researcher", "I-researcher", "O", "B-researcher", "I-researcher", "I-researcher", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-university", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, person, researcher, organization, country, metric, programming language, university, field, location, algorithm, task, product and O.\nSentence: At UCSD , Norman was a founder of the Institute for Cognitive Science and one of the organizers of the Cognitive Science Society ( along with Roger Schank , Allan M. Collins , and others ) , which held its first meeting at the UCSD campus in 1979 .", "prompt_labels": "At(O) UCSD(B-university) ,(O) Norman(B-researcher) was(O) a(O) founder(O) of(O) the(B-organization) Institute(I-organization) for(I-organization) Cognitive(I-organization) Science(I-organization) and(O) one(O) of(O) the(O) organizers(O) of(O) the(O) Cognitive(B-organization) Science(I-organization) Society(I-organization) ((O) along(O) with(O) Roger(B-researcher) Schank(I-researcher) ,(O) Allan(B-researcher) M.(I-researcher) Collins(I-researcher) ,(O) and(O) others(O) )(O) ,(O) which(O) held(O) its(O) first(O) meeting(O) at(O) the(O) UCSD(B-university) campus(O) in(O) 1979(O) .(O)"}, "label_list": ["conference", "person", "researcher", "organization", "country", "metric", "programming language", "university", "field", "location", "algorithm", "task", "product"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10017, 11, 1732, 11, 32185, 11, 7471, 11, 3224, 11, 18767, 11, 15840, 4221, 11, 12374, 11, 2115, 11, 3813, 11, 12384, 11, 3465, 11, 2027, 323, 507, 627, 85664, 25, 2468, 31613, 5608, 1174, 41168, 574, 264, 19533, 315, 279, 10181, 369, 73235, 10170, 323, 832, 315, 279, 44318, 315, 279, 73235, 10170, 13581, 320, 3235, 449, 29607, 5124, 1201, 1174, 61325, 386, 13, 29770, 1174, 323, 3885, 883, 1174, 902, 5762, 1202, 1176, 6574, 520, 279, 31613, 5608, 15679, 304, 220, 4468, 24, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "238", "dataset": "mit-movie", "split": "dev", "prediction": "how(O) many(O) star(B-title) wars(I-title) films(O) are(O) there(O)", "instance": {"id": "238", "words": ["how", "many", "star", "wars", "films", "are", "there"], "labels": ["O", "O", "B-title", "I-title", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, trailer, plot, genre, actor, character, rating, review, average ratings, title, year, song and O.\nSentence: how many star wars films are there", "prompt_labels": "how(O) many(O) star(B-title) wars(I-title) films(O) are(O) there(O)"}, "label_list": ["director", "trailer", "plot", "genre", "actor", "character", "rating", "review", "average ratings", "title", "year", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 19809, 11, 7234, 11, 17779, 11, 12360, 11, 3752, 11, 10959, 11, 3477, 11, 5578, 18594, 11, 2316, 11, 1060, 11, 5609, 323, 507, 627, 85664, 25, 1268, 1690, 6917, 25981, 12631, 527, 1070, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2290", "dataset": "mit-movie", "split": "dev", "prediction": "which(O) biography(B-genre) about(O) a(O) classical(B-plot) composer(I-plot) featuring(O) deforest(B-actor) kelly(I-actor) received(O) an(O) eight(B-average ratings) star(I-average ratings) rating(O)", "instance": {"id": "2290", "words": ["which", "biography", "about", "a", "classical", "composer", "featuring", "deforest", "kelly", "received", "an", "eight", "star", "rating"], "labels": ["O", "B-genre", "O", "O", "B-plot", "I-plot", "O", "B-actor", "I-actor", "O", "O", "B-average ratings", "I-average ratings", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, review, plot, year, actor, rating, director, genre, title, song, character, average ratings and O.\nSentence: which biography about a classical composer featuring deforest kelly received an eight star rating", "prompt_labels": "which(O) biography(B-genre) about(O) a(O) classical(B-plot) composer(I-plot) featuring(O) deforest(B-actor) kelly(I-actor) received(O) an(O) eight(B-average ratings) star(I-average ratings) rating(O)"}, "label_list": ["trailer", "review", "plot", "year", "actor", "rating", "director", "genre", "title", "song", "character", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 3477, 11, 7234, 11, 1060, 11, 12360, 11, 10959, 11, 7690, 11, 17779, 11, 2316, 11, 5609, 11, 3752, 11, 5578, 18594, 323, 507, 627, 85664, 25, 902, 48345, 922, 264, 29924, 40550, 16850, 711, 42519, 597, 12160, 4036, 459, 8223, 6917, 10959, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "781", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) live(O) action(B-genre) movie(O) based(O) on(O) action(O) figure(O) toys(O) was(O) released(O) in(O) 2009(B-year)", "instance": {"id": "781", "words": ["what", "live", "action", "movie", "based", "on", "action", "figure", "toys", "was", "released", "in", "2009"], "labels": ["O", "B-genre", "I-genre", "O", "O", "O", "B-plot", "I-plot", "I-plot", "O", "O", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, rating, trailer, title, year, genre, actor, average ratings, song, director, character, review and O.\nSentence: what live action movie based on action figure toys was released in 2009", "prompt_labels": "what(O) live(B-genre) action(I-genre) movie(O) based(O) on(O) action(B-plot) figure(I-plot) toys(I-plot) was(O) released(O) in(O) 2009(B-year)"}, "label_list": ["plot", "rating", "trailer", "title", "year", "genre", "actor", "average ratings", "song", "director", "character", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 10959, 11, 19809, 11, 2316, 11, 1060, 11, 17779, 11, 12360, 11, 5578, 18594, 11, 5609, 11, 7690, 11, 3752, 11, 3477, 323, 507, 627, 85664, 25, 1148, 3974, 1957, 5818, 3196, 389, 1957, 7216, 23939, 574, 6004, 304, 220, 1049, 24, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "222", "dataset": "crossner_music", "split": "dev", "prediction": "Music(O) critic(O) Richie(B-musical artist) Unterberger(I-musical artist) has(O) noted(O) that(O) the(O) commercial(O) success(O) of(O) the(O) Byrds(O) '(O) cover(O) version(O) of(O) Dylan(B-musical artist)'s(O) Mr.(B-song) Tambourine(I-song) Man(I-song),(O) along(O) with(O) Dylan(B-musical artist)'s(O) own(O) contributions(O) to(O) the(O) genre(O) on(O) the(O) albums(O) Bringing(B-album) It(I-album) All(I-album) Back(I-album) Home(I-album),(O) Highway(B-album) 61(I-album) Revisited(I-album),(O) and(O) Blonde(B-album) on(I-album) Blonde(I-album),(O) initiated(O) an(O) explosion(O) of(O) emulators(O) and(O) imitators(O).(O)", "instance": {"id": "222", "words": ["Music", "critic", "Richie", "Unterberger", "has", "noted", "that", "the", "commercial", "success", "of", "the", "Byrds", "'", "cover", "version", "of", "Dylan", "'s", "Mr.", "Tambourine", "Man", ",", "along", "with", "Dylan", "'s", "own", "contributions", "to", "the", "genre", "on", "the", "albums", "Bringing", "It", "All", "Back", "Home", ",", "Highway", "61", "Revisited", ",", "and", "Blonde", "on", "Blonde", ",", "initiated", "an", "explosion", "of", "emulators", "and", "imitators", "."], "labels": ["O", "O", "B-person", "I-person", "O", "O", "O", "O", "O", "O", "O", "O", "B-band", "O", "O", "O", "O", "B-musical artist", "O", "B-song", "I-song", "I-song", "O", "O", "O", "B-musical artist", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-album", "I-album", "I-album", "I-album", "I-album", "O", "B-album", "I-album", "I-album", "O", "O", "B-album", "I-album", "I-album", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, album, organization, award, musical instrument, person, musical artist, music genre, event, country, band, song and O.\nSentence: Music critic Richie Unterberger has noted that the commercial success of the Byrds ' cover version of Dylan 's Mr. Tambourine Man , along with Dylan 's own contributions to the genre on the albums Bringing It All Back Home , Highway 61 Revisited , and Blonde on Blonde , initiated an explosion of emulators and imitators .", "prompt_labels": "Music(O) critic(O) Richie(B-person) Unterberger(I-person) has(O) noted(O) that(O) the(O) commercial(O) success(O) of(O) the(O) Byrds(B-band) '(O) cover(O) version(O) of(O) Dylan(B-musical artist) 's(O) Mr.(B-song) Tambourine(I-song) Man(I-song) ,(O) along(O) with(O) Dylan(B-musical artist) 's(O) own(O) contributions(O) to(O) the(O) genre(O) on(O) the(O) albums(O) Bringing(B-album) It(I-album) All(I-album) Back(I-album) Home(I-album) ,(O) Highway(B-album) 61(I-album) Revisited(I-album) ,(O) and(O) Blonde(B-album) on(I-album) Blonde(I-album) ,(O) initiated(O) an(O) explosion(O) of(O) emulators(O) and(O) imitators(O) .(O)"}, "label_list": ["location", "album", "organization", "award", "musical instrument", "person", "musical artist", "music genre", "event", "country", "band", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 8176, 11, 7471, 11, 10292, 11, 18273, 14473, 11, 1732, 11, 18273, 10255, 11, 4731, 17779, 11, 1567, 11, 3224, 11, 7200, 11, 5609, 323, 507, 627, 85664, 25, 10948, 9940, 100074, 34412, 49120, 706, 10555, 430, 279, 8518, 2450, 315, 279, 3296, 81, 5469, 364, 3504, 2373, 315, 44458, 364, 82, 4491, 13, 59226, 414, 483, 2418, 1174, 3235, 449, 44458, 364, 82, 1866, 19564, 311, 279, 17779, 389, 279, 28785, 98173, 1102, 2052, 6984, 5492, 1174, 29866, 220, 5547, 1050, 29968, 1174, 323, 53556, 389, 53556, 1174, 33230, 459, 25176, 315, 991, 42391, 323, 737, 275, 3046, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2266", "dataset": "mit-movie", "split": "dev", "prediction": "when(O) did(O) the(O) movie(O) titled(O) b(B-title) girl(I-title) come(O) out(O)", "instance": {"id": "2266", "words": ["when", "did", "the", "movie", "titled", "b", "girl", "come", "out"], "labels": ["O", "O", "O", "O", "O", "B-title", "I-title", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, song, plot, actor, genre, average ratings, review, trailer, title, character, rating, year and O.\nSentence: when did the movie titled b girl come out", "prompt_labels": "when(O) did(O) the(O) movie(O) titled(O) b(B-title) girl(I-title) come(O) out(O)"}, "label_list": ["director", "song", "plot", "actor", "genre", "average ratings", "review", "trailer", "title", "character", "rating", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 5609, 11, 7234, 11, 12360, 11, 17779, 11, 5578, 18594, 11, 3477, 11, 19809, 11, 2316, 11, 3752, 11, 10959, 11, 1060, 323, 507, 627, 85664, 25, 994, 1550, 279, 5818, 25891, 293, 3828, 2586, 704, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1491", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) there(O) a(O) good(O) psychological(B-genre) drama(I-genre) bout(O) a(O) struggle(B-plot)", "instance": {"id": "1491", "words": ["is", "there", "a", "good", "psychological", "drama", "bout", "a", "struggle"], "labels": ["O", "O", "O", "O", "B-genre", "I-genre", "O", "O", "B-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, plot, genre, director, character, title, average ratings, song, trailer, rating, review, year and O.\nSentence: is there a good psychological drama bout a struggle", "prompt_labels": "is(O) there(O) a(O) good(O) psychological(B-genre) drama(I-genre) bout(O) a(O) struggle(B-plot)"}, "label_list": ["actor", "plot", "genre", "director", "character", "title", "average ratings", "song", "trailer", "rating", "review", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 7234, 11, 17779, 11, 7690, 11, 3752, 11, 2316, 11, 5578, 18594, 11, 5609, 11, 19809, 11, 10959, 11, 3477, 11, 1060, 323, 507, 627, 85664, 25, 374, 1070, 264, 1695, 24064, 20156, 25646, 264, 14993, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "98", "dataset": "mit-movie", "split": "dev", "prediction": "i(O) am(O) looking(O) for(O) a(O) movie(B-plot) about(I-plot) talking(I-plot) animals(I-plot)", "instance": {"id": "98", "words": ["i", "am", "looking", "for", "a", "movie", "about", "talking", "animals"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, rating, average ratings, plot, review, title, actor, character, song, year, trailer, genre and O.\nSentence: i am looking for a movie about talking animals", "prompt_labels": "i(O) am(O) looking(O) for(O) a(O) movie(O) about(O) talking(B-plot) animals(I-plot)"}, "label_list": ["director", "rating", "average ratings", "plot", "review", "title", "actor", "character", "song", "year", "trailer", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 10959, 11, 5578, 18594, 11, 7234, 11, 3477, 11, 2316, 11, 12360, 11, 3752, 11, 5609, 11, 1060, 11, 19809, 11, 17779, 323, 507, 627, 85664, 25, 602, 1097, 3411, 369, 264, 5818, 922, 7556, 10099, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "873", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) is(O) doing(O) the(O) soundtrack(B-song) for(O) prometheus(B-title)", "instance": {"id": "873", "words": ["who", "is", "doing", "the", "soundtrack", "for", "prometheus"], "labels": ["B-song", "I-song", "I-song", "I-song", "I-song", "I-song", "I-song"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, song, average ratings, title, year, character, review, genre, actor, rating, director, plot and O.\nSentence: who is doing the soundtrack for prometheus", "prompt_labels": "who(B-song) is(I-song) doing(I-song) the(I-song) soundtrack(I-song) for(I-song) prometheus(I-song)"}, "label_list": ["trailer", "song", "average ratings", "title", "year", "character", "review", "genre", "actor", "rating", "director", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 5609, 11, 5578, 18594, 11, 2316, 11, 1060, 11, 3752, 11, 3477, 11, 17779, 11, 12360, 11, 10959, 11, 7690, 11, 7234, 323, 507, 627, 85664, 25, 889, 374, 3815, 279, 45999, 369, 2773, 40805, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "533", "dataset": "mit-movie", "split": "dev", "prediction": "how(O) many(O) movies(O) did(O) bela(B-actor) lugosi(I-actor) appear(O) in(O)", "instance": {"id": "533", "words": ["how", "many", "movies", "did", "bela", "lugosi", "appear", "in"], "labels": ["O", "O", "O", "O", "B-actor", "I-actor", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, title, review, character, plot, genre, director, trailer, song, rating, actor, average ratings and O.\nSentence: how many movies did bela lugosi appear in", "prompt_labels": "how(O) many(O) movies(O) did(O) bela(B-actor) lugosi(I-actor) appear(O) in(O)"}, "label_list": ["year", "title", "review", "character", "plot", "genre", "director", "trailer", "song", "rating", "actor", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 2316, 11, 3477, 11, 3752, 11, 7234, 11, 17779, 11, 7690, 11, 19809, 11, 5609, 11, 10959, 11, 12360, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1268, 1690, 9698, 1550, 1689, 64, 54510, 31824, 5101, 304, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "212", "dataset": "crossner_music", "split": "dev", "prediction": "The(O) film(O) won(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Picture(I-award),(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Director(I-award) and(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Adapted(I-award) Screenplay(I-award),(O) and(O) Hopkins(B-person) also(O) picked(O) up(O) his(O) first(O) BAFTA(B-award) for(I-award) Best(I-award) Actor(I-award).(O)", "instance": {"id": "212", "words": ["The", "film", "won", "Academy", "Award", "for", "Best", "Picture", ",", "Academy", "Award", "for", "Best", "Director", "and", "Academy", "Award", "for", "Best", "Adapted", "Screenplay", ",", "and", "Hopkins", "also", "picked", "up", "his", "first", "BAFTA", "for", "Best", "Actor", "."], "labels": ["O", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O", "O", "B-person", "O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, band, album, event, organization, country, location, award, musical artist, person, music genre, song and O.\nSentence: The film won Academy Award for Best Picture , Academy Award for Best Director and Academy Award for Best Adapted Screenplay , and Hopkins also picked up his first BAFTA for Best Actor .", "prompt_labels": "The(O) film(O) won(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Picture(I-award) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Director(I-award) and(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Adapted(I-award) Screenplay(I-award) ,(O) and(O) Hopkins(B-person) also(O) picked(O) up(O) his(O) first(O) BAFTA(B-award) for(I-award) Best(I-award) Actor(I-award) .(O)"}, "label_list": ["musical instrument", "band", "album", "event", "organization", "country", "location", "award", "musical artist", "person", "music genre", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18273, 14473, 11, 7200, 11, 8176, 11, 1567, 11, 7471, 11, 3224, 11, 3813, 11, 10292, 11, 18273, 10255, 11, 1732, 11, 4731, 17779, 11, 5609, 323, 507, 627, 85664, 25, 578, 4632, 2834, 16192, 17768, 369, 7252, 25586, 1174, 16192, 17768, 369, 7252, 10783, 323, 16192, 17768, 369, 7252, 59531, 291, 14275, 1387, 1174, 323, 45316, 1101, 13061, 709, 813, 1176, 34589, 59512, 369, 7252, 25749, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "848", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movies(O) has(O) edward(B-actor) norton(I-actor) been(O) in(O)", "instance": {"id": "848", "words": ["what", "movies", "has", "edward", "norton", "been", "in"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, character, year, director, title, rating, actor, trailer, review, genre, song, plot and O.\nSentence: what movies has edward norton been in", "prompt_labels": "what(O) movies(O) has(O) edward(B-actor) norton(I-actor) been(O) in(O)"}, "label_list": ["average ratings", "character", "year", "director", "title", "rating", "actor", "trailer", "review", "genre", "song", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 3752, 11, 1060, 11, 7690, 11, 2316, 11, 10959, 11, 12360, 11, 19809, 11, 3477, 11, 17779, 11, 5609, 11, 7234, 323, 507, 627, 85664, 25, 1148, 9698, 706, 1608, 1637, 308, 38200, 1027, 304, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "296", "dataset": "crossner_literature", "split": "dev", "prediction": "In(O) 1947(O),(O) Capp(B-writer) earned(O) a(O) Newsweek(B-magazine) cover(O) story(O).(O)", "instance": {"id": "296", "words": ["In", "1947", ",", "Capp", "earned", "a", "Newsweek", "cover", "story", "."], "labels": ["O", "O", "O", "B-writer", "O", "O", "B-magazine", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, award, location, literary genre, event, poem, writer, person, country, organization, book and O.\nSentence: In 1947 , Capp earned a Newsweek cover story .", "prompt_labels": "In(O) 1947(O) ,(O) Capp(B-writer) earned(O) a(O) Newsweek(B-magazine) cover(O) story(O) .(O)"}, "label_list": ["magazine", "award", "location", "literary genre", "event", "poem", "writer", "person", "country", "organization", "book"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 14756, 11, 10292, 11, 3813, 11, 32465, 17779, 11, 1567, 11, 33894, 11, 7061, 11, 1732, 11, 3224, 11, 7471, 11, 2363, 323, 507, 627, 85664, 25, 763, 220, 6393, 22, 1174, 356, 680, 15662, 264, 5513, 10476, 3504, 3446, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "341", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) directed(O) blazing(B-title) saddles(I-title)", "instance": {"id": "341", "words": ["who", "directed", "blazing", "saddles"], "labels": ["O", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, genre, average ratings, plot, song, rating, character, title, trailer, actor, review, year and O.\nSentence: who directed blazing saddles", "prompt_labels": "who(O) directed(O) blazing(B-title) saddles(I-title)"}, "label_list": ["director", "genre", "average ratings", "plot", "song", "rating", "character", "title", "trailer", "actor", "review", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 17779, 11, 5578, 18594, 11, 7234, 11, 5609, 11, 10959, 11, 3752, 11, 2316, 11, 19809, 11, 12360, 11, 3477, 11, 1060, 323, 507, 627, 85664, 25, 889, 15910, 86350, 58272, 645, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2246", "dataset": "mit-movie", "split": "dev", "prediction": "whats(O) fright(B-title) night(I-title) about(O)", "instance": {"id": "2246", "words": ["whats", "fright", "night", "about"], "labels": ["O", "B-title", "I-title", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, average ratings, trailer, character, year, title, director, plot, actor, song, review, genre and O.\nSentence: whats fright night about", "prompt_labels": "whats(O) fright(B-title) night(I-title) about(O)"}, "label_list": ["rating", "average ratings", "trailer", "character", "year", "title", "director", "plot", "actor", "song", "review", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 5578, 18594, 11, 19809, 11, 3752, 11, 1060, 11, 2316, 11, 7690, 11, 7234, 11, 12360, 11, 5609, 11, 3477, 11, 17779, 323, 507, 627, 85664, 25, 41209, 30647, 3814, 922, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2147", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movies(O) has(O) david(B-director) lean(I-director) directed(O)", "instance": {"id": "2147", "words": ["what", "movies", "has", "david", "lean", "directed"], "labels": ["O", "O", "O", "B-director", "I-director", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, rating, title, song, character, year, review, average ratings, plot, actor, genre, trailer and O.\nSentence: what movies has david lean directed", "prompt_labels": "what(O) movies(O) has(O) david(B-director) lean(I-director) directed(O)"}, "label_list": ["director", "rating", "title", "song", "character", "year", "review", "average ratings", "plot", "actor", "genre", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 10959, 11, 2316, 11, 5609, 11, 3752, 11, 1060, 11, 3477, 11, 5578, 18594, 11, 7234, 11, 12360, 11, 17779, 11, 19809, 323, 507, 627, 85664, 25, 1148, 9698, 706, 55046, 16025, 15910, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "97", "dataset": "crossner_ai", "split": "dev", "prediction": "The(O) back-of-the-envelope(O) calculations(O) by(O) Doug(B-researcher),(O) Alan(B-researcher),(O) and(O) their(O) colleagues(O) ((O) including(O) Marvin(B-researcher) Minsky(I-researcher),(O) Allen(B-researcher) Newell(I-researcher),(O) Edward(B-researcher) Feigenbaum(I-researcher),(O) and(O) John(B-researcher) McCarthy(I-researcher) )(O) indicated(O) that(O) that(O) effort(O) would(O) require(O) between(O) 1000(O) and(O) 3000(O) person-years(O) of(O) effort(O),(O) far(O) beyond(O) the(O) standard(O) academic(O) project(O) model(O).(O)", "instance": {"id": "97", "words": ["The", "back-of-the-envelope", "calculations", "by", "Doug", ",", "Alan", ",", "and", "their", "colleagues", "(", "including", "Marvin", "Minsky", ",", "Allen", "Newell", ",", "Edward", "Feigenbaum", ",", "and", "John", "McCarthy", ")", "indicated", "that", "that", "effort", "would", "require", "between", "1000", "and", "3000", "person-years", "of", "effort", ",", "far", "beyond", "the", "standard", "academic", "project", "model", "."], "labels": ["O", "O", "O", "O", "B-researcher", "O", "B-researcher", "O", "O", "O", "O", "O", "O", "B-researcher", "I-researcher", "O", "B-researcher", "I-researcher", "O", "B-researcher", "I-researcher", "O", "O", "B-researcher", "I-researcher", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: metric, product, programming language, university, organization, conference, country, person, algorithm, task, researcher, location, field and O.\nSentence: The back-of-the-envelope calculations by Doug , Alan , and their colleagues ( including Marvin Minsky , Allen Newell , Edward Feigenbaum , and John McCarthy ) indicated that that effort would require between 1000 and 3000 person-years of effort , far beyond the standard academic project model .", "prompt_labels": "The(O) back-of-the-envelope(O) calculations(O) by(O) Doug(B-researcher) ,(O) Alan(B-researcher) ,(O) and(O) their(O) colleagues(O) ((O) including(O) Marvin(B-researcher) Minsky(I-researcher) ,(O) Allen(B-researcher) Newell(I-researcher) ,(O) Edward(B-researcher) Feigenbaum(I-researcher) ,(O) and(O) John(B-researcher) McCarthy(I-researcher) )(O) indicated(O) that(O) that(O) effort(O) would(O) require(O) between(O) 1000(O) and(O) 3000(O) person-years(O) of(O) effort(O) ,(O) far(O) beyond(O) the(O) standard(O) academic(O) project(O) model(O) .(O)"}, "label_list": ["metric", "product", "programming language", "university", "organization", "conference", "country", "person", "algorithm", "task", "researcher", "location", "field"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18767, 11, 2027, 11, 15840, 4221, 11, 12374, 11, 7471, 11, 10017, 11, 3224, 11, 1732, 11, 12384, 11, 3465, 11, 32185, 11, 3813, 11, 2115, 323, 507, 627, 85664, 25, 578, 1203, 8838, 10826, 64625, 29217, 555, 32608, 1174, 26349, 1174, 323, 872, 18105, 320, 2737, 74626, 386, 52541, 1174, 20661, 1561, 616, 1174, 22653, 3926, 6569, 59611, 1174, 323, 3842, 45040, 883, 16717, 430, 430, 5149, 1053, 1397, 1990, 220, 1041, 15, 323, 220, 3101, 15, 1732, 57188, 315, 5149, 1174, 3117, 7953, 279, 5410, 14584, 2447, 1646, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "565", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) have(O) an(O) important(O) business(O) luncheon(O) and(O) need(O) to(O) find(O) a(O) place(O) that(O) caters(B-Amenity) to(O) professionals(B-Amenity)", "instance": {"id": "565", "words": ["i", "have", "an", "important", "business", "luncheon", "and", "need", "to", "find", "a", "place", "that", "caters", "to", "professionals"], "labels": ["O", "O", "O", "O", "B-Amenity", "B-Hours", "O", "O", "O", "O", "O", "O", "O", "B-Amenity", "I-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Price, Hours, Rating, Location, Cuisine, Dish, Restaurant Name and O.\nSentence: i have an important business luncheon and need to find a place that caters to professionals", "prompt_labels": "i(O) have(O) an(O) important(O) business(B-Amenity) luncheon(B-Hours) and(O) need(O) to(O) find(O) a(O) place(O) that(O) caters(B-Amenity) to(I-Amenity) professionals(I-Amenity)"}, "label_list": ["Amenity", "Price", "Hours", "Rating", "Location", "Cuisine", "Dish", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 8650, 11, 30192, 11, 19767, 11, 10067, 11, 81961, 11, 49268, 11, 26568, 4076, 323, 507, 627, 85664, 25, 602, 617, 459, 3062, 2626, 33073, 76269, 323, 1205, 311, 1505, 264, 2035, 430, 8415, 388, 311, 15749, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "56", "dataset": "mit-restaurant", "split": "dev", "prediction": "are(O) there(O) any(O) locally(B-Amenity) owned(I-Amenity) franchises(O) that(O) give(B-Amenity) money(I-Amenity) to(I-Amenity) charity(I-Amenity)", "instance": {"id": "56", "words": ["are", "there", "any", "locally", "owned", "franchises", "that", "give", "money", "to", "charity"], "labels": ["O", "O", "O", "B-Amenity", "I-Amenity", "O", "O", "B-Amenity", "I-Amenity", "I-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Amenity, Restaurant Name, Price, Cuisine, Dish, Hours, Location and O.\nSentence: are there any locally owned franchises that give money to charity", "prompt_labels": "are(O) there(O) any(O) locally(B-Amenity) owned(I-Amenity) franchises(O) that(O) give(B-Amenity) money(I-Amenity) to(I-Amenity) charity(I-Amenity)"}, "label_list": ["Rating", "Amenity", "Restaurant Name", "Price", "Cuisine", "Dish", "Hours", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 3383, 56685, 11, 26568, 4076, 11, 8650, 11, 81961, 11, 49268, 11, 30192, 11, 10067, 323, 507, 627, 85664, 25, 527, 1070, 904, 24392, 13234, 65003, 430, 3041, 3300, 311, 23693, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "732", "dataset": "mit-movie", "split": "dev", "prediction": "are(O) there(O) any(O) musicals(B-genre) from(O) the(O) 1990s(B-year)", "instance": {"id": "732", "words": ["are", "there", "any", "musicals", "from", "the", "1990s"], "labels": ["O", "O", "O", "O", "O", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, trailer, average ratings, title, song, year, actor, director, rating, genre, review, plot and O.\nSentence: are there any musicals from the 1990s", "prompt_labels": "are(O) there(O) any(O) musicals(O) from(O) the(O) 1990s(B-year)"}, "label_list": ["character", "trailer", "average ratings", "title", "song", "year", "actor", "director", "rating", "genre", "review", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 19809, 11, 5578, 18594, 11, 2316, 11, 5609, 11, 1060, 11, 12360, 11, 7690, 11, 10959, 11, 17779, 11, 3477, 11, 7234, 323, 507, 627, 85664, 25, 527, 1070, 904, 18273, 82, 505, 279, 220, 2550, 15, 82, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "180", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movie(O) stars(O) reese(B-actor) witherspoon(I-actor) in(O) 2004(B-year)", "instance": {"id": "180", "words": ["what", "movie", "stars", "reese", "witherspoon", "in", "2004"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, plot, character, rating, average ratings, song, actor, title, trailer, year, review, director and O.\nSentence: what movie stars reese witherspoon in 2004", "prompt_labels": "what(O) movie(O) stars(O) reese(B-actor) witherspoon(I-actor) in(O) 2004(B-year)"}, "label_list": ["genre", "plot", "character", "rating", "average ratings", "song", "actor", "title", "trailer", "year", "review", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 7234, 11, 3752, 11, 10959, 11, 5578, 18594, 11, 5609, 11, 12360, 11, 2316, 11, 19809, 11, 1060, 11, 3477, 11, 7690, 323, 507, 627, 85664, 25, 1148, 5818, 9958, 312, 2423, 449, 388, 33076, 304, 220, 1049, 19, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "245", "dataset": "crossner_music", "split": "dev", "prediction": "In(O) the(O) 1970s(O) and(O) 1980s(O),(O) tension(O) and(O) conflict(O) emerged(O) between(O) Southern(B-music genre) gospel(I-music genre) and(O) the(O) newer(O) developments(O) of(O) Jesus(B-music genre) music(I-music genre) and(O) Contemporary(B-music genre) Christian(I-music genre) music(I-music genre).(O)", "instance": {"id": "245", "words": ["In", "the", "1970s", "and", "1980s", ",", "tension", "and", "conflict", "emerged", "between", "Southern", "gospel", "and", "the", "newer", "developments", "of", "Jesus", "music", "and", "Contemporary", "Christian", "music", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-music genre", "I-music genre", "O", "O", "O", "O", "O", "B-music genre", "I-music genre", "O", "B-music genre", "I-music genre", "I-music genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, country, song, band, musical artist, event, organization, album, musical instrument, person, location, music genre and O.\nSentence: In the 1970s and 1980s , tension and conflict emerged between Southern gospel and the newer developments of Jesus music and Contemporary Christian music .", "prompt_labels": "In(O) the(O) 1970s(O) and(O) 1980s(O) ,(O) tension(O) and(O) conflict(O) emerged(O) between(O) Southern(B-music genre) gospel(I-music genre) and(O) the(O) newer(O) developments(O) of(O) Jesus(B-music genre) music(I-music genre) and(O) Contemporary(B-music genre) Christian(I-music genre) music(I-music genre) .(O)"}, "label_list": ["award", "country", "song", "band", "musical artist", "event", "organization", "album", "musical instrument", "person", "location", "music genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10292, 11, 3224, 11, 5609, 11, 7200, 11, 18273, 10255, 11, 1567, 11, 7471, 11, 8176, 11, 18273, 14473, 11, 1732, 11, 3813, 11, 4731, 17779, 323, 507, 627, 85664, 25, 763, 279, 220, 4468, 15, 82, 323, 220, 3753, 15, 82, 1174, 24408, 323, 12324, 22763, 1990, 16642, 42582, 323, 279, 26627, 26006, 315, 10811, 4731, 323, 48302, 9052, 4731, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "188", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) dramas(B-genre) about(O) the(O) british(B-plot) royal(I-plot) family(I-plot)", "instance": {"id": "188", "words": ["show", "me", "dramas", "about", "the", "british", "royal", "family"], "labels": ["O", "O", "B-genre", "O", "O", "B-plot", "I-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, rating, review, character, actor, year, song, genre, average ratings, title, director, trailer and O.\nSentence: show me dramas about the british royal family", "prompt_labels": "show(O) me(O) dramas(B-genre) about(O) the(O) british(B-plot) royal(I-plot) family(I-plot)"}, "label_list": ["plot", "rating", "review", "character", "actor", "year", "song", "genre", "average ratings", "title", "director", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 10959, 11, 3477, 11, 3752, 11, 12360, 11, 1060, 11, 5609, 11, 17779, 11, 5578, 18594, 11, 2316, 11, 7690, 11, 19809, 323, 507, 627, 85664, 25, 1501, 757, 88826, 922, 279, 95027, 30336, 3070, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1674", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) an(O) emotional(B-genre) movie(O) during(O) the(O) year(O) 1990(B-year) s(I-year)", "instance": {"id": "1674", "words": ["list", "an", "emotional", "movie", "during", "the", "year", "1990", "s"], "labels": ["O", "O", "B-genre", "O", "O", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, title, rating, year, director, average ratings, genre, actor, character, plot, trailer, review and O.\nSentence: list an emotional movie during the year 1990 s", "prompt_labels": "list(O) an(O) emotional(B-genre) movie(O) during(O) the(O) year(O) 1990(B-year) s(I-year)"}, "label_list": ["song", "title", "rating", "year", "director", "average ratings", "genre", "actor", "character", "plot", "trailer", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 2316, 11, 10959, 11, 1060, 11, 7690, 11, 5578, 18594, 11, 17779, 11, 12360, 11, 3752, 11, 7234, 11, 19809, 11, 3477, 323, 507, 627, 85664, 25, 1160, 459, 14604, 5818, 2391, 279, 1060, 220, 2550, 15, 274, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "610", "dataset": "mit-movie", "split": "dev", "prediction": "find(O) the(O) air(B-title) bud(I-title) movie(O) about(O) baseball(B-plot)", "instance": {"id": "610", "words": ["find", "the", "air", "bud", "movie", "about", "baseball"], "labels": ["O", "O", "B-character", "I-character", "O", "O", "B-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, genre, year, song, character, average ratings, trailer, director, plot, rating, actor, title and O.\nSentence: find the air bud movie about baseball", "prompt_labels": "find(O) the(O) air(B-character) bud(I-character) movie(O) about(O) baseball(B-plot)"}, "label_list": ["review", "genre", "year", "song", "character", "average ratings", "trailer", "director", "plot", "rating", "actor", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 17779, 11, 1060, 11, 5609, 11, 3752, 11, 5578, 18594, 11, 19809, 11, 7690, 11, 7234, 11, 10959, 11, 12360, 11, 2316, 323, 507, 627, 85664, 25, 1505, 279, 3805, 37808, 5818, 922, 20075, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1432", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) is(O) the(O) nearest(B-Location) chinese(B-Cuisine) restaurant(O) with(O) more(B-Rating) than(I-Rating) 3(I-Rating) stars(I-Rating) that(O) is(O) under(B-Price) 10(I-Price) an(O) entree(O)", "instance": {"id": "1432", "words": ["where", "is", "the", "nearest", "chinese", "restaurant", "with", "more", "than", "3", "stars", "that", "is", "under", "10", "an", "entree"], "labels": ["O", "O", "O", "B-Location", "B-Cuisine", "O", "O", "B-Rating", "I-Rating", "I-Rating", "I-Rating", "O", "O", "B-Price", "I-Price", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Rating, Amenity, Location, Dish, Restaurant Name, Price, Hours and O.\nSentence: where is the nearest chinese restaurant with more than 3 stars that is under 10 an entree", "prompt_labels": "where(O) is(O) the(O) nearest(B-Location) chinese(B-Cuisine) restaurant(O) with(O) more(B-Rating) than(I-Rating) 3(I-Rating) stars(I-Rating) that(O) is(O) under(B-Price) 10(I-Price) an(O) entree(O)"}, "label_list": ["Cuisine", "Rating", "Amenity", "Location", "Dish", "Restaurant Name", "Price", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 19767, 11, 3383, 56685, 11, 10067, 11, 49268, 11, 26568, 4076, 11, 8650, 11, 30192, 323, 507, 627, 85664, 25, 1405, 374, 279, 24379, 57487, 10960, 449, 810, 1109, 220, 18, 9958, 430, 374, 1234, 220, 605, 459, 1218, 770, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "299", "dataset": "crossner_science", "split": "dev", "prediction": "A(O) Chamberland(O) filter(O),(O) also(O) known(O) as(O) a(O) Louis(B-scientist) Pasteur(I-scientist) -Chamberland(O) filter(O),(O) is(O) a(O) porcelain(O) water(O) filter(O) invented(O) by(O) Charles(B-scientist) Chamberland(I-scientist) in(O) 1884(O).(O)", "instance": {"id": "299", "words": ["A", "Chamberland", "filter", ",", "also", "known", "as", "a", "Louis", "Pasteur", "-Chamberland", "filter", ",", "is", "a", "porcelain", "water", "filter", "invented", "by", "Charles", "Chamberland", "in", "1884", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-scientist", "I-scientist", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, chemical element, enzyme, organization, theory, scientist, person, academic journal, astronomical object, location, award, country, university, event, discipline, protein and O.\nSentence: A Chamberland filter , also known as a Louis Pasteur -Chamberland filter , is a porcelain water filter invented by Charles Chamberland in 1884 .", "prompt_labels": "A(O) Chamberland(O) filter(O) ,(O) also(O) known(O) as(O) a(O) Louis(O) Pasteur(O) -Chamberland(O) filter(O) ,(O) is(O) a(O) porcelain(O) water(O) filter(O) invented(O) by(O) Charles(B-scientist) Chamberland(I-scientist) in(O) 1884(O) .(O)"}, "label_list": ["chemical compound", "chemical element", "enzyme", "organization", "theory", "scientist", "person", "academic journal", "astronomical object", "location", "award", "country", "university", "event", "discipline", "protein"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 11742, 24549, 11, 11742, 2449, 11, 49242, 11, 7471, 11, 10334, 11, 28568, 11, 1732, 11, 14584, 8486, 11, 87283, 1665, 11, 3813, 11, 10292, 11, 3224, 11, 12374, 11, 1567, 11, 26434, 11, 13128, 323, 507, 627, 85664, 25, 362, 32479, 1974, 4141, 1174, 1101, 3967, 439, 264, 12140, 58325, 324, 482, 1163, 15578, 1974, 4141, 1174, 374, 264, 78742, 3090, 4141, 36592, 555, 15274, 32479, 1974, 304, 220, 9367, 19, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "233", "dataset": "crossner_ai", "split": "dev", "prediction": "This(O) was(O) won(O) by(O) an(O) United(B-country) States(I-country) team(O) from(O) Newton(B-organization) Labs(I-organization),(O) and(O) the(O) competition(O) was(O) shown(O) on(O) CNN(O).(O)", "instance": {"id": "233", "words": ["This", "was", "won", "by", "an", "United", "States", "team", "from", "Newton", "Labs", ",", "and", "the", "competition", "was", "shown", "on", "CNN", "."], "labels": ["O", "O", "O", "O", "O", "B-country", "I-country", "O", "O", "B-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "B-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, country, university, location, conference, algorithm, field, metric, product, programming language, person, researcher, task and O.\nSentence: This was won by an United States team from Newton Labs , and the competition was shown on CNN .", "prompt_labels": "This(O) was(O) won(O) by(O) an(O) United(B-country) States(I-country) team(O) from(O) Newton(B-organization) Labs(I-organization) ,(O) and(O) the(O) competition(O) was(O) shown(O) on(O) CNN(B-organization) .(O)"}, "label_list": ["organization", "country", "university", "location", "conference", "algorithm", "field", "metric", "product", "programming language", "person", "researcher", "task"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 3224, 11, 12374, 11, 3813, 11, 10017, 11, 12384, 11, 2115, 11, 18767, 11, 2027, 11, 15840, 4221, 11, 1732, 11, 32185, 11, 3465, 323, 507, 627, 85664, 25, 1115, 574, 2834, 555, 459, 3723, 4273, 2128, 505, 21324, 41740, 1174, 323, 279, 10937, 574, 6982, 389, 20352, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "256", "dataset": "crossner_literature", "split": "dev", "prediction": "In(O) 1946(O),(O) she(O) was(O) awarded(O) a(O) Guggenheim(B-award) Fellowship(I-award) for(I-award) Creative(I-award) Work(I-award) in(I-award) the(I-award) Field(I-award) of(I-award) Motion(I-award) Pictures(I-award),(O) and(O) won(O) the(O) Grand(B-award) Prix(I-award) Internationale(I-award) for(I-award) 16mm(I-award) experimental(I-award) film(I-award) at(O) the(O) Cannes(B-event) Film(I-event) Festival(I-event) for(O) Meshes(B-book) of(I-book) the(I-book) Afternoon(I-book) ((O) 1943(O) )(O).(O)", "instance": {"id": "256", "words": ["In", "1946", ",", "she", "was", "awarded", "a", "Guggenheim", "Fellowship", "for", "Creative", "Work", "in", "the", "Field", "of", "Motion", "Pictures", ",", "and", "won", "the", "Grand", "Prix", "Internationale", "for", "16mm", "experimental", "film", "at", "the", "Cannes", "Film", "Festival", "for", "Meshes", "of", "the", "Afternoon", "(", "1943", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O", "O", "O", "O", "B-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, magazine, literary genre, person, book, location, writer, award, country, organization, poem and O.\nSentence: In 1946 , she was awarded a Guggenheim Fellowship for Creative Work in the Field of Motion Pictures , and won the Grand Prix Internationale for 16mm experimental film at the Cannes Film Festival for Meshes of the Afternoon ( 1943 ) .", "prompt_labels": "In(O) 1946(O) ,(O) she(O) was(O) awarded(O) a(O) Guggenheim(B-award) Fellowship(I-award) for(I-award) Creative(I-award) Work(I-award) in(I-award) the(I-award) Field(I-award) of(I-award) Motion(I-award) Pictures(I-award) ,(O) and(O) won(O) the(O) Grand(B-award) Prix(I-award) Internationale(O) for(O) 16mm(O) experimental(O) film(O) at(O) the(O) Cannes(B-event) Film(I-event) Festival(I-event) for(O) Meshes(O) of(O) the(O) Afternoon(O) ((O) 1943(O) )(O) .(O)"}, "label_list": ["event", "magazine", "literary genre", "person", "book", "location", "writer", "award", "country", "organization", "poem"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 14756, 11, 32465, 17779, 11, 1732, 11, 2363, 11, 3813, 11, 7061, 11, 10292, 11, 3224, 11, 7471, 11, 33894, 323, 507, 627, 85664, 25, 763, 220, 6393, 21, 1174, 1364, 574, 22034, 264, 480, 2661, 92710, 65742, 369, 25248, 5664, 304, 279, 8771, 315, 27660, 29485, 1174, 323, 2834, 279, 10517, 44394, 4514, 38135, 369, 220, 845, 3906, 22772, 4632, 520, 279, 84620, 17042, 17772, 369, 26179, 288, 315, 279, 4740, 12684, 320, 220, 6393, 18, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "474", "dataset": "crossner_politics", "split": "dev", "prediction": "The(O) USSR(B-country) anti-religious(O) campaign(O) of(O) 1928-1941(O) was(O) a(O) new(O) phase(O) of(O) anti-religious(O) campaign(O) in(O) the(O) Soviet(B-country) Union(I-country) following(O) the(O) anti-religious(O) campaign(O) of(O) 1921-1928(O).(O)", "instance": {"id": "474", "words": ["The", "USSR", "anti-religious", "campaign", "of", "1928-1941", "was", "a", "new", "phase", "of", "anti-religious", "campaign", "in", "the", "Soviet", "Union", "following", "the", "anti-religious", "campaign", "of", "1921-1928", "."], "labels": ["O", "B-event", "I-event", "I-event", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-country", "I-country", "O", "O", "B-event", "I-event", "I-event", "I-event", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, election, organization, political party, country, person, politician, location and O.\nSentence: The USSR anti-religious campaign of 1928-1941 was a new phase of anti-religious campaign in the Soviet Union following the anti-religious campaign of 1921-1928 .", "prompt_labels": "The(O) USSR(B-event) anti-religious(I-event) campaign(I-event) of(O) 1928-1941(O) was(O) a(O) new(O) phase(O) of(O) anti-religious(O) campaign(O) in(O) the(O) Soviet(B-country) Union(I-country) following(O) the(O) anti-religious(B-event) campaign(I-event) of(I-event) 1921-1928(I-event) .(O)"}, "label_list": ["event", "election", "organization", "political party", "country", "person", "politician", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 6355, 11, 7471, 11, 5054, 4717, 11, 3224, 11, 1732, 11, 37038, 11, 3813, 323, 507, 627, 85664, 25, 578, 73315, 7294, 48712, 22941, 4901, 315, 220, 5926, 23, 12, 6393, 16, 574, 264, 502, 10474, 315, 7294, 48712, 22941, 4901, 304, 279, 19953, 9323, 2768, 279, 7294, 48712, 22941, 4901, 315, 220, 5926, 16, 12, 5926, 23, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "750", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) an(O) action(B-genre) movie(O) starring(O) clint(B-actor) eastwood(I-actor)", "instance": {"id": "750", "words": ["show", "me", "an", "action", "movie", "starring", "clint", "eastwood"], "labels": ["O", "O", "O", "B-genre", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, year, title, song, actor, character, director, trailer, average ratings, review, genre, rating and O.\nSentence: show me an action movie starring clint eastwood", "prompt_labels": "show(O) me(O) an(O) action(B-genre) movie(O) starring(O) clint(B-actor) eastwood(I-actor)"}, "label_list": ["plot", "year", "title", "song", "actor", "character", "director", "trailer", "average ratings", "review", "genre", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 1060, 11, 2316, 11, 5609, 11, 12360, 11, 3752, 11, 7690, 11, 19809, 11, 5578, 18594, 11, 3477, 11, 17779, 11, 10959, 323, 507, 627, 85664, 25, 1501, 757, 459, 1957, 5818, 40500, 1206, 396, 11226, 6798, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1416", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) is(O) the(O) closest(B-Location) pizza(B-Restaurant Name) hut(I-Restaurant Name)", "instance": {"id": "1416", "words": ["where", "is", "the", "closest", "pizza", "hut"], "labels": ["O", "O", "O", "B-Location", "B-Restaurant Name", "I-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Restaurant Name, Price, Location, Cuisine, Dish, Hours, Amenity and O.\nSentence: where is the closest pizza hut", "prompt_labels": "where(O) is(O) the(O) closest(B-Location) pizza(B-Restaurant Name) hut(I-Restaurant Name)"}, "label_list": ["Rating", "Restaurant Name", "Price", "Location", "Cuisine", "Dish", "Hours", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 26568, 4076, 11, 8650, 11, 10067, 11, 81961, 11, 49268, 11, 30192, 11, 3383, 56685, 323, 507, 627, 85664, 25, 1405, 374, 279, 18585, 23317, 76979, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "51", "dataset": "crossner_music", "split": "dev", "prediction": "This(O) album(O) featured(O) vocal(O) contributions(O) by(O) Vicotnik(B-song) of(O) Ved(B-location) Buens(I-location) Ende(I-location) and(O) D\u00f8dheimsgard(B-song) and(O) Aldrahn(B-song) of(O) D\u00f8dheimsgard(O) and(O) Zyklon-B(B-song).(O)", "instance": {"id": "51", "words": ["This", "album", "featured", "vocal", "contributions", "by", "Vicotnik", "of", "Ved", "Buens", "Ende", "and", "D\u00f8dheimsgard", "and", "Aldrahn", "of", "D\u00f8dheimsgard", "and", "Zyklon-B", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-musical artist", "O", "B-band", "I-band", "I-band", "O", "B-band", "O", "B-musical artist", "O", "B-band", "O", "B-band", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, song, band, organization, country, music genre, album, musical artist, award, location, event, person and O.\nSentence: This album featured vocal contributions by Vicotnik of Ved Buens Ende and D\u00f8dheimsgard and Aldrahn of D\u00f8dheimsgard and Zyklon-B .", "prompt_labels": "This(O) album(O) featured(O) vocal(O) contributions(O) by(O) Vicotnik(B-musical artist) of(O) Ved(B-band) Buens(I-band) Ende(I-band) and(O) D\u00f8dheimsgard(B-band) and(O) Aldrahn(B-musical artist) of(O) D\u00f8dheimsgard(B-band) and(O) Zyklon-B(B-band) .(O)"}, "label_list": ["musical instrument", "song", "band", "organization", "country", "music genre", "album", "musical artist", "award", "location", "event", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18273, 14473, 11, 5609, 11, 7200, 11, 7471, 11, 3224, 11, 4731, 17779, 11, 8176, 11, 18273, 10255, 11, 10292, 11, 3813, 11, 1567, 11, 1732, 323, 507, 627, 85664, 25, 1115, 8176, 15109, 26480, 19564, 555, 44847, 354, 22212, 315, 75887, 28326, 729, 52392, 323, 423, 75820, 21215, 2034, 569, 323, 31447, 969, 25105, 315, 423, 75820, 21215, 2034, 569, 323, 87654, 10784, 263, 7826, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "844", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) a(O) place(O) to(O) eat(O) in(O) the(O) abington(B-Location) theatre(I-Location) district(I-Location) open(B-Hours) after(I-Hours) midnight(I-Hours)", "instance": {"id": "844", "words": ["is", "there", "a", "place", "to", "eat", "in", "the", "abington", "theatre", "district", "open", "after", "midnight"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-Location", "I-Location", "I-Location", "O", "B-Hours", "I-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Rating, Location, Hours, Dish, Restaurant Name, Cuisine, Amenity and O.\nSentence: is there a place to eat in the abington theatre district open after midnight", "prompt_labels": "is(O) there(O) a(O) place(O) to(O) eat(O) in(O) the(O) abington(B-Location) theatre(I-Location) district(I-Location) open(O) after(B-Hours) midnight(I-Hours)"}, "label_list": ["Price", "Rating", "Location", "Hours", "Dish", "Restaurant Name", "Cuisine", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 19767, 11, 10067, 11, 30192, 11, 49268, 11, 26568, 4076, 11, 81961, 11, 3383, 56685, 323, 507, 627, 85664, 25, 374, 1070, 264, 2035, 311, 8343, 304, 279, 671, 4910, 34596, 9474, 1825, 1306, 33433, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "16", "dataset": "crossner_literature", "split": "dev", "prediction": "His(O) works(O) include(O) not(O) only(O) science(B-literary genre) fiction(I-literary genre),(O) but(O) also(O) articles(O) for(O) Playboy(B-magazine) and(O) Family(B-magazine) Circle(I-magazine) magazines(O) and(O) nonfiction(O) books(O).(O)", "instance": {"id": "16", "words": ["His", "works", "include", "not", "only", "science", "fiction", ",", "but", "also", "articles", "for", "Playboy", "and", "Family", "Circle", "magazines", "and", "nonfiction", "books", "."], "labels": ["O", "O", "O", "O", "O", "B-literary genre", "I-literary genre", "O", "O", "O", "O", "O", "B-magazine", "O", "B-magazine", "I-magazine", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, award, book, writer, person, location, poem, literary genre, magazine, event, country and O.\nSentence: His works include not only science fiction , but also articles for Playboy and Family Circle magazines and nonfiction books .", "prompt_labels": "His(O) works(O) include(O) not(O) only(O) science(B-literary genre) fiction(I-literary genre) ,(O) but(O) also(O) articles(O) for(O) Playboy(B-magazine) and(O) Family(B-magazine) Circle(I-magazine) magazines(O) and(O) nonfiction(O) books(O) .(O)"}, "label_list": ["organization", "award", "book", "writer", "person", "location", "poem", "literary genre", "magazine", "event", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 10292, 11, 2363, 11, 7061, 11, 1732, 11, 3813, 11, 33894, 11, 32465, 17779, 11, 14756, 11, 1567, 11, 3224, 323, 507, 627, 85664, 25, 5414, 4375, 2997, 539, 1193, 8198, 17422, 1174, 719, 1101, 9908, 369, 91079, 323, 12517, 21918, 32947, 323, 2536, 58162, 6603, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1036", "dataset": "mit-restaurant", "split": "dev", "prediction": "please(O) name(O) all(O) restaurants(O) that(O) offer(O) curb(B-Amenity) side(I-Amenity) pick(I-Amenity) up(I-Amenity) on(O) highway(B-Location) 43(I-Location) south(I-Location)", "instance": {"id": "1036", "words": ["please", "name", "all", "restaurants", "that", "offer", "curb", "side", "pick", "up", "on", "highway", "43", "south"], "labels": ["O", "O", "O", "O", "O", "O", "B-Amenity", "I-Amenity", "I-Amenity", "I-Amenity", "O", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Amenity, Restaurant Name, Cuisine, Price, Location, Dish, Hours and O.\nSentence: please name all restaurants that offer curb side pick up on highway 43 south", "prompt_labels": "please(O) name(O) all(O) restaurants(O) that(O) offer(O) curb(B-Amenity) side(I-Amenity) pick(I-Amenity) up(I-Amenity) on(O) highway(B-Location) 43(I-Location) south(I-Location)"}, "label_list": ["Rating", "Amenity", "Restaurant Name", "Cuisine", "Price", "Location", "Dish", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 3383, 56685, 11, 26568, 4076, 11, 81961, 11, 8650, 11, 10067, 11, 49268, 11, 30192, 323, 507, 627, 85664, 25, 4587, 836, 682, 15926, 430, 3085, 44962, 3185, 3820, 709, 389, 27834, 220, 3391, 10007, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "427", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) are(O) some(O) funny(B-review) betty(B-actor) white(I-actor) movies(O)", "instance": {"id": "427", "words": ["what", "are", "some", "funny", "betty", "white", "movies"], "labels": ["O", "O", "O", "B-genre", "B-actor", "I-actor", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, genre, average ratings, character, rating, trailer, year, review, actor, title, director, plot and O.\nSentence: what are some funny betty white movies", "prompt_labels": "what(O) are(O) some(O) funny(B-genre) betty(B-actor) white(I-actor) movies(O)"}, "label_list": ["song", "genre", "average ratings", "character", "rating", "trailer", "year", "review", "actor", "title", "director", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 17779, 11, 5578, 18594, 11, 3752, 11, 10959, 11, 19809, 11, 1060, 11, 3477, 11, 12360, 11, 2316, 11, 7690, 11, 7234, 323, 507, 627, 85664, 25, 1148, 527, 1063, 15526, 1297, 1919, 4251, 9698, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1094", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) are(O) the(O) average(O) prices(O) for(O) lunch(O) at(O) mikanos(B-Restaurant Name)", "instance": {"id": "1094", "words": ["what", "are", "the", "average", "prices", "for", "lunch", "at", "mikanos"], "labels": ["O", "O", "O", "O", "O", "O", "B-Hours", "O", "B-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Location, Dish, Amenity, Hours, Price, Cuisine, Rating and O.\nSentence: what are the average prices for lunch at mikanos", "prompt_labels": "what(O) are(O) the(O) average(O) prices(O) for(O) lunch(B-Hours) at(O) mikanos(B-Restaurant Name)"}, "label_list": ["Restaurant Name", "Location", "Dish", "Amenity", "Hours", "Price", "Cuisine", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 10067, 11, 49268, 11, 3383, 56685, 11, 30192, 11, 8650, 11, 81961, 11, 19767, 323, 507, 627, 85664, 25, 1148, 527, 279, 5578, 7729, 369, 16163, 520, 296, 23014, 437, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1015", "dataset": "mit-restaurant", "split": "dev", "prediction": "of(O) the(O) restaurants(O) that(O) require(B-Amenity) suit(I-Amenity) for(I-Amenity) men(I-Amenity) which(O) have(O) the(O) best(B-Rating) service(I-Rating) and(O) food(O)", "instance": {"id": "1015", "words": ["of", "the", "restaurants", "that", "require", "suit", "jackets", "for", "men", "which", "have", "the", "best", "service", "and", "food"], "labels": ["O", "O", "O", "O", "B-Amenity", "I-Amenity", "I-Amenity", "I-Amenity", "I-Amenity", "O", "O", "O", "B-Rating", "I-Rating", "I-Rating", "I-Rating"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Cuisine, Dish, Location, Amenity, Price, Hours, Restaurant Name and O.\nSentence: of the restaurants that require suit jackets for men which have the best service and food", "prompt_labels": "of(O) the(O) restaurants(O) that(O) require(B-Amenity) suit(I-Amenity) jackets(I-Amenity) for(I-Amenity) men(I-Amenity) which(O) have(O) the(O) best(B-Rating) service(I-Rating) and(I-Rating) food(I-Rating)"}, "label_list": ["Rating", "Cuisine", "Dish", "Location", "Amenity", "Price", "Hours", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 81961, 11, 49268, 11, 10067, 11, 3383, 56685, 11, 8650, 11, 30192, 11, 26568, 4076, 323, 507, 627, 85664, 25, 315, 279, 15926, 430, 1397, 7937, 61242, 369, 3026, 902, 617, 279, 1888, 2532, 323, 3691, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "178", "dataset": "crossner_ai", "split": "dev", "prediction": "Decision(B-algorithm) tree(I-algorithm) learning(I-algorithm),(O) neural(B-algorithm) networks(I-algorithm),(O) or(O) a(O) naive(B-algorithm) Bayes(I-algorithm) classifier(I-algorithm) could(O) be(O) used(O) in(O) combination(O) with(O) measures(O) of(O) model(O) quality(O) such(O) as(O) balanced(B-metric) accuracy(I-metric)", "instance": {"id": "178", "words": ["Decision", "tree", "learning", ",", "neural", "networks", ",", "or", "a", "naive", "Bayes", "classifier", "could", "be", "used", "in", "combination", "with", "measures", "of", "model", "quality", "such", "as", "balanced", "accuracy"], "labels": ["B-algorithm", "I-algorithm", "I-algorithm", "O", "B-algorithm", "I-algorithm", "O", "O", "O", "B-algorithm", "I-algorithm", "I-algorithm", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-metric", "I-metric"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, programming language, organization, product, algorithm, field, person, country, university, researcher, task, conference, metric and O.\nSentence: Decision tree learning , neural networks , or a naive Bayes classifier could be used in combination with measures of model quality such as balanced accuracy", "prompt_labels": "Decision(B-algorithm) tree(I-algorithm) learning(I-algorithm) ,(O) neural(B-algorithm) networks(I-algorithm) ,(O) or(O) a(O) naive(B-algorithm) Bayes(I-algorithm) classifier(I-algorithm) could(O) be(O) used(O) in(O) combination(O) with(O) measures(O) of(O) model(O) quality(O) such(O) as(O) balanced(B-metric) accuracy(I-metric)"}, "label_list": ["location", "programming language", "organization", "product", "algorithm", "field", "person", "country", "university", "researcher", "task", "conference", "metric"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 15840, 4221, 11, 7471, 11, 2027, 11, 12384, 11, 2115, 11, 1732, 11, 3224, 11, 12374, 11, 32185, 11, 3465, 11, 10017, 11, 18767, 323, 507, 627, 85664, 25, 41525, 5021, 6975, 1174, 30828, 14488, 1174, 477, 264, 50765, 9332, 288, 34465, 1436, 387, 1511, 304, 10824, 449, 11193, 315, 1646, 4367, 1778, 439, 24770, 13708, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "65", "dataset": "crossner_literature", "split": "dev", "prediction": "Among(O) the(O) books(O) found(O) in(O) his(O) library(O) ((O) as(O) evidenced(O) in(O) Lovecraft(B-writer)'s(O) Library(O) by(O) S.(B-writer) T.(I-writer) Joshi(I-writer) )(O) was(O) The(B-book) Seven(I-book) Who(I-book) Were(I-book) Hanged(I-book) by(O) Leonid(B-writer) Andreyev(I-writer) and(O) A(B-book) Strange(I-book) Manuscript(I-book) Found(I-book) in(I-book) a(I-book) Copper(I-book) Cylinder(I-book) by(O) James(B-writer) De(I-writer) Mille(I-writer).(O)", "instance": {"id": "65", "words": ["Among", "the", "books", "found", "in", "his", "library", "(", "as", "evidenced", "in", "Lovecraft", "'s", "Library", "by", "S.", "T.", "Joshi", ")", "was", "The", "Seven", "Who", "Were", "Hanged", "by", "Leonid", "Andreyev", "and", "A", "Strange", "Manuscript", "Found", "in", "a", "Copper", "Cylinder", "by", "James", "De", "Mille", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-book", "I-book", "I-book", "O", "B-writer", "I-writer", "I-writer", "O", "O", "B-book", "I-book", "I-book", "I-book", "I-book", "O", "B-writer", "I-writer", "O", "B-book", "I-book", "I-book", "I-book", "I-book", "I-book", "I-book", "I-book", "O", "B-writer", "I-writer", "I-writer", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, poem, location, literary genre, book, organization, writer, magazine, event, country, person and O.\nSentence: Among the books found in his library ( as evidenced in Lovecraft 's Library by S. T. Joshi ) was The Seven Who Were Hanged by Leonid Andreyev and A Strange Manuscript Found in a Copper Cylinder by James De Mille .", "prompt_labels": "Among(O) the(O) books(O) found(O) in(O) his(O) library(O) ((O) as(O) evidenced(O) in(O) Lovecraft(B-book) 's(I-book) Library(I-book) by(O) S.(B-writer) T.(I-writer) Joshi(I-writer) )(O) was(O) The(B-book) Seven(I-book) Who(I-book) Were(I-book) Hanged(I-book) by(O) Leonid(B-writer) Andreyev(I-writer) and(O) A(B-book) Strange(I-book) Manuscript(I-book) Found(I-book) in(I-book) a(I-book) Copper(I-book) Cylinder(I-book) by(O) James(B-writer) De(I-writer) Mille(I-writer) .(O)"}, "label_list": ["award", "poem", "location", "literary genre", "book", "organization", "writer", "magazine", "event", "country", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10292, 11, 33894, 11, 3813, 11, 32465, 17779, 11, 2363, 11, 7471, 11, 7061, 11, 14756, 11, 1567, 11, 3224, 11, 1732, 323, 507, 627, 85664, 25, 22395, 279, 6603, 1766, 304, 813, 6875, 320, 439, 69457, 304, 10919, 7868, 364, 82, 11896, 555, 328, 13, 350, 13, 28978, 6151, 883, 574, 578, 31048, 10699, 40070, 473, 3811, 555, 21605, 307, 1628, 8233, 5230, 323, 362, 43693, 96433, 1250, 12595, 304, 264, 43640, 87762, 555, 7957, 1611, 386, 4618, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "156", "dataset": "crossner_science", "split": "dev", "prediction": "An(O) approved(O) residency(O) program(O) and(O) certification(O) ((O) in(O) the(O) U.S.(B-country),(O) the(O) American(B-organization) Board(I-organization) of(I-organization) Pathology(I-organization) or(O) the(O) American(B-organization) Osteopathic(I-organization) Board(I-organization) of(I-organization) Pathology(I-organization) )(O) is(O) usually(O) required(O) to(O) obtain(O) employment(O) or(O) hospital(O) privileges(O).(O)", "instance": {"id": "156", "words": ["An", "approved", "residency", "program", "and", "certification", "(", "in", "the", "U.S.", ",", "the", "American", "Board", "of", "Pathology", "or", "the", "American", "Osteopathic", "Board", "of", "Pathology", ")", "is", "usually", "required", "to", "obtain", "employment", "or", "hospital", "privileges", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-country", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, chemical element, scientist, academic journal, enzyme, location, award, chemical compound, discipline, organization, protein, theory, person, event, astronomical object, country and O.\nSentence: An approved residency program and certification ( in the U.S. , the American Board of Pathology or the American Osteopathic Board of Pathology ) is usually required to obtain employment or hospital privileges .", "prompt_labels": "An(O) approved(O) residency(O) program(O) and(O) certification(O) ((O) in(O) the(O) U.S.(B-country) ,(O) the(O) American(B-organization) Board(I-organization) of(I-organization) Pathology(I-organization) or(O) the(O) American(B-organization) Osteopathic(I-organization) Board(I-organization) of(I-organization) Pathology(I-organization) )(O) is(O) usually(O) required(O) to(O) obtain(O) employment(O) or(O) hospital(O) privileges(O) .(O)"}, "label_list": ["university", "chemical element", "scientist", "academic journal", "enzyme", "location", "award", "chemical compound", "discipline", "organization", "protein", "theory", "person", "event", "astronomical object", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12374, 11, 11742, 2449, 11, 28568, 11, 14584, 8486, 11, 49242, 11, 3813, 11, 10292, 11, 11742, 24549, 11, 26434, 11, 7471, 11, 13128, 11, 10334, 11, 1732, 11, 1567, 11, 87283, 1665, 11, 3224, 323, 507, 627, 85664, 25, 1556, 12054, 53966, 2068, 323, 28706, 320, 304, 279, 549, 815, 13, 1174, 279, 3778, 8925, 315, 8092, 2508, 477, 279, 3778, 507, 5455, 62209, 8925, 315, 8092, 2508, 883, 374, 6118, 2631, 311, 6994, 14740, 477, 8952, 36832, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1604", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) a(O) biographical(B-genre) movie(O) that(O) has(B-average ratings) excellent(I-average ratings) ratings(I-average ratings) starring(O) john(B-actor) travolta(I-actor)", "instance": {"id": "1604", "words": ["list", "a", "biographical", "movie", "that", "has", "excellent", "ratings", "starring", "john", "travolta"], "labels": ["O", "O", "B-genre", "O", "O", "B-average ratings", "I-average ratings", "I-average ratings", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, trailer, rating, plot, actor, song, director, review, character, year, average ratings, title and O.\nSentence: list a biographical movie that has excellent ratings starring john travolta", "prompt_labels": "list(O) a(O) biographical(B-genre) movie(O) that(O) has(B-average ratings) excellent(I-average ratings) ratings(I-average ratings) starring(O) john(B-actor) travolta(I-actor)"}, "label_list": ["genre", "trailer", "rating", "plot", "actor", "song", "director", "review", "character", "year", "average ratings", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 19809, 11, 10959, 11, 7234, 11, 12360, 11, 5609, 11, 7690, 11, 3477, 11, 3752, 11, 1060, 11, 5578, 18594, 11, 2316, 323, 507, 627, 85664, 25, 1160, 264, 6160, 32277, 5818, 430, 706, 9250, 18594, 40500, 40742, 10346, 60954, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "224", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) was(O) the(O) actor(O) in(O) the(O) movie(O) teen(B-title) wolf(I-title)", "instance": {"id": "224", "words": ["who", "was", "the", "actor", "in", "the", "movie", "teen", "wolf"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, year, title, character, director, actor, average ratings, genre, trailer, rating, plot, review and O.\nSentence: who was the actor in the movie teen wolf", "prompt_labels": "who(O) was(O) the(O) actor(O) in(O) the(O) movie(O) teen(B-title) wolf(I-title)"}, "label_list": ["song", "year", "title", "character", "director", "actor", "average ratings", "genre", "trailer", "rating", "plot", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 1060, 11, 2316, 11, 3752, 11, 7690, 11, 12360, 11, 5578, 18594, 11, 17779, 11, 19809, 11, 10959, 11, 7234, 11, 3477, 323, 507, 627, 85664, 25, 889, 574, 279, 12360, 304, 279, 5818, 9562, 37642, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "398", "dataset": "crossner_literature", "split": "dev", "prediction": "He(O) taught(O) French(O) for(O) a(O) year(O) at(O) Eton(B-location) College(I-location),(O) where(O) Eric(B-person) Blair(I-person) ((O) who(O) was(O) to(O) take(O) the(O) pen(O) name(O) George(B-writer) Orwell(I-writer) )(O) and(O) Steven(B-writer) Runciman(I-writer) were(O) among(O) his(O) pupils(O).(O)", "instance": {"id": "398", "words": ["He", "taught", "French", "for", "a", "year", "at", "Eton", "College", ",", "where", "Eric", "Blair", "(", "who", "was", "to", "take", "the", "pen", "name", "George", "Orwell", ")", "and", "Steven", "Runciman", "were", "among", "his", "pupils", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "O", "B-writer", "I-writer", "O", "O", "O", "O", "O", "O", "O", "O", "B-writer", "I-writer", "O", "O", "B-writer", "I-writer", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, person, writer, book, literary genre, country, magazine, poem, location, award, event and O.\nSentence: He taught French for a year at Eton College , where Eric Blair ( who was to take the pen name George Orwell ) and Steven Runciman were among his pupils .", "prompt_labels": "He(O) taught(O) French(O) for(O) a(O) year(O) at(O) Eton(B-organization) College(I-organization) ,(O) where(O) Eric(B-writer) Blair(I-writer) ((O) who(O) was(O) to(O) take(O) the(O) pen(O) name(O) George(B-writer) Orwell(I-writer) )(O) and(O) Steven(B-writer) Runciman(I-writer) were(O) among(O) his(O) pupils(O) .(O)"}, "label_list": ["organization", "person", "writer", "book", "literary genre", "country", "magazine", "poem", "location", "award", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 1732, 11, 7061, 11, 2363, 11, 32465, 17779, 11, 3224, 11, 14756, 11, 33894, 11, 3813, 11, 10292, 11, 1567, 323, 507, 627, 85664, 25, 1283, 15972, 8753, 369, 264, 1060, 520, 469, 783, 9304, 1174, 1405, 16645, 42969, 320, 889, 574, 311, 1935, 279, 5869, 836, 10058, 83853, 883, 323, 24565, 432, 1371, 40310, 1051, 4315, 813, 45172, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "299", "dataset": "crossner_literature", "split": "dev", "prediction": "She(O) left(O) the(O) year(O) after(O) to(O) teach(O) her(O) sisters(O),(O) Emily(B-writer) Bront\u00eb(I-writer) and(O) Anne(B-writer) Bront\u00eb(I-writer),(O) at(B-location) home(I-location),(O) returning(O) in(O) 1835(O) as(O) a(O) governess(O).(O)", "instance": {"id": "299", "words": ["She", "left", "the", "year", "after", "to", "teach", "her", "sisters", ",", "Emily", "Bront\u00eb", "and", "Anne", "Bront\u00eb", ",", "at", "home", ",", "returning", "in", "1835", "as", "a", "governess", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, award, event, location, literary genre, book, organization, magazine, writer, poem, country and O.\nSentence: She left the year after to teach her sisters , Emily Bront\u00eb and Anne Bront\u00eb , at home , returning in 1835 as a governess .", "prompt_labels": "She(O) left(O) the(O) year(O) after(O) to(O) teach(O) her(O) sisters(O) ,(O) Emily(B-writer) Bront\u00eb(I-writer) and(O) Anne(B-writer) Bront\u00eb(I-writer) ,(O) at(O) home(O) ,(O) returning(O) in(O) 1835(O) as(O) a(O) governess(O) .(O)"}, "label_list": ["person", "award", "event", "location", "literary genre", "book", "organization", "magazine", "writer", "poem", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 10292, 11, 1567, 11, 3813, 11, 32465, 17779, 11, 2363, 11, 7471, 11, 14756, 11, 7061, 11, 33894, 11, 3224, 323, 507, 627, 85664, 25, 3005, 2163, 279, 1060, 1306, 311, 4639, 1077, 30393, 1174, 35266, 3320, 546, 12456, 323, 29026, 3320, 546, 12456, 1174, 520, 2162, 1174, 13758, 304, 220, 10750, 20, 439, 264, 2372, 2136, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "900", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) any(O) 24(B-Hours) hour(I-Hours) deli(B-Cuisine) on(O) the(O) west(B-Location) side(I-Location) of(I-Location) town(I-Location)", "instance": {"id": "900", "words": ["is", "there", "any", "24", "hour", "deli", "on", "the", "west", "side", "of", "town"], "labels": ["O", "O", "O", "B-Hours", "I-Hours", "B-Cuisine", "O", "O", "B-Location", "I-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Rating, Amenity, Price, Dish, Hours, Cuisine, Restaurant Name and O.\nSentence: is there any 24 hour deli on the west side of town", "prompt_labels": "is(O) there(O) any(O) 24(B-Hours) hour(I-Hours) deli(B-Cuisine) on(O) the(O) west(B-Location) side(I-Location) of(I-Location) town(I-Location)"}, "label_list": ["Location", "Rating", "Amenity", "Price", "Dish", "Hours", "Cuisine", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 19767, 11, 3383, 56685, 11, 8650, 11, 49268, 11, 30192, 11, 81961, 11, 26568, 4076, 323, 507, 627, 85664, 25, 374, 1070, 904, 220, 1187, 6596, 1624, 72, 389, 279, 9909, 3185, 315, 6424, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "121", "dataset": "crossner_music", "split": "dev", "prediction": "The(O) venue(O) was(O) the(O) site(O) of(O) several(O) Commonwealth(B-event) Games(I-event) sports(O) in(O) 1978(B-event) Commonwealth(I-event) Games(I-event),(O) and(O) part(O) of(O) Universiade(B-event) ((O) the(O) World(B-event) University(I-event) Games(I-event) )(O) in(O) 1983(O).(O)", "instance": {"id": "121", "words": ["The", "venue", "was", "the", "site", "of", "several", "Commonwealth", "Games", "sports", "in", "1978", "Commonwealth", "Games", ",", "and", "part", "of", "Universiade", "(", "the", "World", "University", "Games", ")", "in", "1983", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "O", "O", "O", "O", "B-event", "O", "O", "B-event", "I-event", "I-event", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, country, song, musical artist, person, organization, band, event, award, musical instrument, album, music genre and O.\nSentence: The venue was the site of several Commonwealth Games sports in 1978 Commonwealth Games , and part of Universiade ( the World University Games ) in 1983 .", "prompt_labels": "The(O) venue(O) was(O) the(O) site(O) of(O) several(O) Commonwealth(O) Games(O) sports(O) in(O) 1978(B-event) Commonwealth(I-event) Games(I-event) ,(O) and(O) part(O) of(O) Universiade(B-event) ((O) the(O) World(B-event) University(I-event) Games(I-event) )(O) in(O) 1983(O) .(O)"}, "label_list": ["location", "country", "song", "musical artist", "person", "organization", "band", "event", "award", "musical instrument", "album", "music genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 3224, 11, 5609, 11, 18273, 10255, 11, 1732, 11, 7471, 11, 7200, 11, 1567, 11, 10292, 11, 18273, 14473, 11, 8176, 11, 4731, 17779, 323, 507, 627, 85664, 25, 578, 22150, 574, 279, 2816, 315, 3892, 38298, 11871, 10034, 304, 220, 4468, 23, 38298, 11871, 1174, 323, 961, 315, 15915, 72, 1037, 320, 279, 4435, 3907, 11871, 883, 304, 220, 3753, 18, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "824", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) a(O) japanese(B-Cuisine) restraunt(O) near(B-Location) by(I-Location)", "instance": {"id": "824", "words": ["is", "there", "a", "japanese", "restraunt", "near", "by"], "labels": ["O", "O", "O", "B-Cuisine", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Dish, Restaurant Name, Cuisine, Location, Rating, Price, Hours and O.\nSentence: is there a japanese restraunt near by", "prompt_labels": "is(O) there(O) a(O) japanese(B-Cuisine) restraunt(O) near(B-Location) by(I-Location)"}, "label_list": ["Amenity", "Dish", "Restaurant Name", "Cuisine", "Location", "Rating", "Price", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 49268, 11, 26568, 4076, 11, 81961, 11, 10067, 11, 19767, 11, 8650, 11, 30192, 323, 507, 627, 85664, 25, 374, 1070, 264, 54048, 312, 13645, 3935, 3221, 555, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "184", "dataset": "crossner_science", "split": "dev", "prediction": "Starting(O) with(O) 1972(O),(O) the(O) Review(O) no(O) longer(O) appear(O) exclusively(O) in(O) Reviews(B-academic journal) of(I-academic journal) Modern(I-academic journal) Physics(I-academic journal),(O) but(O) also(O) in(O) Physics(B-academic journal) Letters(I-academic journal) B(I-academic journal),(O) European(B-academic journal) Physical(I-academic journal) Journal(I-academic journal) C(I-academic journal),(O) Journal(B-academic journal) of(I-academic journal) Physics(I-academic journal) G(I-academic journal),(O) Physical(B-academic journal) Review(I-academic journal) D(I-academic journal),(O) and(O) Chinese(B-academic journal) Physics(I-academic journal) C(I-academic journal) ((O) depending(O) on(O) the(O) year(O) )(O).(O)", "instance": {"id": "184", "words": ["Starting", "with", "1972", ",", "the", "Review", "no", "longer", "appear", "exclusively", "in", "Reviews", "of", "Modern", "Physics", ",", "but", "also", "in", "Physics", "Letters", "B", ",", "European", "Physical", "Journal", "C", ",", "Journal", "of", "Physics", "G", ",", "Physical", "Review", "D", ",", "and", "Chinese", "Physics", "C", "(", "depending", "on", "the", "year", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O", "O", "O", "O", "B-academic journal", "I-academic journal", "I-academic journal", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O", "B-academic journal", "I-academic journal", "I-academic journal", "O", "O", "B-academic journal", "I-academic journal", "I-academic journal", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, discipline, university, astronomical object, location, chemical element, chemical compound, academic journal, enzyme, person, organization, country, award, theory, event, protein and O.\nSentence: Starting with 1972 , the Review no longer appear exclusively in Reviews of Modern Physics , but also in Physics Letters B , European Physical Journal C , Journal of Physics G , Physical Review D , and Chinese Physics C ( depending on the year ) .", "prompt_labels": "Starting(O) with(O) 1972(O) ,(O) the(O) Review(O) no(O) longer(O) appear(O) exclusively(O) in(O) Reviews(B-academic journal) of(I-academic journal) Modern(I-academic journal) Physics(I-academic journal) ,(O) but(O) also(O) in(O) Physics(B-academic journal) Letters(I-academic journal) B(I-academic journal) ,(O) European(B-academic journal) Physical(I-academic journal) Journal(I-academic journal) C(I-academic journal) ,(O) Journal(B-academic journal) of(I-academic journal) Physics(I-academic journal) G(I-academic journal) ,(O) Physical(B-academic journal) Review(I-academic journal) D(I-academic journal) ,(O) and(O) Chinese(B-academic journal) Physics(I-academic journal) C(I-academic journal) ((O) depending(O) on(O) the(O) year(O) )(O) .(O)"}, "label_list": ["scientist", "discipline", "university", "astronomical object", "location", "chemical element", "chemical compound", "academic journal", "enzyme", "person", "organization", "country", "award", "theory", "event", "protein"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 28568, 11, 26434, 11, 12374, 11, 87283, 1665, 11, 3813, 11, 11742, 2449, 11, 11742, 24549, 11, 14584, 8486, 11, 49242, 11, 1732, 11, 7471, 11, 3224, 11, 10292, 11, 10334, 11, 1567, 11, 13128, 323, 507, 627, 85664, 25, 28757, 449, 220, 4468, 17, 1174, 279, 10506, 912, 5129, 5101, 24121, 304, 19832, 315, 18766, 28415, 1174, 719, 1101, 304, 28415, 45397, 426, 1174, 7665, 28479, 10139, 356, 1174, 10139, 315, 28415, 480, 1174, 28479, 10506, 423, 1174, 323, 8620, 28415, 356, 320, 11911, 389, 279, 1060, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "725", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) r(B-rating) rated(O) movies(O) from(O) 2011(B-year) do(O) not(O) have(O) full(B-plot) frontal(I-plot) nudity(I-plot) in(O) them(O)", "instance": {"id": "725", "words": ["what", "r", "rated", "movies", "from", "2011", "do", "not", "have", "full", "frontal", "nudity", "in", "them"], "labels": ["O", "B-rating", "I-rating", "O", "O", "B-year", "O", "O", "O", "B-plot", "I-plot", "I-plot", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, genre, director, actor, title, rating, plot, review, average ratings, character, trailer, year and O.\nSentence: what r rated movies from 2011 do not have full frontal nudity in them", "prompt_labels": "what(O) r(B-rating) rated(I-rating) movies(O) from(O) 2011(B-year) do(O) not(O) have(O) full(B-plot) frontal(I-plot) nudity(I-plot) in(O) them(O)"}, "label_list": ["song", "genre", "director", "actor", "title", "rating", "plot", "review", "average ratings", "character", "trailer", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 17779, 11, 7690, 11, 12360, 11, 2316, 11, 10959, 11, 7234, 11, 3477, 11, 5578, 18594, 11, 3752, 11, 19809, 11, 1060, 323, 507, 627, 85664, 25, 1148, 436, 22359, 9698, 505, 220, 679, 16, 656, 539, 617, 2539, 66746, 92472, 304, 1124, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "153", "dataset": "crossner_ai", "split": "dev", "prediction": "It(O) has(O) been(O) pointed(O) out(O) that(O) precision(B-metric) is(O) usually(O) twinned(O) with(O) recall(B-metric) to(O) overcome(O) this(O) problem(O)", "instance": {"id": "153", "words": ["It", "has", "been", "pointed", "out", "that", "precision", "is", "usually", "twinned", "with", "recall", "to", "overcome", "this", "problem"], "labels": ["O", "O", "O", "O", "O", "O", "B-metric", "O", "O", "O", "O", "B-metric", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, university, programming language, person, country, task, researcher, product, algorithm, conference, field, metric, location and O.\nSentence: It has been pointed out that precision is usually twinned with recall to overcome this problem", "prompt_labels": "It(O) has(O) been(O) pointed(O) out(O) that(O) precision(B-metric) is(O) usually(O) twinned(O) with(O) recall(B-metric) to(O) overcome(O) this(O) problem(O)"}, "label_list": ["organization", "university", "programming language", "person", "country", "task", "researcher", "product", "algorithm", "conference", "field", "metric", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 12374, 11, 15840, 4221, 11, 1732, 11, 3224, 11, 3465, 11, 32185, 11, 2027, 11, 12384, 11, 10017, 11, 2115, 11, 18767, 11, 3813, 323, 507, 627, 85664, 25, 1102, 706, 1027, 14618, 704, 430, 16437, 374, 6118, 4483, 21203, 449, 19635, 311, 23075, 420, 3575, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2090", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) name(O) of(O) r(B-rating) rated(O) gangster(B-genre) movie(O) from(O) 1940(B-year) that(O) matthew(B-actor) lawrence(I-actor) was(O) in(O)", "instance": {"id": "2090", "words": ["what", "is", "the", "name", "of", "r", "rated", "gangster", "movie", "from", "1940", "that", "matthew", "lawrence", "was", "in"], "labels": ["O", "O", "O", "O", "O", "B-rating", "O", "B-genre", "O", "O", "B-year", "O", "B-actor", "I-actor", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, title, average ratings, review, plot, year, rating, director, trailer, genre, actor, song and O.\nSentence: what is the name of r rated gangster movie from 1940 that matthew lawrence was in", "prompt_labels": "what(O) is(O) the(O) name(O) of(O) r(B-rating) rated(O) gangster(B-genre) movie(O) from(O) 1940(B-year) that(O) matthew(B-actor) lawrence(I-actor) was(O) in(O)"}, "label_list": ["character", "title", "average ratings", "review", "plot", "year", "rating", "director", "trailer", "genre", "actor", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 2316, 11, 5578, 18594, 11, 3477, 11, 7234, 11, 1060, 11, 10959, 11, 7690, 11, 19809, 11, 17779, 11, 12360, 11, 5609, 323, 507, 627, 85664, 25, 1148, 374, 279, 836, 315, 436, 22359, 13481, 3751, 5818, 505, 220, 6393, 15, 430, 5634, 16142, 2383, 16271, 574, 304, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "24", "dataset": "crossner_science", "split": "dev", "prediction": "He(O) received(O) the(O) Society(B-award) of(I-award) Experimental(I-award) Test(I-award) Pilots(I-award) ((O) SETP(B-award) )(O) James(B-scientist) H.(I-scientist) Doolittle(I-scientist) Award(I-award) in(O) 1972(O) and(O) the(O) SETP(Iven(B-scientist) C.(I-scientist) Kincheloe(I-scientist) Award(I-award).(O)", "instance": {"id": "24", "words": ["He", "received", "the", "Society", "of", "Experimental", "Test", "Pilots", "(", "SETP", ")", "James", "H.", "Doolittle", "Award", "in", "1972", "and", "the", "SETP", "Iven", "C.", "Kincheloe", "Award", "."], "labels": ["O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "O", "B-award", "I-award", "I-award", "I-award", "O", "O", "O", "O", "B-organization", "B-award", "I-award", "I-award", "I-award", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, event, astronomical object, theory, scientist, person, chemical compound, discipline, location, award, academic journal, protein, university, chemical element, enzyme, organization and O.\nSentence: He received the Society of Experimental Test Pilots ( SETP ) James H. Doolittle Award in 1972 and the SETP Iven C. Kincheloe Award .", "prompt_labels": "He(O) received(O) the(O) Society(B-organization) of(I-organization) Experimental(I-organization) Test(I-organization) Pilots(I-organization) ((O) SETP(B-organization) )(O) James(B-award) H.(I-award) Doolittle(I-award) Award(I-award) in(O) 1972(O) and(O) the(O) SETP(B-organization) Iven(B-award) C.(I-award) Kincheloe(I-award) Award(I-award) .(O)"}, "label_list": ["country", "event", "astronomical object", "theory", "scientist", "person", "chemical compound", "discipline", "location", "award", "academic journal", "protein", "university", "chemical element", "enzyme", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 1567, 11, 87283, 1665, 11, 10334, 11, 28568, 11, 1732, 11, 11742, 24549, 11, 26434, 11, 3813, 11, 10292, 11, 14584, 8486, 11, 13128, 11, 12374, 11, 11742, 2449, 11, 49242, 11, 7471, 323, 507, 627, 85664, 25, 1283, 4036, 279, 13581, 315, 57708, 3475, 37451, 2469, 320, 9196, 47, 883, 7957, 473, 13, 423, 1786, 2433, 17768, 304, 220, 4468, 17, 323, 279, 9196, 47, 358, 1055, 356, 13, 31991, 331, 301, 4748, 17768, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2381", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) r(B-rating) rated(O) movies(O) with(O) john(B-actor) cusak(I-actor) got(O) all(B-average ratings) right(I-average ratings) ratings(O)", "instance": {"id": "2381", "words": ["what", "r", "rated", "movies", "with", "john", "cusak", "got", "all", "right", "ratings"], "labels": ["O", "B-rating", "O", "O", "O", "B-actor", "I-actor", "O", "B-average ratings", "I-average ratings", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, average ratings, character, year, trailer, plot, song, actor, rating, review, genre, director and O.\nSentence: what r rated movies with john cusak got all right ratings", "prompt_labels": "what(O) r(B-rating) rated(O) movies(O) with(O) john(B-actor) cusak(I-actor) got(O) all(B-average ratings) right(I-average ratings) ratings(O)"}, "label_list": ["title", "average ratings", "character", "year", "trailer", "plot", "song", "actor", "rating", "review", "genre", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 5578, 18594, 11, 3752, 11, 1060, 11, 19809, 11, 7234, 11, 5609, 11, 12360, 11, 10959, 11, 3477, 11, 17779, 11, 7690, 323, 507, 627, 85664, 25, 1148, 436, 22359, 9698, 449, 40742, 81070, 587, 2751, 682, 1314, 18594, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1867", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) r(B-rating) rated(O) suspense(B-genre) movies(O) came(O) out(O) in(O) 1990(B-year)", "instance": {"id": "1867", "words": ["what", "r", "rated", "suspense", "movies", "came", "out", "in", "1990"], "labels": ["O", "B-rating", "O", "B-genre", "O", "O", "O", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, trailer, plot, song, review, average ratings, genre, actor, year, character, director, title and O.\nSentence: what r rated suspense movies came out in 1990", "prompt_labels": "what(O) r(B-rating) rated(O) suspense(B-genre) movies(O) came(O) out(O) in(O) 1990(B-year)"}, "label_list": ["rating", "trailer", "plot", "song", "review", "average ratings", "genre", "actor", "year", "character", "director", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 19809, 11, 7234, 11, 5609, 11, 3477, 11, 5578, 18594, 11, 17779, 11, 12360, 11, 1060, 11, 3752, 11, 7690, 11, 2316, 323, 507, 627, 85664, 25, 1148, 436, 22359, 72930, 9698, 3782, 704, 304, 220, 2550, 15, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1750", "dataset": "mit-movie", "split": "dev", "prediction": "please(O) list(O) movies(O) in(O) the(O) crime(B-genre) genre(O) that(O) were(O) given(O) an(O) average(O) rating(O) of(O) six(B-average ratings)", "instance": {"id": "1750", "words": ["please", "list", "movies", "in", "the", "crime", "genre", "that", "were", "given", "an", "average", "rating", "of", "six"], "labels": ["O", "O", "O", "O", "O", "B-genre", "O", "O", "O", "O", "O", "O", "O", "O", "B-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, year, plot, actor, genre, review, rating, trailer, director, song, title, character and O.\nSentence: please list movies in the crime genre that were given an average rating of six", "prompt_labels": "please(O) list(O) movies(O) in(O) the(O) crime(B-genre) genre(O) that(O) were(O) given(O) an(O) average(O) rating(O) of(O) six(B-average ratings)"}, "label_list": ["average ratings", "year", "plot", "actor", "genre", "review", "rating", "trailer", "director", "song", "title", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 1060, 11, 7234, 11, 12360, 11, 17779, 11, 3477, 11, 10959, 11, 19809, 11, 7690, 11, 5609, 11, 2316, 11, 3752, 323, 507, 627, 85664, 25, 4587, 1160, 9698, 304, 279, 9977, 17779, 430, 1051, 2728, 459, 5578, 10959, 315, 4848, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1830", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) 2000(B-year) highly(B-average ratings) recommended(I-average ratings) kristen(B-actor) scott(I-actor) thomas(I-actor) movie(O) about(O) a(O) runaway(B-plot) was(O) rated(O) nc(B-rating) 17(I-rating)", "instance": {"id": "1830", "words": ["what", "2000", "highly", "recommended", "kristen", "scott", "thomas", "movie", "about", "a", "runaway", "was", "rated", "nc", "17"], "labels": ["O", "B-year", "B-average ratings", "I-average ratings", "B-actor", "I-actor", "I-actor", "O", "O", "O", "B-plot", "O", "O", "B-rating", "I-rating"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, title, average ratings, genre, director, year, review, actor, plot, rating, song, trailer and O.\nSentence: what 2000 highly recommended kristen scott thomas movie about a runaway was rated nc 17", "prompt_labels": "what(O) 2000(B-year) highly(B-average ratings) recommended(I-average ratings) kristen(B-actor) scott(I-actor) thomas(I-actor) movie(O) about(O) a(O) runaway(B-plot) was(O) rated(O) nc(B-rating) 17(I-rating)"}, "label_list": ["character", "title", "average ratings", "genre", "director", "year", "review", "actor", "plot", "rating", "song", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 2316, 11, 5578, 18594, 11, 17779, 11, 7690, 11, 1060, 11, 3477, 11, 12360, 11, 7234, 11, 10959, 11, 5609, 11, 19809, 323, 507, 627, 85664, 25, 1148, 220, 1049, 15, 7701, 11349, 86948, 268, 1156, 1751, 270, 23063, 5818, 922, 264, 91740, 574, 22359, 26183, 220, 1114, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "824", "dataset": "mit-movie", "split": "dev", "prediction": "find(O) movies(O) with(O) halle(B-actor) berry(I-actor)", "instance": {"id": "824", "words": ["find", "movies", "with", "halle", "berry"], "labels": ["O", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, genre, character, song, review, plot, title, year, rating, trailer, actor, average ratings and O.\nSentence: find movies with halle berry", "prompt_labels": "find(O) movies(O) with(O) halle(B-actor) berry(I-actor)"}, "label_list": ["director", "genre", "character", "song", "review", "plot", "title", "year", "rating", "trailer", "actor", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 17779, 11, 3752, 11, 5609, 11, 3477, 11, 7234, 11, 2316, 11, 1060, 11, 10959, 11, 19809, 11, 12360, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1505, 9698, 449, 305, 5164, 86188, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "253", "dataset": "crossner_ai", "split": "dev", "prediction": "These(O) methods(O) may(O) also(O) analyze(O) a(O) program(O)'s(O) output(O) and(O) its(O) usefulness(O) and(O) therefore(O) may(O) involve(O) the(O) analysis(O) of(O) its(O) confusion(O) matrix(O) ((O) or(O) table(O) of(O) confusion(O) )(O).(O)", "instance": {"id": "253", "words": ["These", "methods", "may", "also", "analyze", "a", "program", "'s", "output", "and", "its", "usefulness", "and", "therefore", "may", "involve", "the", "analysis", "of", "its", "confusion", "matrix", "(", "or", "table", "of", "confusion", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-metric", "I-metric", "O", "O", "B-metric", "I-metric", "I-metric", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, researcher, person, conference, metric, university, product, location, programming language, country, task, organization, algorithm and O.\nSentence: These methods may also analyze a program 's output and its usefulness and therefore may involve the analysis of its confusion matrix ( or table of confusion ) .", "prompt_labels": "These(O) methods(O) may(O) also(O) analyze(O) a(O) program(O) 's(O) output(O) and(O) its(O) usefulness(O) and(O) therefore(O) may(O) involve(O) the(O) analysis(O) of(O) its(O) confusion(B-metric) matrix(I-metric) ((O) or(O) table(B-metric) of(I-metric) confusion(I-metric) )(O) .(O)"}, "label_list": ["field", "researcher", "person", "conference", "metric", "university", "product", "location", "programming language", "country", "task", "organization", "algorithm"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2115, 11, 32185, 11, 1732, 11, 10017, 11, 18767, 11, 12374, 11, 2027, 11, 3813, 11, 15840, 4221, 11, 3224, 11, 3465, 11, 7471, 11, 12384, 323, 507, 627, 85664, 25, 4314, 5528, 1253, 1101, 24564, 264, 2068, 364, 82, 2612, 323, 1202, 76964, 323, 9093, 1253, 21736, 279, 6492, 315, 1202, 22047, 6303, 320, 477, 2007, 315, 22047, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1464", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) there(O) a(O) pg(B-rating) 13(I-rating) film(O) out(O) there(O) from(O) the(O) 2000(B-year) s(I-year) that(O) focuses(O) on(O) an(O) evil(B-plot) character(O)", "instance": {"id": "1464", "words": ["is", "there", "a", "pg", "13", "film", "out", "there", "from", "the", "2000", "s", "that", "focuses", "on", "an", "evil", "character"], "labels": ["O", "O", "O", "B-rating", "I-rating", "O", "O", "O", "O", "O", "B-year", "I-year", "O", "O", "O", "O", "B-plot", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, actor, song, director, genre, year, rating, plot, review, trailer, title, average ratings and O.\nSentence: is there a pg 13 film out there from the 2000 s that focuses on an evil character", "prompt_labels": "is(O) there(O) a(O) pg(B-rating) 13(I-rating) film(O) out(O) there(O) from(O) the(O) 2000(B-year) s(I-year) that(O) focuses(O) on(O) an(O) evil(B-plot) character(O)"}, "label_list": ["character", "actor", "song", "director", "genre", "year", "rating", "plot", "review", "trailer", "title", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 12360, 11, 5609, 11, 7690, 11, 17779, 11, 1060, 11, 10959, 11, 7234, 11, 3477, 11, 19809, 11, 2316, 11, 5578, 18594, 323, 507, 627, 85664, 25, 374, 1070, 264, 17953, 220, 1032, 4632, 704, 1070, 505, 279, 220, 1049, 15, 274, 430, 24400, 389, 459, 14289, 3752, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "436", "dataset": "mit-restaurant", "split": "dev", "prediction": "find(O) me(O) the(O) nearest(B-Location) mcdonalds(B-Restaurant Name) please(O)", "instance": {"id": "436", "words": ["find", "me", "the", "nearest", "mcdonalds", "please"], "labels": ["O", "O", "O", "B-Location", "B-Restaurant Name", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Location, Price, Restaurant Name, Rating, Amenity, Hours, Cuisine and O.\nSentence: find me the nearest mcdonalds please", "prompt_labels": "find(O) me(O) the(O) nearest(B-Location) mcdonalds(B-Restaurant Name) please(O)"}, "label_list": ["Dish", "Location", "Price", "Restaurant Name", "Rating", "Amenity", "Hours", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 10067, 11, 8650, 11, 26568, 4076, 11, 19767, 11, 3383, 56685, 11, 30192, 11, 81961, 323, 507, 627, 85664, 25, 1505, 757, 279, 24379, 296, 4484, 80794, 82, 4587, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2416", "dataset": "mit-movie", "split": "dev", "prediction": "monty(B-title) python(I-title) and(I-title) the(I-title) holy(I-title) grail(I-title)", "instance": {"id": "2416", "words": ["monty", "python", "and", "the", "holy", "grail"], "labels": ["B-title", "I-title", "I-title", "I-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, trailer, song, plot, year, title, character, director, actor, review, genre, average ratings and O.\nSentence: monty python and the holy grail", "prompt_labels": "monty(B-title) python(I-title) and(I-title) the(I-title) holy(I-title) grail(I-title)"}, "label_list": ["rating", "trailer", "song", "plot", "year", "title", "character", "director", "actor", "review", "genre", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 19809, 11, 5609, 11, 7234, 11, 1060, 11, 2316, 11, 3752, 11, 7690, 11, 12360, 11, 3477, 11, 17779, 11, 5578, 18594, 323, 507, 627, 85664, 25, 20605, 88, 10344, 323, 279, 27823, 1099, 607, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2439", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) the(B-title) good(I-title) thief(I-title) review(B-review)", "instance": {"id": "2439", "words": ["show", "me", "the", "good", "thief", "review"], "labels": ["O", "O", "B-title", "I-title", "I-title", "B-review"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, director, genre, trailer, year, title, plot, song, character, average ratings, rating, review and O.\nSentence: show me the good thief review", "prompt_labels": "show(O) me(O) the(B-title) good(I-title) thief(I-title) review(B-review)"}, "label_list": ["actor", "director", "genre", "trailer", "year", "title", "plot", "song", "character", "average ratings", "rating", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 7690, 11, 17779, 11, 19809, 11, 1060, 11, 2316, 11, 7234, 11, 5609, 11, 3752, 11, 5578, 18594, 11, 10959, 11, 3477, 323, 507, 627, 85664, 25, 1501, 757, 279, 1695, 58835, 3477, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "689", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) would(O) like(O) to(O) eat(O) fish(B-Dish) today(O) any(O) recommendations(B-Rating)", "instance": {"id": "689", "words": ["i", "would", "like", "to", "eat", "fish", "today", "any", "recommendations"], "labels": ["O", "O", "O", "O", "O", "B-Dish", "B-Hours", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Dish, Restaurant Name, Cuisine, Price, Rating, Hours, Amenity and O.\nSentence: i would like to eat fish today any recommendations", "prompt_labels": "i(O) would(O) like(O) to(O) eat(O) fish(B-Dish) today(B-Hours) any(O) recommendations(O)"}, "label_list": ["Location", "Dish", "Restaurant Name", "Cuisine", "Price", "Rating", "Hours", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 49268, 11, 26568, 4076, 11, 81961, 11, 8650, 11, 19767, 11, 30192, 11, 3383, 56685, 323, 507, 627, 85664, 25, 602, 1053, 1093, 311, 8343, 7795, 3432, 904, 19075, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "997", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) what(O) films(O) were(O) directed(O) by(O) the(B-director) wachowski(I-director) brothers(I-director)", "instance": {"id": "997", "words": ["show", "me", "what", "films", "were", "directed", "by", "the", "wachowski", "brothers"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, average ratings, character, actor, director, plot, genre, year, review, trailer, title, rating and O.\nSentence: show me what films were directed by the wachowski brothers", "prompt_labels": "show(O) me(O) what(O) films(O) were(O) directed(O) by(O) the(O) wachowski(B-director) brothers(I-director)"}, "label_list": ["song", "average ratings", "character", "actor", "director", "plot", "genre", "year", "review", "trailer", "title", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 5578, 18594, 11, 3752, 11, 12360, 11, 7690, 11, 7234, 11, 17779, 11, 1060, 11, 3477, 11, 19809, 11, 2316, 11, 10959, 323, 507, 627, 85664, 25, 1501, 757, 1148, 12631, 1051, 15910, 555, 279, 289, 613, 29384, 20820, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1456", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) there(O) a(O) dean(B-actor) martin(I-actor) action(B-genre) film(O) that(O) was(B-average ratings) liked(I-average ratings) a(I-average ratings) lot(I-average ratings) this(O) past(B-year) year(I-year)", "instance": {"id": "1456", "words": ["is", "there", "a", "dean", "martin", "action", "film", "that", "was", "liked", "a", "lot", "this", "past", "year"], "labels": ["O", "O", "O", "B-actor", "I-actor", "B-genre", "O", "O", "B-average ratings", "I-average ratings", "I-average ratings", "I-average ratings", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, genre, review, title, actor, rating, trailer, year, song, character, director, average ratings and O.\nSentence: is there a dean martin action film that was liked a lot this past year", "prompt_labels": "is(O) there(O) a(O) dean(B-actor) martin(I-actor) action(B-genre) film(O) that(O) was(B-average ratings) liked(I-average ratings) a(I-average ratings) lot(I-average ratings) this(O) past(B-year) year(I-year)"}, "label_list": ["plot", "genre", "review", "title", "actor", "rating", "trailer", "year", "song", "character", "director", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 17779, 11, 3477, 11, 2316, 11, 12360, 11, 10959, 11, 19809, 11, 1060, 11, 5609, 11, 3752, 11, 7690, 11, 5578, 18594, 323, 507, 627, 85664, 25, 374, 1070, 264, 73962, 96016, 1957, 4632, 430, 574, 15262, 264, 2763, 420, 3347, 1060, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1935", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) avante(B-genre) garde(I-genre) film(O) is(O) the(O) director(O) orson(B-director) welles(I-director) best(O) known(O) for(O)", "instance": {"id": "1935", "words": ["what", "avante", "garde", "film", "is", "the", "director", "orson", "welles", "best", "known", "for"], "labels": ["O", "B-genre", "I-genre", "O", "O", "O", "O", "B-director", "I-director", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, average ratings, genre, trailer, rating, year, title, director, song, review, plot, actor and O.\nSentence: what avante garde film is the director orson welles best known for", "prompt_labels": "what(O) avante(B-genre) garde(I-genre) film(O) is(O) the(O) director(O) orson(B-director) welles(I-director) best(O) known(O) for(O)"}, "label_list": ["character", "average ratings", "genre", "trailer", "rating", "year", "title", "director", "song", "review", "plot", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 5578, 18594, 11, 17779, 11, 19809, 11, 10959, 11, 1060, 11, 2316, 11, 7690, 11, 5609, 11, 3477, 11, 7234, 11, 12360, 323, 507, 627, 85664, 25, 1148, 1860, 5048, 7515, 451, 4632, 374, 279, 7690, 477, 942, 12724, 645, 1888, 3967, 369, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "551", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) a(O) movie(O) with(O) arnold(B-actor) schwarzenegger(I-actor) that(O) is(O) directed(O) by(O) james(B-director) cameron(I-director)", "instance": {"id": "551", "words": ["show", "me", "a", "movie", "with", "arnold", "schwarzenegger", "that", "is", "directed", "by", "james", "cameron"], "labels": ["O", "O", "O", "O", "O", "B-actor", "I-actor", "O", "O", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, actor, year, director, rating, song, review, title, trailer, genre, average ratings, character and O.\nSentence: show me a movie with arnold schwarzenegger that is directed by james cameron", "prompt_labels": "show(O) me(O) a(O) movie(O) with(O) arnold(B-actor) schwarzenegger(I-actor) that(O) is(O) directed(O) by(O) james(B-director) cameron(I-director)"}, "label_list": ["plot", "actor", "year", "director", "rating", "song", "review", "title", "trailer", "genre", "average ratings", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 12360, 11, 1060, 11, 7690, 11, 10959, 11, 5609, 11, 3477, 11, 2316, 11, 19809, 11, 17779, 11, 5578, 18594, 11, 3752, 323, 507, 627, 85664, 25, 1501, 757, 264, 5818, 449, 802, 77, 820, 82928, 5797, 797, 1414, 430, 374, 15910, 555, 86046, 6730, 20110, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "114", "dataset": "crossner_music", "split": "dev", "prediction": "With(O) the(O) continued(O) success(O) of(O) Backstreet(B-band) Boys(I-band) and(O) NSYNC(B-band),(O) American(O) and(O) British(O) groups(O) like(O) 98(B-band) Degrees(I-band),(O) Westlife(B-band),(O) O-Town(B-band),(O) A1(B-band),(O) Blue(B-band),(O) and(O) Busted(B-band) gained(O) quick(O) popularity(O) both(O) domestically(O) and(O) internationally(O).(O)", "instance": {"id": "114", "words": ["With", "the", "continued", "success", "of", "Backstreet", "Boys", "and", "NSYNC", ",", "American", "and", "British", "groups", "like", "98", "Degrees", ",", "Westlife", ",", "O-Town", ",", "A1", ",", "Blue", ",", "and", "Busted", "gained", "quick", "popularity", "both", "domestically", "and", "internationally", "."], "labels": ["O", "O", "O", "O", "O", "B-band", "I-band", "O", "B-band", "O", "O", "O", "O", "O", "O", "B-band", "I-band", "O", "B-band", "O", "B-band", "O", "B-band", "O", "B-band", "O", "O", "B-band", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, musical instrument, music genre, location, event, band, award, person, country, musical artist, song, album and O.\nSentence: With the continued success of Backstreet Boys and NSYNC , American and British groups like 98 Degrees , Westlife , O-Town , A1 , Blue , and Busted gained quick popularity both domestically and internationally .", "prompt_labels": "With(O) the(O) continued(O) success(O) of(O) Backstreet(B-band) Boys(I-band) and(O) NSYNC(B-band) ,(O) American(O) and(O) British(O) groups(O) like(O) 98(B-band) Degrees(I-band) ,(O) Westlife(B-band) ,(O) O-Town(B-band) ,(O) A1(B-band) ,(O) Blue(B-band) ,(O) and(O) Busted(B-band) gained(O) quick(O) popularity(O) both(O) domestically(O) and(O) internationally(O) .(O)"}, "label_list": ["organization", "musical instrument", "music genre", "location", "event", "band", "award", "person", "country", "musical artist", "song", "album"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 18273, 14473, 11, 4731, 17779, 11, 3813, 11, 1567, 11, 7200, 11, 10292, 11, 1732, 11, 3224, 11, 18273, 10255, 11, 5609, 11, 8176, 323, 507, 627, 85664, 25, 3161, 279, 8738, 2450, 315, 6984, 28451, 30857, 323, 3119, 72501, 1174, 3778, 323, 8013, 5315, 1093, 220, 3264, 94001, 1174, 4410, 14789, 1174, 507, 9469, 785, 1174, 362, 16, 1174, 8868, 1174, 323, 426, 28244, 18661, 4062, 23354, 2225, 98890, 323, 37545, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1740", "dataset": "mit-movie", "split": "dev", "prediction": "name(O) decently(B-average ratings) rated(I-average ratings) fun(B-plot) party(I-plot) movies(O) of(O) the(O) past(B-year) nine(I-year) decades(I-year)", "instance": {"id": "1740", "words": ["name", "decently", "rated", "fun", "party", "movies", "of", "the", "past", "nine", "decades"], "labels": ["O", "B-average ratings", "O", "B-genre", "B-plot", "O", "O", "O", "B-year", "I-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, plot, character, year, title, trailer, review, song, average ratings, rating, genre, director and O.\nSentence: name decently rated fun party movies of the past nine decades", "prompt_labels": "name(O) decently(B-average ratings) rated(O) fun(B-genre) party(B-plot) movies(O) of(O) the(O) past(B-year) nine(I-year) decades(I-year)"}, "label_list": ["actor", "plot", "character", "year", "title", "trailer", "review", "song", "average ratings", "rating", "genre", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 7234, 11, 3752, 11, 1060, 11, 2316, 11, 19809, 11, 3477, 11, 5609, 11, 5578, 18594, 11, 10959, 11, 17779, 11, 7690, 323, 507, 627, 85664, 25, 836, 15326, 398, 22359, 2523, 4717, 9698, 315, 279, 3347, 11888, 11026, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1100", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) are(O) the(O) prices(O) like(O) at(O) gregorys(B-Restaurant Name) restaurant(I-Restaurant Name)", "instance": {"id": "1100", "words": ["what", "are", "the", "prices", "like", "at", "gregorys", "restaurant"], "labels": ["O", "O", "O", "O", "O", "O", "B-Restaurant Name", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Price, Rating, Cuisine, Amenity, Dish, Restaurant Name, Hours and O.\nSentence: what are the prices like at gregorys restaurant", "prompt_labels": "what(O) are(O) the(O) prices(O) like(O) at(O) gregorys(B-Restaurant Name) restaurant(O)"}, "label_list": ["Location", "Price", "Rating", "Cuisine", "Amenity", "Dish", "Restaurant Name", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 8650, 11, 19767, 11, 81961, 11, 3383, 56685, 11, 49268, 11, 26568, 4076, 11, 30192, 323, 507, 627, 85664, 25, 1148, 527, 279, 7729, 1093, 520, 342, 1610, 683, 82, 10960, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "245", "dataset": "crossner_ai", "split": "dev", "prediction": "Applications(O) of(O) DSP(B-field) include(O) audio(B-task) signal(I-task) processing(I-task),(O) audio(B-task) compression(I-task),(O) digital(B-task) image(I-task) processing(I-task),(O) video(B-task) compression(I-task),(O) speech(B-task) processing(I-task),(O) speech(B-task) recognition(I-task),(O) digital(B-field) communication(I-field) s(O),(O) digital(B-field) synthesizer(I-field) s(O),(O) radar(B-task),(O) sonar(B-task),(O) financial(B-field) signal(I-field) processing(I-field),(O) seismology(B-field) and(O) biomedicine(B-field).(O)", "instance": {"id": "245", "words": ["Applications", "of", "DSP", "include", "audio", "signal", "processing", ",", "audio", "compression", ",", "digital", "image", "processing", ",", "video", "compression", ",", "speech", "processing", ",", "speech", "recognition", ",", "digital", "communication", "s", ",", "digital", "synthesizer", "s", ",", "radar", ",", "sonar", ",", "financial", "signal", "processing", ",", "seismology", "and", "biomedicine", "."], "labels": ["O", "O", "B-field", "O", "B-task", "I-task", "I-task", "O", "B-task", "I-task", "O", "B-task", "B-task", "B-task", "O", "B-task", "I-task", "O", "B-task", "I-task", "O", "B-task", "I-task", "O", "B-task", "I-task", "O", "O", "B-task", "I-task", "O", "O", "B-field", "O", "B-field", "O", "B-field", "I-field", "I-field", "O", "B-field", "O", "B-field", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, country, location, programming language, product, researcher, task, field, person, organization, conference, metric, algorithm and O.\nSentence: Applications of DSP include audio signal processing , audio compression , digital image processing , video compression , speech processing , speech recognition , digital communication s , digital synthesizer s , radar , sonar , financial signal processing , seismology and biomedicine .", "prompt_labels": "Applications(O) of(O) DSP(B-field) include(O) audio(B-task) signal(I-task) processing(I-task) ,(O) audio(B-task) compression(I-task) ,(O) digital(B-task) image(B-task) processing(B-task) ,(O) video(B-task) compression(I-task) ,(O) speech(B-task) processing(I-task) ,(O) speech(B-task) recognition(I-task) ,(O) digital(B-task) communication(I-task) s(O) ,(O) digital(B-task) synthesizer(I-task) s(O) ,(O) radar(B-field) ,(O) sonar(B-field) ,(O) financial(B-field) signal(I-field) processing(I-field) ,(O) seismology(B-field) and(O) biomedicine(B-field) .(O)"}, "label_list": ["university", "country", "location", "programming language", "product", "researcher", "task", "field", "person", "organization", "conference", "metric", "algorithm"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12374, 11, 3224, 11, 3813, 11, 15840, 4221, 11, 2027, 11, 32185, 11, 3465, 11, 2115, 11, 1732, 11, 7471, 11, 10017, 11, 18767, 11, 12384, 323, 507, 627, 85664, 25, 32625, 315, 57693, 2997, 7855, 8450, 8863, 1174, 7855, 26168, 1174, 7528, 2217, 8863, 1174, 2835, 26168, 1174, 8982, 8863, 1174, 8982, 18324, 1174, 7528, 10758, 274, 1174, 7528, 52389, 3213, 274, 1174, 28608, 1174, 4538, 277, 1174, 6020, 8450, 8863, 1174, 513, 2191, 2508, 323, 6160, 25111, 55103, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1107", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) fast(B-Cuisine) food(I-Cuisine) is(O) near(B-Location) by(I-Location)", "instance": {"id": "1107", "words": ["what", "fast", "food", "is", "near", "by"], "labels": ["O", "B-Cuisine", "I-Cuisine", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Amenity, Dish, Hours, Price, Restaurant Name, Cuisine, Location and O.\nSentence: what fast food is near by", "prompt_labels": "what(O) fast(B-Cuisine) food(I-Cuisine) is(O) near(B-Location) by(I-Location)"}, "label_list": ["Rating", "Amenity", "Dish", "Hours", "Price", "Restaurant Name", "Cuisine", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 3383, 56685, 11, 49268, 11, 30192, 11, 8650, 11, 26568, 4076, 11, 81961, 11, 10067, 323, 507, 627, 85664, 25, 1148, 5043, 3691, 374, 3221, 555, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "77", "dataset": "crossner_science", "split": "dev", "prediction": "In(O) the(O) second(O) half(O) of(O) the(O) 20th(O) century(O),(O) plate(B-event) tectonics(I-event) theory(O) was(O) developed(O) by(O) several(O) contributors(O) including(O) Alfred(B-scientist) Wegener(I-scientist),(O) Maurice(B-scientist) Ewing(I-scientist),(O) Robert(B-scientist) S.(I-scientist) Dietz(I-scientist),(O) Harry(B-scientist) Hammond(I-scientist) Hess(I-scientist),(O) Hugo(B-scientist) Benioff(I-scientist),(O) Walter(B-scientist) C.(I-scientist) Pitman(I-scientist),(O) III(O),(O) Frederick(B-scientist) Vine(I-scientist),(O) Drummond(B-scientist) Matthews(I-scientist),(O) Keith(B-scientist) Runcorn(I-scientist),(O) Bryan(B-scientist) L.(I-scientist) Isacks(I-scientist),(O) Edward(B-scientist) Bullard(I-scientist),(O) Xavier(B-scientist) Le(I-scientist) Pichon(I-scientist),(O) Dan(B-scientist) McKenzie(I-scientist),(O) W.(B-scientist) Jason(I-scientist) Morgan(I-scientist) and(O) John(B-scientist) Tuzo(I-scientist) Wilson(I-scientist).(O)", "instance": {"id": "77", "words": ["In", "the", "second", "half", "of", "the", "20th", "century", ",", "plate", "tectonics", "theory", "was", "developed", "by", "several", "contributors", "including", "Alfred", "Wegener", ",", "Maurice", "Ewing", ",", "Robert", "S.", "Dietz", ",", "Harry", "Hammond", "Hess", ",", "Hugo", "Benioff", ",", "Walter", "C.", "Pitman", ",", "III", ",", "Frederick", "Vine", ",", "Drummond", "Matthews", ",", "Keith", "Runcorn", ",", "Bryan", "L.", "Isacks", ",", "Edward", "Bullard", ",", "Xavier", "Le", "Pichon", ",", "Dan", "McKenzie", ",", "W.", "Jason", "Morgan", "and", "John", "Tuzo", "Wilson", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-theory", "I-theory", "I-theory", "O", "O", "O", "O", "O", "O", "B-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "I-scientist", "I-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "I-scientist", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, discipline, protein, enzyme, university, chemical element, location, person, academic journal, astronomical object, theory, award, organization, chemical compound, scientist, country and O.\nSentence: In the second half of the 20th century , plate tectonics theory was developed by several contributors including Alfred Wegener , Maurice Ewing , Robert S. Dietz , Harry Hammond Hess , Hugo Benioff , Walter C. Pitman , III , Frederick Vine , Drummond Matthews , Keith Runcorn , Bryan L. Isacks , Edward Bullard , Xavier Le Pichon , Dan McKenzie , W. Jason Morgan and John Tuzo Wilson .", "prompt_labels": "In(O) the(O) second(O) half(O) of(O) the(O) 20th(O) century(O) ,(O) plate(B-theory) tectonics(I-theory) theory(I-theory) was(O) developed(O) by(O) several(O) contributors(O) including(O) Alfred(B-scientist) Wegener(I-scientist) ,(O) Maurice(B-scientist) Ewing(I-scientist) ,(O) Robert(B-scientist) S.(I-scientist) Dietz(I-scientist) ,(O) Harry(B-scientist) Hammond(I-scientist) Hess(I-scientist) ,(O) Hugo(B-scientist) Benioff(I-scientist) ,(O) Walter(B-scientist) C.(I-scientist) Pitman(I-scientist) ,(I-scientist) III(I-scientist) ,(O) Frederick(B-scientist) Vine(I-scientist) ,(O) Drummond(B-scientist) Matthews(I-scientist) ,(O) Keith(B-scientist) Runcorn(I-scientist) ,(O) Bryan(B-scientist) L.(I-scientist) Isacks(I-scientist) ,(O) Edward(B-scientist) Bullard(I-scientist) ,(O) Xavier(B-scientist) Le(I-scientist) Pichon(I-scientist) ,(O) Dan(B-scientist) McKenzie(I-scientist) ,(O) W.(B-scientist) Jason(I-scientist) Morgan(I-scientist) and(O) John(B-scientist) Tuzo(I-scientist) Wilson(I-scientist) .(O)"}, "label_list": ["event", "discipline", "protein", "enzyme", "university", "chemical element", "location", "person", "academic journal", "astronomical object", "theory", "award", "organization", "chemical compound", "scientist", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 26434, 11, 13128, 11, 49242, 11, 12374, 11, 11742, 2449, 11, 3813, 11, 1732, 11, 14584, 8486, 11, 87283, 1665, 11, 10334, 11, 10292, 11, 7471, 11, 11742, 24549, 11, 28568, 11, 3224, 323, 507, 627, 85664, 25, 763, 279, 2132, 4376, 315, 279, 220, 508, 339, 9478, 1174, 12235, 259, 440, 263, 1233, 10334, 574, 8040, 555, 3892, 20965, 2737, 42592, 59634, 804, 1174, 68529, 469, 24510, 1174, 8563, 328, 13, 27304, 89, 1174, 14253, 65443, 99805, 1174, 52194, 7505, 822, 544, 1174, 33305, 356, 13, 40079, 1543, 1174, 14767, 1174, 51764, 50795, 1174, 46506, 12669, 51784, 1174, 32602, 432, 1371, 1540, 1174, 37453, 445, 13, 2209, 7977, 1174, 22653, 22353, 569, 1174, 62860, 2009, 393, 718, 263, 1174, 11824, 93723, 1174, 468, 13, 18984, 23809, 323, 3842, 350, 5308, 78, 17882, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1646", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) a(O) teen(B-genre) movie(O) thats(O) rated(O) pg(B-rating) 13(I-rating) that(O) received(O) a(O) five(B-average ratings) stars(I-average ratings) and(I-average ratings) above(I-average ratings) rating(O)", "instance": {"id": "1646", "words": ["list", "a", "teen", "movie", "thats", "rated", "pg", "13", "that", "received", "a", "five", "stars", "and", "above", "rating"], "labels": ["O", "O", "B-genre", "O", "O", "O", "B-rating", "I-rating", "O", "O", "O", "B-average ratings", "I-average ratings", "I-average ratings", "I-average ratings", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, review, year, actor, plot, character, song, trailer, rating, title, director, genre and O.\nSentence: list a teen movie thats rated pg 13 that received a five stars and above rating", "prompt_labels": "list(O) a(O) teen(B-genre) movie(O) thats(O) rated(O) pg(B-rating) 13(I-rating) that(O) received(O) a(O) five(B-average ratings) stars(I-average ratings) and(I-average ratings) above(I-average ratings) rating(O)"}, "label_list": ["average ratings", "review", "year", "actor", "plot", "character", "song", "trailer", "rating", "title", "director", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 3477, 11, 1060, 11, 12360, 11, 7234, 11, 3752, 11, 5609, 11, 19809, 11, 10959, 11, 2316, 11, 7690, 11, 17779, 323, 507, 627, 85664, 25, 1160, 264, 9562, 5818, 41136, 22359, 17953, 220, 1032, 430, 4036, 264, 4330, 9958, 323, 3485, 10959, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1160", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) kind(O) of(O) food(O) does(O) ubice(B-Restaurant Name) sell(O)", "instance": {"id": "1160", "words": ["what", "kind", "of", "food", "does", "ubice", "sell"], "labels": ["O", "O", "O", "O", "O", "B-Restaurant Name", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Rating, Price, Location, Dish, Hours, Amenity, Restaurant Name and O.\nSentence: what kind of food does ubice sell", "prompt_labels": "what(O) kind(O) of(O) food(O) does(O) ubice(B-Restaurant Name) sell(O)"}, "label_list": ["Cuisine", "Rating", "Price", "Location", "Dish", "Hours", "Amenity", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 19767, 11, 8650, 11, 10067, 11, 49268, 11, 30192, 11, 3383, 56685, 11, 26568, 4076, 323, 507, 627, 85664, 25, 1148, 3169, 315, 3691, 1587, 18393, 560, 4662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1907", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) are(O) some(O) good(O) kids(B-genre) movies(O) starring(O) adrian(B-actor) pasdar(I-actor)", "instance": {"id": "1907", "words": ["what", "are", "some", "good", "kids", "movies", "starring", "adrian", "pasdar"], "labels": ["O", "O", "O", "B-average ratings", "B-genre", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, song, review, average ratings, plot, genre, actor, trailer, director, character, year, title and O.\nSentence: what are some good kids movies starring adrian pasdar", "prompt_labels": "what(O) are(O) some(O) good(B-average ratings) kids(B-genre) movies(O) starring(O) adrian(B-actor) pasdar(I-actor)"}, "label_list": ["rating", "song", "review", "average ratings", "plot", "genre", "actor", "trailer", "director", "character", "year", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 5609, 11, 3477, 11, 5578, 18594, 11, 7234, 11, 17779, 11, 12360, 11, 19809, 11, 7690, 11, 3752, 11, 1060, 11, 2316, 323, 507, 627, 85664, 25, 1148, 527, 1063, 1695, 6980, 9698, 40500, 1008, 7414, 6502, 35223, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1159", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) kind(O) of(O) food(O) does(O) this(O) place(O) have(O)", "instance": {"id": "1159", "words": ["what", "kind", "of", "food", "does", "this", "place", "have"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Rating, Price, Dish, Location, Restaurant Name, Amenity, Cuisine and O.\nSentence: what kind of food does this place have", "prompt_labels": "what(O) kind(O) of(O) food(O) does(O) this(O) place(O) have(O)"}, "label_list": ["Hours", "Rating", "Price", "Dish", "Location", "Restaurant Name", "Amenity", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 19767, 11, 8650, 11, 49268, 11, 10067, 11, 26568, 4076, 11, 3383, 56685, 11, 81961, 323, 507, 627, 85664, 25, 1148, 3169, 315, 3691, 1587, 420, 2035, 617, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1225", "dataset": "mit-restaurant", "split": "dev", "prediction": "whats(O) a(O) popular(B-Rating) place(O) to(O) east(B-Location)", "instance": {"id": "1225", "words": ["whats", "a", "popular", "place", "to", "east"], "labels": ["O", "O", "B-Rating", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Dish, Restaurant Name, Rating, Cuisine, Hours, Amenity, Location and O.\nSentence: whats a popular place to east", "prompt_labels": "whats(O) a(O) popular(B-Rating) place(O) to(O) east(O)"}, "label_list": ["Price", "Dish", "Restaurant Name", "Rating", "Cuisine", "Hours", "Amenity", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 49268, 11, 26568, 4076, 11, 19767, 11, 81961, 11, 30192, 11, 3383, 56685, 11, 10067, 323, 507, 627, 85664, 25, 41209, 264, 5526, 2035, 311, 11226, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "89", "dataset": "mit-movie", "split": "dev", "prediction": "are(O) there(O) any(O) movies(O) about(O) popular(B-average ratings) game(B-plot) shows(I-plot)", "instance": {"id": "89", "words": ["are", "there", "any", "movies", "about", "popular", "game", "shows"], "labels": ["O", "O", "O", "O", "O", "B-plot", "I-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, title, director, character, song, average ratings, rating, year, plot, actor, genre, trailer and O.\nSentence: are there any movies about popular game shows", "prompt_labels": "are(O) there(O) any(O) movies(O) about(O) popular(B-plot) game(I-plot) shows(I-plot)"}, "label_list": ["review", "title", "director", "character", "song", "average ratings", "rating", "year", "plot", "actor", "genre", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 2316, 11, 7690, 11, 3752, 11, 5609, 11, 5578, 18594, 11, 10959, 11, 1060, 11, 7234, 11, 12360, 11, 17779, 11, 19809, 323, 507, 627, 85664, 25, 527, 1070, 904, 9698, 922, 5526, 1847, 5039, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1572", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) there(O) biographical(B-genre) movie(O) witch(O) director(O) is(O) fritz(B-director) lang(I-director)", "instance": {"id": "1572", "words": ["is", "there", "biographical", "movie", "witch", "director", "is", "fritz", "lang"], "labels": ["O", "O", "B-genre", "O", "O", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, actor, title, plot, average ratings, director, trailer, genre, character, song, year, rating and O.\nSentence: is there biographical movie witch director is fritz lang", "prompt_labels": "is(O) there(O) biographical(B-genre) movie(O) witch(O) director(O) is(O) fritz(B-director) lang(I-director)"}, "label_list": ["review", "actor", "title", "plot", "average ratings", "director", "trailer", "genre", "character", "song", "year", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 12360, 11, 2316, 11, 7234, 11, 5578, 18594, 11, 7690, 11, 19809, 11, 17779, 11, 3752, 11, 5609, 11, 1060, 11, 10959, 323, 507, 627, 85664, 25, 374, 1070, 6160, 32277, 5818, 37482, 7690, 374, 282, 57821, 8859, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "145", "dataset": "crossner_literature", "split": "dev", "prediction": "Spengler(B-writer) spent(O) his(O) final(O) years(O) in(O) Munich(B-location),(O) listening(O) to(O) Ludwig(B-writer) van(I-writer) Beethoven(I-writer),(O) reading(O) Moli\u00e8re(B-writer) and(O) Shakespeare(B-writer),(O) buying(O) several(O) thousand(O) books(O),(O) and(O) collecting(O) ancient(O) Turkey(B-country),(O) Persia(B-country) n(O) and(O) India(B-country) n(O) weapons(O).(O)", "instance": {"id": "145", "words": ["Spengler", "spent", "his", "final", "years", "in", "Munich", ",", "listening", "to", "Ludwig", "van", "Beethoven", ",", "reading", "Moli\u00e8re", "and", "Shakespeare", ",", "buying", "several", "thousand", "books", ",", "and", "collecting", "ancient", "Turkey", ",", "Persia", "n", "and", "India", "n", "weapons", "."], "labels": ["B-person", "O", "O", "O", "O", "O", "B-location", "O", "O", "O", "B-person", "I-person", "I-person", "O", "O", "B-writer", "O", "B-writer", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-country", "O", "B-country", "O", "O", "B-country", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, book, writer, person, award, event, literary genre, organization, country, magazine, poem and O.\nSentence: Spengler spent his final years in Munich , listening to Ludwig van Beethoven , reading Moli\u00e8re and Shakespeare , buying several thousand books , and collecting ancient Turkey , Persia n and India n weapons .", "prompt_labels": "Spengler(B-person) spent(O) his(O) final(O) years(O) in(O) Munich(B-location) ,(O) listening(O) to(O) Ludwig(B-person) van(I-person) Beethoven(I-person) ,(O) reading(O) Moli\u00e8re(B-writer) and(O) Shakespeare(B-writer) ,(O) buying(O) several(O) thousand(O) books(O) ,(O) and(O) collecting(O) ancient(O) Turkey(B-country) ,(O) Persia(B-country) n(O) and(O) India(B-country) n(O) weapons(O) .(O)"}, "label_list": ["location", "book", "writer", "person", "award", "event", "literary genre", "organization", "country", "magazine", "poem"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 2363, 11, 7061, 11, 1732, 11, 10292, 11, 1567, 11, 32465, 17779, 11, 7471, 11, 3224, 11, 14756, 11, 33894, 323, 507, 627, 85664, 25, 3165, 833, 1565, 7543, 813, 1620, 1667, 304, 47304, 1174, 14624, 311, 85550, 5355, 2893, 93622, 1174, 5403, 386, 14559, 12339, 323, 42482, 1174, 12096, 3892, 16579, 6603, 1174, 323, 26984, 14154, 17442, 1174, 21097, 689, 308, 323, 6890, 308, 10094, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "71", "dataset": "crossner_science", "split": "dev", "prediction": "The(O) theory(O) has(O) been(O) published(O) in(O) three(O) peer-reviewed(O) journals(O) :(O) The(B-academic journal) Quarterly(I-academic journal) Review(I-academic journal) of(I-academic journal) Biology(I-academic journal),(O) Evolutionary(B-academic journal) Anthropology(I-academic journal) and(O) the(O) Journal(B-academic journal) of(I-academic journal) Theoretical(I-academic journal) Biology(I-academic journal).(O)", "instance": {"id": "71", "words": ["The", "theory", "has", "been", "published", "in", "three", "peer-reviewed", "journals", ":", "The", "Quarterly", "Review", "of", "Biology", ",", "Evolutionary", "Anthropology", "and", "the", "Journal", "of", "Theoretical", "Biology", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O", "B-academic journal", "I-academic journal", "O", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, event, award, theory, astronomical object, academic journal, organization, country, chemical element, enzyme, protein, location, discipline, person, chemical compound, university and O.\nSentence: The theory has been published in three peer-reviewed journals : The Quarterly Review of Biology , Evolutionary Anthropology and the Journal of Theoretical Biology .", "prompt_labels": "The(O) theory(O) has(O) been(O) published(O) in(O) three(O) peer-reviewed(O) journals(O) :(O) The(B-academic journal) Quarterly(I-academic journal) Review(I-academic journal) of(I-academic journal) Biology(I-academic journal) ,(O) Evolutionary(B-academic journal) Anthropology(I-academic journal) and(O) the(O) Journal(B-academic journal) of(I-academic journal) Theoretical(I-academic journal) Biology(I-academic journal) .(O)"}, "label_list": ["scientist", "event", "award", "theory", "astronomical object", "academic journal", "organization", "country", "chemical element", "enzyme", "protein", "location", "discipline", "person", "chemical compound", "university"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 28568, 11, 1567, 11, 10292, 11, 10334, 11, 87283, 1665, 11, 14584, 8486, 11, 7471, 11, 3224, 11, 11742, 2449, 11, 49242, 11, 13128, 11, 3813, 11, 26434, 11, 1732, 11, 11742, 24549, 11, 12374, 323, 507, 627, 85664, 25, 578, 10334, 706, 1027, 4756, 304, 2380, 14734, 79804, 42780, 551, 578, 75483, 10506, 315, 40023, 1174, 38321, 661, 70384, 2508, 323, 279, 10139, 315, 578, 91867, 40023, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "253", "dataset": "crossner_science", "split": "dev", "prediction": "In(O) 2005(O),(O) he(O) won(O) Grammy(B-award) Award(I-award) for(I-award) Best(I-award) Pop(I-award) Instrumental(I-award) Performance(I-award) for(O) Caravan(B-song) and(O) Grammy(B-award) Award(I-award) for(I-award) Best(I-award) Rock(I-award) Instrumental(I-award) Performance(I-award) for(O) 69(B-song) Freedom(I-song) Special(I-song).(O)", "instance": {"id": "253", "words": ["In", "2005", ",", "he", "won", "Grammy", "Award", "for", "Best", "Pop", "Instrumental", "Performance", "for", "Caravan", "and", "Grammy", "Award", "for", "Best", "Rock", "Instrumental", "Performance", "for", "69", "Freedom", "Special", "."], "labels": ["O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: theory, enzyme, academic journal, person, protein, chemical compound, location, organization, event, award, university, discipline, chemical element, astronomical object, scientist, country and O.\nSentence: In 2005 , he won Grammy Award for Best Pop Instrumental Performance for Caravan and Grammy Award for Best Rock Instrumental Performance for 69 Freedom Special .", "prompt_labels": "In(O) 2005(O) ,(O) he(O) won(O) Grammy(B-award) Award(I-award) for(I-award) Best(I-award) Pop(I-award) Instrumental(I-award) Performance(I-award) for(O) Caravan(O) and(O) Grammy(B-award) Award(I-award) for(I-award) Best(I-award) Rock(I-award) Instrumental(I-award) Performance(I-award) for(O) 69(O) Freedom(O) Special(O) .(O)"}, "label_list": ["theory", "enzyme", "academic journal", "person", "protein", "chemical compound", "location", "organization", "event", "award", "university", "discipline", "chemical element", "astronomical object", "scientist", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10334, 11, 49242, 11, 14584, 8486, 11, 1732, 11, 13128, 11, 11742, 24549, 11, 3813, 11, 7471, 11, 1567, 11, 10292, 11, 12374, 11, 26434, 11, 11742, 2449, 11, 87283, 1665, 11, 28568, 11, 3224, 323, 507, 627, 85664, 25, 763, 220, 1049, 20, 1174, 568, 2834, 74679, 17768, 369, 7252, 10466, 43405, 278, 21304, 369, 3341, 32005, 323, 74679, 17768, 369, 7252, 9305, 43405, 278, 21304, 369, 220, 3076, 25320, 9984, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "394", "dataset": "mit-movie", "split": "dev", "prediction": "name(O) the(O) film(O) that(O) features(O) the(O) song(O) sway(B-song) by(O) bic(B-song) runga(I-song)", "instance": {"id": "394", "words": ["name", "the", "film", "that", "features", "the", "song", "sway", "by", "bic", "runga"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-song", "I-song", "I-song", "I-song"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, year, trailer, review, character, title, song, average ratings, genre, rating, actor, director and O.\nSentence: name the film that features the song sway by bic runga", "prompt_labels": "name(O) the(O) film(O) that(O) features(O) the(O) song(O) sway(B-song) by(I-song) bic(I-song) runga(I-song)"}, "label_list": ["plot", "year", "trailer", "review", "character", "title", "song", "average ratings", "genre", "rating", "actor", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 1060, 11, 19809, 11, 3477, 11, 3752, 11, 2316, 11, 5609, 11, 5578, 18594, 11, 17779, 11, 10959, 11, 12360, 11, 7690, 323, 507, 627, 85664, 25, 836, 279, 4632, 430, 4519, 279, 5609, 61229, 555, 60831, 1629, 6885, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1285", "dataset": "mit-movie", "split": "dev", "prediction": "has(O) phylicia(B-actor) rashad(I-actor) done(O) any(O) r(B-rating) rated(O) action(B-genre) movies(O) in(O) the(O) past(B-year) six(I-year) years(I-year)", "instance": {"id": "1285", "words": ["has", "phylicia", "rashad", "done", "any", "r", "rated", "action", "movies", "in", "the", "past", "six", "years"], "labels": ["O", "B-actor", "I-actor", "O", "O", "B-rating", "O", "B-genre", "O", "O", "O", "B-year", "I-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, song, title, average ratings, actor, plot, genre, rating, character, trailer, review, year and O.\nSentence: has phylicia rashad done any r rated action movies in the past six years", "prompt_labels": "has(O) phylicia(B-actor) rashad(I-actor) done(O) any(O) r(B-rating) rated(O) action(B-genre) movies(O) in(O) the(O) past(B-year) six(I-year) years(I-year)"}, "label_list": ["director", "song", "title", "average ratings", "actor", "plot", "genre", "rating", "character", "trailer", "review", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 5609, 11, 2316, 11, 5578, 18594, 11, 12360, 11, 7234, 11, 17779, 11, 10959, 11, 3752, 11, 19809, 11, 3477, 11, 1060, 323, 507, 627, 85664, 25, 706, 37555, 416, 689, 57342, 329, 2884, 904, 436, 22359, 1957, 9698, 304, 279, 3347, 4848, 1667, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1583", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) r(B-rating) rated(O) movies(O) starring(O) clint(B-actor) eastwood(I-actor) in(O) the(O) last(B-year) ten(I-year) decades(I-year) with(O) a(O) fugitive(B-plot) plot(O) style(O)", "instance": {"id": "1583", "words": ["list", "r", "rated", "movies", "starring", "clint", "eastwood", "in", "the", "last", "ten", "decades", "with", "a", "fugitive", "plot", "style"], "labels": ["O", "B-rating", "O", "O", "O", "B-actor", "I-actor", "O", "O", "B-year", "I-year", "I-year", "O", "O", "B-plot", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, year, plot, average ratings, genre, character, actor, rating, title, song, director, trailer and O.\nSentence: list r rated movies starring clint eastwood in the last ten decades with a fugitive plot style", "prompt_labels": "list(O) r(B-rating) rated(O) movies(O) starring(O) clint(B-actor) eastwood(I-actor) in(O) the(O) last(B-year) ten(I-year) decades(I-year) with(O) a(O) fugitive(B-plot) plot(O) style(O)"}, "label_list": ["review", "year", "plot", "average ratings", "genre", "character", "actor", "rating", "title", "song", "director", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 1060, 11, 7234, 11, 5578, 18594, 11, 17779, 11, 3752, 11, 12360, 11, 10959, 11, 2316, 11, 5609, 11, 7690, 11, 19809, 323, 507, 627, 85664, 25, 1160, 436, 22359, 9698, 40500, 1206, 396, 11226, 6798, 304, 279, 1566, 5899, 11026, 449, 264, 49184, 3486, 7234, 1742, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "105", "dataset": "crossner_ai", "split": "dev", "prediction": "For(O) many(O) years(O) starting(O) from(O) 1986(O),(O) Miller(B-researcher) directed(O) the(O) development(O) of(O) WordNet(B-product),(O) a(O) large(O) computer-readable(O) electronic(O) reference(O) usable(O) in(O) applications(O) such(O) as(O) search(O) engines(O).(O)", "instance": {"id": "105", "words": ["For", "many", "years", "starting", "from", "1986", ",", "Miller", "directed", "the", "development", "of", "WordNet", ",", "a", "large", "computer-readable", "electronic", "reference", "usable", "in", "applications", "such", "as", "search", "engines", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-researcher", "O", "O", "O", "O", "B-product", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-product", "I-product", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: metric, algorithm, person, field, programming language, researcher, organization, task, university, product, location, country, conference and O.\nSentence: For many years starting from 1986 , Miller directed the development of WordNet , a large computer-readable electronic reference usable in applications such as search engines .", "prompt_labels": "For(O) many(O) years(O) starting(O) from(O) 1986(O) ,(O) Miller(B-researcher) directed(O) the(O) development(O) of(O) WordNet(B-product) ,(O) a(O) large(O) computer-readable(O) electronic(O) reference(O) usable(O) in(O) applications(O) such(O) as(O) search(B-product) engines(I-product) .(O)"}, "label_list": ["metric", "algorithm", "person", "field", "programming language", "researcher", "organization", "task", "university", "product", "location", "country", "conference"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18767, 11, 12384, 11, 1732, 11, 2115, 11, 15840, 4221, 11, 32185, 11, 7471, 11, 3465, 11, 12374, 11, 2027, 11, 3813, 11, 3224, 11, 10017, 323, 507, 627, 85664, 25, 1789, 1690, 1667, 6041, 505, 220, 3753, 21, 1174, 17472, 15910, 279, 4500, 315, 9506, 7099, 1174, 264, 3544, 6500, 84318, 14683, 5905, 41030, 304, 8522, 1778, 439, 2778, 21787, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "507", "dataset": "mit-movie", "split": "dev", "prediction": "in(O) what(O) year(O) did(O) the(O) film(O) vegas(B-title) vacation(I-title) come(O) out(O)", "instance": {"id": "507", "words": ["in", "what", "year", "did", "the", "film", "vegas", "vacation", "come", "out"], "labels": ["O", "O", "O", "O", "O", "O", "B-title", "I-title", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, trailer, director, year, review, character, genre, average ratings, rating, plot, title, song and O.\nSentence: in what year did the film vegas vacation come out", "prompt_labels": "in(O) what(O) year(O) did(O) the(O) film(O) vegas(B-title) vacation(I-title) come(O) out(O)"}, "label_list": ["actor", "trailer", "director", "year", "review", "character", "genre", "average ratings", "rating", "plot", "title", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 19809, 11, 7690, 11, 1060, 11, 3477, 11, 3752, 11, 17779, 11, 5578, 18594, 11, 10959, 11, 7234, 11, 2316, 11, 5609, 323, 507, 627, 85664, 25, 304, 1148, 1060, 1550, 279, 4632, 73539, 20769, 2586, 704, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1353", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) can(O) i(O) have(O) a(O) glass(B-Dish) of(I-Dish) wine(I-Dish) in(O) jamaica(B-Location) plain(I-Location) that(O) also(O) does(B-Amenity) not(I-Amenity) allow(I-Amenity) smoking(I-Amenity)", "instance": {"id": "1353", "words": ["where", "can", "i", "have", "a", "glass", "of", "wine", "in", "jamaica", "plain", "that", "also", "does", "not", "allow", "smoking"], "labels": ["O", "O", "O", "O", "O", "B-Rating", "O", "B-Cuisine", "O", "B-Location", "I-Location", "O", "O", "B-Amenity", "I-Amenity", "I-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Amenity, Dish, Location, Price, Rating, Cuisine, Restaurant Name and O.\nSentence: where can i have a glass of wine in jamaica plain that also does not allow smoking", "prompt_labels": "where(O) can(O) i(O) have(O) a(O) glass(B-Rating) of(O) wine(B-Cuisine) in(O) jamaica(B-Location) plain(I-Location) that(O) also(O) does(B-Amenity) not(I-Amenity) allow(I-Amenity) smoking(I-Amenity)"}, "label_list": ["Hours", "Amenity", "Dish", "Location", "Price", "Rating", "Cuisine", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 3383, 56685, 11, 49268, 11, 10067, 11, 8650, 11, 19767, 11, 81961, 11, 26568, 4076, 323, 507, 627, 85664, 25, 1405, 649, 602, 617, 264, 9168, 315, 13378, 304, 503, 3105, 3074, 14733, 430, 1101, 1587, 539, 2187, 20149, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1216", "dataset": "mit-movie", "split": "dev", "prediction": "do(O) you(O) know(O) the(O) title(O) to(O) the(O) documentary(B-genre) that(O) rutger(B-director) hauer(I-director) appeared(O) in(O) some(O) time(O) around(O) 1950(B-year)", "instance": {"id": "1216", "words": ["do", "you", "know", "the", "title", "to", "the", "documentary", "that", "rutger", "hauer", "appeared", "in", "some", "time", "around", "1950"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-genre", "O", "B-actor", "I-actor", "O", "O", "O", "O", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, actor, review, genre, title, character, director, rating, plot, year, trailer, song and O.\nSentence: do you know the title to the documentary that rutger hauer appeared in some time around 1950", "prompt_labels": "do(O) you(O) know(O) the(O) title(O) to(O) the(O) documentary(B-genre) that(O) rutger(B-actor) hauer(I-actor) appeared(O) in(O) some(O) time(O) around(O) 1950(B-year)"}, "label_list": ["average ratings", "actor", "review", "genre", "title", "character", "director", "rating", "plot", "year", "trailer", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 12360, 11, 3477, 11, 17779, 11, 2316, 11, 3752, 11, 7690, 11, 10959, 11, 7234, 11, 1060, 11, 19809, 11, 5609, 323, 507, 627, 85664, 25, 656, 499, 1440, 279, 2316, 311, 279, 25999, 430, 55719, 1414, 305, 28196, 9922, 304, 1063, 892, 2212, 220, 6280, 15, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "660", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) want(O) to(O) find(O) a(O) place(O) with(O) spaghetti(B-Dish) and(I-Dish) meatballs(I-Dish)", "instance": {"id": "660", "words": ["i", "want", "to", "find", "a", "place", "with", "spaghetti", "and", "meatballs"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-Dish", "I-Dish", "I-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Location, Price, Rating, Amenity, Hours, Restaurant Name, Dish and O.\nSentence: i want to find a place with spaghetti and meatballs", "prompt_labels": "i(O) want(O) to(O) find(O) a(O) place(O) with(O) spaghetti(B-Dish) and(I-Dish) meatballs(I-Dish)"}, "label_list": ["Cuisine", "Location", "Price", "Rating", "Amenity", "Hours", "Restaurant Name", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 10067, 11, 8650, 11, 19767, 11, 3383, 56685, 11, 30192, 11, 26568, 4076, 11, 49268, 323, 507, 627, 85664, 25, 602, 1390, 311, 1505, 264, 2035, 449, 88010, 323, 13339, 46618, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "138", "dataset": "mit-restaurant", "split": "dev", "prediction": "can(O) you(O) find(O) a(O) pizza(B-Cuisine) place(O) with(O) a(O) buffet(B-Amenity) within(B-Location) 15(I-Location) miles(I-Location)", "instance": {"id": "138", "words": ["can", "you", "find", "a", "pizza", "place", "with", "a", "buffet", "within", "15", "miles"], "labels": ["O", "O", "O", "O", "B-Cuisine", "O", "O", "O", "B-Amenity", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Location, Cuisine, Hours, Dish, Rating, Restaurant Name, Amenity and O.\nSentence: can you find a pizza place with a buffet within 15 miles", "prompt_labels": "can(O) you(O) find(O) a(O) pizza(B-Cuisine) place(O) with(O) a(O) buffet(B-Amenity) within(B-Location) 15(I-Location) miles(I-Location)"}, "label_list": ["Price", "Location", "Cuisine", "Hours", "Dish", "Rating", "Restaurant Name", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 10067, 11, 81961, 11, 30192, 11, 49268, 11, 19767, 11, 26568, 4076, 11, 3383, 56685, 323, 507, 627, 85664, 25, 649, 499, 1505, 264, 23317, 2035, 449, 264, 61886, 2949, 220, 868, 8931, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "386", "dataset": "crossner_science", "split": "dev", "prediction": "The(O) 2002(O) Nobel(B-award) Prize(I-award) in(I-award) Physiology(I-award) or(I-award) Medicine(I-award) was(O) awarded(O) to(O) Sydney(B-scientist) Brenner(I-scientist),(O) Horvitz(B-scientist) and(O) John(B-scientist) Sulston(I-scientist) for(O) their(O) work(O) identifying(O) genes(O) that(O) control(O) apoptosis(O).(O)", "instance": {"id": "386", "words": ["The", "2002", "Nobel", "Prize", "in", "Physiology", "or", "Medicine", "was", "awarded", "to", "Sydney", "Brenner", ",", "Horvitz", "and", "John", "Sulston", "for", "their", "work", "identifying", "genes", "that", "control", "apoptosis", "."], "labels": ["O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O", "O", "O", "B-scientist", "I-scientist", "O", "B-scientist", "O", "B-scientist", "I-scientist", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: theory, event, location, scientist, protein, organization, award, country, person, university, chemical element, discipline, academic journal, astronomical object, chemical compound, enzyme and O.\nSentence: The 2002 Nobel Prize in Physiology or Medicine was awarded to Sydney Brenner , Horvitz and John Sulston for their work identifying genes that control apoptosis .", "prompt_labels": "The(O) 2002(O) Nobel(B-award) Prize(I-award) in(I-award) Physiology(I-award) or(I-award) Medicine(I-award) was(O) awarded(O) to(O) Sydney(B-scientist) Brenner(I-scientist) ,(O) Horvitz(B-scientist) and(O) John(B-scientist) Sulston(I-scientist) for(O) their(O) work(O) identifying(O) genes(O) that(O) control(O) apoptosis(O) .(O)"}, "label_list": ["theory", "event", "location", "scientist", "protein", "organization", "award", "country", "person", "university", "chemical element", "discipline", "academic journal", "astronomical object", "chemical compound", "enzyme"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10334, 11, 1567, 11, 3813, 11, 28568, 11, 13128, 11, 7471, 11, 10292, 11, 3224, 11, 1732, 11, 12374, 11, 11742, 2449, 11, 26434, 11, 14584, 8486, 11, 87283, 1665, 11, 11742, 24549, 11, 49242, 323, 507, 627, 85664, 25, 578, 220, 1049, 17, 48078, 32293, 304, 95946, 477, 19152, 574, 22034, 311, 21972, 44808, 1215, 1174, 15083, 85, 11289, 323, 3842, 46962, 7876, 369, 872, 990, 25607, 21389, 430, 2585, 95874, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2301", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) directed(O) but(B-title) im(I-title) a(I-title) cheerleader(I-title)", "instance": {"id": "2301", "words": ["who", "directed", "but", "im", "a", "cheerleader"], "labels": ["O", "O", "B-title", "I-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, song, review, plot, year, actor, trailer, director, rating, average ratings, title, genre and O.\nSentence: who directed but im a cheerleader", "prompt_labels": "who(O) directed(O) but(B-title) im(I-title) a(I-title) cheerleader(I-title)"}, "label_list": ["character", "song", "review", "plot", "year", "actor", "trailer", "director", "rating", "average ratings", "title", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 5609, 11, 3477, 11, 7234, 11, 1060, 11, 12360, 11, 19809, 11, 7690, 11, 10959, 11, 5578, 18594, 11, 2316, 11, 17779, 323, 507, 627, 85664, 25, 889, 15910, 719, 737, 264, 26085, 38491, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "115", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) puss(B-title) in(I-title) boots(I-title) about(O)", "instance": {"id": "115", "words": ["what", "is", "puss", "in", "boots", "about"], "labels": ["O", "O", "B-title", "I-title", "I-title", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, year, review, genre, plot, character, director, actor, song, trailer, rating, average ratings and O.\nSentence: what is puss in boots about", "prompt_labels": "what(O) is(O) puss(B-title) in(I-title) boots(I-title) about(O)"}, "label_list": ["title", "year", "review", "genre", "plot", "character", "director", "actor", "song", "trailer", "rating", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 1060, 11, 3477, 11, 17779, 11, 7234, 11, 3752, 11, 7690, 11, 12360, 11, 5609, 11, 19809, 11, 10959, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1148, 374, 84800, 304, 26302, 922, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "913", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) any(O) restaurant(O) in(B-Location) the(I-Location) city(I-Location) that(O) serves(O) congee(B-Dish)", "instance": {"id": "913", "words": ["is", "there", "any", "restaurant", "in", "the", "city", "that", "serves", "congee"], "labels": ["O", "O", "O", "O", "B-Location", "I-Location", "I-Location", "O", "O", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Amenity, Dish, Cuisine, Rating, Location, Restaurant Name, Price and O.\nSentence: is there any restaurant in the city that serves congee", "prompt_labels": "is(O) there(O) any(O) restaurant(O) in(B-Location) the(I-Location) city(I-Location) that(O) serves(O) congee(B-Dish)"}, "label_list": ["Hours", "Amenity", "Dish", "Cuisine", "Rating", "Location", "Restaurant Name", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 3383, 56685, 11, 49268, 11, 81961, 11, 19767, 11, 10067, 11, 26568, 4076, 11, 8650, 323, 507, 627, 85664, 25, 374, 1070, 904, 10960, 304, 279, 3363, 430, 17482, 390, 99494, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1163", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) nearby(B-Location) is(O) open(B-Hours) past(I-Hours) midnight(I-Hours) and(O) has(O) fabulous(B-Amenity) service(I-Amenity)", "instance": {"id": "1163", "words": ["what", "nearby", "is", "open", "past", "midnight", "and", "has", "fabulous", "service"], "labels": ["O", "B-Location", "O", "B-Hours", "I-Hours", "I-Hours", "O", "O", "B-Rating", "I-Rating"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Hours, Rating, Cuisine, Dish, Location, Price, Amenity and O.\nSentence: what nearby is open past midnight and has fabulous service", "prompt_labels": "what(O) nearby(B-Location) is(O) open(B-Hours) past(I-Hours) midnight(I-Hours) and(O) has(O) fabulous(B-Rating) service(I-Rating)"}, "label_list": ["Restaurant Name", "Hours", "Rating", "Cuisine", "Dish", "Location", "Price", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 30192, 11, 19767, 11, 81961, 11, 49268, 11, 10067, 11, 8650, 11, 3383, 56685, 323, 507, 627, 85664, 25, 1148, 14373, 374, 1825, 3347, 33433, 323, 706, 35631, 2532, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1841", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) gary(B-actor) cooper(I-actor) thriller(B-genre) in(O) the(O) last(B-year) nine(I-year) years(I-year) has(O) a(O) very(B-average ratings) popular(I-average ratings) rating(O)", "instance": {"id": "1841", "words": ["what", "gary", "cooper", "thriller", "in", "the", "last", "nine", "years", "has", "a", "very", "popular", "rating"], "labels": ["O", "B-actor", "I-actor", "B-genre", "O", "O", "B-year", "I-year", "I-year", "O", "O", "B-average ratings", "I-average ratings", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, song, year, trailer, review, average ratings, title, plot, rating, director, character, actor and O.\nSentence: what gary cooper thriller in the last nine years has a very popular rating", "prompt_labels": "what(O) gary(B-actor) cooper(I-actor) thriller(B-genre) in(O) the(O) last(B-year) nine(I-year) years(I-year) has(O) a(O) very(B-average ratings) popular(I-average ratings) rating(O)"}, "label_list": ["genre", "song", "year", "trailer", "review", "average ratings", "title", "plot", "rating", "director", "character", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 5609, 11, 1060, 11, 19809, 11, 3477, 11, 5578, 18594, 11, 2316, 11, 7234, 11, 10959, 11, 7690, 11, 3752, 11, 12360, 323, 507, 627, 85664, 25, 1148, 342, 661, 22415, 54461, 304, 279, 1566, 11888, 1667, 706, 264, 1633, 5526, 10959, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "300", "dataset": "crossner_ai", "split": "dev", "prediction": "The(O) FALSE(B-metric) positive(I-metric) rate(I-metric) is(O) the(O) proportion(O) of(O) all(O) negatives(O) that(O) still(O) yield(O) positive(O) test(O) outcomes(O),(O) i.e.(O),(O) the(O) conditional(O) probability(O) of(O) a(O) positive(O) test(O) result(O) given(O) an(O) event(O) that(O) was(O) not(O) present(O).(O)", "instance": {"id": "300", "words": ["The", "FALSE", "positive", "rate", "is", "the", "proportion", "of", "all", "negatives", "that", "still", "yield", "positive", "test", "outcomes", ",", "i.e.", ",", "the", "conditional", "probability", "of", "a", "positive", "test", "result", "given", "an", "event", "that", "was", "not", "present", "."], "labels": ["O", "B-metric", "I-metric", "I-metric", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, field, university, product, country, organization, conference, metric, location, algorithm, researcher, programming language, task and O.\nSentence: The FALSE positive rate is the proportion of all negatives that still yield positive test outcomes , i.e. , the conditional probability of a positive test result given an event that was not present .", "prompt_labels": "The(O) FALSE(B-metric) positive(I-metric) rate(I-metric) is(O) the(O) proportion(O) of(O) all(O) negatives(O) that(O) still(O) yield(O) positive(O) test(O) outcomes(O) ,(O) i.e.(O) ,(O) the(O) conditional(O) probability(O) of(O) a(O) positive(O) test(O) result(O) given(O) an(O) event(O) that(O) was(O) not(O) present(O) .(O)"}, "label_list": ["person", "field", "university", "product", "country", "organization", "conference", "metric", "location", "algorithm", "researcher", "programming language", "task"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 2115, 11, 12374, 11, 2027, 11, 3224, 11, 7471, 11, 10017, 11, 18767, 11, 3813, 11, 12384, 11, 32185, 11, 15840, 4221, 11, 3465, 323, 507, 627, 85664, 25, 578, 7989, 6928, 4478, 374, 279, 21801, 315, 682, 75185, 430, 2103, 7692, 6928, 1296, 20124, 1174, 602, 1770, 13, 1174, 279, 35787, 19463, 315, 264, 6928, 1296, 1121, 2728, 459, 1567, 430, 574, 539, 3118, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2029", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) a(O) must(B-average ratings) see(I-average ratings) pg(B-rating) short(B-genre) film(O) directed(O) by(O) jonathan(B-director) demme(I-director)", "instance": {"id": "2029", "words": ["what", "is", "a", "must", "see", "pg", "short", "film", "directed", "by", "jonathan", "demme"], "labels": ["O", "O", "O", "B-average ratings", "I-average ratings", "B-rating", "B-genre", "O", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, rating, genre, trailer, character, director, average ratings, title, song, review, year, actor and O.\nSentence: what is a must see pg short film directed by jonathan demme", "prompt_labels": "what(O) is(O) a(O) must(B-average ratings) see(I-average ratings) pg(B-rating) short(B-genre) film(O) directed(O) by(O) jonathan(B-director) demme(I-director)"}, "label_list": ["plot", "rating", "genre", "trailer", "character", "director", "average ratings", "title", "song", "review", "year", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 10959, 11, 17779, 11, 19809, 11, 3752, 11, 7690, 11, 5578, 18594, 11, 2316, 11, 5609, 11, 3477, 11, 1060, 11, 12360, 323, 507, 627, 85664, 25, 1148, 374, 264, 2011, 1518, 17953, 2875, 4632, 15910, 555, 89604, 14308, 2486, 2727, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "89", "dataset": "crossner_literature", "split": "dev", "prediction": "Powers(B-writer) has(O) won(O) the(O) World(B-award) Fantasy(I-award) Award(I-award) twice(O) for(O) his(O) critically(O) acclaimed(O) novels(B-literary genre) Last(B-book) Call(I-book) and(O) Declare(B-book).(O)", "instance": {"id": "89", "words": ["Powers", "has", "won", "the", "World", "Fantasy", "Award", "twice", "for", "his", "critically", "acclaimed", "novels", "Last", "Call", "and", "Declare", "."], "labels": ["B-writer", "O", "O", "O", "B-award", "I-award", "I-award", "O", "O", "O", "O", "O", "B-literary genre", "B-book", "I-book", "O", "B-book", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, person, country, book, poem, award, event, literary genre, writer, organization, magazine and O.\nSentence: Powers has won the World Fantasy Award twice for his critically acclaimed novels Last Call and Declare .", "prompt_labels": "Powers(B-writer) has(O) won(O) the(O) World(B-award) Fantasy(I-award) Award(I-award) twice(O) for(O) his(O) critically(O) acclaimed(O) novels(B-literary genre) Last(B-book) Call(I-book) and(O) Declare(B-book) .(O)"}, "label_list": ["location", "person", "country", "book", "poem", "award", "event", "literary genre", "writer", "organization", "magazine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 1732, 11, 3224, 11, 2363, 11, 33894, 11, 10292, 11, 1567, 11, 32465, 17779, 11, 7061, 11, 7471, 11, 14756, 323, 507, 627, 85664, 25, 46137, 706, 2834, 279, 4435, 27582, 17768, 11157, 369, 813, 41440, 50082, 32963, 8155, 7290, 323, 62410, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "366", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) played(O) as(O) morpheus(B-character) in(O) the(B-title) matrix(I-title)", "instance": {"id": "366", "words": ["who", "played", "as", "morpheus", "in", "the", "matrix"], "labels": ["O", "O", "O", "B-character", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, director, title, actor, trailer, genre, year, character, review, plot, average ratings, song and O.\nSentence: who played as morpheus in the matrix", "prompt_labels": "who(O) played(O) as(O) morpheus(B-character) in(O) the(B-title) matrix(I-title)"}, "label_list": ["rating", "director", "title", "actor", "trailer", "genre", "year", "character", "review", "plot", "average ratings", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 7690, 11, 2316, 11, 12360, 11, 19809, 11, 17779, 11, 1060, 11, 3752, 11, 3477, 11, 7234, 11, 5578, 18594, 11, 5609, 323, 507, 627, 85664, 25, 889, 6476, 439, 4411, 81906, 355, 304, 279, 6303, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1307", "dataset": "mit-movie", "split": "dev", "prediction": "how(O) many(O) levels(O) of(O) dreams(O) are(O) in(O) the(O) movie(O) inception(B-title)", "instance": {"id": "1307", "words": ["how", "many", "levels", "of", "dreams", "are", "in", "the", "movie", "inception"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, average ratings, year, director, genre, trailer, character, actor, rating, plot, title, song and O.\nSentence: how many levels of dreams are in the movie inception", "prompt_labels": "how(O) many(O) levels(O) of(O) dreams(O) are(O) in(O) the(O) movie(O) inception(B-title)"}, "label_list": ["review", "average ratings", "year", "director", "genre", "trailer", "character", "actor", "rating", "plot", "title", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 5578, 18594, 11, 1060, 11, 7690, 11, 17779, 11, 19809, 11, 3752, 11, 12360, 11, 10959, 11, 7234, 11, 2316, 11, 5609, 323, 507, 627, 85664, 25, 1268, 1690, 5990, 315, 19226, 527, 304, 279, 5818, 54529, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "524", "dataset": "mit-movie", "split": "dev", "prediction": "run(O) a(O) trailer(B-trailer) for(O) an(O) audry(B-actor) murphy(I-actor) show(O)", "instance": {"id": "524", "words": ["run", "a", "trailer", "for", "an", "audry", "murphy", "show"], "labels": ["O", "O", "O", "O", "O", "B-actor", "I-actor", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, song, rating, title, character, actor, year, plot, director, average ratings, review, genre and O.\nSentence: run a trailer for an audry murphy show", "prompt_labels": "run(O) a(O) trailer(O) for(O) an(O) audry(B-actor) murphy(I-actor) show(O)"}, "label_list": ["trailer", "song", "rating", "title", "character", "actor", "year", "plot", "director", "average ratings", "review", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 5609, 11, 10959, 11, 2316, 11, 3752, 11, 12360, 11, 1060, 11, 7234, 11, 7690, 11, 5578, 18594, 11, 3477, 11, 17779, 323, 507, 627, 85664, 25, 1629, 264, 19809, 369, 459, 6264, 894, 8309, 12989, 1501, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "374", "dataset": "crossner_literature", "split": "dev", "prediction": "Turtledove(B-writer) won(O) the(O) Homer(B-award) Award(I-award) for(I-award) Short(I-award) Story(I-award) in(O) 1990(O) for(O) Designated(B-hitter) Hitter(I-hitter),(O) the(O) John(B-writer) Esten(I-writer) Cooke(I-writer) Award(I-writer) for(I-writer) Southern(I-writer) Fiction(I-writer) in(O) 1993(O) for(O) The(B-book) Guns(I-book) of(I-book) the(I-book) South(I-book),(O) and(O) the(O) Hugo(B-award) Award(I-award) for(I-award) Novella(I-award) in(O) 1994(O) for(O) Down(B-book) in(I-book) the(I-book) Bottomlands(I-book).(O)", "instance": {"id": "374", "words": ["Turtledove", "won", "the", "Homer", "Award", "for", "Short", "Story", "in", "1990", "for", "Designated", "Hitter", ",", "the", "John", "Esten", "Cooke", "Award", "for", "Southern", "Fiction", "in", "1993", "for", "The", "Guns", "of", "the", "South", ",", "and", "the", "Hugo", "Award", "for", "Novella", "in", "1994", "for", "Down", "in", "the", "Bottomlands", "."], "labels": ["B-writer", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "O", "O", "O", "B-book", "I-book", "O", "O", "B-award", "I-award", "I-award", "I-award", "O", "B-literary genre", "I-literary genre", "O", "O", "O", "B-book", "I-book", "I-book", "I-book", "I-book", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "O", "O", "O", "B-book", "I-book", "I-book", "I-book", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, location, literary genre, writer, book, country, magazine, award, organization, poem, event and O.\nSentence: Turtledove won the Homer Award for Short Story in 1990 for Designated Hitter , the John Esten Cooke Award for Southern Fiction in 1993 for The Guns of the South , and the Hugo Award for Novella in 1994 for Down in the Bottomlands .", "prompt_labels": "Turtledove(B-writer) won(O) the(O) Homer(B-award) Award(I-award) for(I-award) Short(I-award) Story(I-award) in(O) 1990(O) for(O) Designated(B-book) Hitter(I-book) ,(O) the(O) John(B-award) Esten(I-award) Cooke(I-award) Award(I-award) for(O) Southern(B-literary genre) Fiction(I-literary genre) in(O) 1993(O) for(O) The(B-book) Guns(I-book) of(I-book) the(I-book) South(I-book) ,(O) and(O) the(O) Hugo(B-award) Award(I-award) for(I-award) Novella(I-award) in(O) 1994(O) for(O) Down(B-book) in(I-book) the(I-book) Bottomlands(I-book) .(O)"}, "label_list": ["person", "location", "literary genre", "writer", "book", "country", "magazine", "award", "organization", "poem", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 3813, 11, 32465, 17779, 11, 7061, 11, 2363, 11, 3224, 11, 14756, 11, 10292, 11, 7471, 11, 33894, 11, 1567, 323, 507, 627, 85664, 25, 350, 5757, 839, 1009, 2834, 279, 66805, 17768, 369, 10928, 15457, 304, 220, 2550, 15, 369, 7127, 660, 473, 3328, 1174, 279, 3842, 9589, 268, 99839, 17768, 369, 16642, 43754, 304, 220, 2550, 18, 369, 578, 60565, 315, 279, 4987, 1174, 323, 279, 52194, 17768, 369, 4723, 6985, 304, 220, 2550, 19, 369, 6419, 304, 279, 26821, 8329, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "207", "dataset": "crossner_ai", "split": "dev", "prediction": "Learning(B-algorithm) classifier(I-algorithm) systems(I-algorithm) ((O) LCS(B-algorithm) )(O) are(O) a(O) family(O) of(O) rule-based(O) machine(B-field) learning(I-field) algorithms(O) that(O) combine(O) a(O) discovery(O) component(O),(O) typically(O) a(O) genetic(B-algorithm) algorithm(I-algorithm),(O) with(O) a(O) learning(O) component(O),(O) performing(O) either(O) supervised(B-field) learning(I-field),(O) reinforcement(B-field) learning(I-field),(O) or(O) unsupervised(B-field) learning(I-field).(O)", "instance": {"id": "207", "words": ["Learning", "classifier", "systems", "(", "LCS", ")", "are", "a", "family", "of", "rule-based", "machine", "learning", "algorithms", "that", "combine", "a", "discovery", "component", ",", "typically", "a", "genetic", "algorithm", ",", "with", "a", "learning", "component", ",", "performing", "either", "supervised", "learning", ",", "reinforcement", "learning", ",", "or", "unsupervised", "learning", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-algorithm", "I-algorithm", "O", "O", "O", "O", "O", "O", "O", "O", "B-field", "I-field", "O", "B-field", "I-field", "O", "O", "B-field", "I-field", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, person, product, conference, metric, country, organization, task, researcher, algorithm, university, location, field and O.\nSentence: Learning classifier systems ( LCS ) are a family of rule-based machine learning algorithms that combine a discovery component , typically a genetic algorithm , with a learning component , performing either supervised learning , reinforcement learning , or unsupervised learning .", "prompt_labels": "Learning(O) classifier(O) systems(O) ((O) LCS(O) )(O) are(O) a(O) family(O) of(O) rule-based(O) machine(O) learning(O) algorithms(O) that(O) combine(O) a(O) discovery(O) component(O) ,(O) typically(O) a(O) genetic(B-algorithm) algorithm(I-algorithm) ,(O) with(O) a(O) learning(O) component(O) ,(O) performing(O) either(O) supervised(B-field) learning(I-field) ,(O) reinforcement(B-field) learning(I-field) ,(O) or(O) unsupervised(B-field) learning(I-field) .(O)"}, "label_list": ["programming language", "person", "product", "conference", "metric", "country", "organization", "task", "researcher", "algorithm", "university", "location", "field"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 15840, 4221, 11, 1732, 11, 2027, 11, 10017, 11, 18767, 11, 3224, 11, 7471, 11, 3465, 11, 32185, 11, 12384, 11, 12374, 11, 3813, 11, 2115, 323, 507, 627, 85664, 25, 21579, 34465, 6067, 320, 84968, 883, 527, 264, 3070, 315, 6037, 6108, 5780, 6975, 26249, 430, 16343, 264, 18841, 3777, 1174, 11383, 264, 19465, 12384, 1174, 449, 264, 6975, 3777, 1174, 16785, 3060, 60089, 6975, 1174, 72378, 6975, 1174, 477, 7120, 455, 79090, 6975, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1427", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) is(O) the(O) nearest(B-Location) asia(B-Restaurant Name) express(I-Restaurant Name) restaurant(O)", "instance": {"id": "1427", "words": ["where", "is", "the", "nearest", "asia", "express", "restaurant"], "labels": ["O", "O", "O", "B-Location", "B-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Price, Dish, Amenity, Hours, Restaurant Name, Rating, Location and O.\nSentence: where is the nearest asia express restaurant", "prompt_labels": "where(O) is(O) the(O) nearest(B-Location) asia(B-Restaurant Name) express(I-Restaurant Name) restaurant(I-Restaurant Name)"}, "label_list": ["Cuisine", "Price", "Dish", "Amenity", "Hours", "Restaurant Name", "Rating", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 8650, 11, 49268, 11, 3383, 56685, 11, 30192, 11, 26568, 4076, 11, 19767, 11, 10067, 323, 507, 627, 85664, 25, 1405, 374, 279, 24379, 84599, 3237, 10960, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "210", "dataset": "crossner_ai", "split": "dev", "prediction": "An(O) illustration(O) of(O) their(O) capabilities(O) is(O) given(O) by(O) the(O) ImageNet(B-conference) Large(I-conference) Scale(I-conference) Visual(I-conference) Recognition(I-conference) Challenge(I-conference) ;(O) this(O) is(O) a(O) benchmark(O) in(O) object(O) classification(O) and(O) detection(O),(O) with(O) millions(O) of(O) images(O) and(O) hundreds(O) of(O) object(O) classes(O).(O)", "instance": {"id": "210", "words": ["An", "illustration", "of", "their", "capabilities", "is", "given", "by", "the", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", ";", "this", "is", "a", "benchmark", "in", "object", "classification", "and", "detection", ",", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-conference", "I-conference", "I-conference", "I-conference", "I-conference", "I-conference", "O", "O", "O", "O", "O", "O", "B-task", "I-task", "I-task", "I-task", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, field, algorithm, metric, task, university, researcher, product, country, person, location, programming language, conference and O.\nSentence: An illustration of their capabilities is given by the ImageNet Large Scale Visual Recognition Challenge ; this is a benchmark in object classification and detection , with millions of images and hundreds of object classes .", "prompt_labels": "An(O) illustration(O) of(O) their(O) capabilities(O) is(O) given(O) by(O) the(O) ImageNet(B-conference) Large(I-conference) Scale(I-conference) Visual(I-conference) Recognition(I-conference) Challenge(I-conference) ;(O) this(O) is(O) a(O) benchmark(O) in(O) object(B-task) classification(I-task) and(I-task) detection(I-task) ,(O) with(O) millions(O) of(O) images(O) and(O) hundreds(O) of(O) object(O) classes(O) .(O)"}, "label_list": ["organization", "field", "algorithm", "metric", "task", "university", "researcher", "product", "country", "person", "location", "programming language", "conference"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 2115, 11, 12384, 11, 18767, 11, 3465, 11, 12374, 11, 32185, 11, 2027, 11, 3224, 11, 1732, 11, 3813, 11, 15840, 4221, 11, 10017, 323, 507, 627, 85664, 25, 1556, 40134, 315, 872, 17357, 374, 2728, 555, 279, 4758, 7099, 20902, 25635, 20796, 48698, 26323, 2652, 420, 374, 264, 29531, 304, 1665, 24790, 323, 18468, 1174, 449, 11990, 315, 5448, 323, 11758, 315, 1665, 6989, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "404", "dataset": "crossner_science", "split": "dev", "prediction": "The(O) Australian(O) leg(O) began(O) on(O) February 28(O),(O) 2013(O),(O) in(O) Perth(B-location) at(O) the(O) Perth(B-location) Arena(I-location) and(O) ran(O) through(O) March(O) 16(O) in(O) Mackay(B-location) at(O) Stadium(B-location) Mackay(I-location).(O)", "instance": {"id": "404", "words": ["The", "Australian", "leg", "began", "on", "February", "28", ",", "2013", ",", "in", "Perth", "at", "the", "Perth", "Arena", "and", "ran", "through", "March", "16", "in", "Mackay", "at", "Stadium", "Mackay", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "O", "O", "B-location", "I-location", "O", "O", "O", "O", "O", "O", "B-location", "O", "B-location", "I-location", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: theory, protein, astronomical object, academic journal, university, person, scientist, event, chemical compound, enzyme, organization, award, country, chemical element, discipline, location and O.\nSentence: The Australian leg began on February 28 , 2013 , in Perth at the Perth Arena and ran through March 16 in Mackay at Stadium Mackay .", "prompt_labels": "The(O) Australian(O) leg(O) began(O) on(O) February(O) 28(O) ,(O) 2013(O) ,(O) in(O) Perth(B-location) at(O) the(O) Perth(B-location) Arena(I-location) and(O) ran(O) through(O) March(O) 16(O) in(O) Mackay(B-location) at(O) Stadium(B-location) Mackay(I-location) .(O)"}, "label_list": ["theory", "protein", "astronomical object", "academic journal", "university", "person", "scientist", "event", "chemical compound", "enzyme", "organization", "award", "country", "chemical element", "discipline", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10334, 11, 13128, 11, 87283, 1665, 11, 14584, 8486, 11, 12374, 11, 1732, 11, 28568, 11, 1567, 11, 11742, 24549, 11, 49242, 11, 7471, 11, 10292, 11, 3224, 11, 11742, 2449, 11, 26434, 11, 3813, 323, 507, 627, 85664, 25, 578, 13673, 2531, 6137, 389, 7552, 220, 1591, 1174, 220, 679, 18, 1174, 304, 50544, 520, 279, 50544, 28145, 323, 10837, 1555, 5587, 220, 845, 304, 33491, 352, 520, 23462, 33491, 352, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "974", "dataset": "mit-restaurant", "split": "dev", "prediction": "looking(O) for(O) crowd(B-Rating) pleasing(I-Rating) fatz(B-Dish) along(B-Location) the(I-Location) way(I-Location)", "instance": {"id": "974", "words": ["looking", "for", "crowd", "pleasing", "fatz", "along", "the", "way"], "labels": ["O", "O", "B-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Amenity, Dish, Rating, Restaurant Name, Cuisine, Hours, Price and O.\nSentence: looking for crowd pleasing fatz along the way", "prompt_labels": "looking(O) for(O) crowd(B-Restaurant Name) pleasing(I-Restaurant Name) fatz(I-Restaurant Name) along(B-Location) the(I-Location) way(I-Location)"}, "label_list": ["Location", "Amenity", "Dish", "Rating", "Restaurant Name", "Cuisine", "Hours", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 3383, 56685, 11, 49268, 11, 19767, 11, 26568, 4076, 11, 81961, 11, 30192, 11, 8650, 323, 507, 627, 85664, 25, 3411, 369, 13734, 54799, 8834, 89, 3235, 279, 1648, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "583", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movie(O) has(O) a(O) great(B-review) car(B-plot) chase(I-plot)", "instance": {"id": "583", "words": ["what", "movie", "has", "a", "great", "car", "chase"], "labels": ["O", "O", "O", "O", "B-plot", "I-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, review, actor, title, genre, character, year, trailer, song, plot, average ratings, rating and O.\nSentence: what movie has a great car chase", "prompt_labels": "what(O) movie(O) has(O) a(O) great(B-plot) car(I-plot) chase(I-plot)"}, "label_list": ["director", "review", "actor", "title", "genre", "character", "year", "trailer", "song", "plot", "average ratings", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 3477, 11, 12360, 11, 2316, 11, 17779, 11, 3752, 11, 1060, 11, 19809, 11, 5609, 11, 7234, 11, 5578, 18594, 11, 10959, 323, 507, 627, 85664, 25, 1148, 5818, 706, 264, 2294, 1841, 33586, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1300", "dataset": "mit-movie", "split": "dev", "prediction": "how(O) did(O) you(O) like(O) 4(B-title) months(I-title) 3(I-title) weeks(I-title) and(I-title) 2(I-title) days(I-title)", "instance": {"id": "1300", "words": ["how", "did", "you", "like", "4", "months", "3", "weeks", "and", "2", "days"], "labels": ["O", "O", "O", "O", "B-title", "I-title", "I-title", "I-title", "I-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, director, actor, review, year, plot, song, rating, title, character, average ratings, genre and O.\nSentence: how did you like 4 months 3 weeks and 2 days", "prompt_labels": "how(O) did(O) you(O) like(O) 4(B-title) months(I-title) 3(I-title) weeks(I-title) and(I-title) 2(I-title) days(I-title)"}, "label_list": ["trailer", "director", "actor", "review", "year", "plot", "song", "rating", "title", "character", "average ratings", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 7690, 11, 12360, 11, 3477, 11, 1060, 11, 7234, 11, 5609, 11, 10959, 11, 2316, 11, 3752, 11, 5578, 18594, 11, 17779, 323, 507, 627, 85664, 25, 1268, 1550, 499, 1093, 220, 19, 4038, 220, 18, 5672, 323, 220, 17, 2919, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "313", "dataset": "crossner_science", "split": "dev", "prediction": "Wang(B-scientist) has(O) published(O) over(O) 300(O) articles(O),(O) which(O) have(O) been(O) featured(O) in(O) publications(O) such(O) as(O) Nature(B-academic journal) Magazine(I-academic journal),(O) Science(B-academic journal),(O) Physical(B-academic journal) Review(I-academic journal) Letters(I-academic journal),(O) Angewandte(B-academic journal) Chemie(I-academic journal),(O) and(O) the(O) Journal(B-academic journal) of(I-academic journal) the(I-academic journal) American(I-academic journal) Chemical(I-academic journal) Society(I-academic journal).(O)", "instance": {"id": "313", "words": ["Wang", "has", "published", "over", "300", "articles", ",", "which", "have", "been", "featured", "in", "publications", "such", "as", "Nature", "Magazine", ",", "Science", ",", "Physical", "Review", "Letters", ",", "Angewandte", "Chemie", ",", "and", "the", "Journal", "of", "the", "American", "Chemical", "Society", "."], "labels": ["B-scientist", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-academic journal", "I-academic journal", "O", "B-academic journal", "O", "B-academic journal", "I-academic journal", "I-academic journal", "O", "B-academic journal", "I-academic journal", "O", "O", "O", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: astronomical object, organization, event, chemical compound, scientist, chemical element, theory, person, location, discipline, country, academic journal, protein, award, university, enzyme and O.\nSentence: Wang has published over 300 articles , which have been featured in publications such as Nature Magazine , Science , Physical Review Letters , Angewandte Chemie , and the Journal of the American Chemical Society .", "prompt_labels": "Wang(B-scientist) has(O) published(O) over(O) 300(O) articles(O) ,(O) which(O) have(O) been(O) featured(O) in(O) publications(O) such(O) as(O) Nature(B-academic journal) Magazine(I-academic journal) ,(O) Science(B-academic journal) ,(O) Physical(B-academic journal) Review(I-academic journal) Letters(I-academic journal) ,(O) Angewandte(B-academic journal) Chemie(I-academic journal) ,(O) and(O) the(O) Journal(B-academic journal) of(I-academic journal) the(I-academic journal) American(I-academic journal) Chemical(I-academic journal) Society(I-academic journal) .(O)"}, "label_list": ["astronomical object", "organization", "event", "chemical compound", "scientist", "chemical element", "theory", "person", "location", "discipline", "country", "academic journal", "protein", "award", "university", "enzyme"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 87283, 1665, 11, 7471, 11, 1567, 11, 11742, 24549, 11, 28568, 11, 11742, 2449, 11, 10334, 11, 1732, 11, 3813, 11, 26434, 11, 3224, 11, 14584, 8486, 11, 13128, 11, 10292, 11, 12374, 11, 49242, 323, 507, 627, 85664, 25, 29346, 706, 4756, 927, 220, 3101, 9908, 1174, 902, 617, 1027, 15109, 304, 29085, 1778, 439, 22037, 22168, 1174, 10170, 1174, 28479, 10506, 45397, 1174, 7568, 365, 438, 668, 19531, 648, 1174, 323, 279, 10139, 315, 279, 3778, 36424, 13581, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "352", "dataset": "mit-restaurant", "split": "dev", "prediction": "find(O) an(O) inexpensive(B-Price) mexican(B-Cuisine) restaurant(O) in(B-Location) the(I-Location) area(I-Location)", "instance": {"id": "352", "words": ["find", "an", "inexpensive", "mexican", "restaurant", "in", "the", "area"], "labels": ["O", "O", "B-Price", "B-Cuisine", "O", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Location, Rating, Hours, Cuisine, Restaurant Name, Dish, Price and O.\nSentence: find an inexpensive mexican restaurant in the area", "prompt_labels": "find(O) an(O) inexpensive(B-Price) mexican(B-Cuisine) restaurant(O) in(B-Location) the(I-Location) area(I-Location)"}, "label_list": ["Amenity", "Location", "Rating", "Hours", "Cuisine", "Restaurant Name", "Dish", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 10067, 11, 19767, 11, 30192, 11, 81961, 11, 26568, 4076, 11, 49268, 11, 8650, 323, 507, 627, 85664, 25, 1505, 459, 44252, 38049, 7210, 10960, 304, 279, 3158, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "193", "dataset": "crossner_science", "split": "dev", "prediction": "He(O) was(O) educated(O) at(O) the(O) Technical(B-university) University(I-university) of(I-university) Munich(I-university) from(O) 1925(O) to(O) 1927(O) and(O) then(O) entered(O) the(O) Technical(B-university) University(I-university) of(I-university) Berlin(I-university),(O) where(O) he(O) posited(O) that(O) microscope(O) s(O) using(O) electrons(O),(O) with(O) wavelengths(O) 1000(O) times(O) shorter(O) than(O) those(O) of(O) light(O),(O) could(O) provide(O) a(O) more(O) detailed(O) picture(O) of(O) an(O) object(O) than(O) a(O) microscope(O) utilizing(O) light(O),(O) in(O) which(O) magnification(O) is(O) limited(O) by(O) the(O) size(O) of(O) the(O) wavelengths(O).(O)", "instance": {"id": "193", "words": ["He", "was", "educated", "at", "the", "Technical", "University", "of", "Munich", "from", "1925", "to", "1927", "and", "then", "entered", "the", "Technical", "University", "of", "Berlin", ",", "where", "he", "posited", "that", "microscope", "s", "using", "electrons", ",", "with", "wavelengths", "1000", "times", "shorter", "than", "those", "of", "light", ",", "could", "provide", "a", "more", "detailed", "picture", "of", "an", "object", "than", "a", "microscope", "utilizing", "light", ",", "in", "which", "magnification", "is", "limited", "by", "the", "size", "of", "the", "wavelengths", "."], "labels": ["O", "O", "O", "O", "O", "B-university", "I-university", "I-university", "I-university", "O", "O", "O", "O", "O", "O", "O", "O", "B-university", "I-university", "I-university", "I-university", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, chemical element, person, location, country, scientist, enzyme, theory, astronomical object, chemical compound, event, discipline, award, protein, university, academic journal and O.\nSentence: He was educated at the Technical University of Munich from 1925 to 1927 and then entered the Technical University of Berlin , where he posited that microscope s using electrons , with wavelengths 1000 times shorter than those of light , could provide a more detailed picture of an object than a microscope utilizing light , in which magnification is limited by the size of the wavelengths .", "prompt_labels": "He(O) was(O) educated(O) at(O) the(O) Technical(B-university) University(I-university) of(I-university) Munich(I-university) from(O) 1925(O) to(O) 1927(O) and(O) then(O) entered(O) the(O) Technical(B-university) University(I-university) of(I-university) Berlin(I-university) ,(O) where(O) he(O) posited(O) that(O) microscope(O) s(O) using(O) electrons(O) ,(O) with(O) wavelengths(O) 1000(O) times(O) shorter(O) than(O) those(O) of(O) light(O) ,(O) could(O) provide(O) a(O) more(O) detailed(O) picture(O) of(O) an(O) object(O) than(O) a(O) microscope(O) utilizing(O) light(O) ,(O) in(O) which(O) magnification(O) is(O) limited(O) by(O) the(O) size(O) of(O) the(O) wavelengths(O) .(O)"}, "label_list": ["organization", "chemical element", "person", "location", "country", "scientist", "enzyme", "theory", "astronomical object", "chemical compound", "event", "discipline", "award", "protein", "university", "academic journal"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 11742, 2449, 11, 1732, 11, 3813, 11, 3224, 11, 28568, 11, 49242, 11, 10334, 11, 87283, 1665, 11, 11742, 24549, 11, 1567, 11, 26434, 11, 10292, 11, 13128, 11, 12374, 11, 14584, 8486, 323, 507, 627, 85664, 25, 1283, 574, 33142, 520, 279, 27766, 3907, 315, 47304, 505, 220, 5926, 20, 311, 220, 5926, 22, 323, 1243, 10862, 279, 27766, 3907, 315, 20437, 1174, 1405, 568, 1153, 1639, 430, 73757, 274, 1701, 57678, 1174, 449, 93959, 220, 1041, 15, 3115, 24210, 1109, 1884, 315, 3177, 1174, 1436, 3493, 264, 810, 11944, 6945, 315, 459, 1665, 1109, 264, 73757, 35988, 3177, 1174, 304, 902, 8622, 2461, 374, 7347, 555, 279, 1404, 315, 279, 93959, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1955", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) five(B-average ratings) star(I-average ratings) movies(O) from(O) the(O) 1950(B-year) s(I-year) featured(O) sophia(B-actor) loren(I-actor)", "instance": {"id": "1955", "words": ["what", "five", "star", "movies", "from", "the", "1950", "s", "featured", "sophia", "loren"], "labels": ["O", "B-average ratings", "O", "O", "O", "O", "B-year", "I-year", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, song, character, average ratings, year, genre, director, title, trailer, review, actor, plot and O.\nSentence: what five star movies from the 1950 s featured sophia loren", "prompt_labels": "what(O) five(B-average ratings) star(O) movies(O) from(O) the(O) 1950(B-year) s(I-year) featured(O) sophia(B-actor) loren(I-actor)"}, "label_list": ["rating", "song", "character", "average ratings", "year", "genre", "director", "title", "trailer", "review", "actor", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 5609, 11, 3752, 11, 5578, 18594, 11, 1060, 11, 17779, 11, 7690, 11, 2316, 11, 19809, 11, 3477, 11, 12360, 11, 7234, 323, 507, 627, 85664, 25, 1148, 4330, 6917, 9698, 505, 279, 220, 6280, 15, 274, 15109, 19219, 689, 326, 24568, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "416", "dataset": "crossner_science", "split": "dev", "prediction": "H3K4me3(O) is(O) an(O) epigenetic(O) modification(O) to(O) the(O) DNA(O) packaging(O) protein(O) Histone(B-protein) H3(I-protein).(O)", "instance": {"id": "416", "words": ["H3K4me3", "is", "an", "epigenetic", "modification", "to", "the", "DNA", "packaging", "protein", "Histone", "H3", "."], "labels": ["B-chemical compound", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-protein", "I-protein", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: theory, event, country, chemical element, scientist, university, astronomical object, organization, chemical compound, protein, location, person, award, academic journal, enzyme, discipline and O.\nSentence: H3K4me3 is an epigenetic modification to the DNA packaging protein Histone H3 .", "prompt_labels": "H3K4me3(B-chemical compound) is(O) an(O) epigenetic(O) modification(O) to(O) the(O) DNA(O) packaging(O) protein(O) Histone(B-protein) H3(I-protein) .(O)"}, "label_list": ["theory", "event", "country", "chemical element", "scientist", "university", "astronomical object", "organization", "chemical compound", "protein", "location", "person", "award", "academic journal", "enzyme", "discipline"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10334, 11, 1567, 11, 3224, 11, 11742, 2449, 11, 28568, 11, 12374, 11, 87283, 1665, 11, 7471, 11, 11742, 24549, 11, 13128, 11, 3813, 11, 1732, 11, 10292, 11, 14584, 8486, 11, 49242, 11, 26434, 323, 507, 627, 85664, 25, 473, 18, 42, 19, 2727, 18, 374, 459, 4248, 6569, 5411, 17466, 311, 279, 15922, 24066, 13128, 67005, 606, 473, 18, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1013", "dataset": "mit-restaurant", "split": "dev", "prediction": "newbury(B-Location) street(I-Location) bakery(B-Cuisine) and(I-Cuisine) deli(I-Cuisine) directions(O)", "instance": {"id": "1013", "words": ["newbury", "street", "bakery", "and", "deli", "directions"], "labels": ["B-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Amenity, Price, Hours, Rating, Location, Dish, Restaurant Name and O.\nSentence: newbury street bakery and deli directions", "prompt_labels": "newbury(B-Restaurant Name) street(I-Restaurant Name) bakery(I-Restaurant Name) and(I-Restaurant Name) deli(I-Restaurant Name) directions(O)"}, "label_list": ["Cuisine", "Amenity", "Price", "Hours", "Rating", "Location", "Dish", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 3383, 56685, 11, 8650, 11, 30192, 11, 19767, 11, 10067, 11, 49268, 11, 26568, 4076, 323, 507, 627, 85664, 25, 502, 20176, 8761, 66244, 323, 1624, 72, 18445, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "449", "dataset": "crossner_politics", "split": "dev", "prediction": "The(O) signatories(O) included(O) Prof(O) David(B-politician) Epstein(I-politician),(O) Mike(B-politician) Leigh(I-politician),(O) Prof(O) Michael(B-politician) Rosen(I-politician),(O) Prof(O) Avi(B-politician) Shlaim(I-politician),(O) Gillian(B-politician) Slovo(I-politician),(O) Prof(O) Annabelle(B-politician) Sreberny(I-politician),(O) Walter(B-politician) Wolfgang(I-politician),(O) Peter(B-politician) Buckman(I-politician),(O) Erica(B-politician) Burman(I-politician),(O) Keith(B-politician) Burstein(I-politician),(O) Miriam(B-politician) David(I-politician),(O) Michael(B-politician) Ellman(I-politician),(O) Nick(B-politician) Foster(I-politician),(O) Susan(B-politician) Himmelweit(I-politician),(O) Selma(B-politician) James(I-politician),(O) Ann(B-politician) Jungman(I-politician),(O) Frank(B-politician) Land(I-politician),(O) Gillian(B-politician) McCall(I-politician),(O) Helen(B-politician) Pearson(I-politician) and(O) Ian(B-politician) Saville(I-politician).(O)", "instance": {"id": "449", "words": ["The", "signatories", "included", "Prof", "David", "Epstein", ",", "Mike", "Leigh", ",", "Prof", "Michael", "Rosen", ",", "Prof", "Avi", "Shlaim", ",", "Gillian", "Slovo", ",", "Prof", "Annabelle", "Sreberny", ",", "Walter", "Wolfgang", ",", "Peter", "Buckman", ",", "Erica", "Burman", ",", "Keith", "Burstein", ",", "Miriam", "David", ",", "Michael", "Ellman", ",", "Nick", "Foster", ",", "Susan", "Himmelweit", ",", "Selma", "James", ",", "Ann", "Jungman", ",", "Frank", "Land", ",", "Gillian", "McCall", ",", "Helen", "Pearson", "and", "Ian", "Saville", "."], "labels": ["O", "O", "O", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "O", "B-person", "I-person", "O", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, political party, organization, location, election, politician, event, person and O.\nSentence: The signatories included Prof David Epstein , Mike Leigh , Prof Michael Rosen , Prof Avi Shlaim , Gillian Slovo , Prof Annabelle Sreberny , Walter Wolfgang , Peter Buckman , Erica Burman , Keith Burstein , Miriam David , Michael Ellman , Nick Foster , Susan Himmelweit , Selma James , Ann Jungman , Frank Land , Gillian McCall , Helen Pearson and Ian Saville .", "prompt_labels": "The(O) signatories(O) included(O) Prof(O) David(B-person) Epstein(I-person) ,(O) Mike(B-person) Leigh(I-person) ,(O) Prof(O) Michael(B-person) Rosen(I-person) ,(O) Prof(O) Avi(B-person) Shlaim(I-person) ,(O) Gillian(B-person) Slovo(I-person) ,(O) Prof(O) Annabelle(B-person) Sreberny(I-person) ,(O) Walter(B-person) Wolfgang(I-person) ,(O) Peter(B-person) Buckman(I-person) ,(O) Erica(B-person) Burman(I-person) ,(O) Keith(B-person) Burstein(I-person) ,(O) Miriam(B-person) David(I-person) ,(O) Michael(B-person) Ellman(I-person) ,(O) Nick(B-person) Foster(I-person) ,(O) Susan(B-person) Himmelweit(I-person) ,(O) Selma(B-person) James(I-person) ,(O) Ann(B-person) Jungman(I-person) ,(O) Frank(B-person) Land(I-person) ,(O) Gillian(B-person) McCall(I-person) ,(O) Helen(B-person) Pearson(I-person) and(O) Ian(B-person) Saville(I-person) .(O)"}, "label_list": ["country", "political party", "organization", "location", "election", "politician", "event", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 5054, 4717, 11, 7471, 11, 3813, 11, 6355, 11, 37038, 11, 1567, 11, 1732, 323, 507, 627, 85664, 25, 578, 1879, 38270, 5343, 8626, 6941, 81132, 1174, 11519, 74122, 1174, 8626, 8096, 35120, 1174, 8626, 7671, 72, 1443, 75, 2706, 1174, 33826, 1122, 26685, 3415, 1174, 8626, 9489, 55267, 328, 265, 655, 3919, 1174, 33305, 87598, 1174, 11291, 27156, 1543, 1174, 92935, 12649, 1543, 1174, 32602, 12649, 12711, 1174, 14603, 5038, 6941, 1174, 8096, 13852, 1543, 1174, 15341, 39274, 1174, 31033, 473, 65964, 74511, 1174, 24082, 1764, 7957, 1174, 9489, 50432, 1543, 1174, 9454, 11680, 1174, 33826, 1122, 4584, 7368, 1174, 43881, 59642, 323, 29335, 20680, 4618, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1417", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) is(O) the(O) closest(B-Location) place(I-Location) to(O) get(O) cheap(B-Price) potatoes(B-Dish)", "instance": {"id": "1417", "words": ["where", "is", "the", "closest", "place", "to", "get", "cheap", "potatoes"], "labels": ["O", "O", "O", "B-Location", "O", "O", "O", "B-Price", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Dish, Amenity, Cuisine, Rating, Hours, Location, Restaurant Name and O.\nSentence: where is the closest place to get cheap potatoes", "prompt_labels": "where(O) is(O) the(O) closest(B-Location) place(O) to(O) get(O) cheap(B-Price) potatoes(B-Dish)"}, "label_list": ["Price", "Dish", "Amenity", "Cuisine", "Rating", "Hours", "Location", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 49268, 11, 3383, 56685, 11, 81961, 11, 19767, 11, 30192, 11, 10067, 11, 26568, 4076, 323, 507, 627, 85664, 25, 1405, 374, 279, 18585, 2035, 311, 636, 12136, 35267, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "521", "dataset": "crossner_politics", "split": "dev", "prediction": "Campaigning(O) in(O) the(O) United(B-country) Kingdom(I-country) European(O) Union(O) membership(O) referendum(O) began(O) unofficially(O) on(O) 20(O) February(O) 2016(O) when(O) Prime(O) Minister(O) David(B-politician) Cameron(I-politician) formally(O) announced(O) under(O) the(O) terms(O) of(O) the(O) European(O) Union(O) Referendum(O) Act(O) 2015(O) that(O) a(O) referendum(O) would(O) be(O) held(O) on(O) the(O) issue(O) of(O) the(O) United(B-country) Kingdom(I-country)'s(O) membership(O) of(O) the(O) European(O) Union(O).(O)", "instance": {"id": "521", "words": ["Campaigning", "in", "the", "United", "Kingdom", "European", "Union", "membership", "referendum", "began", "unofficially", "on", "20", "February", "2016", "when", "Prime", "Minister", "David", "Cameron", "formally", "announced", "under", "the", "terms", "of", "the", "European", "Union", "Referendum", "Act", "2015", "that", "a", "referendum", "would", "be", "held", "on", "the", "issue", "of", "the", "United", "Kingdom", "'s", "membership", "of", "the", "European", "Union", "."], "labels": ["O", "O", "O", "B-country", "I-country", "B-event", "I-event", "I-event", "I-event", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-politician", "I-politician", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-country", "I-country", "O", "O", "O", "O", "B-organization", "I-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, election, political party, person, country, politician, event, location and O.\nSentence: Campaigning in the United Kingdom European Union membership referendum began unofficially on 20 February 2016 when Prime Minister David Cameron formally announced under the terms of the European Union Referendum Act 2015 that a referendum would be held on the issue of the United Kingdom 's membership of the European Union .", "prompt_labels": "Campaigning(O) in(O) the(O) United(B-country) Kingdom(I-country) European(B-event) Union(I-event) membership(I-event) referendum(I-event) began(O) unofficially(O) on(O) 20(O) February(O) 2016(O) when(O) Prime(O) Minister(O) David(B-politician) Cameron(I-politician) formally(O) announced(O) under(O) the(O) terms(O) of(O) the(O) European(O) Union(O) Referendum(O) Act(O) 2015(O) that(O) a(O) referendum(O) would(O) be(O) held(O) on(O) the(O) issue(O) of(O) the(O) United(B-country) Kingdom(I-country) 's(O) membership(O) of(O) the(O) European(B-organization) Union(I-organization) .(O)"}, "label_list": ["organization", "election", "political party", "person", "country", "politician", "event", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 6355, 11, 5054, 4717, 11, 1732, 11, 3224, 11, 37038, 11, 1567, 11, 3813, 323, 507, 627, 85664, 25, 27643, 287, 304, 279, 3723, 15422, 7665, 9323, 16250, 30798, 6137, 57751, 398, 389, 220, 508, 7552, 220, 679, 21, 994, 12801, 9675, 6941, 27524, 37402, 7376, 1234, 279, 3878, 315, 279, 7665, 9323, 29734, 25547, 3298, 220, 679, 20, 430, 264, 30798, 1053, 387, 5762, 389, 279, 4360, 315, 279, 3723, 15422, 364, 82, 16250, 315, 279, 7665, 9323, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2441", "dataset": "mit-movie", "split": "dev", "prediction": "find(O) me(O) some(O) adventure(B-genre) movies(O) with(O) indiana(B-character) jones(I-character)", "instance": {"id": "2441", "words": ["find", "me", "some", "adventure", "movies", "with", "indiana", "jones"], "labels": ["O", "O", "O", "B-genre", "O", "O", "B-character", "I-character"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, review, trailer, character, plot, rating, actor, average ratings, title, year, song, genre and O.\nSentence: find me some adventure movies with indiana jones", "prompt_labels": "find(O) me(O) some(O) adventure(B-genre) movies(O) with(O) indiana(B-character) jones(I-character)"}, "label_list": ["director", "review", "trailer", "character", "plot", "rating", "actor", "average ratings", "title", "year", "song", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 3477, 11, 19809, 11, 3752, 11, 7234, 11, 10959, 11, 12360, 11, 5578, 18594, 11, 2316, 11, 1060, 11, 5609, 11, 17779, 323, 507, 627, 85664, 25, 1505, 757, 1063, 18427, 9698, 449, 1280, 12699, 503, 3233, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "67", "dataset": "crossner_literature", "split": "dev", "prediction": "This(O) aversion(O) to(O) war(B-genre) also(O) led(O) Einstein(B-writer) to(O) befriend(O) author(O) Upton(B-writer) Sinclair(I-writer) and(O) film(O) star(O) Charlie(B-person) Chaplin(I-person),(O) both(O) noted(O) for(O) their(O) pacifism(O).(O)", "instance": {"id": "67", "words": ["This", "aversion", "to", "war", "also", "led", "Einstein", "to", "befriend", "author", "Upton", "Sinclair", "and", "film", "star", "Charlie", "Chaplin", ",", "both", "noted", "for", "their", "pacifism", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-person", "O", "O", "O", "B-writer", "I-writer", "O", "O", "O", "B-person", "I-person", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: book, poem, magazine, organization, location, person, event, country, writer, literary genre, award and O.\nSentence: This aversion to war also led Einstein to befriend author Upton Sinclair and film star Charlie Chaplin , both noted for their pacifism .", "prompt_labels": "This(O) aversion(O) to(O) war(O) also(O) led(O) Einstein(B-person) to(O) befriend(O) author(O) Upton(B-writer) Sinclair(I-writer) and(O) film(O) star(O) Charlie(B-person) Chaplin(I-person) ,(O) both(O) noted(O) for(O) their(O) pacifism(O) .(O)"}, "label_list": ["book", "poem", "magazine", "organization", "location", "person", "event", "country", "writer", "literary genre", "award"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2363, 11, 33894, 11, 14756, 11, 7471, 11, 3813, 11, 1732, 11, 1567, 11, 3224, 11, 7061, 11, 32465, 17779, 11, 10292, 323, 507, 627, 85664, 25, 1115, 1860, 1349, 311, 4208, 1101, 6197, 55152, 311, 387, 10931, 3229, 549, 19271, 74289, 323, 4632, 6917, 25972, 27747, 3817, 1174, 2225, 10555, 369, 872, 23744, 333, 2191, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "16", "dataset": "mit-restaurant", "split": "dev", "prediction": "anything(O) open(B-Hours) after(I-Hours) midnight(I-Hours) with(O) reasonable(B-Price) prices(O)", "instance": {"id": "16", "words": ["anything", "open", "after", "midnight", "with", "reasonable", "prices"], "labels": ["O", "B-Hours", "I-Hours", "I-Hours", "O", "B-Price", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Price, Rating, Cuisine, Hours, Dish, Amenity, Location and O.\nSentence: anything open after midnight with reasonable prices", "prompt_labels": "anything(O) open(B-Hours) after(I-Hours) midnight(I-Hours) with(O) reasonable(B-Price) prices(O)"}, "label_list": ["Restaurant Name", "Price", "Rating", "Cuisine", "Hours", "Dish", "Amenity", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 8650, 11, 19767, 11, 81961, 11, 30192, 11, 49268, 11, 3383, 56685, 11, 10067, 323, 507, 627, 85664, 25, 4205, 1825, 1306, 33433, 449, 13579, 7729, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "525", "dataset": "mit-movie", "split": "dev", "prediction": "find(O) a(O) horror(B-genre) movie(O) with(O) creepy(B-plot) little(I-plot) girls(I-plot)", "instance": {"id": "525", "words": ["find", "a", "horror", "movie", "with", "creepy", "little", "girls"], "labels": ["O", "O", "B-genre", "O", "O", "B-plot", "I-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, year, average ratings, genre, review, actor, plot, director, song, character, rating, trailer and O.\nSentence: find a horror movie with creepy little girls", "prompt_labels": "find(O) a(O) horror(B-genre) movie(O) with(O) creepy(B-plot) little(I-plot) girls(I-plot)"}, "label_list": ["title", "year", "average ratings", "genre", "review", "actor", "plot", "director", "song", "character", "rating", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 1060, 11, 5578, 18594, 11, 17779, 11, 3477, 11, 12360, 11, 7234, 11, 7690, 11, 5609, 11, 3752, 11, 10959, 11, 19809, 323, 507, 627, 85664, 25, 1505, 264, 22169, 5818, 449, 51940, 2697, 7724, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "465", "dataset": "mit-movie", "split": "dev", "prediction": "find(O) me(O) the(O) review(B-average ratings) of(O) black(B-title) swan(I-title)", "instance": {"id": "465", "words": ["find", "me", "the", "review", "of", "black", "swan"], "labels": ["O", "O", "O", "B-average ratings", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, title, genre, actor, director, trailer, song, review, plot, rating, average ratings, year and O.\nSentence: find me the review of black swan", "prompt_labels": "find(O) me(O) the(O) review(B-average ratings) of(O) black(B-title) swan(I-title)"}, "label_list": ["character", "title", "genre", "actor", "director", "trailer", "song", "review", "plot", "rating", "average ratings", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 2316, 11, 17779, 11, 12360, 11, 7690, 11, 19809, 11, 5609, 11, 3477, 11, 7234, 11, 10959, 11, 5578, 18594, 11, 1060, 323, 507, 627, 85664, 25, 1505, 757, 279, 3477, 315, 3776, 2064, 276, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "284", "dataset": "crossner_music", "split": "dev", "prediction": "Wills(B-musical artist) favored(O) jazz-like(O) arrangements(O) and(O) the(O) band(O) found(O) national(O) popularity(O) into(O) the(O) 1940s(O) with(O) such(O) hits(O) as(O) Steel(B-song) Guitar(I-song) Rag(I-song),(O) New(B-song) San(I-song) Antonio(I-song) Rose(I-song),(O) Smoke(B-song) On(I-song) The(I-song) Water(I-song),(O) Stars(B-song) And(I-song) Stripes(I-song) On(I-song) Iwo(I-song) Jima(I-song),(O) and(O) New(B-song) Spanish(I-song) Two(I-song) Step(I-song).(O)", "instance": {"id": "284", "words": ["Wills", "favored", "jazz-like", "arrangements", "and", "the", "band", "found", "national", "popularity", "into", "the", "1940s", "with", "such", "hits", "as", "Steel", "Guitar", "Rag", ",", "New", "San", "Antonio", "Rose", ",", "Smoke", "On", "The", "Water", ",", "Stars", "And", "Stripes", "On", "Iwo", "Jima", ",", "and", "New", "Spanish", "Two", "Step", "."], "labels": ["B-musical artist", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-song", "I-song", "I-song", "O", "B-song", "I-song", "I-song", "I-song", "O", "B-song", "I-song", "I-song", "I-song", "O", "B-song", "I-song", "I-song", "I-song", "I-song", "I-song", "O", "O", "B-song", "I-song", "I-song", "I-song", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, person, award, event, musical artist, location, music genre, album, organization, song, country, band and O.\nSentence: Wills favored jazz-like arrangements and the band found national popularity into the 1940s with such hits as Steel Guitar Rag , New San Antonio Rose , Smoke On The Water , Stars And Stripes On Iwo Jima , and New Spanish Two Step .", "prompt_labels": "Wills(B-musical artist) favored(O) jazz-like(O) arrangements(O) and(O) the(O) band(O) found(O) national(O) popularity(O) into(O) the(O) 1940s(O) with(O) such(O) hits(O) as(O) Steel(B-song) Guitar(I-song) Rag(I-song) ,(O) New(B-song) San(I-song) Antonio(I-song) Rose(I-song) ,(O) Smoke(B-song) On(I-song) The(I-song) Water(I-song) ,(O) Stars(B-song) And(I-song) Stripes(I-song) On(I-song) Iwo(I-song) Jima(I-song) ,(O) and(O) New(B-song) Spanish(I-song) Two(I-song) Step(I-song) .(O)"}, "label_list": ["musical instrument", "person", "award", "event", "musical artist", "location", "music genre", "album", "organization", "song", "country", "band"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18273, 14473, 11, 1732, 11, 10292, 11, 1567, 11, 18273, 10255, 11, 3813, 11, 4731, 17779, 11, 8176, 11, 7471, 11, 5609, 11, 3224, 11, 7200, 323, 507, 627, 85664, 25, 468, 3385, 46603, 34997, 12970, 28904, 323, 279, 7200, 1766, 5426, 23354, 1139, 279, 220, 6393, 15, 82, 449, 1778, 13280, 439, 12783, 47759, 51359, 1174, 1561, 5960, 23245, 16344, 1174, 54304, 1952, 578, 10164, 1174, 25676, 1628, 4610, 9100, 1952, 358, 1146, 622, 7675, 1174, 323, 1561, 15506, 9220, 15166, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2097", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) name(O) of(O) the(O) g(B-rating) rated(O) animated(B-genre) movie(O) about(O) a(O) hyena(B-plot) directed(O) by(O) shunji(B-director) iwai(I-director)", "instance": {"id": "2097", "words": ["what", "is", "the", "name", "of", "the", "g", "rated", "animated", "movie", "about", "a", "hyena", "directed", "by", "shunji", "iwai"], "labels": ["O", "O", "O", "O", "O", "O", "B-rating", "O", "B-genre", "O", "O", "O", "B-plot", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, genre, year, trailer, rating, director, average ratings, song, review, actor, plot, title and O.\nSentence: what is the name of the g rated animated movie about a hyena directed by shunji iwai", "prompt_labels": "what(O) is(O) the(O) name(O) of(O) the(O) g(B-rating) rated(O) animated(B-genre) movie(O) about(O) a(O) hyena(B-plot) directed(O) by(O) shunji(B-director) iwai(I-director)"}, "label_list": ["character", "genre", "year", "trailer", "rating", "director", "average ratings", "song", "review", "actor", "plot", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 17779, 11, 1060, 11, 19809, 11, 10959, 11, 7690, 11, 5578, 18594, 11, 5609, 11, 3477, 11, 12360, 11, 7234, 11, 2316, 323, 507, 627, 85664, 25, 1148, 374, 279, 836, 315, 279, 342, 22359, 11625, 5818, 922, 264, 6409, 7304, 15910, 555, 559, 359, 7910, 73368, 2192, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "237", "dataset": "crossner_politics", "split": "dev", "prediction": "The(O) Foundation(O)'s(O) website(O) includes(O) the(O) Cato(B-organization) Institute(I-organization),(O) Earhart(B-organization) Foundation(I-organization),(O) John(B-organization) M.(I-organization) Olin(I-organization) Foundation(I-organization) and(O) Foreign(B-organization) Policy(I-organization) Research(I-organization) Institute(I-organization) among(O) its(O) donors(O) and(O) sponsors(O).(O) Free(B-organization) Africa(I-organization) Foundation(I-organization),(O) accessed(O) 2(O) August(O) 2010(O).(O)", "instance": {"id": "237", "words": ["The", "Foundation", "'s", "website", "includes", "the", "Cato", "Institute", ",", "Earhart", "Foundation", ",", "John", "M.", "Olin", "Foundation", "and", "Foreign", "Policy", "Research", "Institute", "among", "its", "donors", "and", "sponsors", ".", "Free", "Africa", "Foundation", ",", "accessed", "2", "August", "2010", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "B-organization", "I-organization", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, politician, location, person, political party, election, country, organization and O.\nSentence: The Foundation 's website includes the Cato Institute , Earhart Foundation , John M. Olin Foundation and Foreign Policy Research Institute among its donors and sponsors . Free Africa Foundation , accessed 2 August 2010 .", "prompt_labels": "The(O) Foundation(O) 's(O) website(O) includes(O) the(O) Cato(B-organization) Institute(I-organization) ,(O) Earhart(B-organization) Foundation(I-organization) ,(O) John(B-organization) M.(I-organization) Olin(I-organization) Foundation(I-organization) and(O) Foreign(B-organization) Policy(I-organization) Research(I-organization) Institute(I-organization) among(O) its(O) donors(O) and(O) sponsors(O) .(O) Free(B-organization) Africa(I-organization) Foundation(I-organization) ,(O) accessed(O) 2(O) August(O) 2010(O) .(O)"}, "label_list": ["event", "politician", "location", "person", "political party", "election", "country", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 37038, 11, 3813, 11, 1732, 11, 5054, 4717, 11, 6355, 11, 3224, 11, 7471, 323, 507, 627, 85664, 25, 578, 5114, 364, 82, 3997, 5764, 279, 356, 4428, 10181, 1174, 6952, 47489, 5114, 1174, 3842, 386, 13, 507, 3817, 5114, 323, 19620, 11216, 8483, 10181, 4315, 1202, 33149, 323, 39701, 662, 3658, 10384, 5114, 1174, 25790, 220, 17, 6287, 220, 679, 15, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "254", "dataset": "crossner_ai", "split": "dev", "prediction": "SURF(B-algorithm) was(O) first(O) published(O) by(O) Herbert(B-researcher) Bay(I-researcher),(O) Tinne(B-researcher) Tuytelaars(I-researcher),(O) and(O) Luc(B-researcher) Van(I-researcher) Gool(I-researcher),(O) and(O) presented(O) at(O) the(O) 2006(B-conference) European(I-conference) Conference(I-conference) on(I-conference) Computer(I-conference) Vision(I-conference).(O)", "instance": {"id": "254", "words": ["SURF", "was", "first", "published", "by", "Herbert", "Bay", ",", "Tinne", "Tuytelaars", ",", "and", "Luc", "Van", "Gool", ",", "and", "presented", "at", "the", "2006", "European", "Conference", "on", "Computer", "Vision", "."], "labels": ["B-product", "O", "O", "O", "O", "B-researcher", "I-researcher", "O", "B-researcher", "I-researcher", "O", "O", "B-researcher", "I-researcher", "I-researcher", "O", "O", "O", "O", "O", "B-conference", "I-conference", "I-conference", "I-conference", "I-conference", "I-conference", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, product, researcher, location, programming language, metric, algorithm, task, country, university, conference, organization, person and O.\nSentence: SURF was first published by Herbert Bay , Tinne Tuytelaars , and Luc Van Gool , and presented at the 2006 European Conference on Computer Vision .", "prompt_labels": "SURF(B-product) was(O) first(O) published(O) by(O) Herbert(B-researcher) Bay(I-researcher) ,(O) Tinne(B-researcher) Tuytelaars(I-researcher) ,(O) and(O) Luc(B-researcher) Van(I-researcher) Gool(I-researcher) ,(O) and(O) presented(O) at(O) the(O) 2006(B-conference) European(I-conference) Conference(I-conference) on(I-conference) Computer(I-conference) Vision(I-conference) .(O)"}, "label_list": ["field", "product", "researcher", "location", "programming language", "metric", "algorithm", "task", "country", "university", "conference", "organization", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2115, 11, 2027, 11, 32185, 11, 3813, 11, 15840, 4221, 11, 18767, 11, 12384, 11, 3465, 11, 3224, 11, 12374, 11, 10017, 11, 7471, 11, 1732, 323, 507, 627, 85664, 25, 53083, 37, 574, 1176, 4756, 555, 58463, 9332, 1174, 57355, 818, 107386, 83, 8458, 1590, 1174, 323, 14103, 13000, 480, 1786, 1174, 323, 10666, 520, 279, 220, 1049, 21, 7665, 15217, 389, 17863, 31541, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "668", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) want(O) to(O) get(O) to(O) a(O) coffee(B-Cuisine) shop(O) that(O) serves(O) breakfast(B-Hours) after(I-Hours) 11(I-Hours) am(I-Hours)", "instance": {"id": "668", "words": ["i", "want", "to", "get", "to", "a", "coffee", "shop", "that", "serves", "breakfast", "after", "11", "am"], "labels": ["O", "O", "O", "O", "O", "O", "B-Cuisine", "O", "O", "O", "B-Hours", "I-Hours", "I-Hours", "I-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Cuisine, Rating, Price, Restaurant Name, Location, Dish, Hours and O.\nSentence: i want to get to a coffee shop that serves breakfast after 11 am", "prompt_labels": "i(O) want(O) to(O) get(O) to(O) a(O) coffee(B-Cuisine) shop(O) that(O) serves(O) breakfast(B-Hours) after(I-Hours) 11(I-Hours) am(I-Hours)"}, "label_list": ["Amenity", "Cuisine", "Rating", "Price", "Restaurant Name", "Location", "Dish", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 81961, 11, 19767, 11, 8650, 11, 26568, 4076, 11, 10067, 11, 49268, 11, 30192, 323, 507, 627, 85664, 25, 602, 1390, 311, 636, 311, 264, 11033, 8221, 430, 17482, 17954, 1306, 220, 806, 1097, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2378", "dataset": "mit-movie", "split": "dev", "prediction": "name(O) some(O) john(B-director) huston(I-director) films(O) about(O) children(B-genre)", "instance": {"id": "2378", "words": ["name", "some", "john", "huston", "films", "about", "children"], "labels": ["O", "O", "B-director", "I-director", "O", "O", "B-genre"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, character, title, actor, review, plot, trailer, director, rating, year, song, average ratings and O.\nSentence: name some john huston films about children", "prompt_labels": "name(O) some(O) john(B-director) huston(I-director) films(O) about(O) children(B-genre)"}, "label_list": ["genre", "character", "title", "actor", "review", "plot", "trailer", "director", "rating", "year", "song", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 3752, 11, 2316, 11, 12360, 11, 3477, 11, 7234, 11, 19809, 11, 7690, 11, 10959, 11, 1060, 11, 5609, 11, 5578, 18594, 323, 507, 627, 85664, 25, 836, 1063, 40742, 59750, 263, 12631, 922, 2911, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2409", "dataset": "mit-movie", "split": "dev", "prediction": "american(B-title) beauty(I-title)", "instance": {"id": "2409", "words": ["american", "beauty"], "labels": ["B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, rating, character, average ratings, title, year, actor, review, plot, song, genre, director and O.\nSentence: american beauty", "prompt_labels": "american(B-title) beauty(I-title)"}, "label_list": ["trailer", "rating", "character", "average ratings", "title", "year", "actor", "review", "plot", "song", "genre", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 10959, 11, 3752, 11, 5578, 18594, 11, 2316, 11, 1060, 11, 12360, 11, 3477, 11, 7234, 11, 5609, 11, 17779, 11, 7690, 323, 507, 627, 85664, 25, 39542, 13444, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "326", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) did(O) michael(B-director) bay(I-director) direct(O) besides(O) transformers(O)", "instance": {"id": "326", "words": ["what", "did", "michael", "bay", "direct", "besides", "transformers"], "labels": ["O", "O", "B-director", "I-director", "O", "O", "B-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, trailer, director, title, song, genre, plot, review, character, average ratings, actor, rating and O.\nSentence: what did michael bay direct besides transformers", "prompt_labels": "what(O) did(O) michael(B-director) bay(I-director) direct(O) besides(O) transformers(B-title)"}, "label_list": ["year", "trailer", "director", "title", "song", "genre", "plot", "review", "character", "average ratings", "actor", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 19809, 11, 7690, 11, 2316, 11, 5609, 11, 17779, 11, 7234, 11, 3477, 11, 3752, 11, 5578, 18594, 11, 12360, 11, 10959, 323, 507, 627, 85664, 25, 1148, 1550, 89006, 23542, 2167, 28858, 87970, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "692", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) provided(O) the(O) voice(O) talent(O) for(O) the(O) tiger(O) in(O) kung(B-title) fu(I-title) panda(I-title)", "instance": {"id": "692", "words": ["who", "provided", "the", "voice", "talent", "for", "the", "tiger", "in", "kung", "fu", "panda"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-character", "O", "B-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, title, average ratings, plot, song, rating, trailer, genre, director, review, year, character and O.\nSentence: who provided the voice talent for the tiger in kung fu panda", "prompt_labels": "who(O) provided(O) the(O) voice(O) talent(O) for(O) the(O) tiger(B-character) in(O) kung(B-title) fu(I-title) panda(I-title)"}, "label_list": ["actor", "title", "average ratings", "plot", "song", "rating", "trailer", "genre", "director", "review", "year", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 2316, 11, 5578, 18594, 11, 7234, 11, 5609, 11, 10959, 11, 19809, 11, 17779, 11, 7690, 11, 3477, 11, 1060, 11, 3752, 323, 507, 627, 85664, 25, 889, 3984, 279, 7899, 11005, 369, 279, 52835, 304, 597, 2234, 18922, 89322, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "198", "dataset": "crossner_politics", "split": "dev", "prediction": "East(B-location) Aberdeenshire(I-location) retained(O) the(O) same(O) boundaries(O) for(O) the(O) 1959(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) the(O) 1964(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) the(O) 1966(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) the(O) 1970(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) the(O) February(B-election) 1974(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) the(O) October(B-election) 1974(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election).(O)", "instance": {"id": "198", "words": ["East", "Aberdeenshire", "retained", "the", "same", "boundaries", "for", "the", "1959", "United", "Kingdom", "general", "election", ",", "the", "1964", "United", "Kingdom", "general", "election", ",", "the", "1966", "United", "Kingdom", "general", "election", ",", "the", "1970", "United", "Kingdom", "general", "election", ",", "the", "February", "1974", "United", "Kingdom", "general", "election", "and", "the", "October", "1974", "United", "Kingdom", "general", "election", "."], "labels": ["B-location", "I-location", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, person, organization, event, election, location, political party, politician and O.\nSentence: East Aberdeenshire retained the same boundaries for the 1959 United Kingdom general election , the 1964 United Kingdom general election , the 1966 United Kingdom general election , the 1970 United Kingdom general election , the February 1974 United Kingdom general election and the October 1974 United Kingdom general election .", "prompt_labels": "East(B-location) Aberdeenshire(I-location) retained(O) the(O) same(O) boundaries(O) for(O) the(O) 1959(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1964(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1966(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1970(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) February(B-election) 1974(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) the(O) October(B-election) 1974(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)"}, "label_list": ["country", "person", "organization", "event", "election", "location", "political party", "politician"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 1732, 11, 7471, 11, 1567, 11, 6355, 11, 3813, 11, 5054, 4717, 11, 37038, 323, 507, 627, 85664, 25, 6460, 37674, 451, 729, 35548, 35363, 279, 1890, 23546, 369, 279, 220, 6280, 24, 3723, 15422, 4689, 6355, 1174, 279, 220, 5162, 19, 3723, 15422, 4689, 6355, 1174, 279, 220, 5162, 21, 3723, 15422, 4689, 6355, 1174, 279, 220, 4468, 15, 3723, 15422, 4689, 6355, 1174, 279, 7552, 220, 4468, 19, 3723, 15422, 4689, 6355, 323, 279, 6664, 220, 4468, 19, 3723, 15422, 4689, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1186", "dataset": "mit-movie", "split": "dev", "prediction": "do(O) you(O) carry(O) the(O) movie(O) the(B-title) a(I-title) team(I-title)", "instance": {"id": "1186", "words": ["do", "you", "carry", "the", "movie", "the", "a", "team"], "labels": ["O", "O", "O", "O", "O", "B-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, plot, trailer, rating, title, average ratings, review, director, genre, actor, year, character and O.\nSentence: do you carry the movie the a team", "prompt_labels": "do(O) you(O) carry(O) the(O) movie(O) the(B-title) a(I-title) team(I-title)"}, "label_list": ["song", "plot", "trailer", "rating", "title", "average ratings", "review", "director", "genre", "actor", "year", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 7234, 11, 19809, 11, 10959, 11, 2316, 11, 5578, 18594, 11, 3477, 11, 7690, 11, 17779, 11, 12360, 11, 1060, 11, 3752, 323, 507, 627, 85664, 25, 656, 499, 6920, 279, 5818, 279, 264, 2128, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2269", "dataset": "mit-movie", "split": "dev", "prediction": "when(O) was(O) the(O) movie(O) sculpture(B-title) released(O)", "instance": {"id": "2269", "words": ["when", "was", "the", "movie", "sculpture", "released"], "labels": ["O", "O", "O", "O", "B-title", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, average ratings, character, plot, actor, year, title, song, review, rating, trailer, director and O.\nSentence: when was the movie sculpture released", "prompt_labels": "when(O) was(O) the(O) movie(O) sculpture(B-title) released(O)"}, "label_list": ["genre", "average ratings", "character", "plot", "actor", "year", "title", "song", "review", "rating", "trailer", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 5578, 18594, 11, 3752, 11, 7234, 11, 12360, 11, 1060, 11, 2316, 11, 5609, 11, 3477, 11, 10959, 11, 19809, 11, 7690, 323, 507, 627, 85664, 25, 994, 574, 279, 5818, 51067, 6004, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1092", "dataset": "mit-movie", "split": "dev", "prediction": "are(O) there(O) any(O) movies(O) on(O) affairs(B-plot) in(O) the(O) past(B-year) year(I-year)", "instance": {"id": "1092", "words": ["are", "there", "any", "movies", "on", "affairs", "in", "the", "past", "year"], "labels": ["O", "O", "O", "O", "O", "B-plot", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, rating, actor, average ratings, song, review, character, title, plot, year, genre, trailer and O.\nSentence: are there any movies on affairs in the past year", "prompt_labels": "are(O) there(O) any(O) movies(O) on(O) affairs(B-plot) in(O) the(O) past(B-year) year(I-year)"}, "label_list": ["director", "rating", "actor", "average ratings", "song", "review", "character", "title", "plot", "year", "genre", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 10959, 11, 12360, 11, 5578, 18594, 11, 5609, 11, 3477, 11, 3752, 11, 2316, 11, 7234, 11, 1060, 11, 17779, 11, 19809, 323, 507, 627, 85664, 25, 527, 1070, 904, 9698, 389, 22747, 304, 279, 3347, 1060, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "930", "dataset": "mit-movie", "split": "dev", "prediction": "find(O) a(O) review(O) for(O) bend(B-title) it(I-title) like(I-title) beckham(I-title)", "instance": {"id": "930", "words": ["find", "a", "review", "for", "bend", "it", "like", "beckham"], "labels": ["O", "O", "B-average ratings", "O", "B-title", "I-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, genre, year, title, trailer, rating, plot, song, character, director, actor, average ratings and O.\nSentence: find a review for bend it like beckham", "prompt_labels": "find(O) a(O) review(B-average ratings) for(O) bend(B-title) it(I-title) like(I-title) beckham(I-title)"}, "label_list": ["review", "genre", "year", "title", "trailer", "rating", "plot", "song", "character", "director", "actor", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 17779, 11, 1060, 11, 2316, 11, 19809, 11, 10959, 11, 7234, 11, 5609, 11, 3752, 11, 7690, 11, 12360, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1505, 264, 3477, 369, 37920, 433, 1093, 92186, 5721, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1258", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) can(O) i(O) eat(O) a(O) nice(B-Rating) sit(B-Amenity) down(I-Amenity) dinner(B-Hours) and(O) have(O) some(O) pho(B-Dish)", "instance": {"id": "1258", "words": ["where", "can", "i", "eat", "a", "nice", "sit", "down", "dinner", "and", "have", "some", "pho"], "labels": ["O", "O", "O", "O", "O", "O", "B-Amenity", "I-Amenity", "I-Amenity", "O", "O", "O", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Cuisine, Restaurant Name, Rating, Amenity, Location, Hours, Price and O.\nSentence: where can i eat a nice sit down dinner and have some pho", "prompt_labels": "where(O) can(O) i(O) eat(O) a(O) nice(O) sit(B-Amenity) down(I-Amenity) dinner(I-Amenity) and(O) have(O) some(O) pho(B-Dish)"}, "label_list": ["Dish", "Cuisine", "Restaurant Name", "Rating", "Amenity", "Location", "Hours", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 81961, 11, 26568, 4076, 11, 19767, 11, 3383, 56685, 11, 10067, 11, 30192, 11, 8650, 323, 507, 627, 85664, 25, 1405, 649, 602, 8343, 264, 6555, 2503, 1523, 14177, 323, 617, 1063, 1343, 78, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "149", "dataset": "crossner_science", "split": "dev", "prediction": "During(O) the(O) Industrial(B-event) Revolution(I-event),(O) it(O) became(O) an(O) important(O) industrial(O) chemical(O) for(O) many(O) applications(O),(O) including(O) the(O) large(O) scale(O) production(O) of(O) organic(O) compounds(O) such(O) as(O) vinyl(B-chemical compound) chloride(I-chemical compound) for(O) PVC(B-polymers) plastic(I-polymers) and(O) Methylene(B-chemical compound) diphenyl(I-chemical compound) diisocyanate(I-chemical compound) /(O) Toluene(B-chemical compound) diisocyanate(I-chemical compound) for(O) polyurethane(B-polymers) and(O) smaller(O) scale(O) applications(O),(O) such(O) as(O) production(O) of(O) gelatin(B-protein) and(O) other(O) ingredients(O) in(O) food(O),(O) and(O) leather(B-person) processing(I-person).(O)", "instance": {"id": "149", "words": ["During", "the", "Industrial", "Revolution", ",", "it", "became", "an", "important", "industrial", "chemical", "for", "many", "applications", ",", "including", "the", "large", "scale", "production", "of", "organic", "compounds", "such", "as", "vinyl", "chloride", "for", "PVC", "plastic", "and", "Methylene", "diphenyl", "diisocyanate", "/", "Toluene", "diisocyanate", "for", "polyurethane", "and", "smaller", "scale", "applications", ",", "such", "as", "production", "of", "gelatin", "and", "other", "ingredients", "in", "food", ",", "and", "leather", "processing", "."], "labels": ["O", "O", "B-event", "I-event", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-chemical compound", "I-chemical compound", "O", "B-chemical compound", "O", "O", "B-chemical compound", "I-chemical compound", "I-chemical compound", "O", "B-chemical compound", "I-chemical compound", "O", "B-chemical compound", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, protein, person, event, award, chemical compound, enzyme, location, country, astronomical object, chemical element, organization, university, discipline, academic journal, theory and O.\nSentence: During the Industrial Revolution , it became an important industrial chemical for many applications , including the large scale production of organic compounds such as vinyl chloride for PVC plastic and Methylene diphenyl diisocyanate / Toluene diisocyanate for polyurethane and smaller scale applications , such as production of gelatin and other ingredients in food , and leather processing .", "prompt_labels": "During(O) the(O) Industrial(B-event) Revolution(I-event) ,(O) it(O) became(O) an(O) important(O) industrial(O) chemical(O) for(O) many(O) applications(O) ,(O) including(O) the(O) large(O) scale(O) production(O) of(O) organic(O) compounds(O) such(O) as(O) vinyl(B-chemical compound) chloride(I-chemical compound) for(O) PVC(B-chemical compound) plastic(O) and(O) Methylene(B-chemical compound) diphenyl(I-chemical compound) diisocyanate(I-chemical compound) /(O) Toluene(B-chemical compound) diisocyanate(I-chemical compound) for(O) polyurethane(B-chemical compound) and(O) smaller(O) scale(O) applications(O) ,(O) such(O) as(O) production(O) of(O) gelatin(O) and(O) other(O) ingredients(O) in(O) food(O) ,(O) and(O) leather(O) processing(O) .(O)"}, "label_list": ["scientist", "protein", "person", "event", "award", "chemical compound", "enzyme", "location", "country", "astronomical object", "chemical element", "organization", "university", "discipline", "academic journal", "theory"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 28568, 11, 13128, 11, 1732, 11, 1567, 11, 10292, 11, 11742, 24549, 11, 49242, 11, 3813, 11, 3224, 11, 87283, 1665, 11, 11742, 2449, 11, 7471, 11, 12374, 11, 26434, 11, 14584, 8486, 11, 10334, 323, 507, 627, 85664, 25, 12220, 279, 25563, 22910, 1174, 433, 6244, 459, 3062, 13076, 11742, 369, 1690, 8522, 1174, 2737, 279, 3544, 5569, 5788, 315, 17808, 32246, 1778, 439, 34549, 82882, 369, 50966, 12466, 323, 386, 88640, 24522, 12301, 4010, 1891, 285, 511, 8503, 349, 611, 350, 44906, 1994, 1891, 285, 511, 8503, 349, 369, 10062, 554, 86185, 323, 9333, 5569, 8522, 1174, 1778, 439, 5788, 315, 18316, 15111, 323, 1023, 14293, 304, 3691, 1174, 323, 18012, 8863, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1404", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) is(O) the(O) best(B-Rating) mediterranean(B-Cuisine) restaurant(O)", "instance": {"id": "1404", "words": ["where", "is", "the", "best", "mediterranean", "restaurant"], "labels": ["O", "O", "O", "B-Rating", "B-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Dish, Cuisine, Restaurant Name, Location, Amenity, Price, Hours and O.\nSentence: where is the best mediterranean restaurant", "prompt_labels": "where(O) is(O) the(O) best(B-Rating) mediterranean(B-Cuisine) restaurant(O)"}, "label_list": ["Rating", "Dish", "Cuisine", "Restaurant Name", "Location", "Amenity", "Price", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 49268, 11, 81961, 11, 26568, 4076, 11, 10067, 11, 3383, 56685, 11, 8650, 11, 30192, 323, 507, 627, 85664, 25, 1405, 374, 279, 1888, 1812, 34925, 33561, 10960, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2162", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) must(B-average ratings) see(I-average ratings) battle(B-genre) movie(O) with(O) angelina(B-actor) jolie(I-actor) was(O) given(O) in(O) r(B-rating) rating(O) in(O) 1980(B-year)", "instance": {"id": "2162", "words": ["what", "must", "see", "battle", "movie", "with", "angelina", "jolie", "was", "given", "in", "r", "rating", "in", "1980"], "labels": ["O", "B-average ratings", "I-average ratings", "B-plot", "O", "O", "B-actor", "I-actor", "O", "O", "O", "B-rating", "O", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, actor, review, trailer, genre, rating, year, plot, title, song, character, average ratings and O.\nSentence: what must see battle movie with angelina jolie was given in r rating in 1980", "prompt_labels": "what(O) must(B-average ratings) see(I-average ratings) battle(B-plot) movie(O) with(O) angelina(B-actor) jolie(I-actor) was(O) given(O) in(O) r(B-rating) rating(O) in(O) 1980(B-year)"}, "label_list": ["director", "actor", "review", "trailer", "genre", "rating", "year", "plot", "title", "song", "character", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 12360, 11, 3477, 11, 19809, 11, 17779, 11, 10959, 11, 1060, 11, 7234, 11, 2316, 11, 5609, 11, 3752, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1148, 2011, 1518, 8209, 5818, 449, 34426, 2259, 503, 62117, 574, 2728, 304, 436, 10959, 304, 220, 3753, 15, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "191", "dataset": "crossner_politics", "split": "dev", "prediction": "1950(O) boundaries(O) were(O) used(O) also(O) for(O) the(O) general(O) elections(O) of(O) 1951(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) 1955(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) 1959(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) 1964(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) 1966(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) 1970(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election).(O)", "instance": {"id": "191", "words": ["1950", "boundaries", "were", "used", "also", "for", "the", "general", "elections", "of", "1951", "United", "Kingdom", "general", "election", ",", "1955", "United", "Kingdom", "general", "election", ",", "1959", "United", "Kingdom", "general", "election", ",", "1964", "United", "Kingdom", "general", "election", ",", "1966", "United", "Kingdom", "general", "election", "and", "1970", "United", "Kingdom", "general", "election", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, location, political party, organization, country, person, election, event and O.\nSentence: 1950 boundaries were used also for the general elections of 1951 United Kingdom general election , 1955 United Kingdom general election , 1959 United Kingdom general election , 1964 United Kingdom general election , 1966 United Kingdom general election and 1970 United Kingdom general election .", "prompt_labels": "1950(O) boundaries(O) were(O) used(O) also(O) for(O) the(O) general(O) elections(O) of(O) 1951(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) 1955(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) 1959(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) 1964(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) 1966(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) 1970(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)"}, "label_list": ["politician", "location", "political party", "organization", "country", "person", "election", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 37038, 11, 3813, 11, 5054, 4717, 11, 7471, 11, 3224, 11, 1732, 11, 6355, 11, 1567, 323, 507, 627, 85664, 25, 220, 6280, 15, 23546, 1051, 1511, 1101, 369, 279, 4689, 16374, 315, 220, 6280, 16, 3723, 15422, 4689, 6355, 1174, 220, 6280, 20, 3723, 15422, 4689, 6355, 1174, 220, 6280, 24, 3723, 15422, 4689, 6355, 1174, 220, 5162, 19, 3723, 15422, 4689, 6355, 1174, 220, 5162, 21, 3723, 15422, 4689, 6355, 323, 220, 4468, 15, 3723, 15422, 4689, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "455", "dataset": "crossner_politics", "split": "dev", "prediction": "Among(O) the(O) organization(O)'s(O) most(O) prominent(O) members(O) are(O) Alfonso(B-politician) Calderon(I-politician),(O) Sarah(B-person) Chadwick(I-person),(O) Jaclyn(B-person) Corin(I-person),(O) Ryan(B-person) Deitsch(I-person),(O) Emma(B-person) Gonz\u00e1lez(I-person),(O) David(B-politician) Hogg(I-politician),(O) Cameron(B-politician) Kasky(I-politician),(O) and(O) Alex(B-politician) Wind(I-politician).(O)", "instance": {"id": "455", "words": ["Among", "the", "organization", "'s", "most", "prominent", "members", "are", "Alfonso", "Calderon", ",", "Sarah", "Chadwick", ",", "Jaclyn", "Corin", ",", "Ryan", "Deitsch", ",", "Emma", "Gonz\u00e1lez", ",", "David", "Hogg", ",", "Cameron", "Kasky", ",", "and", "Alex", "Wind", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "O", "B-person", "I-person", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, location, election, political party, person, organization, politician, country and O.\nSentence: Among the organization 's most prominent members are Alfonso Calderon , Sarah Chadwick , Jaclyn Corin , Ryan Deitsch , Emma Gonz\u00e1lez , David Hogg , Cameron Kasky , and Alex Wind .", "prompt_labels": "Among(O) the(O) organization(O) 's(O) most(O) prominent(O) members(O) are(O) Alfonso(B-person) Calderon(I-person) ,(O) Sarah(B-person) Chadwick(I-person) ,(O) Jaclyn(B-person) Corin(I-person) ,(O) Ryan(B-person) Deitsch(I-person) ,(O) Emma(B-person) Gonz\u00e1lez(I-person) ,(O) David(B-person) Hogg(I-person) ,(O) Cameron(B-person) Kasky(I-person) ,(O) and(O) Alex(B-person) Wind(I-person) .(O)"}, "label_list": ["event", "location", "election", "political party", "person", "organization", "politician", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 3813, 11, 6355, 11, 5054, 4717, 11, 1732, 11, 7471, 11, 37038, 11, 3224, 323, 507, 627, 85664, 25, 22395, 279, 7471, 364, 82, 1455, 21102, 3697, 527, 1708, 22188, 708, 76400, 263, 1174, 21077, 43130, 21878, 1174, 15385, 18499, 4563, 258, 1174, 13960, 1611, 1220, 331, 1174, 36035, 33555, 97465, 1174, 6941, 473, 16499, 1174, 27524, 735, 1091, 88, 1174, 323, 8683, 22862, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1988", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) welcome(B-title) to(I-title) the(I-title) rileys(I-title) about(O)", "instance": {"id": "1988", "words": ["what", "is", "welcome", "to", "the", "rileys", "about"], "labels": ["O", "O", "B-title", "I-title", "I-title", "I-title", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, review, title, plot, director, genre, rating, average ratings, song, year, character, trailer and O.\nSentence: what is welcome to the rileys about", "prompt_labels": "what(O) is(O) welcome(B-title) to(I-title) the(I-title) rileys(I-title) about(O)"}, "label_list": ["actor", "review", "title", "plot", "director", "genre", "rating", "average ratings", "song", "year", "character", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 3477, 11, 2316, 11, 7234, 11, 7690, 11, 17779, 11, 10959, 11, 5578, 18594, 11, 5609, 11, 1060, 11, 3752, 11, 19809, 323, 507, 627, 85664, 25, 1148, 374, 10788, 311, 279, 436, 458, 1065, 922, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1865", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) r(B-rating) rated(O) movies(O) did(O) robert(B-director) vaughn(I-director) star(O) in(O) this(B-year) year(I-year)", "instance": {"id": "1865", "words": ["what", "r", "rated", "movies", "did", "robert", "vaughn", "star", "in", "this", "year"], "labels": ["O", "B-rating", "O", "O", "O", "B-actor", "I-actor", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, director, trailer, actor, plot, song, average ratings, rating, review, genre, character, title and O.\nSentence: what r rated movies did robert vaughn star in this year", "prompt_labels": "what(O) r(B-rating) rated(O) movies(O) did(O) robert(B-actor) vaughn(I-actor) star(O) in(O) this(B-year) year(I-year)"}, "label_list": ["year", "director", "trailer", "actor", "plot", "song", "average ratings", "rating", "review", "genre", "character", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 7690, 11, 19809, 11, 12360, 11, 7234, 11, 5609, 11, 5578, 18594, 11, 10959, 11, 3477, 11, 17779, 11, 3752, 11, 2316, 323, 507, 627, 85664, 25, 1148, 436, 22359, 9698, 1550, 89993, 11412, 7595, 77, 6917, 304, 420, 1060, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "170", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) are(O) some(O) horror(B-genre) movies(O) from(O) the(O) 1970s(B-year)", "instance": {"id": "170", "words": ["what", "are", "some", "horror", "movies", "from", "the", "1970s"], "labels": ["O", "O", "O", "B-genre", "O", "O", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, character, review, song, plot, genre, title, year, director, average ratings, trailer, rating and O.\nSentence: what are some horror movies from the 1970s", "prompt_labels": "what(O) are(O) some(O) horror(B-genre) movies(O) from(O) the(O) 1970s(B-year)"}, "label_list": ["actor", "character", "review", "song", "plot", "genre", "title", "year", "director", "average ratings", "trailer", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 3752, 11, 3477, 11, 5609, 11, 7234, 11, 17779, 11, 2316, 11, 1060, 11, 7690, 11, 5578, 18594, 11, 19809, 11, 10959, 323, 507, 627, 85664, 25, 1148, 527, 1063, 22169, 9698, 505, 279, 220, 4468, 15, 82, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1130", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) clint(B-director) eastwood(I-director) direct(O) inception(B-title)", "instance": {"id": "1130", "words": ["did", "clint", "eastwood", "direct", "inception"], "labels": ["O", "B-director", "I-director", "O", "B-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, trailer, plot, character, genre, song, year, review, actor, title, director, average ratings and O.\nSentence: did clint eastwood direct inception", "prompt_labels": "did(O) clint(B-director) eastwood(I-director) direct(O) inception(B-title)"}, "label_list": ["rating", "trailer", "plot", "character", "genre", "song", "year", "review", "actor", "title", "director", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 19809, 11, 7234, 11, 3752, 11, 17779, 11, 5609, 11, 1060, 11, 3477, 11, 12360, 11, 2316, 11, 7690, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1550, 1206, 396, 11226, 6798, 2167, 54529, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "319", "dataset": "crossner_literature", "split": "dev", "prediction": "In(O) 2006(O),(O) a(O) musical(O) version(O) of(O) Fell(B-writer)'s(O) play(O) was(O) staged(O) during(O) the(O) New(B-event) York(I-event) Musical(I-event) Theatre(I-event) Festival(I-event),(O) produced(O) by(O) George(B-person) DeMarco(I-person) and(O) David(B-person) Gerard(I-person),(O) both(O) of(O) whom(O) produced(O) the(O) 1996(O) production(O).(O)", "instance": {"id": "319", "words": ["In", "2006", ",", "a", "musical", "version", "of", "Fell", "'s", "play", "was", "staged", "during", "the", "New", "York", "Musical", "Theatre", "Festival", ",", "produced", "by", "George", "DeMarco", "and", "David", "Gerard", ",", "both", "of", "whom", "produced", "the", "1996", "production", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-writer", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "I-event", "I-event", "O", "O", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, person, writer, poem, award, location, organization, book, magazine, event, literary genre and O.\nSentence: In 2006 , a musical version of Fell 's play was staged during the New York Musical Theatre Festival , produced by George DeMarco and David Gerard , both of whom produced the 1996 production .", "prompt_labels": "In(O) 2006(O) ,(O) a(O) musical(O) version(O) of(O) Fell(B-writer) 's(O) play(O) was(O) staged(O) during(O) the(O) New(B-event) York(I-event) Musical(I-event) Theatre(I-event) Festival(I-event) ,(O) produced(O) by(O) George(B-person) DeMarco(I-person) and(O) David(B-person) Gerard(I-person) ,(O) both(O) of(O) whom(O) produced(O) the(O) 1996(O) production(O) .(O)"}, "label_list": ["country", "person", "writer", "poem", "award", "location", "organization", "book", "magazine", "event", "literary genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 1732, 11, 7061, 11, 33894, 11, 10292, 11, 3813, 11, 7471, 11, 2363, 11, 14756, 11, 1567, 11, 32465, 17779, 323, 507, 627, 85664, 25, 763, 220, 1049, 21, 1174, 264, 18273, 2373, 315, 63705, 364, 82, 1514, 574, 51157, 2391, 279, 1561, 4356, 57357, 27315, 17772, 1174, 9124, 555, 10058, 1611, 86484, 323, 6941, 82218, 1174, 2225, 315, 8884, 9124, 279, 220, 2550, 21, 5788, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1423", "dataset": "mit-movie", "split": "dev", "prediction": "in(O) the(O) past(B-year) nine(I-year) decades(I-year) did(O) ken(B-director) bruce(I-director) direct(O) a(O) g(B-rating) rated(O) sci(B-genre) fi(I-genre) about(O) galactic(B-plot) war(I-plot) that(O) received(O) an(O) average(O) rating(O) of(O) eight(B-average ratings)", "instance": {"id": "1423", "words": ["in", "the", "past", "nine", "decades", "did", "ken", "bruce", "direct", "a", "g", "rated", "sci", "fi", "about", "galactic", "war", "that", "received", "an", "average", "rating", "of", "eight"], "labels": ["O", "O", "B-year", "I-year", "I-year", "O", "B-director", "I-director", "O", "O", "B-rating", "O", "B-genre", "I-genre", "O", "B-plot", "I-plot", "O", "O", "O", "O", "O", "O", "B-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, average ratings, character, director, rating, trailer, review, title, actor, plot, year, song and O.\nSentence: in the past nine decades did ken bruce direct a g rated sci fi about galactic war that received an average rating of eight", "prompt_labels": "in(O) the(O) past(B-year) nine(I-year) decades(I-year) did(O) ken(B-director) bruce(I-director) direct(O) a(O) g(B-rating) rated(O) sci(B-genre) fi(I-genre) about(O) galactic(B-plot) war(I-plot) that(O) received(O) an(O) average(O) rating(O) of(O) eight(B-average ratings)"}, "label_list": ["genre", "average ratings", "character", "director", "rating", "trailer", "review", "title", "actor", "plot", "year", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 5578, 18594, 11, 3752, 11, 7690, 11, 10959, 11, 19809, 11, 3477, 11, 2316, 11, 12360, 11, 7234, 11, 1060, 11, 5609, 323, 507, 627, 85664, 25, 304, 279, 3347, 11888, 11026, 1550, 50332, 1437, 10743, 2167, 264, 342, 22359, 39074, 9314, 922, 15730, 24045, 4208, 430, 4036, 459, 5578, 10959, 315, 8223, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "436", "dataset": "crossner_science", "split": "dev", "prediction": "The(O) film(O) was(O) also(O) nominated(O) for(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Supporting(I-award) Actor(I-award) ((O) Sam(B-person) Shepard(I-person) )(O),(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Production(I-award) Design(I-award) ((O) Art(B-person) Direction(I-person) :(O) Geoffrey(B-person) Kirkland(I-person),(O) Richard(B-person) Lawrence(I-person),(O) W.(B-person) Stewart(I-person) Campbell(I-person) and(O) Peter(B-person) R.(I-person) Romero(I-person) ;(O) Set(B-person) Decoration(I-person) :(O) George(B-person) R.(I-person) Nelson(I-person) )(O),(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Cinematography(I-award) ((O) Caleb(B-person) Deschanel(I-person) )(O) and(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Picture(I-award).(O)", "instance": {"id": "436", "words": ["The", "film", "was", "also", "nominated", "for", "Academy", "Award", "for", "Best", "Supporting", "Actor", "(", "Sam", "Shepard", ")", ",", "Academy", "Award", "for", "Best", "Production", "Design", "(", "Art", "Direction", ":", "Geoffrey", "Kirkland", ",", "Richard", "Lawrence", ",", "W.", "Stewart", "Campbell", "and", "Peter", "R.", "Romero", ";", "Set", "Decoration", ":", "George", "R.", "Nelson", ")", ",", "Academy", "Award", "for", "Best", "Cinematography", "(", "Caleb", "Deschanel", ")", "and", "Academy", "Award", "for", "Best", "Picture", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O", "B-person", "I-person", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "I-person", "O", "B-person", "I-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "I-person", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "O", "B-person", "I-person", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: enzyme, protein, country, chemical compound, discipline, academic journal, event, university, scientist, chemical element, theory, award, organization, person, astronomical object, location and O.\nSentence: The film was also nominated for Academy Award for Best Supporting Actor ( Sam Shepard ) , Academy Award for Best Production Design ( Art Direction : Geoffrey Kirkland , Richard Lawrence , W. Stewart Campbell and Peter R. Romero ; Set Decoration : George R. Nelson ) , Academy Award for Best Cinematography ( Caleb Deschanel ) and Academy Award for Best Picture .", "prompt_labels": "The(O) film(O) was(O) also(O) nominated(O) for(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Supporting(I-award) Actor(I-award) ((O) Sam(B-person) Shepard(I-person) )(O) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Production(I-award) Design(I-award) ((O) Art(B-person) Direction(I-person) :(O) Geoffrey(B-person) Kirkland(I-person) ,(O) Richard(B-person) Lawrence(I-person) ,(O) W.(B-person) Stewart(I-person) Campbell(I-person) and(O) Peter(B-person) R.(I-person) Romero(I-person) ;(O) Set(B-person) Decoration(I-person) :(O) George(B-person) R.(I-person) Nelson(I-person) )(O) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Cinematography(I-award) ((O) Caleb(B-person) Deschanel(I-person) )(O) and(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Picture(I-award) .(O)"}, "label_list": ["enzyme", "protein", "country", "chemical compound", "discipline", "academic journal", "event", "university", "scientist", "chemical element", "theory", "award", "organization", "person", "astronomical object", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49242, 11, 13128, 11, 3224, 11, 11742, 24549, 11, 26434, 11, 14584, 8486, 11, 1567, 11, 12374, 11, 28568, 11, 11742, 2449, 11, 10334, 11, 10292, 11, 7471, 11, 1732, 11, 87283, 1665, 11, 3813, 323, 507, 627, 85664, 25, 578, 4632, 574, 1101, 39048, 369, 16192, 17768, 369, 7252, 75096, 25749, 320, 8388, 72919, 883, 1174, 16192, 17768, 369, 7252, 25003, 7127, 320, 5277, 19438, 551, 89239, 32446, 1974, 1174, 12131, 28574, 1174, 468, 13, 29868, 30524, 323, 11291, 432, 13, 78487, 2652, 2638, 65119, 551, 10058, 432, 13, 27562, 883, 1174, 16192, 17768, 369, 7252, 30011, 43698, 5814, 320, 84162, 3959, 331, 2444, 883, 323, 16192, 17768, 369, 7252, 25586, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "699", "dataset": "mit-movie", "split": "dev", "prediction": "find(O) the(O) movie(O) with(O) robin(B-actor) williams(I-actor) as(O) a(O) dj(B-plot) in(O) vietnam(B-plot)", "instance": {"id": "699", "words": ["find", "the", "movie", "with", "robin", "williams", "as", "a", "dj", "in", "vietnam"], "labels": ["O", "O", "O", "O", "B-actor", "I-actor", "O", "O", "B-plot", "I-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, character, director, rating, plot, song, trailer, review, average ratings, title, actor, year and O.\nSentence: find the movie with robin williams as a dj in vietnam", "prompt_labels": "find(O) the(O) movie(O) with(O) robin(B-actor) williams(I-actor) as(O) a(O) dj(B-plot) in(I-plot) vietnam(I-plot)"}, "label_list": ["genre", "character", "director", "rating", "plot", "song", "trailer", "review", "average ratings", "title", "actor", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 3752, 11, 7690, 11, 10959, 11, 7234, 11, 5609, 11, 19809, 11, 3477, 11, 5578, 18594, 11, 2316, 11, 12360, 11, 1060, 323, 507, 627, 85664, 25, 1505, 279, 5818, 449, 99685, 690, 12663, 439, 264, 48856, 304, 85459, 12682, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2250", "dataset": "mit-movie", "split": "dev", "prediction": "whats(O) a(O) nine(B-average ratings) star(I-average ratings) reviewed(O) movie(O) from(O) last(B-year) year(I-year) that(O) features(O) chris(B-actor) tucker(I-actor)", "instance": {"id": "2250", "words": ["whats", "a", "nine", "star", "reviewed", "movie", "from", "last", "year", "that", "features", "chris", "tucker"], "labels": ["O", "O", "B-average ratings", "I-average ratings", "O", "O", "O", "B-year", "I-year", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, average ratings, rating, review, trailer, character, genre, director, year, song, actor, plot and O.\nSentence: whats a nine star reviewed movie from last year that features chris tucker", "prompt_labels": "whats(O) a(O) nine(B-average ratings) star(I-average ratings) reviewed(O) movie(O) from(O) last(B-year) year(I-year) that(O) features(O) chris(B-actor) tucker(I-actor)"}, "label_list": ["title", "average ratings", "rating", "review", "trailer", "character", "genre", "director", "year", "song", "actor", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 5578, 18594, 11, 10959, 11, 3477, 11, 19809, 11, 3752, 11, 17779, 11, 7690, 11, 1060, 11, 5609, 11, 12360, 11, 7234, 323, 507, 627, 85664, 25, 41209, 264, 11888, 6917, 22690, 5818, 505, 1566, 1060, 430, 4519, 523, 6091, 259, 25369, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1441", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) quentin(B-director) tarantino(I-director) planning(O) on(O) working(O) on(O) any(O) animated(B-genre) films(O) soon(O)", "instance": {"id": "1441", "words": ["is", "quentin", "tarantino", "planning", "on", "working", "on", "any", "animated", "films", "soon"], "labels": ["O", "B-director", "I-director", "O", "O", "O", "O", "O", "B-genre", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, actor, average ratings, review, year, character, genre, rating, trailer, title, song, director and O.\nSentence: is quentin tarantino planning on working on any animated films soon", "prompt_labels": "is(O) quentin(B-director) tarantino(I-director) planning(O) on(O) working(O) on(O) any(O) animated(B-genre) films(O) soon(O)"}, "label_list": ["plot", "actor", "average ratings", "review", "year", "character", "genre", "rating", "trailer", "title", "song", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 12360, 11, 5578, 18594, 11, 3477, 11, 1060, 11, 3752, 11, 17779, 11, 10959, 11, 19809, 11, 2316, 11, 5609, 11, 7690, 323, 507, 627, 85664, 25, 374, 934, 44509, 12460, 96464, 9293, 389, 3318, 389, 904, 11625, 12631, 5246, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2299", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) are(O) the(O) actors(O) in(O) the(O) movie(O) couples(B-title) retreat(I-title)", "instance": {"id": "2299", "words": ["who", "are", "the", "actors", "in", "the", "movie", "couples", "retreat"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, year, average ratings, trailer, director, review, song, rating, plot, title, genre, actor and O.\nSentence: who are the actors in the movie couples retreat", "prompt_labels": "who(O) are(O) the(O) actors(O) in(O) the(O) movie(O) couples(B-title) retreat(I-title)"}, "label_list": ["character", "year", "average ratings", "trailer", "director", "review", "song", "rating", "plot", "title", "genre", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 1060, 11, 5578, 18594, 11, 19809, 11, 7690, 11, 3477, 11, 5609, 11, 10959, 11, 7234, 11, 2316, 11, 17779, 11, 12360, 323, 507, 627, 85664, 25, 889, 527, 279, 20142, 304, 279, 5818, 21961, 31114, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1978", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) horrors(B-title) of(I-title) the(I-title) black(I-title) museum(I-title)", "instance": {"id": "1978", "words": ["what", "is", "horrors", "of", "the", "black", "museum"], "labels": ["O", "O", "B-title", "I-title", "I-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, genre, average ratings, plot, director, review, actor, trailer, title, character, year, rating and O.\nSentence: what is horrors of the black museum", "prompt_labels": "what(O) is(O) horrors(B-title) of(I-title) the(I-title) black(I-title) museum(I-title)"}, "label_list": ["song", "genre", "average ratings", "plot", "director", "review", "actor", "trailer", "title", "character", "year", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 17779, 11, 5578, 18594, 11, 7234, 11, 7690, 11, 3477, 11, 12360, 11, 19809, 11, 2316, 11, 3752, 11, 1060, 11, 10959, 323, 507, 627, 85664, 25, 1148, 374, 70618, 315, 279, 3776, 24925, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1514", "dataset": "mit-restaurant", "split": "dev", "prediction": "who(O) will(O) give(O) me(O) the(O) best(B-Price) priced(O) party(B-Dish) subs(I-Dish) in(B-Location) town(I-Location)", "instance": {"id": "1514", "words": ["who", "will", "give", "me", "the", "best", "priced", "party", "subs", "in", "town"], "labels": ["O", "O", "O", "O", "O", "B-Rating", "O", "B-Dish", "I-Dish", "O", "B-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Amenity, Price, Location, Rating, Dish, Cuisine, Hours and O.\nSentence: who will give me the best priced party subs in town", "prompt_labels": "who(O) will(O) give(O) me(O) the(O) best(B-Rating) priced(O) party(B-Dish) subs(I-Dish) in(O) town(B-Location)"}, "label_list": ["Restaurant Name", "Amenity", "Price", "Location", "Rating", "Dish", "Cuisine", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 3383, 56685, 11, 8650, 11, 10067, 11, 19767, 11, 49268, 11, 81961, 11, 30192, 323, 507, 627, 85664, 25, 889, 690, 3041, 757, 279, 1888, 33705, 4717, 5258, 304, 6424, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "36", "dataset": "crossner_politics", "split": "dev", "prediction": "It(O) was(O) set(O) up(O) by(O) former(O) left-leaning(O) Christian(O) Democrats(O),(O) ((O) former(O) Italian(B-political party) Liberal(I-political party) Party(I-political party) and(O) former(O) Italian(B-political party) Republican(I-political party) Party(I-political party) )(O),(O) as(O) well(O) as(O) other(O) left-wing(O) politicians(O) from(O) the(O) former(O) Italian(B-political party) Socialist(I-political party) Party(I-political party) and(O) Federation(B-political party) of(I-political party) the(I-political party) Greens(I-political party).(O)", "instance": {"id": "36", "words": ["It", "was", "set", "up", "by", "former", "left-leaning", "Christian", "Democrats", ",", "(", "former", "Italian", "Liberal", "Party", "and", "former", "Italian", "Republican", "Party", ")", ",", "as", "well", "as", "other", "left-wing", "politicians", "from", "the", "former", "Italian", "Socialist", "Party", "and", "Federation", "of", "the", "Greens", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, location, event, country, organization, person, politician, political party and O.\nSentence: It was set up by former left-leaning Christian Democrats , ( former Italian Liberal Party and former Italian Republican Party ) , as well as other left-wing politicians from the former Italian Socialist Party and Federation of the Greens .", "prompt_labels": "It(O) was(O) set(O) up(O) by(O) former(O) left-leaning(O) Christian(O) Democrats(O) ,(O) ((O) former(O) Italian(B-political party) Liberal(I-political party) Party(I-political party) and(O) former(O) Italian(B-political party) Republican(I-political party) Party(I-political party) )(O) ,(O) as(O) well(O) as(O) other(O) left-wing(O) politicians(O) from(O) the(O) former(O) Italian(B-political party) Socialist(I-political party) Party(I-political party) and(O) Federation(B-political party) of(I-political party) the(I-political party) Greens(I-political party) .(O)"}, "label_list": ["election", "location", "event", "country", "organization", "person", "politician", "political party"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 6355, 11, 3813, 11, 1567, 11, 3224, 11, 7471, 11, 1732, 11, 37038, 11, 5054, 4717, 323, 507, 627, 85664, 25, 1102, 574, 743, 709, 555, 4846, 2163, 78461, 9052, 12643, 1174, 320, 4846, 15155, 31158, 8722, 323, 4846, 15155, 9540, 8722, 883, 1174, 439, 1664, 439, 1023, 2163, 29480, 19287, 505, 279, 4846, 15155, 57210, 8722, 323, 28331, 315, 279, 42691, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "29", "dataset": "crossner_politics", "split": "dev", "prediction": "As(O) they(O) had(O) done(O) while(O) campaigning(O) for(O) the(O) 2004(B-election) Canadian(I-election) federal(I-election) election(I-election),(O) the(O) New(B-political party) Democratic(I-political party) Party(I-political party) and(O) Bloc(B-political party) Qu\u00e9b\u00e9cois(I-political party) stated(O),(O) during(O) the(O) leadup(O) to(O) the(O) 2006(B-election) Canadian(I-election) federal(I-election) election(I-election),(O) their(O) support(O) for(O) an(O) apology(O) and(O) redress(O) for(O) the(O) head(B-event) tax(I-event).(O)", "instance": {"id": "29", "words": ["As", "they", "had", "done", "while", "campaigning", "for", "the", "2004", "Canadian", "federal", "election", ",", "the", "New", "Democratic", "Party", "and", "Bloc", "Qu\u00e9b\u00e9cois", "stated", ",", "during", "the", "leadup", "to", "the", "2006", "Canadian", "federal", "election", ",", "their", "support", "for", "an", "apology", "and", "redress", "for", "the", "head", "tax", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "B-political party", "I-political party", "I-political party", "O", "B-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, country, person, location, political party, organization, election, event and O.\nSentence: As they had done while campaigning for the 2004 Canadian federal election , the New Democratic Party and Bloc Qu\u00e9b\u00e9cois stated , during the leadup to the 2006 Canadian federal election , their support for an apology and redress for the head tax .", "prompt_labels": "As(O) they(O) had(O) done(O) while(O) campaigning(O) for(O) the(O) 2004(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) the(O) New(B-political party) Democratic(I-political party) Party(I-political party) and(O) Bloc(B-political party) Qu\u00e9b\u00e9cois(I-political party) stated(O) ,(O) during(O) the(O) leadup(O) to(O) the(O) 2006(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) their(O) support(O) for(O) an(O) apology(O) and(O) redress(O) for(O) the(O) head(O) tax(O) .(O)"}, "label_list": ["politician", "country", "person", "location", "political party", "organization", "election", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 37038, 11, 3224, 11, 1732, 11, 3813, 11, 5054, 4717, 11, 7471, 11, 6355, 11, 1567, 323, 507, 627, 85664, 25, 1666, 814, 1047, 2884, 1418, 55927, 369, 279, 220, 1049, 19, 12152, 6918, 6355, 1174, 279, 1561, 11650, 8722, 323, 72496, 66703, 92174, 1030, 285, 11224, 1174, 2391, 279, 3063, 455, 311, 279, 220, 1049, 21, 12152, 6918, 6355, 1174, 872, 1862, 369, 459, 41258, 323, 2579, 676, 369, 279, 2010, 3827, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "162", "dataset": "crossner_science", "split": "dev", "prediction": "The(O) film(O) was(O) nominated(O) for(O) two(O) Academy(B-award) Awards(I-award) for(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Cinematography(I-award) and(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Visual(I-award) Effects(I-award).(O)", "instance": {"id": "162", "words": ["The", "film", "was", "nominated", "for", "two", "Academy", "Awards", "for", "Academy", "Award", "for", "Best", "Cinematography", "and", "Academy", "Award", "for", "Best", "Visual", "Effects", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, chemical compound, theory, organization, astronomical object, location, protein, discipline, academic journal, country, enzyme, award, event, scientist, chemical element, person and O.\nSentence: The film was nominated for two Academy Awards for Academy Award for Best Cinematography and Academy Award for Best Visual Effects .", "prompt_labels": "The(O) film(O) was(O) nominated(O) for(O) two(O) Academy(O) Awards(O) for(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Cinematography(I-award) and(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Visual(I-award) Effects(I-award) .(O)"}, "label_list": ["university", "chemical compound", "theory", "organization", "astronomical object", "location", "protein", "discipline", "academic journal", "country", "enzyme", "award", "event", "scientist", "chemical element", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12374, 11, 11742, 24549, 11, 10334, 11, 7471, 11, 87283, 1665, 11, 3813, 11, 13128, 11, 26434, 11, 14584, 8486, 11, 3224, 11, 49242, 11, 10292, 11, 1567, 11, 28568, 11, 11742, 2449, 11, 1732, 323, 507, 627, 85664, 25, 578, 4632, 574, 39048, 369, 1403, 16192, 23488, 369, 16192, 17768, 369, 7252, 30011, 43698, 5814, 323, 16192, 17768, 369, 7252, 20796, 30246, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "217", "dataset": "mit-movie", "split": "dev", "prediction": "has(O) samuel(B-actor) jackson(I-actor) been(O) in(O) any(O) thriller(B-genre) flicks(O)", "instance": {"id": "217", "words": ["has", "samuel", "jackson", "been", "in", "any", "thriller", "flicks"], "labels": ["O", "B-actor", "I-actor", "O", "O", "O", "B-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, character, genre, plot, actor, title, trailer, review, average ratings, rating, director, year and O.\nSentence: has samuel jackson been in any thriller flicks", "prompt_labels": "has(O) samuel(B-actor) jackson(I-actor) been(O) in(O) any(O) thriller(B-genre) flicks(O)"}, "label_list": ["song", "character", "genre", "plot", "actor", "title", "trailer", "review", "average ratings", "rating", "director", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 3752, 11, 17779, 11, 7234, 11, 12360, 11, 2316, 11, 19809, 11, 3477, 11, 5578, 18594, 11, 10959, 11, 7690, 11, 1060, 323, 507, 627, 85664, 25, 706, 10167, 4088, 503, 19950, 1027, 304, 904, 54461, 29447, 82, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "788", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) the(O) pricing(O) fair(O)", "instance": {"id": "788", "words": ["is", "the", "pricing", "fair"], "labels": ["O", "O", "B-Price", "I-Price"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Cuisine, Location, Price, Amenity, Dish, Restaurant Name, Rating and O.\nSentence: is the pricing fair", "prompt_labels": "is(O) the(O) pricing(B-Price) fair(I-Price)"}, "label_list": ["Hours", "Cuisine", "Location", "Price", "Amenity", "Dish", "Restaurant Name", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 81961, 11, 10067, 11, 8650, 11, 3383, 56685, 11, 49268, 11, 26568, 4076, 11, 19767, 323, 507, 627, 85664, 25, 374, 279, 21913, 6762, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "405", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) diablo(B-director) cody(I-director) direct(O) any(O) movies(O) this(B-year) year(I-year)", "instance": {"id": "405", "words": ["did", "diablo", "cody", "direct", "any", "movies", "this", "year"], "labels": ["O", "B-director", "I-director", "O", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, trailer, genre, review, rating, plot, year, actor, character, title, song, average ratings and O.\nSentence: did diablo cody direct any movies this year", "prompt_labels": "did(O) diablo(B-director) cody(I-director) direct(O) any(O) movies(O) this(B-year) year(I-year)"}, "label_list": ["director", "trailer", "genre", "review", "rating", "plot", "year", "actor", "character", "title", "song", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 19809, 11, 17779, 11, 3477, 11, 10959, 11, 7234, 11, 1060, 11, 12360, 11, 3752, 11, 2316, 11, 5609, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1550, 1891, 32560, 272, 1094, 2167, 904, 9698, 420, 1060, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "6", "dataset": "crossner_science", "split": "dev", "prediction": "Like(O) aluminium(B-chemical element),(O) According(O) to(O) the(O) International(B-organization) Resource(I-organization) Panel(I-organization) '(O) s(O) Metal(O) Stocks(O) in(O) Society(O) report(O),(O) the(O) global(O) per(O) capita(O) stock(O) of(O) copper(B-chemical element) in(O) use(O) in(O) society(O) is(O) 35-55(O) kg(O).(O)", "instance": {"id": "6", "words": ["Like", "aluminium", ",", "According", "to", "the", "International", "Resource", "Panel", "'", "s", "Metal", "Stocks", "in", "Society", "report", ",", "the", "global", "per", "capita", "stock", "of", "copper", "in", "use", "in", "society", "is", "35-55", "kg", "."], "labels": ["O", "B-chemical element", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, person, university, theory, scientist, award, event, enzyme, country, chemical element, chemical compound, discipline, astronomical object, protein, location, academic journal and O.\nSentence: Like aluminium , According to the International Resource Panel ' s Metal Stocks in Society report , the global per capita stock of copper in use in society is 35-55 kg .", "prompt_labels": "Like(O) aluminium(B-chemical element) ,(O) According(O) to(O) the(O) International(B-organization) Resource(I-organization) Panel(I-organization) '(O) s(O) Metal(B-organization) Stocks(I-organization) in(I-organization) Society(I-organization) report(O) ,(O) the(O) global(O) per(O) capita(O) stock(O) of(O) copper(O) in(O) use(O) in(O) society(O) is(O) 35-55(O) kg(O) .(O)"}, "label_list": ["organization", "person", "university", "theory", "scientist", "award", "event", "enzyme", "country", "chemical element", "chemical compound", "discipline", "astronomical object", "protein", "location", "academic journal"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 1732, 11, 12374, 11, 10334, 11, 28568, 11, 10292, 11, 1567, 11, 49242, 11, 3224, 11, 11742, 2449, 11, 11742, 24549, 11, 26434, 11, 87283, 1665, 11, 13128, 11, 3813, 11, 14584, 8486, 323, 507, 627, 85664, 25, 9086, 55993, 1174, 10771, 311, 279, 7327, 12027, 19482, 364, 274, 19757, 80336, 304, 13581, 1934, 1174, 279, 3728, 824, 53155, 5708, 315, 24166, 304, 1005, 304, 8396, 374, 220, 1758, 12, 2131, 21647, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1439", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) is(O) the(O) nearest(B-Location) place(I-Location) that(O) serves(O) nachos(B-Dish)", "instance": {"id": "1439", "words": ["where", "is", "the", "nearest", "place", "that", "serves", "nachos"], "labels": ["O", "O", "O", "B-Location", "O", "O", "O", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Price, Hours, Dish, Rating, Cuisine, Location, Amenity and O.\nSentence: where is the nearest place that serves nachos", "prompt_labels": "where(O) is(O) the(O) nearest(B-Location) place(O) that(O) serves(O) nachos(B-Dish)"}, "label_list": ["Restaurant Name", "Price", "Hours", "Dish", "Rating", "Cuisine", "Location", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 8650, 11, 30192, 11, 49268, 11, 19767, 11, 81961, 11, 10067, 11, 3383, 56685, 323, 507, 627, 85664, 25, 1405, 374, 279, 24379, 2035, 430, 17482, 14375, 437, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "290", "dataset": "crossner_science", "split": "dev", "prediction": "Six(O) planet(O) s(O) are(O) visible(O) in(O) the(O) mosaic(O),(O) from(O) left(O) to(O) right(O) :(O) Jupiter(B-astronomical object),(O) Earth(B-astronomical object),(O) Venus(B-astronomical object),(O) Saturn(B-astronomical object),(O) Uranus(B-astronomical object),(O) Neptune(B-astronomical object).(O)", "instance": {"id": "290", "words": ["Six", "planet", "s", "are", "visible", "in", "the", "mosaic", ",", "from", "left", "to", "right", ":", "Jupiter", ",", "Earth", ",", "Venus", ",", "Saturn", ",", "Uranus", ",", "Neptune", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-astronomical object", "O", "B-astronomical object", "O", "B-astronomical object", "O", "B-astronomical object", "O", "B-astronomical object", "O", "B-astronomical object", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, academic journal, chemical compound, person, country, theory, university, chemical element, location, scientist, organization, protein, discipline, enzyme, astronomical object, award and O.\nSentence: Six planet s are visible in the mosaic , from left to right : Jupiter , Earth , Venus , Saturn , Uranus , Neptune .", "prompt_labels": "Six(O) planet(O) s(O) are(O) visible(O) in(O) the(O) mosaic(O) ,(O) from(O) left(O) to(O) right(O) :(O) Jupiter(B-astronomical object) ,(O) Earth(B-astronomical object) ,(O) Venus(B-astronomical object) ,(O) Saturn(B-astronomical object) ,(O) Uranus(B-astronomical object) ,(O) Neptune(B-astronomical object) .(O)"}, "label_list": ["event", "academic journal", "chemical compound", "person", "country", "theory", "university", "chemical element", "location", "scientist", "organization", "protein", "discipline", "enzyme", "astronomical object", "award"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 14584, 8486, 11, 11742, 24549, 11, 1732, 11, 3224, 11, 10334, 11, 12374, 11, 11742, 2449, 11, 3813, 11, 28568, 11, 7471, 11, 13128, 11, 26434, 11, 49242, 11, 87283, 1665, 11, 10292, 323, 507, 627, 85664, 25, 19198, 11841, 274, 527, 9621, 304, 279, 71624, 1174, 505, 2163, 311, 1314, 551, 50789, 1174, 9420, 1174, 50076, 1174, 50253, 1174, 80770, 355, 1174, 80724, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "55", "dataset": "crossner_music", "split": "dev", "prediction": "The(O) film(O) won(O) Academy(B-award) Awards(I-award) for(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Actor(I-award) ((O) James(B-musical artist) Cagney(I-musical artist) )(O),(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Original(I-award) Score(I-award) and(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Sound(I-award) Mixing(I-award) ((O) Nathan(B-musical artist) Levinson(I-musical artist) )(O).(O)", "instance": {"id": "55", "words": ["The", "film", "won", "Academy", "Awards", "for", "Academy", "Award", "for", "Best", "Actor", "(", "James", "Cagney", ")", ",", "Academy", "Award", "for", "Best", "Original", "Score", "and", "Academy", "Award", "for", "Best", "Sound", "Mixing", "(", "Nathan", "Levinson", ")", "."], "labels": ["O", "O", "O", "B-award", "I-award", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "O", "B-person", "I-person", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O", "B-musical artist", "I-musical artist", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, album, award, person, band, event, location, song, organization, musical artist, musical instrument, music genre and O.\nSentence: The film won Academy Awards for Academy Award for Best Actor ( James Cagney ) , Academy Award for Best Original Score and Academy Award for Best Sound Mixing ( Nathan Levinson ) .", "prompt_labels": "The(O) film(O) won(O) Academy(B-award) Awards(I-award) for(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Actor(I-award) ((O) James(B-person) Cagney(I-person) )(O) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Original(I-award) Score(I-award) and(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Sound(I-award) Mixing(I-award) ((O) Nathan(B-musical artist) Levinson(I-musical artist) )(O) .(O)"}, "label_list": ["country", "album", "award", "person", "band", "event", "location", "song", "organization", "musical artist", "musical instrument", "music genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 8176, 11, 10292, 11, 1732, 11, 7200, 11, 1567, 11, 3813, 11, 5609, 11, 7471, 11, 18273, 10255, 11, 18273, 14473, 11, 4731, 17779, 323, 507, 627, 85664, 25, 578, 4632, 2834, 16192, 23488, 369, 16192, 17768, 369, 7252, 25749, 320, 7957, 356, 351, 3520, 883, 1174, 16192, 17768, 369, 7252, 17674, 18607, 323, 16192, 17768, 369, 7252, 14936, 97699, 320, 37837, 67977, 942, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "160", "dataset": "crossner_literature", "split": "dev", "prediction": "In(O) the(O) sultanate(O),(O) Burgess(B-writer) sketched(O) the(O) novel(O) that(O),(O) when(O) it(O) was(O) published(O) in(O) 1961(O),(O) was(O) to(O) be(O) entitled(O) Devil(B-book) of(I-book) a(I-book) State(I-book) and(O),(O) although(O) it(O) dealt(O) with(O) Brunei(B-country),(O) for(O) libel(O) reasons(O) the(O) action(O) had(O) to(O) be(O) transposed(O) to(O) an(O) imaginary(O) East(B-location) African(I-location) territory(O) similar(O) to(O) Zanzibar(B-country),(O) named(O) Dunia(O).(O)", "instance": {"id": "160", "words": ["In", "the", "sultanate", ",", "Burgess", "sketched", "the", "novel", "that", ",", "when", "it", "was", "published", "in", "1961", ",", "was", "to", "be", "entitled", "Devil", "of", "a", "State", "and", ",", "although", "it", "dealt", "with", "Brunei", ",", "for", "libel", "reasons", "the", "action", "had", "to", "be", "transposed", "to", "an", "imaginary", "East", "African", "territory", "similar", "to", "Zanzibar", ",", "named", "Dunia", "."], "labels": ["O", "O", "O", "O", "B-writer", "O", "O", "B-literary genre", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-book", "I-book", "I-book", "I-book", "O", "O", "O", "O", "O", "O", "B-country", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "O", "O", "O", "B-country", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, event, writer, country, location, award, poem, person, literary genre, book, magazine and O.\nSentence: In the sultanate , Burgess sketched the novel that , when it was published in 1961 , was to be entitled Devil of a State and , although it dealt with Brunei , for libel reasons the action had to be transposed to an imaginary East African territory similar to Zanzibar , named Dunia .", "prompt_labels": "In(O) the(O) sultanate(O) ,(O) Burgess(B-writer) sketched(O) the(O) novel(B-literary genre) that(O) ,(O) when(O) it(O) was(O) published(O) in(O) 1961(O) ,(O) was(O) to(O) be(O) entitled(O) Devil(B-book) of(I-book) a(I-book) State(I-book) and(O) ,(O) although(O) it(O) dealt(O) with(O) Brunei(B-country) ,(O) for(O) libel(O) reasons(O) the(O) action(O) had(O) to(O) be(O) transposed(O) to(O) an(O) imaginary(O) East(B-location) African(I-location) territory(O) similar(O) to(O) Zanzibar(B-country) ,(O) named(O) Dunia(O) .(O)"}, "label_list": ["organization", "event", "writer", "country", "location", "award", "poem", "person", "literary genre", "book", "magazine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 1567, 11, 7061, 11, 3224, 11, 3813, 11, 10292, 11, 33894, 11, 1732, 11, 32465, 17779, 11, 2363, 11, 14756, 323, 507, 627, 85664, 25, 763, 279, 274, 61193, 349, 1174, 98567, 1940, 37880, 279, 11775, 430, 1174, 994, 433, 574, 4756, 304, 220, 5162, 16, 1174, 574, 311, 387, 20458, 40301, 315, 264, 3314, 323, 1174, 8051, 433, 27023, 449, 3320, 96323, 1174, 369, 3127, 301, 8125, 279, 1957, 1047, 311, 387, 1380, 3950, 311, 459, 51052, 6460, 11904, 18455, 4528, 311, 1901, 12341, 106954, 1174, 7086, 29838, 689, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "969", "dataset": "mit-restaurant", "split": "dev", "prediction": "looking(O) for(O) a(O) three(B-Rating) star(I-Rating) restaurant(O) along(B-Location) my(I-Location) current(I-Location) route(I-Location) within(I-Location) the(I-Location) next(I-Location) hundred(I-Location) miles(I-Location) and(O) not(B-Location) more(I-Location) then(I-Location) a(I-Location) mile(I-Location) off(I-Location) route(I-Location) any(O) suggestions(O)", "instance": {"id": "969", "words": ["looking", "for", "a", "three", "star", "restaurant", "along", "my", "current", "route", "within", "the", "next", "hundred", "miles", "and", "not", "more", "then", "a", "mile", "off", "route", "any", "suggestions"], "labels": ["O", "O", "O", "B-Rating", "I-Rating", "O", "B-Location", "I-Location", "I-Location", "I-Location", "I-Location", "I-Location", "I-Location", "I-Location", "I-Location", "O", "B-Location", "I-Location", "I-Location", "I-Location", "I-Location", "I-Location", "I-Location", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Hours, Restaurant Name, Cuisine, Price, Location, Amenity, Rating and O.\nSentence: looking for a three star restaurant along my current route within the next hundred miles and not more then a mile off route any suggestions", "prompt_labels": "looking(O) for(O) a(O) three(B-Rating) star(I-Rating) restaurant(O) along(B-Location) my(I-Location) current(I-Location) route(I-Location) within(I-Location) the(I-Location) next(I-Location) hundred(I-Location) miles(I-Location) and(O) not(B-Location) more(I-Location) then(I-Location) a(I-Location) mile(I-Location) off(I-Location) route(I-Location) any(O) suggestions(O)"}, "label_list": ["Dish", "Hours", "Restaurant Name", "Cuisine", "Price", "Location", "Amenity", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 30192, 11, 26568, 4076, 11, 81961, 11, 8650, 11, 10067, 11, 3383, 56685, 11, 19767, 323, 507, 627, 85664, 25, 3411, 369, 264, 2380, 6917, 10960, 3235, 856, 1510, 6149, 2949, 279, 1828, 7895, 8931, 323, 539, 810, 1243, 264, 14929, 1022, 6149, 904, 18726, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1649", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) a(O) war(B-genre) film(O) starring(O) robert(B-actor) evan(I-actor)", "instance": {"id": "1649", "words": ["list", "a", "war", "film", "starring", "robert", "evan"], "labels": ["O", "O", "B-genre", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, average ratings, song, director, actor, trailer, character, plot, rating, year, review, title and O.\nSentence: list a war film starring robert evan", "prompt_labels": "list(O) a(O) war(B-genre) film(O) starring(O) robert(B-actor) evan(I-actor)"}, "label_list": ["genre", "average ratings", "song", "director", "actor", "trailer", "character", "plot", "rating", "year", "review", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 5578, 18594, 11, 5609, 11, 7690, 11, 12360, 11, 19809, 11, 3752, 11, 7234, 11, 10959, 11, 1060, 11, 3477, 11, 2316, 323, 507, 627, 85664, 25, 1160, 264, 4208, 4632, 40500, 89993, 3721, 276, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "82", "dataset": "mit-restaurant", "split": "dev", "prediction": "are(O) there(O) any(O) restaurants(O) that(O) serve(O) raw(B-Cuisine) and(I-Cuisine) organic(I-Cuisine) food(O) nearby(B-Location)", "instance": {"id": "82", "words": ["are", "there", "any", "restaurants", "that", "serve", "raw", "and", "organic", "food", "nearby"], "labels": ["O", "O", "O", "O", "O", "O", "B-Cuisine", "I-Cuisine", "I-Cuisine", "O", "B-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Rating, Hours, Dish, Location, Restaurant Name, Cuisine, Price and O.\nSentence: are there any restaurants that serve raw and organic food nearby", "prompt_labels": "are(O) there(O) any(O) restaurants(O) that(O) serve(O) raw(B-Cuisine) and(I-Cuisine) organic(I-Cuisine) food(O) nearby(B-Location)"}, "label_list": ["Amenity", "Rating", "Hours", "Dish", "Location", "Restaurant Name", "Cuisine", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 19767, 11, 30192, 11, 49268, 11, 10067, 11, 26568, 4076, 11, 81961, 11, 8650, 323, 507, 627, 85664, 25, 527, 1070, 904, 15926, 430, 8854, 7257, 323, 17808, 3691, 14373, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "30", "dataset": "crossner_politics", "split": "dev", "prediction": "In(O) that(O) election(O) he(O) defeated(O) William(B-politician) Ross(I-politician) of(O) the(O) Ulster(B-political party) Unionist(I-political party) Party(I-political party) who(O) had(O) represented(O) East(B-location) Londonderry(I-location) since(O) 1983(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) its(O) predecessor(O) seat(O) of(O) Londonderry(B-location) between(O) February(O) 1974(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) 1983(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election).(O)", "instance": {"id": "30", "words": ["In", "that", "election", "he", "defeated", "William", "Ross", "of", "the", "Ulster", "Unionist", "Party", "who", "had", "represented", "East", "Londonderry", "since", "1983", "United", "Kingdom", "general", "election", "and", "its", "predecessor", "seat", "of", "Londonderry", "between", "February", "1974", "United", "Kingdom", "general", "election", "and", "1983", "United", "Kingdom", "general", "election", "."], "labels": ["O", "O", "O", "O", "O", "B-politician", "I-politician", "O", "O", "B-political party", "I-political party", "I-political party", "O", "O", "O", "B-location", "I-location", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "B-location", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, politician, country, election, event, political party, location, person and O.\nSentence: In that election he defeated William Ross of the Ulster Unionist Party who had represented East Londonderry since 1983 United Kingdom general election and its predecessor seat of Londonderry between February 1974 United Kingdom general election and 1983 United Kingdom general election .", "prompt_labels": "In(O) that(O) election(O) he(O) defeated(O) William(B-politician) Ross(I-politician) of(O) the(O) Ulster(B-political party) Unionist(I-political party) Party(I-political party) who(O) had(O) represented(O) East(B-location) Londonderry(I-location) since(O) 1983(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) its(O) predecessor(O) seat(O) of(O) Londonderry(B-location) between(O) February(B-election) 1974(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) 1983(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)"}, "label_list": ["organization", "politician", "country", "election", "event", "political party", "location", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 37038, 11, 3224, 11, 6355, 11, 1567, 11, 5054, 4717, 11, 3813, 11, 1732, 323, 507, 627, 85664, 25, 763, 430, 6355, 568, 24164, 12656, 21116, 315, 279, 16991, 3751, 9323, 380, 8722, 889, 1047, 15609, 6460, 80693, 2159, 5515, 2533, 220, 3753, 18, 3723, 15422, 4689, 6355, 323, 1202, 40274, 10954, 315, 80693, 2159, 5515, 1990, 7552, 220, 4468, 19, 3723, 15422, 4689, 6355, 323, 220, 3753, 18, 3723, 15422, 4689, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "939", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) comedys(B-genre) had(O) eddie(B-actor) murphy(I-actor) play(O) a(O) big(O) role(O) in(O)", "instance": {"id": "939", "words": ["what", "comedys", "had", "eddie", "murphy", "play", "a", "big", "role", "in"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, director, plot, average ratings, character, year, song, title, actor, trailer, rating, genre and O.\nSentence: what comedys had eddie murphy play a big role in", "prompt_labels": "what(O) comedys(O) had(O) eddie(B-actor) murphy(I-actor) play(O) a(O) big(O) role(O) in(O)"}, "label_list": ["review", "director", "plot", "average ratings", "character", "year", "song", "title", "actor", "trailer", "rating", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 7690, 11, 7234, 11, 5578, 18594, 11, 3752, 11, 1060, 11, 5609, 11, 2316, 11, 12360, 11, 19809, 11, 10959, 11, 17779, 323, 507, 627, 85664, 25, 1148, 63113, 1065, 1047, 1608, 27591, 8309, 12989, 1514, 264, 2466, 3560, 304, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "596", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) need(O) directions(O) to(O) the(O) nearest(B-Location) ethiopian(B-Cuisine) restaurant(O)", "instance": {"id": "596", "words": ["i", "need", "directions", "to", "the", "nearest", "ethiopian", "restaurant"], "labels": ["O", "O", "O", "O", "O", "B-Location", "B-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Price, Cuisine, Hours, Amenity, Restaurant Name, Rating, Location and O.\nSentence: i need directions to the nearest ethiopian restaurant", "prompt_labels": "i(O) need(O) directions(O) to(O) the(O) nearest(B-Location) ethiopian(B-Cuisine) restaurant(O)"}, "label_list": ["Dish", "Price", "Cuisine", "Hours", "Amenity", "Restaurant Name", "Rating", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 8650, 11, 81961, 11, 30192, 11, 3383, 56685, 11, 26568, 4076, 11, 19767, 11, 10067, 323, 507, 627, 85664, 25, 602, 1205, 18445, 311, 279, 24379, 8537, 72, 48748, 10960, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "304", "dataset": "crossner_literature", "split": "dev", "prediction": "At(O) the(O) entrance(O) to(O) the(O) Gerasimov(B-organization) Institute(I-organization) of(I-organization) Cinematography(I-organization) in(O) Moscow(B-location),(O) there(O) is(O) a(O) monument(O) that(O) includes(O) statues(O) of(O) Tarkovsky(B-writer),(O) Gennady(B-writer) Shpalikov(I-writer) and(O) Vasily(B-writer) Shukshin(I-writer).(O)", "instance": {"id": "304", "words": ["At", "the", "entrance", "to", "the", "Gerasimov", "Institute", "of", "Cinematography", "in", "Moscow", ",", "there", "is", "a", "monument", "that", "includes", "statues", "of", "Tarkovsky", ",", "Gennady", "Shpalikov", "and", "Vasily", "Shukshin", "."], "labels": ["O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "B-location", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-writer", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, person, book, literary genre, poem, writer, location, magazine, event, award, country and O.\nSentence: At the entrance to the Gerasimov Institute of Cinematography in Moscow , there is a monument that includes statues of Tarkovsky , Gennady Shpalikov and Vasily Shukshin .", "prompt_labels": "At(O) the(O) entrance(O) to(O) the(O) Gerasimov(B-organization) Institute(I-organization) of(I-organization) Cinematography(I-organization) in(O) Moscow(B-location) ,(O) there(O) is(O) a(O) monument(O) that(O) includes(O) statues(O) of(O) Tarkovsky(B-writer) ,(O) Gennady(B-writer) Shpalikov(I-writer) and(O) Vasily(B-writer) Shukshin(I-writer) .(O)"}, "label_list": ["organization", "person", "book", "literary genre", "poem", "writer", "location", "magazine", "event", "award", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 1732, 11, 2363, 11, 32465, 17779, 11, 33894, 11, 7061, 11, 3813, 11, 14756, 11, 1567, 11, 10292, 11, 3224, 323, 507, 627, 85664, 25, 2468, 279, 20396, 311, 279, 480, 9431, 318, 869, 10181, 315, 30011, 43698, 5814, 304, 23223, 1174, 1070, 374, 264, 37997, 430, 5764, 59002, 315, 350, 847, 79678, 1174, 480, 2734, 7759, 1443, 19866, 1609, 869, 323, 650, 38367, 1443, 3178, 939, 258, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "258", "dataset": "crossner_literature", "split": "dev", "prediction": "The(O) Chicago(B-location) Tribune(I-location) quoted(O) Pulitzer(B-award) Prize(I-award) -winning(O) author(O) Stephen(B-writer) Hunter(I-writer) as(O) saying(O),(O) When(O) he(O) published(O) The(B-book) Hunt(I-book) for(I-book) Red(I-book) October(I-book),(O) he(O) redefined(O) and(O) expanded(O) the(O) genre(O) and(O) as(O) a(O) consequence(O) of(O) that(O),(O) many(O) people(O) were(O) able(O) to(O) publish(O) such(O) books(O) who(O) had(O) previously(O) been(O) unable(O) to(O) do(O) so(O).(O)", "instance": {"id": "258", "words": ["The", "Chicago", "Tribune", "quoted", "Pulitzer", "Prize", "-winning", "author", "Stephen", "Hunter", "as", "saying", ",", "When", "he", "published", "The", "Hunt", "for", "Red", "October", ",", "he", "redefined", "and", "expanded", "the", "genre", "and", "as", "a", "consequence", "of", "that", ",", "many", "people", "were", "able", "to", "publish", "such", "books", "who", "had", "previously", "been", "unable", "to", "do", "so", "."], "labels": ["O", "B-organization", "I-organization", "O", "B-award", "I-award", "O", "O", "B-writer", "I-writer", "O", "O", "O", "O", "O", "O", "B-book", "I-book", "I-book", "I-book", "I-book", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: writer, event, person, organization, poem, book, location, literary genre, award, country, magazine and O.\nSentence: The Chicago Tribune quoted Pulitzer Prize -winning author Stephen Hunter as saying , When he published The Hunt for Red October , he redefined and expanded the genre and as a consequence of that , many people were able to publish such books who had previously been unable to do so .", "prompt_labels": "The(O) Chicago(B-organization) Tribune(I-organization) quoted(O) Pulitzer(B-award) Prize(I-award) -winning(O) author(O) Stephen(B-writer) Hunter(I-writer) as(O) saying(O) ,(O) When(O) he(O) published(O) The(B-book) Hunt(I-book) for(I-book) Red(I-book) October(I-book) ,(O) he(O) redefined(O) and(O) expanded(O) the(O) genre(O) and(O) as(O) a(O) consequence(O) of(O) that(O) ,(O) many(O) people(O) were(O) able(O) to(O) publish(O) such(O) books(O) who(O) had(O) previously(O) been(O) unable(O) to(O) do(O) so(O) .(O)"}, "label_list": ["writer", "event", "person", "organization", "poem", "book", "location", "literary genre", "award", "country", "magazine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7061, 11, 1567, 11, 1732, 11, 7471, 11, 33894, 11, 2363, 11, 3813, 11, 32465, 17779, 11, 10292, 11, 3224, 11, 14756, 323, 507, 627, 85664, 25, 578, 10780, 41439, 24116, 96815, 32293, 482, 7678, 1251, 3229, 18587, 24008, 439, 5605, 1174, 3277, 568, 4756, 578, 27690, 369, 3816, 6664, 1174, 568, 312, 9910, 323, 17626, 279, 17779, 323, 439, 264, 29774, 315, 430, 1174, 1690, 1274, 1051, 3025, 311, 3498, 1778, 6603, 889, 1047, 8767, 1027, 12153, 311, 656, 779, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "122", "dataset": "crossner_science", "split": "dev", "prediction": "Since(O) then(O),(O) names(O) have(O) been(O) given(O) to(O) 134(O) additional(O) satellites(O) :(O) 57(O) satellites(O) of(O) Jupiter(B-astronomical object),(O) 43(O) of(O) Saturn(B-astronomical object),(O) 22(O) of(O) Uranus(B-astronomical object),(O) 12(O) of(O) Neptune(B-astronomical object),(O) 5(O) of(O) Pluto(B-astronomical object),(O) 1(O) of(O) Eris(B-astronomical object),(O) and(O) 2(O) of(O) Haumea(B-astronomical object).(O)", "instance": {"id": "122", "words": ["Since", "then", ",", "names", "have", "been", "given", "to", "134", "additional", "satellites", ":", "57", "satellites", "of", "Jupiter", ",", "43", "of", "Saturn", ",", "22", "of", "Uranus", ",", "12", "of", "Neptune", ",", "5", "of", "Pluto", ",", "1", "of", "Eris", ",", "and", "2", "of", "Haumea", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-astronomical object", "O", "O", "O", "B-astronomical object", "O", "O", "O", "B-astronomical object", "O", "O", "O", "B-astronomical object", "O", "O", "O", "B-astronomical object", "O", "O", "O", "B-astronomical object", "O", "O", "O", "O", "B-astronomical object", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical element, country, astronomical object, university, award, person, academic journal, discipline, event, chemical compound, enzyme, protein, organization, scientist, theory, location and O.\nSentence: Since then , names have been given to 134 additional satellites : 57 satellites of Jupiter , 43 of Saturn , 22 of Uranus , 12 of Neptune , 5 of Pluto , 1 of Eris , and 2 of Haumea .", "prompt_labels": "Since(O) then(O) ,(O) names(O) have(O) been(O) given(O) to(O) 134(O) additional(O) satellites(O) :(O) 57(O) satellites(O) of(O) Jupiter(B-astronomical object) ,(O) 43(O) of(O) Saturn(B-astronomical object) ,(O) 22(O) of(O) Uranus(B-astronomical object) ,(O) 12(O) of(O) Neptune(B-astronomical object) ,(O) 5(O) of(O) Pluto(B-astronomical object) ,(O) 1(O) of(O) Eris(B-astronomical object) ,(O) and(O) 2(O) of(O) Haumea(B-astronomical object) .(O)"}, "label_list": ["chemical element", "country", "astronomical object", "university", "award", "person", "academic journal", "discipline", "event", "chemical compound", "enzyme", "protein", "organization", "scientist", "theory", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 11742, 2449, 11, 3224, 11, 87283, 1665, 11, 12374, 11, 10292, 11, 1732, 11, 14584, 8486, 11, 26434, 11, 1567, 11, 11742, 24549, 11, 49242, 11, 13128, 11, 7471, 11, 28568, 11, 10334, 11, 3813, 323, 507, 627, 85664, 25, 8876, 1243, 1174, 5144, 617, 1027, 2728, 311, 220, 9565, 5217, 47710, 551, 220, 3226, 47710, 315, 50789, 1174, 220, 3391, 315, 50253, 1174, 220, 1313, 315, 80770, 355, 1174, 220, 717, 315, 80724, 1174, 220, 20, 315, 78681, 1174, 220, 16, 315, 469, 6091, 1174, 323, 220, 17, 315, 14433, 3972, 64, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "917", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) best(O) action(B-genre) movie(O) this(B-year) year(I-year)", "instance": {"id": "917", "words": ["what", "is", "the", "best", "action", "movie", "this", "year"], "labels": ["O", "O", "O", "B-average ratings", "B-genre", "I-genre", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, title, year, director, average ratings, actor, character, song, genre, plot, trailer, review and O.\nSentence: what is the best action movie this year", "prompt_labels": "what(O) is(O) the(O) best(B-average ratings) action(B-genre) movie(I-genre) this(B-year) year(I-year)"}, "label_list": ["rating", "title", "year", "director", "average ratings", "actor", "character", "song", "genre", "plot", "trailer", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 2316, 11, 1060, 11, 7690, 11, 5578, 18594, 11, 12360, 11, 3752, 11, 5609, 11, 17779, 11, 7234, 11, 19809, 11, 3477, 323, 507, 627, 85664, 25, 1148, 374, 279, 1888, 1957, 5818, 420, 1060, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2180", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) scary(B-genre) movies(O) have(O) sylvain(B-director) chomet(I-director) directed(O)", "instance": {"id": "2180", "words": ["what", "scary", "movies", "have", "sylvain", "chomet", "directed"], "labels": ["O", "B-genre", "O", "O", "B-director", "I-director", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, review, director, genre, character, year, title, trailer, song, rating, average ratings, actor and O.\nSentence: what scary movies have sylvain chomet directed", "prompt_labels": "what(O) scary(B-genre) movies(O) have(O) sylvain(B-director) chomet(I-director) directed(O)"}, "label_list": ["plot", "review", "director", "genre", "character", "year", "title", "trailer", "song", "rating", "average ratings", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 3477, 11, 7690, 11, 17779, 11, 3752, 11, 1060, 11, 2316, 11, 19809, 11, 5609, 11, 10959, 11, 5578, 18594, 11, 12360, 323, 507, 627, 85664, 25, 1148, 29565, 9698, 617, 274, 15095, 467, 523, 4512, 15910, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "907", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) any(O) place(O) on(O) the(O) waterfront(B-Location) that(O) does(B-Amenity) not(I-Amenity) allow(I-Amenity) smoking(I-Amenity) on(I-Amenity) the(I-Amenity) outside(I-Amenity) decks(I-Amenity)", "instance": {"id": "907", "words": ["is", "there", "any", "place", "on", "the", "waterfront", "that", "does", "not", "allow", "smoking", "on", "the", "outside", "decks"], "labels": ["O", "O", "O", "O", "O", "O", "B-Location", "O", "O", "B-Amenity", "I-Amenity", "I-Amenity", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Dish, Hours, Location, Cuisine, Rating, Price, Amenity and O.\nSentence: is there any place on the waterfront that does not allow smoking on the outside decks", "prompt_labels": "is(O) there(O) any(O) place(O) on(O) the(O) waterfront(B-Location) that(O) does(O) not(B-Amenity) allow(I-Amenity) smoking(I-Amenity) on(O) the(O) outside(B-Amenity) decks(I-Amenity)"}, "label_list": ["Restaurant Name", "Dish", "Hours", "Location", "Cuisine", "Rating", "Price", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 49268, 11, 30192, 11, 10067, 11, 81961, 11, 19767, 11, 8650, 11, 3383, 56685, 323, 507, 627, 85664, 25, 374, 1070, 904, 2035, 389, 279, 70027, 430, 1587, 539, 2187, 20149, 389, 279, 4994, 30881, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1247", "dataset": "mit-restaurant", "split": "dev", "prediction": "when(O) does(O) churchs(B-Restaurant Name) open(O)", "instance": {"id": "1247", "words": ["when", "does", "churchs", "open"], "labels": ["O", "O", "B-Restaurant Name", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Dish, Cuisine, Amenity, Rating, Price, Hours, Location and O.\nSentence: when does churchs open", "prompt_labels": "when(O) does(O) churchs(B-Restaurant Name) open(O)"}, "label_list": ["Restaurant Name", "Dish", "Cuisine", "Amenity", "Rating", "Price", "Hours", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 49268, 11, 81961, 11, 3383, 56685, 11, 19767, 11, 8650, 11, 30192, 11, 10067, 323, 507, 627, 85664, 25, 994, 1587, 8993, 82, 1825, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1518", "dataset": "mit-restaurant", "split": "dev", "prediction": "yes(O) the(O) new(B-Amenity) diner(B-Cuisine) on(O) south(B-Location) street(I-Location) please(O)", "instance": {"id": "1518", "words": ["yes", "the", "new", "diner", "on", "south", "street", "please"], "labels": ["O", "O", "O", "B-Cuisine", "O", "B-Location", "I-Location", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Price, Hours, Location, Cuisine, Restaurant Name, Dish, Rating and O.\nSentence: yes the new diner on south street please", "prompt_labels": "yes(O) the(O) new(O) diner(B-Cuisine) on(O) south(B-Location) street(I-Location) please(O)"}, "label_list": ["Amenity", "Price", "Hours", "Location", "Cuisine", "Restaurant Name", "Dish", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 8650, 11, 30192, 11, 10067, 11, 81961, 11, 26568, 4076, 11, 49268, 11, 19767, 323, 507, 627, 85664, 25, 10035, 279, 502, 89206, 389, 10007, 8761, 4587, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2315", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) is(O) the(O) main(B-character) character(O) in(O) the(O) movie(O) tenshi(B-title) no(I-title) tamago(I-title)", "instance": {"id": "2315", "words": ["who", "is", "the", "main", "character", "in", "the", "movie", "tenshi", "no", "tamago"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, review, trailer, average ratings, genre, director, year, actor, rating, title, character, plot and O.\nSentence: who is the main character in the movie tenshi no tamago", "prompt_labels": "who(O) is(O) the(O) main(O) character(O) in(O) the(O) movie(O) tenshi(B-title) no(I-title) tamago(I-title)"}, "label_list": ["song", "review", "trailer", "average ratings", "genre", "director", "year", "actor", "rating", "title", "character", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 3477, 11, 19809, 11, 5578, 18594, 11, 17779, 11, 7690, 11, 1060, 11, 12360, 11, 10959, 11, 2316, 11, 3752, 11, 7234, 323, 507, 627, 85664, 25, 889, 374, 279, 1925, 3752, 304, 279, 5818, 22781, 6151, 912, 26555, 6438, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "23", "dataset": "mit-restaurant", "split": "dev", "prediction": "are(O) there(O) any(O) bars(B-Cuisine) nearby(O) that(O) serve(O) food(O) like(O) italian(B-Cuisine) or(O) french(B-Cuisine)", "instance": {"id": "23", "words": ["are", "there", "any", "bars", "nearby", "that", "serve", "food", "like", "italian", "or", "french"], "labels": ["O", "O", "O", "B-Cuisine", "B-Location", "O", "O", "O", "O", "B-Cuisine", "O", "B-Cuisine"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Dish, Hours, Cuisine, Location, Restaurant Name, Price, Rating and O.\nSentence: are there any bars nearby that serve food like italian or french", "prompt_labels": "are(O) there(O) any(O) bars(B-Cuisine) nearby(B-Location) that(O) serve(O) food(O) like(O) italian(B-Cuisine) or(O) french(B-Cuisine)"}, "label_list": ["Amenity", "Dish", "Hours", "Cuisine", "Location", "Restaurant Name", "Price", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 49268, 11, 30192, 11, 81961, 11, 10067, 11, 26568, 4076, 11, 8650, 11, 19767, 323, 507, 627, 85664, 25, 527, 1070, 904, 16283, 14373, 430, 8854, 3691, 1093, 29048, 477, 42293, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "55", "dataset": "mit-restaurant", "split": "dev", "prediction": "are(O) there(O) any(O) kid(B-Amenity) friendly(I-Amenity) restaurants(O) with(O) valet(B-Amenity) parking(I-Amenity)", "instance": {"id": "55", "words": ["are", "there", "any", "kid", "friendly", "restaurants", "with", "valet", "parking"], "labels": ["O", "O", "O", "B-Amenity", "I-Amenity", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Dish, Amenity, Price, Hours, Location, Restaurant Name, Cuisine and O.\nSentence: are there any kid friendly restaurants with valet parking", "prompt_labels": "are(O) there(O) any(O) kid(B-Amenity) friendly(I-Amenity) restaurants(O) with(O) valet(B-Amenity) parking(I-Amenity)"}, "label_list": ["Rating", "Dish", "Amenity", "Price", "Hours", "Location", "Restaurant Name", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 49268, 11, 3383, 56685, 11, 8650, 11, 30192, 11, 10067, 11, 26568, 4076, 11, 81961, 323, 507, 627, 85664, 25, 527, 1070, 904, 10585, 11919, 15926, 449, 11412, 1169, 13217, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1505", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) there(O) a(O) horror(B-genre) film(O) starring(O) charles(B-director) chaplin(I-director)", "instance": {"id": "1505", "words": ["is", "there", "a", "horror", "film", "starring", "charles", "chaplin"], "labels": ["O", "O", "O", "B-genre", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, rating, actor, review, title, song, average ratings, year, director, character, trailer, genre and O.\nSentence: is there a horror film starring charles chaplin", "prompt_labels": "is(O) there(O) a(O) horror(B-genre) film(O) starring(O) charles(B-director) chaplin(I-director)"}, "label_list": ["plot", "rating", "actor", "review", "title", "song", "average ratings", "year", "director", "character", "trailer", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 10959, 11, 12360, 11, 3477, 11, 2316, 11, 5609, 11, 5578, 18594, 11, 1060, 11, 7690, 11, 3752, 11, 19809, 11, 17779, 323, 507, 627, 85664, 25, 374, 1070, 264, 22169, 4632, 40500, 1181, 645, 38838, 3817, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "64", "dataset": "crossner_music", "split": "dev", "prediction": "One(O) of(O) the(O) best-selling(O) music(O) groups(O) of(O) the(O) 1960s(O),(O) their(O) biggest(O) hits(O) -(O) including(O) The(B-song) Sound(I-song) of(I-song) Silence(I-song) ((O) 1965(O) )(O),(O) Mrs(B-song) Robinson(I-song) ((O) 1968(O) )(O),(O) The(B-song) Boxer(I-song) ((O) 1969(O) )(O),(O) and(O) Bridge(B-song) over(I-song) Troubled(I-song) Water(I-song) ((O) 1970(O) )(O) -(O) reached(O) number(O) one(O) on(O) singles(O) charts(O) worldwide(O).(O)", "instance": {"id": "64", "words": ["One", "of", "the", "best-selling", "music", "groups", "of", "the", "1960s", ",", "their", "biggest", "hits", "-", "including", "The", "Sound", "of", "Silence", "(", "1965", ")", ",", "Mrs.", "Robinson", "(", "1968", ")", ",", "The", "Boxer", "(", "1969", ")", ",", "and", "Bridge", "over", "Troubled", "Water", "(", "1970", ")", "-", "reached", "number", "one", "on", "singles", "charts", "worldwide", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-song", "I-song", "I-song", "I-song", "O", "O", "O", "O", "B-song", "I-song", "O", "O", "O", "O", "B-song", "I-song", "O", "O", "O", "O", "O", "B-album", "I-album", "I-album", "I-album", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, country, person, band, song, musical artist, award, organization, event, music genre, album, musical instrument and O.\nSentence: One of the best-selling music groups of the 1960s , their biggest hits - including The Sound of Silence ( 1965 ) , Mrs. Robinson ( 1968 ) , The Boxer ( 1969 ) , and Bridge over Troubled Water ( 1970 ) - reached number one on singles charts worldwide .", "prompt_labels": "One(O) of(O) the(O) best-selling(O) music(O) groups(O) of(O) the(O) 1960s(O) ,(O) their(O) biggest(O) hits(O) -(O) including(O) The(B-song) Sound(I-song) of(I-song) Silence(I-song) ((O) 1965(O) )(O) ,(O) Mrs.(B-song) Robinson(I-song) ((O) 1968(O) )(O) ,(O) The(B-song) Boxer(I-song) ((O) 1969(O) )(O) ,(O) and(O) Bridge(B-album) over(I-album) Troubled(I-album) Water(I-album) ((O) 1970(O) )(O) -(O) reached(O) number(O) one(O) on(O) singles(O) charts(O) worldwide(O) .(O)"}, "label_list": ["location", "country", "person", "band", "song", "musical artist", "award", "organization", "event", "music genre", "album", "musical instrument"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 3224, 11, 1732, 11, 7200, 11, 5609, 11, 18273, 10255, 11, 10292, 11, 7471, 11, 1567, 11, 4731, 17779, 11, 8176, 11, 18273, 14473, 323, 507, 627, 85664, 25, 3861, 315, 279, 1888, 48724, 4731, 5315, 315, 279, 220, 5162, 15, 82, 1174, 872, 8706, 13280, 482, 2737, 578, 14936, 315, 69188, 320, 220, 5162, 20, 883, 1174, 18083, 13, 28280, 320, 220, 5162, 23, 883, 1174, 578, 8425, 261, 320, 220, 5162, 24, 883, 1174, 323, 20467, 927, 42782, 38759, 10164, 320, 220, 4468, 15, 883, 482, 8813, 1396, 832, 389, 17845, 27223, 15603, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "448", "dataset": "crossner_science", "split": "dev", "prediction": "She(O) is(O) a(O) member(O) of(O) the(O) Australian(B-organization) Antarctic(I-organization) Research(I-organization) Advisory(I-organization) Committee(I-organization) and(O) serves(O) on(O) the(O) Editorial(O) Boards(O) of(O) the(O) international(O) journals(O) :(O) Ecosystems(B-academic journal),(O) Global(B-academic journal) Change(I-academic journal) Biology(I-academic journal),(O) Oecologia(B-academic journal),(O) Plant(B-academic journal),(O) Cell(B-academic journal) ;(O) Environment(B-academic journal),(O) and(O) Tree(B-academic journal) Physiology(I-academic journal).(O)", "instance": {"id": "448", "words": ["She", "is", "a", "member", "of", "the", "Australian", "Antarctic", "Research", "Advisory", "Committee", "and", "serves", "on", "the", "Editorial", "Boards", "of", "the", "international", "journals", ":", "Ecosystems", ",", "Global", "Change", "Biology", ",", "Oecologia", ",", "Plant", ",", "Cell", ";", "Environment", ",", "and", "Tree", "Physiology", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-academic journal", "O", "B-academic journal", "I-academic journal", "I-academic journal", "O", "B-academic journal", "O", "B-academic journal", "O", "B-academic journal", "O", "B-academic journal", "O", "O", "B-academic journal", "I-academic journal", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, organization, theory, protein, astronomical object, person, chemical element, discipline, chemical compound, enzyme, country, location, academic journal, event, university, scientist and O.\nSentence: She is a member of the Australian Antarctic Research Advisory Committee and serves on the Editorial Boards of the international journals : Ecosystems , Global Change Biology , Oecologia , Plant , Cell ; Environment , and Tree Physiology .", "prompt_labels": "She(O) is(O) a(O) member(O) of(O) the(O) Australian(B-organization) Antarctic(I-organization) Research(I-organization) Advisory(I-organization) Committee(I-organization) and(O) serves(O) on(O) the(O) Editorial(O) Boards(O) of(O) the(O) international(O) journals(O) :(O) Ecosystems(B-academic journal) ,(O) Global(B-academic journal) Change(I-academic journal) Biology(I-academic journal) ,(O) Oecologia(B-academic journal) ,(O) Plant(B-academic journal) ,(O) Cell(B-academic journal) ;(O) Environment(B-academic journal) ,(O) and(O) Tree(B-academic journal) Physiology(I-academic journal) .(O)"}, "label_list": ["award", "organization", "theory", "protein", "astronomical object", "person", "chemical element", "discipline", "chemical compound", "enzyme", "country", "location", "academic journal", "event", "university", "scientist"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10292, 11, 7471, 11, 10334, 11, 13128, 11, 87283, 1665, 11, 1732, 11, 11742, 2449, 11, 26434, 11, 11742, 24549, 11, 49242, 11, 3224, 11, 3813, 11, 14584, 8486, 11, 1567, 11, 12374, 11, 28568, 323, 507, 627, 85664, 25, 3005, 374, 264, 4562, 315, 279, 13673, 80841, 8483, 45013, 10554, 323, 17482, 389, 279, 66233, 72186, 315, 279, 6625, 42780, 551, 469, 24168, 82, 1174, 8121, 10604, 40023, 1174, 507, 762, 39073, 1174, 18317, 1174, 14299, 2652, 11847, 1174, 323, 9119, 95946, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2017", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) a(O) good(O) mockumentary(B-genre)", "instance": {"id": "2017", "words": ["what", "is", "a", "good", "mockumentary"], "labels": ["O", "O", "O", "O", "B-genre"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, title, actor, director, genre, rating, average ratings, song, plot, review, character, trailer and O.\nSentence: what is a good mockumentary", "prompt_labels": "what(O) is(O) a(O) good(O) mockumentary(B-genre)"}, "label_list": ["year", "title", "actor", "director", "genre", "rating", "average ratings", "song", "plot", "review", "character", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 2316, 11, 12360, 11, 7690, 11, 17779, 11, 10959, 11, 5578, 18594, 11, 5609, 11, 7234, 11, 3477, 11, 3752, 11, 19809, 323, 507, 627, 85664, 25, 1148, 374, 264, 1695, 8018, 1143, 661, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1340", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) can(O) i(O) get(O) some(O) slushy(B-Dish)", "instance": {"id": "1340", "words": ["where", "can", "i", "get", "some", "slushy"], "labels": ["O", "O", "O", "O", "O", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Dish, Cuisine, Restaurant Name, Rating, Price, Hours, Location and O.\nSentence: where can i get some slushy", "prompt_labels": "where(O) can(O) i(O) get(O) some(O) slushy(B-Dish)"}, "label_list": ["Amenity", "Dish", "Cuisine", "Restaurant Name", "Rating", "Price", "Hours", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 49268, 11, 81961, 11, 26568, 4076, 11, 19767, 11, 8650, 11, 30192, 11, 10067, 323, 507, 627, 85664, 25, 1405, 649, 602, 636, 1063, 1776, 1136, 88, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "276", "dataset": "crossner_politics", "split": "dev", "prediction": "All(O) MPs(O) are(O) listed(O) except(O) those(O) from(O) the(O) Ulster(B-political party) Unionist(I-political party) Party(I-political party) ((O) affiliated(O) to(O) the(O) Conservative(B-political party) Party(I-political party) during(O) this(O) period(O) )(O),(O) the(O) Nationalist(B-political party) Party(I-political party),(O) Sinn(B-political party) F\u00e9in(I-political party),(O) the(O) Liberal(B-political party) Party(I-political party),(O) the(O) Liberal(B-political party) Unionist(I-political party) Party(I-political party) and(O) the(O) Home(B-political party) Rule(I-political party) candidates(O).(O)", "instance": {"id": "276", "words": ["All", "MPs", "are", "listed", "except", "those", "from", "the", "Ulster", "Unionist", "Party", "(", "affiliated", "to", "the", "Conservative", "Party", "during", "this", "period", ")", ",", "the", "Nationalist", "Party", ",", "Sinn", "F\u00e9in", ",", "the", "Liberal", "Party", ",", "the", "Liberal", "Unionist", "Party", "and", "the", "Home", "Rule", "candidates", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "O", "O", "O", "O", "B-political party", "I-political party", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "O", "B-political party", "I-political party", "O", "O", "B-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, politician, election, organization, person, location, political party, country and O.\nSentence: All MPs are listed except those from the Ulster Unionist Party ( affiliated to the Conservative Party during this period ) , the Nationalist Party , Sinn F\u00e9in , the Liberal Party , the Liberal Unionist Party and the Home Rule candidates .", "prompt_labels": "All(O) MPs(O) are(O) listed(O) except(O) those(O) from(O) the(O) Ulster(B-political party) Unionist(I-political party) Party(I-political party) ((O) affiliated(O) to(O) the(O) Conservative(B-political party) Party(I-political party) during(O) this(O) period(O) )(O) ,(O) the(O) Nationalist(B-political party) Party(I-political party) ,(O) Sinn(B-political party) F\u00e9in(I-political party) ,(O) the(O) Liberal(B-political party) Party(I-political party) ,(O) the(O) Liberal(B-political party) Unionist(I-political party) Party(I-political party) and(O) the(O) Home(O) Rule(O) candidates(O) .(O)"}, "label_list": ["event", "politician", "election", "organization", "person", "location", "political party", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 37038, 11, 6355, 11, 7471, 11, 1732, 11, 3813, 11, 5054, 4717, 11, 3224, 323, 507, 627, 85664, 25, 2052, 37761, 527, 10212, 3734, 1884, 505, 279, 16991, 3751, 9323, 380, 8722, 320, 37506, 311, 279, 30071, 8722, 2391, 420, 4261, 883, 1174, 279, 5165, 380, 8722, 1174, 85679, 89250, 258, 1174, 279, 31158, 8722, 1174, 279, 31158, 9323, 380, 8722, 323, 279, 5492, 18592, 11426, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "980", "dataset": "mit-restaurant", "split": "dev", "prediction": "looking(O) for(O) olympic(B-Restaurant Name) house(I-Restaurant Name) of(I-Restaurant Name) pizza(I-Restaurant Name) for(O) lunch(B-Hours) any(B-Location) close(I-Location) by(I-Location)", "instance": {"id": "980", "words": ["looking", "for", "olympic", "house", "of", "pizza", "for", "lunch", "any", "close", "by"], "labels": ["O", "O", "B-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name", "O", "B-Hours", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Location, Price, Dish, Rating, Cuisine, Restaurant Name, Hours and O.\nSentence: looking for olympic house of pizza for lunch any close by", "prompt_labels": "looking(O) for(O) olympic(B-Restaurant Name) house(I-Restaurant Name) of(I-Restaurant Name) pizza(I-Restaurant Name) for(O) lunch(B-Hours) any(O) close(B-Location) by(I-Location)"}, "label_list": ["Amenity", "Location", "Price", "Dish", "Rating", "Cuisine", "Restaurant Name", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 10067, 11, 8650, 11, 49268, 11, 19767, 11, 81961, 11, 26568, 4076, 11, 30192, 323, 507, 627, 85664, 25, 3411, 369, 297, 14163, 292, 3838, 315, 23317, 369, 16163, 904, 3345, 555, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "157", "dataset": "crossner_music", "split": "dev", "prediction": "In(O) the(O) 2010s(O),(O) the(O) alt-country(B-music genre) genre(O) saw(O) an(O) increase(O) in(O) its(O) critical(O) and(O) commercial(O) popularity(O),(O) owing(O) to(O) the(O) success(O) of(O) artists(O) such(O) as(O) The(B-band) Civil(I-band) Wars(I-band),(O) Chris(B-musical artist) Stapleton(I-musical artist),(O) Sturgill(B-musical artist) Simpson(I-musical artist),(O) Jason(B-musical artist) Isbell(I-musical artist),(O) Lydia(B-musical artist) Loveless(I-musical artist) and(O) Margo(B-musical artist) Price(I-musical artist).(O)", "instance": {"id": "157", "words": ["In", "the", "2010s", ",", "the", "alt-country", "genre", "saw", "an", "increase", "in", "its", "critical", "and", "commercial", "popularity", ",", "owing", "to", "the", "success", "of", "artists", "such", "as", "The", "Civil", "Wars", ",", "Chris", "Stapleton", ",", "Sturgill", "Simpson", ",", "Jason", "Isbell", ",", "Lydia", "Loveless", "and", "Margo", "Price", "."], "labels": ["O", "O", "O", "O", "O", "B-music genre", "I-music genre", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-band", "I-band", "I-band", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-band", "I-band", "O", "B-musical artist", "I-musical artist", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, person, location, event, award, album, musical artist, music genre, organization, country, song, band and O.\nSentence: In the 2010s , the alt-country genre saw an increase in its critical and commercial popularity , owing to the success of artists such as The Civil Wars , Chris Stapleton , Sturgill Simpson , Jason Isbell , Lydia Loveless and Margo Price .", "prompt_labels": "In(O) the(O) 2010s(O) ,(O) the(O) alt-country(B-music genre) genre(I-music genre) saw(O) an(O) increase(O) in(O) its(O) critical(O) and(O) commercial(O) popularity(O) ,(O) owing(O) to(O) the(O) success(O) of(O) artists(O) such(O) as(O) The(B-band) Civil(I-band) Wars(I-band) ,(O) Chris(B-musical artist) Stapleton(I-musical artist) ,(O) Sturgill(B-musical artist) Simpson(I-musical artist) ,(O) Jason(B-musical artist) Isbell(I-musical artist) ,(O) Lydia(B-band) Loveless(I-band) and(O) Margo(B-musical artist) Price(I-musical artist) .(O)"}, "label_list": ["musical instrument", "person", "location", "event", "award", "album", "musical artist", "music genre", "organization", "country", "song", "band"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18273, 14473, 11, 1732, 11, 3813, 11, 1567, 11, 10292, 11, 8176, 11, 18273, 10255, 11, 4731, 17779, 11, 7471, 11, 3224, 11, 5609, 11, 7200, 323, 507, 627, 85664, 25, 763, 279, 220, 679, 15, 82, 1174, 279, 4902, 56971, 17779, 5602, 459, 5376, 304, 1202, 9200, 323, 8518, 23354, 1174, 56612, 311, 279, 2450, 315, 13820, 1778, 439, 578, 16803, 15317, 1174, 11517, 63606, 15989, 1174, 800, 5673, 484, 35766, 1174, 18984, 2209, 17696, 1174, 92306, 10919, 1752, 323, 386, 12359, 8650, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "254", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) were(O) the(O) reviews(B-average ratings) like(O) for(O) the(B-title) man(I-title) who(I-title) shot(I-title) liberty(I-title) valance(I-title)", "instance": {"id": "254", "words": ["what", "were", "the", "reviews", "like", "for", "the", "man", "who", "shot", "liberty", "valance"], "labels": ["O", "O", "O", "O", "O", "O", "B-title", "I-title", "I-title", "I-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, actor, review, director, year, genre, title, trailer, plot, character, average ratings, song and O.\nSentence: what were the reviews like for the man who shot liberty valance", "prompt_labels": "what(O) were(O) the(O) reviews(O) like(O) for(O) the(B-title) man(I-title) who(I-title) shot(I-title) liberty(I-title) valance(I-title)"}, "label_list": ["rating", "actor", "review", "director", "year", "genre", "title", "trailer", "plot", "character", "average ratings", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 12360, 11, 3477, 11, 7690, 11, 1060, 11, 17779, 11, 2316, 11, 19809, 11, 7234, 11, 3752, 11, 5578, 18594, 11, 5609, 323, 507, 627, 85664, 25, 1148, 1051, 279, 8544, 1093, 369, 279, 893, 889, 6689, 31220, 1062, 685, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "216", "dataset": "mit-restaurant", "split": "dev", "prediction": "cocktails(B-Amenity) and(I-Amenity) dancing(I-Amenity)", "instance": {"id": "216", "words": ["cocktails", "and", "dancing"], "labels": ["B-Dish", "O", "B-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Hours, Dish, Cuisine, Amenity, Rating, Price, Restaurant Name and O.\nSentence: cocktails and dancing", "prompt_labels": "cocktails(B-Dish) and(O) dancing(B-Amenity)"}, "label_list": ["Location", "Hours", "Dish", "Cuisine", "Amenity", "Rating", "Price", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 30192, 11, 49268, 11, 81961, 11, 3383, 56685, 11, 19767, 11, 8650, 11, 26568, 4076, 323, 507, 627, 85664, 25, 58076, 323, 29066, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2072", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) last(O) science(B-genre) fiction(I-genre) movie(O) that(O) george(B-director) lucas(I-director) directed(O)", "instance": {"id": "2072", "words": ["what", "is", "the", "last", "science", "fiction", "movie", "that", "george", "lucas", "directed"], "labels": ["O", "O", "O", "O", "B-genre", "I-genre", "O", "O", "B-director", "I-director", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, plot, review, rating, trailer, song, year, character, title, average ratings, genre, director and O.\nSentence: what is the last science fiction movie that george lucas directed", "prompt_labels": "what(O) is(O) the(O) last(O) science(B-genre) fiction(I-genre) movie(O) that(O) george(B-director) lucas(I-director) directed(O)"}, "label_list": ["actor", "plot", "review", "rating", "trailer", "song", "year", "character", "title", "average ratings", "genre", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 7234, 11, 3477, 11, 10959, 11, 19809, 11, 5609, 11, 1060, 11, 3752, 11, 2316, 11, 5578, 18594, 11, 17779, 11, 7690, 323, 507, 627, 85664, 25, 1148, 374, 279, 1566, 8198, 17422, 5818, 430, 3980, 6809, 27016, 300, 15910, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1803", "dataset": "mit-movie", "split": "dev", "prediction": "was(O) nikki(B-actor) cox(I-actor) in(O) an(O) animation(B-genre) movie(O)", "instance": {"id": "1803", "words": ["was", "nikki", "cox", "in", "an", "animation", "movie"], "labels": ["O", "B-actor", "I-actor", "O", "O", "B-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, song, actor, title, plot, genre, average ratings, character, review, trailer, year, rating and O.\nSentence: was nikki cox in an animation movie", "prompt_labels": "was(O) nikki(B-actor) cox(I-actor) in(O) an(O) animation(B-genre) movie(O)"}, "label_list": ["director", "song", "actor", "title", "plot", "genre", "average ratings", "character", "review", "trailer", "year", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 5609, 11, 12360, 11, 2316, 11, 7234, 11, 17779, 11, 5578, 18594, 11, 3752, 11, 3477, 11, 19809, 11, 1060, 11, 10959, 323, 507, 627, 85664, 25, 574, 76202, 6780, 1080, 87, 304, 459, 10571, 5818, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "650", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) want(O) to(O) eat(O) some(O) pasta(B-Dish)", "instance": {"id": "650", "words": ["i", "want", "to", "eat", "some", "pasta"], "labels": ["O", "O", "O", "O", "O", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Dish, Price, Location, Cuisine, Restaurant Name, Rating, Hours and O.\nSentence: i want to eat some pasta", "prompt_labels": "i(O) want(O) to(O) eat(O) some(O) pasta(B-Dish)"}, "label_list": ["Amenity", "Dish", "Price", "Location", "Cuisine", "Restaurant Name", "Rating", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 49268, 11, 8650, 11, 10067, 11, 81961, 11, 26568, 4076, 11, 19767, 11, 30192, 323, 507, 627, 85664, 25, 602, 1390, 311, 8343, 1063, 37547, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "330", "dataset": "mit-restaurant", "split": "dev", "prediction": "fast(B-Cuisine) food(I-Cuisine) restaurant(O) in(B-Location) the(I-Location) area(I-Location)", "instance": {"id": "330", "words": ["fast", "food", "restaurant", "in", "the", "area"], "labels": ["B-Cuisine", "I-Cuisine", "O", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Amenity, Restaurant Name, Cuisine, Hours, Location, Dish, Price and O.\nSentence: fast food restaurant in the area", "prompt_labels": "fast(B-Cuisine) food(I-Cuisine) restaurant(O) in(B-Location) the(I-Location) area(I-Location)"}, "label_list": ["Rating", "Amenity", "Restaurant Name", "Cuisine", "Hours", "Location", "Dish", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 3383, 56685, 11, 26568, 4076, 11, 81961, 11, 30192, 11, 10067, 11, 49268, 11, 8650, 323, 507, 627, 85664, 25, 5043, 3691, 10960, 304, 279, 3158, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1012", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) plot(O) of(O) happy(B-title) gilmore(I-title)", "instance": {"id": "1012", "words": ["what", "is", "the", "plot", "of", "happy", "gilmore"], "labels": ["B-plot", "I-plot", "I-plot", "I-plot", "I-plot", "I-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, rating, title, trailer, character, song, average ratings, review, actor, director, plot, year and O.\nSentence: what is the plot of happy gilmore", "prompt_labels": "what(B-plot) is(I-plot) the(I-plot) plot(I-plot) of(I-plot) happy(I-plot) gilmore(I-plot)"}, "label_list": ["genre", "rating", "title", "trailer", "character", "song", "average ratings", "review", "actor", "director", "plot", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 10959, 11, 2316, 11, 19809, 11, 3752, 11, 5609, 11, 5578, 18594, 11, 3477, 11, 12360, 11, 7690, 11, 7234, 11, 1060, 323, 507, 627, 85664, 25, 1148, 374, 279, 7234, 315, 6380, 342, 321, 6518, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "891", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) an(O) expensive(B-Price) restaurant(O) near(B-Location) here(I-Location)", "instance": {"id": "891", "words": ["is", "there", "an", "expensive", "restaurant", "near", "here"], "labels": ["O", "O", "O", "B-Price", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Hours, Rating, Price, Cuisine, Location, Dish, Amenity and O.\nSentence: is there an expensive restaurant near here", "prompt_labels": "is(O) there(O) an(O) expensive(B-Price) restaurant(O) near(B-Location) here(I-Location)"}, "label_list": ["Restaurant Name", "Hours", "Rating", "Price", "Cuisine", "Location", "Dish", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 30192, 11, 19767, 11, 8650, 11, 81961, 11, 10067, 11, 49268, 11, 3383, 56685, 323, 507, 627, 85664, 25, 374, 1070, 459, 11646, 10960, 3221, 1618, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "97", "dataset": "crossner_music", "split": "dev", "prediction": "A(O) more(O) extensive(O) tribute(O) was(O) given(O) later(O) that(O) year(O) in(O) December(O) at(O) the(O) Southbank(B-location) Centre(I-location) in(O) the(O) Queen(B-location) Elizabeth(I-location) Hall(I-location) called(O) The(B-event) Lady(I-event) :(O) A(O) Tribute(O) to(O) Sandy(B-musical artist) Denny(I-musical artist) with(O) a(O) band(O) composed(O) of(O) members(O) of(O) Bellowhead(B-band),(O) the(O) evening(O) featured(O) a(O) mix(O) of(O) young(O) folk(O) acts(O) like(O) Jim(B-musical artist) Moray(I-musical artist) and(O) Lisa(B-musical artist) Knapp(I-musical artist) alongside(O) those(O) that(O) had(O) known(O) and(O) worked(O) with(O) Denny(B-musical artist) such(O) as(O) Dave(B-musical artist) Swarbrick(I-musical artist) and(O) Jerry(B-musical artist) Donahue(I-musical artist).(O)", "instance": {"id": "97", "words": ["A", "more", "extensive", "tribute", "was", "given", "later", "that", "year", "in", "December", "at", "the", "Southbank", "Centre", "in", "the", "Queen", "Elizabeth", "Hall", "called", "The", "Lady", ":", "A", "Tribute", "to", "Sandy", "Denny", "with", "a", "band", "composed", "of", "members", "of", "Bellowhead", ",", "the", "evening", "featured", "a", "mix", "of", "young", "folk", "acts", "like", "Jim", "Moray", "and", "Lisa", "Knapp", "alongside", "those", "that", "had", "known", "and", "worked", "with", "Denny", "such", "as", "Dave", "Swarbrick", "and", "Jerry", "Donahue", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "O", "O", "B-location", "I-location", "I-location", "O", "B-event", "I-event", "I-event", "I-event", "I-event", "I-event", "I-event", "I-event", "O", "O", "O", "O", "O", "O", "O", "B-band", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "O", "O", "O", "O", "O", "O", "O", "B-musical artist", "O", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, event, music genre, location, award, person, song, musical artist, musical instrument, organization, country, album and O.\nSentence: A more extensive tribute was given later that year in December at the Southbank Centre in the Queen Elizabeth Hall called The Lady : A Tribute to Sandy Denny with a band composed of members of Bellowhead , the evening featured a mix of young folk acts like Jim Moray and Lisa Knapp alongside those that had known and worked with Denny such as Dave Swarbrick and Jerry Donahue .", "prompt_labels": "A(O) more(O) extensive(O) tribute(O) was(O) given(O) later(O) that(O) year(O) in(O) December(O) at(O) the(O) Southbank(B-location) Centre(I-location) in(O) the(O) Queen(B-location) Elizabeth(I-location) Hall(I-location) called(O) The(B-event) Lady(I-event) :(I-event) A(I-event) Tribute(I-event) to(I-event) Sandy(I-event) Denny(I-event) with(O) a(O) band(O) composed(O) of(O) members(O) of(O) Bellowhead(B-band) ,(O) the(O) evening(O) featured(O) a(O) mix(O) of(O) young(O) folk(O) acts(O) like(O) Jim(B-musical artist) Moray(I-musical artist) and(O) Lisa(B-musical artist) Knapp(I-musical artist) alongside(O) those(O) that(O) had(O) known(O) and(O) worked(O) with(O) Denny(B-musical artist) such(O) as(O) Dave(B-musical artist) Swarbrick(I-musical artist) and(O) Jerry(B-musical artist) Donahue(I-musical artist) .(O)"}, "label_list": ["band", "event", "music genre", "location", "award", "person", "song", "musical artist", "musical instrument", "organization", "country", "album"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7200, 11, 1567, 11, 4731, 17779, 11, 3813, 11, 10292, 11, 1732, 11, 5609, 11, 18273, 10255, 11, 18273, 14473, 11, 7471, 11, 3224, 11, 8176, 323, 507, 627, 85664, 25, 362, 810, 16781, 35491, 574, 2728, 3010, 430, 1060, 304, 6790, 520, 279, 4987, 17469, 14821, 304, 279, 16657, 21393, 11166, 2663, 578, 21270, 551, 362, 96302, 311, 39485, 423, 18314, 449, 264, 7200, 24306, 315, 3697, 315, 426, 5412, 2025, 1174, 279, 11714, 15109, 264, 6651, 315, 3995, 29036, 14385, 1093, 11641, 8613, 352, 323, 29656, 13934, 680, 16662, 1884, 430, 1047, 3967, 323, 6575, 449, 423, 18314, 1778, 439, 20851, 4593, 277, 70773, 323, 29808, 4418, 1494, 361, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "546", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) am(O) looking(O) for(O) a(O) good(B-Rating) place(O) to(O) eat(O)", "instance": {"id": "546", "words": ["i", "am", "looking", "for", "a", "good", "place", "to", "eat"], "labels": ["O", "O", "O", "O", "O", "B-Rating", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Restaurant Name, Cuisine, Hours, Amenity, Dish, Location, Price and O.\nSentence: i am looking for a good place to eat", "prompt_labels": "i(O) am(O) looking(O) for(O) a(O) good(B-Rating) place(O) to(O) eat(O)"}, "label_list": ["Rating", "Restaurant Name", "Cuisine", "Hours", "Amenity", "Dish", "Location", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 26568, 4076, 11, 81961, 11, 30192, 11, 3383, 56685, 11, 49268, 11, 10067, 11, 8650, 323, 507, 627, 85664, 25, 602, 1097, 3411, 369, 264, 1695, 2035, 311, 8343, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "399", "dataset": "crossner_politics", "split": "dev", "prediction": "The(O) Democratic(O) primary(O) campaign(O) featured(O) State(O) Attorney(O) General(O) Robert(B-politician) Abrams(I-politician),(O) former(O) U.S.(B-country) Congresswoman(O) and(O) 1984(O) vice(O) presidential(O) candidate(O) Geraldine(B-politician) Ferraro(I-politician),(O) Reverend(O) Al(B-politician) Sharpton(I-politician),(O) Congressman(O) Robert(B-politician) J.(I-politician) Mrazek(I-politician),(O) and(O) New(B-location) York(I-location) City(O) Comptroller(O) and(O) former(O) Congresswoman(O) Elizabeth(B-politician) Holtzman(I-politician).(O)", "instance": {"id": "399", "words": ["The", "Democratic", "primary", "campaign", "featured", "State", "Attorney", "General", "Robert", "Abrams", ",", "former", "U.S.", "Congresswoman", "and", "1984", "vice", "presidential", "candidate", "Geraldine", "Ferraro", ",", "Reverend", "Al", "Sharpton", ",", "Congressman", "Robert", "J.", "Mrazek", ",", "and", "New", "York", "City", "Comptroller", "and", "former", "Congresswoman", "Elizabeth", "Holtzman", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-politician", "I-politician", "O", "O", "B-country", "O", "O", "O", "O", "O", "O", "B-politician", "I-politician", "O", "O", "B-person", "I-person", "O", "O", "B-politician", "I-politician", "I-politician", "O", "O", "B-location", "I-location", "I-location", "O", "O", "O", "O", "B-politician", "I-politician", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, election, politician, location, country, person, event, organization and O.\nSentence: The Democratic primary campaign featured State Attorney General Robert Abrams , former U.S. Congresswoman and 1984 vice presidential candidate Geraldine Ferraro , Reverend Al Sharpton , Congressman Robert J. Mrazek , and New York City Comptroller and former Congresswoman Elizabeth Holtzman .", "prompt_labels": "The(O) Democratic(O) primary(O) campaign(O) featured(O) State(O) Attorney(O) General(O) Robert(B-politician) Abrams(I-politician) ,(O) former(O) U.S.(B-country) Congresswoman(O) and(O) 1984(O) vice(O) presidential(O) candidate(O) Geraldine(B-politician) Ferraro(I-politician) ,(O) Reverend(O) Al(B-person) Sharpton(I-person) ,(O) Congressman(O) Robert(B-politician) J.(I-politician) Mrazek(I-politician) ,(O) and(O) New(B-location) York(I-location) City(I-location) Comptroller(O) and(O) former(O) Congresswoman(O) Elizabeth(B-politician) Holtzman(I-politician) .(O)"}, "label_list": ["political party", "election", "politician", "location", "country", "person", "event", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5054, 4717, 11, 6355, 11, 37038, 11, 3813, 11, 3224, 11, 1732, 11, 1567, 11, 7471, 323, 507, 627, 85664, 25, 578, 11650, 6156, 4901, 15109, 3314, 18919, 3331, 8563, 75331, 1174, 4846, 549, 815, 13, 8151, 22803, 323, 220, 3753, 19, 17192, 13621, 9322, 55357, 483, 29042, 17606, 1174, 83279, 408, 1708, 36216, 19271, 1174, 71483, 8563, 622, 13, 386, 8875, 1247, 1174, 323, 1561, 4356, 4409, 1219, 418, 1496, 323, 4846, 8151, 22803, 21393, 60006, 82016, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "514", "dataset": "mit-restaurant", "split": "dev", "prediction": "how(O) far(O) is(O) evergreen(B-Restaurant Name) taiwanese(I-Restaurant Name) restaurant(I-Restaurant Name) from(O) the(O) himalayan(O)", "instance": {"id": "514", "words": ["how", "far", "is", "evergreen", "taiwanese", "restaurant", "from", "the", "himalayan"], "labels": ["O", "O", "O", "B-Restaurant Name", "I-Restaurant Name", "O", "O", "O", "B-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Amenity, Rating, Restaurant Name, Cuisine, Dish, Hours, Price and O.\nSentence: how far is evergreen taiwanese restaurant from the himalayan", "prompt_labels": "how(O) far(O) is(O) evergreen(B-Restaurant Name) taiwanese(I-Restaurant Name) restaurant(O) from(O) the(O) himalayan(B-Location)"}, "label_list": ["Location", "Amenity", "Rating", "Restaurant Name", "Cuisine", "Dish", "Hours", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 3383, 56685, 11, 19767, 11, 26568, 4076, 11, 81961, 11, 49268, 11, 30192, 11, 8650, 323, 507, 627, 85664, 25, 1268, 3117, 374, 3596, 13553, 53637, 16965, 2423, 10960, 505, 279, 1461, 278, 44957, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "195", "dataset": "mit-restaurant", "split": "dev", "prediction": "can(O) you(O) make(O) me(O) a(O) reservation(O) at(O) the(O) cheapest(B-Price) restaurant(O) with(O) valet(B-Amenity) parking(I-Amenity)", "instance": {"id": "195", "words": ["can", "you", "make", "me", "a", "reservation", "at", "the", "cheapest", "restaurant", "with", "valet", "parking"], "labels": ["O", "O", "O", "O", "O", "B-Amenity", "O", "O", "B-Price", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Rating, Dish, Location, Cuisine, Amenity, Restaurant Name, Price and O.\nSentence: can you make me a reservation at the cheapest restaurant with valet parking", "prompt_labels": "can(O) you(O) make(O) me(O) a(O) reservation(B-Amenity) at(O) the(O) cheapest(B-Price) restaurant(O) with(O) valet(B-Amenity) parking(I-Amenity)"}, "label_list": ["Hours", "Rating", "Dish", "Location", "Cuisine", "Amenity", "Restaurant Name", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 19767, 11, 49268, 11, 10067, 11, 81961, 11, 3383, 56685, 11, 26568, 4076, 11, 8650, 323, 507, 627, 85664, 25, 649, 499, 1304, 757, 264, 28767, 520, 279, 43149, 10960, 449, 11412, 1169, 13217, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "358", "dataset": "crossner_politics", "split": "dev", "prediction": "No(O) attempts(O) were(O) made(O) during(O) the(O) 1903(B-election) Australian(I-election) federal(I-election) election(I-election),(O) owing(O) to(O) the(O) House(O) seats(O) split(O) almost(O) evenly(O) between(O) the(O) Protectionist(B-political party) Party(I-political party),(O) the(O) Free(B-political party) Trade(I-political party) Party(I-political party) and(O) the(O) new(O) Labour(B-political party) Party(I-political party).(O)", "instance": {"id": "358", "words": ["No", "attempts", "were", "made", "during", "the", "1903", "Australian", "federal", "election", ",", "owing", "to", "the", "House", "seats", "split", "almost", "evenly", "between", "the", "Protectionist", "Party", ",", "the", "Free", "Trade", "Party", "and", "the", "new", "Labour", "Party", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "O", "O", "O", "B-political party", "I-political party", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, politician, country, person, organization, location, election, event and O.\nSentence: No attempts were made during the 1903 Australian federal election , owing to the House seats split almost evenly between the Protectionist Party , the Free Trade Party and the new Labour Party .", "prompt_labels": "No(O) attempts(O) were(O) made(O) during(O) the(O) 1903(B-election) Australian(I-election) federal(I-election) election(I-election) ,(O) owing(O) to(O) the(O) House(O) seats(O) split(O) almost(O) evenly(O) between(O) the(O) Protectionist(B-political party) Party(I-political party) ,(O) the(O) Free(B-political party) Trade(I-political party) Party(I-political party) and(O) the(O) new(O) Labour(B-political party) Party(I-political party) .(O)"}, "label_list": ["political party", "politician", "country", "person", "organization", "location", "election", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5054, 4717, 11, 37038, 11, 3224, 11, 1732, 11, 7471, 11, 3813, 11, 6355, 11, 1567, 323, 507, 627, 85664, 25, 2360, 13865, 1051, 1903, 2391, 279, 220, 7028, 18, 13673, 6918, 6355, 1174, 56612, 311, 279, 4783, 16712, 6859, 4661, 42147, 1990, 279, 19721, 380, 8722, 1174, 279, 3658, 17657, 8722, 323, 279, 502, 18993, 8722, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1296", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) can(O) i(O) find(O) naugles(B-Restaurant Name)", "instance": {"id": "1296", "words": ["where", "can", "i", "find", "naugles"], "labels": ["O", "O", "O", "O", "B-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Amenity, Dish, Cuisine, Price, Location, Hours, Rating and O.\nSentence: where can i find naugles", "prompt_labels": "where(O) can(O) i(O) find(O) naugles(B-Restaurant Name)"}, "label_list": ["Restaurant Name", "Amenity", "Dish", "Cuisine", "Price", "Location", "Hours", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 3383, 56685, 11, 49268, 11, 81961, 11, 8650, 11, 10067, 11, 30192, 11, 19767, 323, 507, 627, 85664, 25, 1405, 649, 602, 1505, 4415, 773, 645, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "5", "dataset": "crossner_ai", "split": "dev", "prediction": "At(O) Indiana(B-university) University(I-university) in(O) 1999(O) he(O) organized(O) such(O) a(O) symposium(O),(O) and(O) in(O) April(O) 2000(O),(O) he(O) organized(O) a(O) larger(O) symposium(O) entitled(O) Spiritual(B-conference) Robots(I-conference) at(O) Stanford(B-university) University(I-university),(O) in(O) which(O) he(O) moderated(O) a(O) panel(O) consisting(O) of(O) Ray(B-researcher) Kurzweil(I-researcher),(O) Hans(B-researcher) Moravec(I-researcher),(O) Kevin(B-researcher) Kelly(I-researcher),(O) Ralph(B-researcher) Merkle(I-researcher),(O) Bill(B-researcher) Joy(I-researcher),(O) Frank(B-researcher) Drake(I-researcher),(O) John(B-researcher) Henry(I-researcher) Holland(I-researcher) and(O) John(B-researcher) Koza(I-researcher).(O)", "instance": {"id": "5", "words": ["At", "Indiana", "University", "in", "1999", "he", "organized", "such", "a", "symposium", ",", "and", "in", "April", "2000", ",", "he", "organized", "a", "larger", "symposium", "entitled", "Spiritual", "Robots", "at", "Stanford", "University", ",", "in", "which", "he", "moderated", "a", "panel", "consisting", "of", "Ray", "Kurzweil", ",", "Hans", "Moravec", ",", "Kevin", "Kelly", ",", "Ralph", "Merkle", ",", "Bill", "Joy", ",", "Frank", "Drake", ",", "John", "Henry", "Holland", "and", "John", "Koza", "."], "labels": ["O", "B-university", "I-university", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-conference", "I-conference", "O", "B-university", "I-university", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-researcher", "I-researcher", "O", "B-researcher", "I-researcher", "O", "B-researcher", "I-researcher", "O", "B-researcher", "I-researcher", "O", "B-researcher", "I-researcher", "O", "B-researcher", "I-researcher", "O", "B-researcher", "I-researcher", "I-researcher", "O", "B-researcher", "I-researcher", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, field, metric, product, programming language, person, conference, algorithm, task, country, researcher, university, location and O.\nSentence: At Indiana University in 1999 he organized such a symposium , and in April 2000 , he organized a larger symposium entitled Spiritual Robots at Stanford University , in which he moderated a panel consisting of Ray Kurzweil , Hans Moravec , Kevin Kelly , Ralph Merkle , Bill Joy , Frank Drake , John Henry Holland and John Koza .", "prompt_labels": "At(O) Indiana(B-university) University(I-university) in(O) 1999(O) he(O) organized(O) such(O) a(O) symposium(O) ,(O) and(O) in(O) April(O) 2000(O) ,(O) he(O) organized(O) a(O) larger(O) symposium(O) entitled(O) Spiritual(B-conference) Robots(I-conference) at(O) Stanford(B-university) University(I-university) ,(O) in(O) which(O) he(O) moderated(O) a(O) panel(O) consisting(O) of(O) Ray(B-researcher) Kurzweil(I-researcher) ,(O) Hans(B-researcher) Moravec(I-researcher) ,(O) Kevin(B-researcher) Kelly(I-researcher) ,(O) Ralph(B-researcher) Merkle(I-researcher) ,(O) Bill(B-researcher) Joy(I-researcher) ,(O) Frank(B-researcher) Drake(I-researcher) ,(O) John(B-researcher) Henry(I-researcher) Holland(I-researcher) and(O) John(B-researcher) Koza(I-researcher) .(O)"}, "label_list": ["organization", "field", "metric", "product", "programming language", "person", "conference", "algorithm", "task", "country", "researcher", "university", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 2115, 11, 18767, 11, 2027, 11, 15840, 4221, 11, 1732, 11, 10017, 11, 12384, 11, 3465, 11, 3224, 11, 32185, 11, 12374, 11, 3813, 323, 507, 627, 85664, 25, 2468, 22319, 3907, 304, 220, 2550, 24, 568, 17057, 1778, 264, 8045, 54237, 1174, 323, 304, 5936, 220, 1049, 15, 1174, 568, 17057, 264, 8294, 8045, 54237, 20458, 63849, 97146, 520, 31788, 3907, 1174, 304, 902, 568, 87316, 264, 7090, 31706, 315, 13558, 32375, 89, 906, 321, 1174, 25844, 8613, 88423, 1174, 16768, 19178, 1174, 40904, 8930, 23960, 1174, 8766, 28237, 1174, 9454, 42865, 1174, 3842, 18063, 38915, 323, 3842, 30417, 4458, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2418", "dataset": "mit-movie", "split": "dev", "prediction": "blow(B-title) up(I-title)", "instance": {"id": "2418", "words": ["blow", "up"], "labels": ["B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, average ratings, genre, actor, rating, song, plot, trailer, director, title, year, review and O.\nSentence: blow up", "prompt_labels": "blow(B-title) up(I-title)"}, "label_list": ["character", "average ratings", "genre", "actor", "rating", "song", "plot", "trailer", "director", "title", "year", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 5578, 18594, 11, 17779, 11, 12360, 11, 10959, 11, 5609, 11, 7234, 11, 19809, 11, 7690, 11, 2316, 11, 1060, 11, 3477, 323, 507, 627, 85664, 25, 12523, 709, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1189", "dataset": "mit-movie", "split": "dev", "prediction": "do(O) you(O) have(O) colossus(B-title) the(I-title) forbin(I-title) project(I-title)", "instance": {"id": "1189", "words": ["do", "you", "have", "colossus", "the", "forbin", "project"], "labels": ["O", "O", "O", "B-title", "I-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, genre, character, plot, review, director, actor, song, average ratings, title, year, trailer and O.\nSentence: do you have colossus the forbin project", "prompt_labels": "do(O) you(O) have(O) colossus(B-title) the(I-title) forbin(I-title) project(I-title)"}, "label_list": ["rating", "genre", "character", "plot", "review", "director", "actor", "song", "average ratings", "title", "year", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 17779, 11, 3752, 11, 7234, 11, 3477, 11, 7690, 11, 12360, 11, 5609, 11, 5578, 18594, 11, 2316, 11, 1060, 11, 19809, 323, 507, 627, 85664, 25, 656, 499, 617, 1400, 3746, 355, 279, 369, 7006, 2447, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "81", "dataset": "mit-movie", "split": "dev", "prediction": "i(O) would(O) like(O) a(O) list(O) of(O) movies(O) about(O) dancing(B-plot) from(O) the(O) past(B-year) 10(I-year) years(I-year)", "instance": {"id": "81", "words": ["i", "would", "like", "a", "list", "of", "movies", "about", "dancing", "from", "the", "past", "10", "years"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-plot", "O", "O", "B-year", "I-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, character, trailer, actor, plot, average ratings, title, genre, rating, director, review, year and O.\nSentence: i would like a list of movies about dancing from the past 10 years", "prompt_labels": "i(O) would(O) like(O) a(O) list(O) of(O) movies(O) about(O) dancing(B-plot) from(O) the(O) past(B-year) 10(I-year) years(I-year)"}, "label_list": ["song", "character", "trailer", "actor", "plot", "average ratings", "title", "genre", "rating", "director", "review", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 3752, 11, 19809, 11, 12360, 11, 7234, 11, 5578, 18594, 11, 2316, 11, 17779, 11, 10959, 11, 7690, 11, 3477, 11, 1060, 323, 507, 627, 85664, 25, 602, 1053, 1093, 264, 1160, 315, 9698, 922, 29066, 505, 279, 3347, 220, 605, 1667, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "761", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) albertos(B-Restaurant Name) deli(I-Restaurant Name) open(B-Hours) until(I-Hours) 11(I-Hours) pm(I-Hours)", "instance": {"id": "761", "words": ["is", "albertos", "deli", "open", "until", "11", "pm"], "labels": ["O", "B-Restaurant Name", "I-Restaurant Name", "B-Hours", "I-Hours", "I-Hours", "I-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Hours, Cuisine, Dish, Rating, Location, Restaurant Name, Amenity and O.\nSentence: is albertos deli open until 11 pm", "prompt_labels": "is(O) albertos(B-Restaurant Name) deli(I-Restaurant Name) open(B-Hours) until(I-Hours) 11(I-Hours) pm(I-Hours)"}, "label_list": ["Price", "Hours", "Cuisine", "Dish", "Rating", "Location", "Restaurant Name", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 30192, 11, 81961, 11, 49268, 11, 19767, 11, 10067, 11, 26568, 4076, 11, 3383, 56685, 323, 507, 627, 85664, 25, 374, 453, 9339, 437, 1624, 72, 1825, 3156, 220, 806, 9012, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1402", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) is(O) the(O) best(B-Rating) italian(B-Cuisine) food(O) in(B-Location) the(I-Location) city(I-Location)", "instance": {"id": "1402", "words": ["where", "is", "the", "best", "italian", "food", "in", "the", "city"], "labels": ["O", "O", "O", "B-Rating", "B-Cuisine", "O", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Rating, Hours, Location, Amenity, Restaurant Name, Price, Dish and O.\nSentence: where is the best italian food in the city", "prompt_labels": "where(O) is(O) the(O) best(B-Rating) italian(B-Cuisine) food(O) in(B-Location) the(I-Location) city(I-Location)"}, "label_list": ["Cuisine", "Rating", "Hours", "Location", "Amenity", "Restaurant Name", "Price", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 19767, 11, 30192, 11, 10067, 11, 3383, 56685, 11, 26568, 4076, 11, 8650, 11, 49268, 323, 507, 627, 85664, 25, 1405, 374, 279, 1888, 29048, 3691, 304, 279, 3363, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "381", "dataset": "crossner_politics", "split": "dev", "prediction": "He(O) was(O) also(O) elected(O) as(O) a(O) deputy(O) representative(O) to(O) the(O) Parliament(B-organization) of(I-organization) Norway(I-organization) from(O) Telemark(B-location) in(O) 1965(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election),(O) and(O) was(O) subsequently(O) elected(O) to(O) four(O) full(O) terms(O) in(O) 1969(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election),(O) 1973(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election),(O) 1977(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election) and(O) 1981(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election).(O)", "instance": {"id": "381", "words": ["He", "was", "also", "elected", "as", "a", "deputy", "representative", "to", "the", "Parliament", "of", "Norway", "from", "Telemark", "in", "1965", "Norwegian", "parliamentary", "election", ",", "and", "was", "subsequently", "elected", "to", "four", "full", "terms", "in", "1969", "Norwegian", "parliamentary", "election", ",", "1973", "Norwegian", "parliamentary", "election", ",", "1977", "Norwegian", "parliamentary", "election", "and", "1981", "Norwegian", "parliamentary", "election", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "B-location", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, organization, person, political party, election, politician, country, event and O.\nSentence: He was also elected as a deputy representative to the Parliament of Norway from Telemark in 1965 Norwegian parliamentary election , and was subsequently elected to four full terms in 1969 Norwegian parliamentary election , 1973 Norwegian parliamentary election , 1977 Norwegian parliamentary election and 1981 Norwegian parliamentary election .", "prompt_labels": "He(O) was(O) also(O) elected(O) as(O) a(O) deputy(O) representative(O) to(O) the(O) Parliament(B-organization) of(I-organization) Norway(I-organization) from(O) Telemark(B-location) in(O) 1965(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election) ,(O) and(O) was(O) subsequently(O) elected(O) to(O) four(O) full(O) terms(O) in(O) 1969(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election) ,(O) 1973(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election) ,(O) 1977(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election) and(O) 1981(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election) .(O)"}, "label_list": ["location", "organization", "person", "political party", "election", "politician", "country", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 7471, 11, 1732, 11, 5054, 4717, 11, 6355, 11, 37038, 11, 3224, 11, 1567, 323, 507, 627, 85664, 25, 1283, 574, 1101, 16689, 439, 264, 27158, 18740, 311, 279, 20302, 315, 32603, 505, 2722, 3516, 847, 304, 220, 5162, 20, 45721, 44250, 6355, 1174, 323, 574, 28520, 16689, 311, 3116, 2539, 3878, 304, 220, 5162, 24, 45721, 44250, 6355, 1174, 220, 4468, 18, 45721, 44250, 6355, 1174, 220, 4468, 22, 45721, 44250, 6355, 323, 220, 3753, 16, 45721, 44250, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "870", "dataset": "mit-movie", "split": "dev", "prediction": "where(O) was(O) red(B-title) tails(I-title) filmed(O)", "instance": {"id": "870", "words": ["where", "was", "red", "tails", "filmed"], "labels": ["O", "O", "B-title", "I-title", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, year, genre, trailer, review, song, rating, character, director, plot, actor, average ratings and O.\nSentence: where was red tails filmed", "prompt_labels": "where(O) was(O) red(B-title) tails(I-title) filmed(O)"}, "label_list": ["title", "year", "genre", "trailer", "review", "song", "rating", "character", "director", "plot", "actor", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 1060, 11, 17779, 11, 19809, 11, 3477, 11, 5609, 11, 10959, 11, 3752, 11, 7690, 11, 7234, 11, 12360, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1405, 574, 2579, 64614, 42508, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "910", "dataset": "mit-movie", "split": "dev", "prediction": "are(O) there(O) any(O) r(B-rating) rated(I-rating) movies(O) about(O) zombies(B-plot)", "instance": {"id": "910", "words": ["are", "there", "any", "r", "rated", "movies", "about", "zombies"], "labels": ["O", "O", "O", "B-rating", "I-rating", "O", "O", "B-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, song, trailer, genre, title, year, rating, director, review, plot, actor, average ratings and O.\nSentence: are there any r rated movies about zombies", "prompt_labels": "are(O) there(O) any(O) r(B-rating) rated(I-rating) movies(O) about(O) zombies(B-plot)"}, "label_list": ["character", "song", "trailer", "genre", "title", "year", "rating", "director", "review", "plot", "actor", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 5609, 11, 19809, 11, 17779, 11, 2316, 11, 1060, 11, 10959, 11, 7690, 11, 3477, 11, 7234, 11, 12360, 11, 5578, 18594, 323, 507, 627, 85664, 25, 527, 1070, 904, 436, 22359, 9698, 922, 48173, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "298", "dataset": "crossner_science", "split": "dev", "prediction": "Activated(O) DHPR(O)'s(O) open(O),(O) forming(O) a(O) L-type(O) calcium(O) channel(O),(O) that(O) allows(O) Casup2(O) +(O) /(O) sup(O) to(O) pass(O) into(O) the(O) cell(O).(O)", "instance": {"id": "298", "words": ["Activated", "DHPR", "'s", "open", ",", "forming", "a", "L-type", "calcium", "channel", ",", "that", "allows", "Casup2", "+", "/", "sup", "to", "pass", "into", "the", "cell", "."], "labels": ["O", "B-chemical compound", "O", "O", "O", "O", "O", "B-protein", "I-protein", "I-protein", "O", "O", "O", "B-chemical element", "I-chemical element", "I-chemical element", "I-chemical element", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: astronomical object, chemical compound, person, enzyme, location, discipline, chemical element, academic journal, award, scientist, university, event, protein, organization, country, theory and O.\nSentence: Activated DHPR 's open , forming a L-type calcium channel , that allows Casup2 + / sup to pass into the cell .", "prompt_labels": "Activated(O) DHPR(B-chemical compound) 's(O) open(O) ,(O) forming(O) a(O) L-type(B-protein) calcium(I-protein) channel(I-protein) ,(O) that(O) allows(O) Casup2(B-chemical element) +(I-chemical element) /(I-chemical element) sup(I-chemical element) to(O) pass(O) into(O) the(O) cell(O) .(O)"}, "label_list": ["astronomical object", "chemical compound", "person", "enzyme", "location", "discipline", "chemical element", "academic journal", "award", "scientist", "university", "event", "protein", "organization", "country", "theory"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 87283, 1665, 11, 11742, 24549, 11, 1732, 11, 49242, 11, 3813, 11, 26434, 11, 11742, 2449, 11, 14584, 8486, 11, 10292, 11, 28568, 11, 12374, 11, 1567, 11, 13128, 11, 7471, 11, 3224, 11, 10334, 323, 507, 627, 85664, 25, 15050, 660, 33887, 6616, 364, 82, 1825, 1174, 30164, 264, 445, 10827, 35719, 5613, 1174, 430, 6276, 11301, 455, 17, 489, 611, 1043, 311, 1522, 1139, 279, 2849, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "410", "dataset": "mit-movie", "split": "dev", "prediction": "whats(O) a(O) film(O) based(O) on(O) a(O) best(B-plot) selling(I-plot) contemporary(I-plot) novel(I-plot)", "instance": {"id": "410", "words": ["whats", "a", "film", "based", "on", "a", "best", "selling", "contemporary", "novel"], "labels": ["O", "O", "O", "O", "O", "O", "B-plot", "I-plot", "I-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, title, year, genre, review, trailer, average ratings, actor, director, plot, song, character and O.\nSentence: whats a film based on a best selling contemporary novel", "prompt_labels": "whats(O) a(O) film(O) based(O) on(O) a(O) best(B-plot) selling(I-plot) contemporary(I-plot) novel(I-plot)"}, "label_list": ["rating", "title", "year", "genre", "review", "trailer", "average ratings", "actor", "director", "plot", "song", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 2316, 11, 1060, 11, 17779, 11, 3477, 11, 19809, 11, 5578, 18594, 11, 12360, 11, 7690, 11, 7234, 11, 5609, 11, 3752, 323, 507, 627, 85664, 25, 41209, 264, 4632, 3196, 389, 264, 1888, 11486, 19225, 11775, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "438", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) was(O) the(O) name(O) of(O) harrison(B-character) fords(I-character) character(O) in(O) star(B-title) wars(I-title)", "instance": {"id": "438", "words": ["what", "was", "the", "name", "of", "harrison", "fords", "character", "in", "star", "wars"], "labels": ["O", "O", "O", "O", "O", "B-actor", "I-actor", "O", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, review, year, song, actor, genre, average ratings, plot, trailer, title, character, director and O.\nSentence: what was the name of harrison fords character in star wars", "prompt_labels": "what(O) was(O) the(O) name(O) of(O) harrison(B-actor) fords(I-actor) character(O) in(O) star(B-title) wars(I-title)"}, "label_list": ["rating", "review", "year", "song", "actor", "genre", "average ratings", "plot", "trailer", "title", "character", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 3477, 11, 1060, 11, 5609, 11, 12360, 11, 17779, 11, 5578, 18594, 11, 7234, 11, 19809, 11, 2316, 11, 3752, 11, 7690, 323, 507, 627, 85664, 25, 1148, 574, 279, 836, 315, 305, 51103, 369, 5469, 3752, 304, 6917, 25981, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "376", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) uma(B-title) thurman(I-title) movies(O)", "instance": {"id": "376", "words": ["list", "uma", "thurman", "movies"], "labels": ["O", "B-actor", "I-actor", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, genre, trailer, year, song, average ratings, director, rating, actor, character, title, plot and O.\nSentence: list uma thurman movies", "prompt_labels": "list(O) uma(B-actor) thurman(I-actor) movies(O)"}, "label_list": ["review", "genre", "trailer", "year", "song", "average ratings", "director", "rating", "actor", "character", "title", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 17779, 11, 19809, 11, 1060, 11, 5609, 11, 5578, 18594, 11, 7690, 11, 10959, 11, 12360, 11, 3752, 11, 2316, 11, 7234, 323, 507, 627, 85664, 25, 1160, 10832, 270, 324, 1543, 9698, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1017", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) movies(O) based(O) on(O) tv(B-genre) shows(I-genre)", "instance": {"id": "1017", "words": ["show", "me", "movies", "based", "on", "tv", "shows"], "labels": ["O", "O", "O", "B-plot", "I-plot", "I-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, character, average ratings, rating, title, trailer, director, genre, year, plot, song, actor and O.\nSentence: show me movies based on tv shows", "prompt_labels": "show(O) me(O) movies(O) based(B-plot) on(I-plot) tv(I-plot) shows(I-plot)"}, "label_list": ["review", "character", "average ratings", "rating", "title", "trailer", "director", "genre", "year", "plot", "song", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 3752, 11, 5578, 18594, 11, 10959, 11, 2316, 11, 19809, 11, 7690, 11, 17779, 11, 1060, 11, 7234, 11, 5609, 11, 12360, 323, 507, 627, 85664, 25, 1501, 757, 9698, 3196, 389, 11333, 5039, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1625", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) a(O) movie(O) about(O) family(B-genre) betrayal(I-genre) directed(O) by(O) arthur(B-director) marks(I-director)", "instance": {"id": "1625", "words": ["list", "a", "movie", "about", "family", "betrayal", "directed", "by", "arthur", "marks"], "labels": ["O", "O", "O", "O", "B-plot", "I-plot", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, title, director, character, trailer, rating, plot, year, genre, review, actor, average ratings and O.\nSentence: list a movie about family betrayal directed by arthur marks", "prompt_labels": "list(O) a(O) movie(O) about(O) family(B-plot) betrayal(I-plot) directed(O) by(O) arthur(B-director) marks(I-director)"}, "label_list": ["song", "title", "director", "character", "trailer", "rating", "plot", "year", "genre", "review", "actor", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 2316, 11, 7690, 11, 3752, 11, 19809, 11, 10959, 11, 7234, 11, 1060, 11, 17779, 11, 3477, 11, 12360, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1160, 264, 5818, 922, 3070, 68376, 15910, 555, 802, 22173, 15785, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2229", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) was(O) the(O) name(O) of(O) the(O) r(B-rating) rated(O) documentary(B-genre) that(O) was(O) received(B-average ratings) well(I-average ratings) and(O) starred(O) angelina(B-actor) jolie(I-actor)", "instance": {"id": "2229", "words": ["what", "was", "the", "name", "of", "the", "r", "rated", "documentary", "that", "was", "received", "well", "and", "starred", "angelina", "jolie"], "labels": ["O", "O", "O", "O", "O", "O", "B-rating", "O", "B-genre", "O", "O", "B-average ratings", "I-average ratings", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, rating, trailer, character, genre, title, plot, review, song, average ratings, director, year and O.\nSentence: what was the name of the r rated documentary that was received well and starred angelina jolie", "prompt_labels": "what(O) was(O) the(O) name(O) of(O) the(O) r(B-rating) rated(O) documentary(B-genre) that(O) was(O) received(B-average ratings) well(I-average ratings) and(O) starred(O) angelina(B-actor) jolie(I-actor)"}, "label_list": ["actor", "rating", "trailer", "character", "genre", "title", "plot", "review", "song", "average ratings", "director", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 10959, 11, 19809, 11, 3752, 11, 17779, 11, 2316, 11, 7234, 11, 3477, 11, 5609, 11, 5578, 18594, 11, 7690, 11, 1060, 323, 507, 627, 85664, 25, 1148, 574, 279, 836, 315, 279, 436, 22359, 25999, 430, 574, 4036, 1664, 323, 59335, 34426, 2259, 503, 62117, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "282", "dataset": "crossner_science", "split": "dev", "prediction": "From(O) 1822(O) to(O) 1826(O),(O) he(O) studied(O) at(O) the(O) University(B-university) of(I-university) Paris(I-university) and(O) at(O) the(O) Coll\u00e8ge(B-university) de(I-university) France(I-university) in(O) Paris(B-location),(O) France(B-country).(O)", "instance": {"id": "282", "words": ["From", "1822", "to", "1826", ",", "he", "studied", "at", "the", "University", "of", "Paris", "and", "at", "the", "Coll\u00e8ge", "de", "France", "in", "Paris", ",", "France", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-university", "I-university", "I-university", "O", "O", "O", "B-university", "I-university", "I-university", "O", "B-location", "O", "B-country", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: theory, astronomical object, event, person, chemical element, academic journal, organization, scientist, enzyme, award, chemical compound, country, discipline, university, protein, location and O.\nSentence: From 1822 to 1826 , he studied at the University of Paris and at the Coll\u00e8ge de France in Paris , France .", "prompt_labels": "From(O) 1822(O) to(O) 1826(O) ,(O) he(O) studied(O) at(O) the(O) University(B-university) of(I-university) Paris(I-university) and(O) at(O) the(O) Coll\u00e8ge(B-university) de(I-university) France(I-university) in(O) Paris(B-location) ,(O) France(B-country) .(O)"}, "label_list": ["theory", "astronomical object", "event", "person", "chemical element", "academic journal", "organization", "scientist", "enzyme", "award", "chemical compound", "country", "discipline", "university", "protein", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10334, 11, 87283, 1665, 11, 1567, 11, 1732, 11, 11742, 2449, 11, 14584, 8486, 11, 7471, 11, 28568, 11, 49242, 11, 10292, 11, 11742, 24549, 11, 3224, 11, 26434, 11, 12374, 11, 13128, 11, 3813, 323, 507, 627, 85664, 25, 5659, 220, 10828, 17, 311, 220, 10828, 21, 1174, 568, 20041, 520, 279, 3907, 315, 12366, 323, 520, 279, 13201, 73899, 409, 9822, 304, 12366, 1174, 9822, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "23", "dataset": "crossner_literature", "split": "dev", "prediction": "The(O) remainder(O) were(O) distributed(O) off(O) a(O) ferry(O) near(O) Hong(B-location) Kong(I-location),(O) the(O) ferry(O) between(O) Hainan(B-location) Island(I-location) and(O) the(O) Chinese(O) mainland(O),(O) a(O) ferry(O) in(O) Vietnam(B-country),(O) White(B-location)'s(I-location) Ferry(I-location) on(O) the(O) Potomac(B-location) River(I-location) in(O) Virginia(B-location) on(O) Father(O)'s(O) Day(O) 2007(O),(O) and(O) on(O) author(O) H.(B-writer) P.(I-writer) Lovecraft(I-writer) '(O) s(O) grave(O) in(O) Providence(B-location),(O) Rhode(B-location) Island(I-location) on(O) December(O) 17(O),(O) 2005(O).(O)", "instance": {"id": "23", "words": ["The", "remainder", "were", "distributed", "off", "a", "ferry", "near", "Hong", "Kong", ",", "the", "ferry", "between", "Hainan", "Island", "and", "the", "Chinese", "mainland", ",", "a", "ferry", "in", "Vietnam", ",", "White", "'s", "Ferry", "on", "the", "Potomac", "River", "in", "Virginia", "on", "Father", "'s", "Day", "2007", ",", "and", "on", "author", "H.", "P.", "Lovecraft", "'", "s", "grave", "in", "Providence", ",", "Rhode", "Island", "on", "December", "17", ",", "2005", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "O", "O", "O", "O", "B-location", "I-location", "O", "O", "B-location", "I-location", "O", "O", "O", "O", "B-country", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "O", "B-location", "O", "B-event", "I-event", "I-event", "O", "O", "O", "O", "O", "B-writer", "I-writer", "I-writer", "O", "O", "O", "O", "B-location", "O", "B-location", "I-location", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, event, organization, person, award, literary genre, location, writer, country, book, poem and O.\nSentence: The remainder were distributed off a ferry near Hong Kong , the ferry between Hainan Island and the Chinese mainland , a ferry in Vietnam , White 's Ferry on the Potomac River in Virginia on Father 's Day 2007 , and on author H. P. Lovecraft ' s grave in Providence , Rhode Island on December 17 , 2005 .", "prompt_labels": "The(O) remainder(O) were(O) distributed(O) off(O) a(O) ferry(O) near(O) Hong(B-location) Kong(I-location) ,(O) the(O) ferry(O) between(O) Hainan(B-location) Island(I-location) and(O) the(O) Chinese(B-location) mainland(I-location) ,(O) a(O) ferry(O) in(O) Vietnam(B-country) ,(O) White(O) 's(O) Ferry(O) on(O) the(O) Potomac(B-location) River(I-location) in(O) Virginia(B-location) on(O) Father(B-event) 's(I-event) Day(I-event) 2007(O) ,(O) and(O) on(O) author(O) H.(B-writer) P.(I-writer) Lovecraft(I-writer) '(O) s(O) grave(O) in(O) Providence(B-location) ,(O) Rhode(B-location) Island(I-location) on(O) December(O) 17(O) ,(O) 2005(O) .(O)"}, "label_list": ["magazine", "event", "organization", "person", "award", "literary genre", "location", "writer", "country", "book", "poem"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 14756, 11, 1567, 11, 7471, 11, 1732, 11, 10292, 11, 32465, 17779, 11, 3813, 11, 7061, 11, 3224, 11, 2363, 11, 33894, 323, 507, 627, 85664, 25, 578, 27410, 1051, 4332, 1022, 264, 52650, 3221, 19730, 18711, 1174, 279, 52650, 1990, 473, 467, 276, 10951, 323, 279, 8620, 51115, 1174, 264, 52650, 304, 23315, 1174, 5929, 364, 82, 79549, 389, 279, 14020, 316, 582, 11188, 304, 13286, 389, 20941, 364, 82, 6187, 220, 1049, 22, 1174, 323, 389, 3229, 473, 13, 393, 13, 10919, 7868, 364, 274, 25165, 304, 58941, 1174, 50981, 10951, 389, 6790, 220, 1114, 1174, 220, 1049, 20, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1126", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) is(O) the(O) closest(B-Location) fast(B-Cuisine) food(I-Cuisine) to(O) me(O)", "instance": {"id": "1126", "words": ["what", "is", "the", "closest", "fast", "food", "to", "me"], "labels": ["O", "O", "O", "B-Location", "B-Cuisine", "I-Cuisine", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Price, Location, Cuisine, Restaurant Name, Hours, Amenity, Dish and O.\nSentence: what is the closest fast food to me", "prompt_labels": "what(O) is(O) the(O) closest(B-Location) fast(B-Cuisine) food(I-Cuisine) to(O) me(O)"}, "label_list": ["Rating", "Price", "Location", "Cuisine", "Restaurant Name", "Hours", "Amenity", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 8650, 11, 10067, 11, 81961, 11, 26568, 4076, 11, 30192, 11, 3383, 56685, 11, 49268, 323, 507, 627, 85664, 25, 1148, 374, 279, 18585, 5043, 3691, 311, 757, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "152", "dataset": "crossner_ai", "split": "dev", "prediction": "An(O) example(O) of(O) non-linear(B-algorithm) normalization(I-algorithm) is(O) when(O) the(O) normalization(O) follows(O) a(O) sigmoid(B-algorithm) function(I-algorithm),(O) in(O) that(O) case(O),(O) the(O) normalized(O) image(O) is(O) computed(O) according(O) to(O) the(O) formula(O)", "instance": {"id": "152", "words": ["An", "example", "of", "non-linear", "normalization", "is", "when", "the", "normalization", "follows", "a", "sigmoid", "function", ",", "in", "that", "case", ",", "the", "normalized", "image", "is", "computed", "according", "to", "the", "formula"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-algorithm", "I-algorithm", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, researcher, task, conference, location, university, product, algorithm, programming language, person, metric, country, organization and O.\nSentence: An example of non-linear normalization is when the normalization follows a sigmoid function , in that case , the normalized image is computed according to the formula", "prompt_labels": "An(O) example(O) of(O) non-linear(O) normalization(O) is(O) when(O) the(O) normalization(O) follows(O) a(O) sigmoid(B-algorithm) function(I-algorithm) ,(O) in(O) that(O) case(O) ,(O) the(O) normalized(O) image(O) is(O) computed(O) according(O) to(O) the(O) formula(O)"}, "label_list": ["field", "researcher", "task", "conference", "location", "university", "product", "algorithm", "programming language", "person", "metric", "country", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2115, 11, 32185, 11, 3465, 11, 10017, 11, 3813, 11, 12374, 11, 2027, 11, 12384, 11, 15840, 4221, 11, 1732, 11, 18767, 11, 3224, 11, 7471, 323, 507, 627, 85664, 25, 1556, 3187, 315, 2536, 62399, 49823, 374, 994, 279, 49823, 11263, 264, 65990, 734, 1174, 304, 430, 1162, 1174, 279, 30510, 2217, 374, 25157, 4184, 311, 279, 15150, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "823", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) a(O) jacks(B-Restaurant Name) restaurant(I-Restaurant Name) around(B-Location) here(I-Location)", "instance": {"id": "823", "words": ["is", "there", "a", "jacks", "restaurant", "around", "here"], "labels": ["O", "O", "O", "B-Restaurant Name", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Restaurant Name, Hours, Dish, Price, Amenity, Cuisine, Location and O.\nSentence: is there a jacks restaurant around here", "prompt_labels": "is(O) there(O) a(O) jacks(B-Restaurant Name) restaurant(O) around(B-Location) here(I-Location)"}, "label_list": ["Rating", "Restaurant Name", "Hours", "Dish", "Price", "Amenity", "Cuisine", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 26568, 4076, 11, 30192, 11, 49268, 11, 8650, 11, 3383, 56685, 11, 81961, 11, 10067, 323, 507, 627, 85664, 25, 374, 1070, 264, 503, 7977, 10960, 2212, 1618, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "448", "dataset": "crossner_politics", "split": "dev", "prediction": "The(O) film(O) stars(O) Ramki(B-actor) and(O) Sanghavi(B-actor),(O) with(O) Manivannan(B-actor),(O) Raadhika(B-actor),(O) Vadivelu(B-actor) and(O) Charle(B-actor) in(O) pivotal(O) roles(O).(O)", "instance": {"id": "448", "words": ["The", "film", "stars", "Ramki", "and", "Sanghavi", ",", "with", "Manivannan", ",", "Raadhika", ",", "Vadivelu", "and", "Charle", "in", "pivotal", "roles", "."], "labels": ["O", "O", "O", "B-person", "O", "B-person", "O", "O", "B-person", "O", "B-person", "O", "B-person", "O", "B-person", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, organization, politician, person, political party, election, event, country and O.\nSentence: The film stars Ramki and Sanghavi , with Manivannan , Raadhika , Vadivelu and Charle in pivotal roles .", "prompt_labels": "The(O) film(O) stars(O) Ramki(B-person) and(O) Sanghavi(B-person) ,(O) with(O) Manivannan(B-person) ,(O) Raadhika(B-person) ,(O) Vadivelu(B-person) and(O) Charle(B-person) in(O) pivotal(O) roles(O) .(O)"}, "label_list": ["location", "organization", "politician", "person", "political party", "election", "event", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 7471, 11, 37038, 11, 1732, 11, 5054, 4717, 11, 6355, 11, 1567, 11, 3224, 323, 507, 627, 85664, 25, 578, 4632, 9958, 15504, 6780, 323, 52022, 71, 6321, 1174, 449, 2418, 344, 1036, 276, 1174, 18989, 52687, 11755, 1174, 93212, 21169, 84, 323, 4969, 273, 304, 60850, 13073, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "339", "dataset": "crossner_music", "split": "dev", "prediction": "Lengthy(O) sleeve(O) notes(O) are(O) included(O) with(O) the(O) albums(O) Black(B-album) Seeds(I-album) of(I-album) Vengeance(I-album),(O) In(B-album) Their(I-album) Darkened(I-album) Shrines(I-album),(O) Annihilation(B-album) of(I-album) the(I-album) Wicked(I-album),(O) Those(B-album) Whom(I-album) the(I-album) Gods(I-album) Detest(I-album),(O) At(B-album) the(I-album) Gate(I-album) of(I-album) Sethu(I-album),(O) and(O) What(B-album) Should(I-album) Not(I-album) Be(I-album) Unearthed(I-album),(O) explaining(O) the(O) inspiration(O) or(O) source(O) for(O) the(O) lyrics(O) of(O) each(O) song(O).(O)", "instance": {"id": "339", "words": ["Lengthy", "sleeve", "notes", "are", "included", "with", "the", "albums", "Black", "Seeds", "of", "Vengeance", ",", "In", "Their", "Darkened", "Shrines", ",", "Annihilation", "of", "the", "Wicked", ",", "Those", "Whom", "the", "Gods", "Detest", ",", "At", "the", "Gate", "of", "Sethu", ",", "and", "What", "Should", "Not", "Be", "Unearthed", ",", "explaining", "the", "inspiration", "or", "source", "for", "the", "lyrics", "of", "each", "song", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-album", "I-album", "I-album", "I-album", "O", "B-album", "I-album", "I-album", "I-album", "O", "B-album", "I-album", "I-album", "I-album", "O", "B-album", "I-album", "I-album", "I-album", "I-album", "O", "B-album", "I-album", "I-album", "I-album", "I-album", "O", "O", "B-album", "I-album", "I-album", "I-album", "I-album", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, song, award, organization, person, location, band, album, event, country, music genre, musical instrument and O.\nSentence: Lengthy sleeve notes are included with the albums Black Seeds of Vengeance , In Their Darkened Shrines , Annihilation of the Wicked , Those Whom the Gods Detest , At the Gate of Sethu , and What Should Not Be Unearthed , explaining the inspiration or source for the lyrics of each song .", "prompt_labels": "Lengthy(O) sleeve(O) notes(O) are(O) included(O) with(O) the(O) albums(O) Black(B-album) Seeds(I-album) of(I-album) Vengeance(I-album) ,(O) In(B-album) Their(I-album) Darkened(I-album) Shrines(I-album) ,(O) Annihilation(B-album) of(I-album) the(I-album) Wicked(I-album) ,(O) Those(B-album) Whom(I-album) the(I-album) Gods(I-album) Detest(I-album) ,(O) At(B-album) the(I-album) Gate(I-album) of(I-album) Sethu(I-album) ,(O) and(O) What(B-album) Should(I-album) Not(I-album) Be(I-album) Unearthed(I-album) ,(O) explaining(O) the(O) inspiration(O) or(O) source(O) for(O) the(O) lyrics(O) of(O) each(O) song(O) .(O)"}, "label_list": ["musical artist", "song", "award", "organization", "person", "location", "band", "album", "event", "country", "music genre", "musical instrument"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18273, 10255, 11, 5609, 11, 10292, 11, 7471, 11, 1732, 11, 3813, 11, 7200, 11, 8176, 11, 1567, 11, 3224, 11, 4731, 17779, 11, 18273, 14473, 323, 507, 627, 85664, 25, 17736, 88, 37253, 8554, 527, 5343, 449, 279, 28785, 5348, 74089, 315, 650, 56479, 1174, 763, 11205, 12538, 6901, 95838, 1572, 1174, 9489, 92341, 315, 279, 468, 19011, 1174, 13266, 1254, 316, 279, 44875, 16828, 478, 1174, 2468, 279, 30343, 315, 45318, 84, 1174, 323, 3639, 12540, 2876, 2893, 1252, 28641, 291, 1174, 26073, 279, 20343, 477, 2592, 369, 279, 24142, 315, 1855, 5609, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1389", "dataset": "mit-movie", "split": "dev", "prediction": "im(O) trying(O) to(O) find(O) a(O) very(B-average ratings) good(I-average ratings) funny(B-genre) movie(O) that(O) was(O) filmed(O) in(O) 1940(B-year) do(O) you(O) have(O) it(O)", "instance": {"id": "1389", "words": ["im", "trying", "to", "find", "a", "very", "good", "funny", "movie", "that", "was", "filmed", "in", "1940", "do", "you", "have", "it"], "labels": ["O", "O", "O", "O", "O", "B-average ratings", "I-average ratings", "B-genre", "O", "O", "O", "O", "O", "B-year", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, actor, rating, title, trailer, director, year, song, genre, character, review, average ratings and O.\nSentence: im trying to find a very good funny movie that was filmed in 1940 do you have it", "prompt_labels": "im(O) trying(O) to(O) find(O) a(O) very(B-average ratings) good(I-average ratings) funny(B-genre) movie(O) that(O) was(O) filmed(O) in(O) 1940(B-year) do(O) you(O) have(O) it(O)"}, "label_list": ["plot", "actor", "rating", "title", "trailer", "director", "year", "song", "genre", "character", "review", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 12360, 11, 10959, 11, 2316, 11, 19809, 11, 7690, 11, 1060, 11, 5609, 11, 17779, 11, 3752, 11, 3477, 11, 5578, 18594, 323, 507, 627, 85664, 25, 737, 4560, 311, 1505, 264, 1633, 1695, 15526, 5818, 430, 574, 42508, 304, 220, 6393, 15, 656, 499, 617, 433, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "283", "dataset": "crossner_politics", "split": "dev", "prediction": "Shaw(B-politician) himself(O) ran(O) for(O) the(O) CCF(B-political party) in(O) the(O) 1945(B-election) Canadian(I-election) federal(I-election) election(I-election) and(O) 1949(B-election) Canadian(I-election) federal(I-election) election(I-election) federal(O) elections(O) and(O) in(O) a(O) federal(O) byelection(O) in(O) 1948(O),(O) and(O) for(O) the(O) NDP(B-political party) in(O) the(O) 1974(B-election) Canadian(I-election) federal(I-election) election(I-election) federal(O) elections(O) and(O) in(O) a(O) federal(O) byelection(O) in(O) 1948(O),(O) and(O) for(O) the(O) House(B-organization) of(I-organization) Commons(I-organization) of(I-organization) Canada(I-organization).(O)", "instance": {"id": "283", "words": ["Shaw", "himself", "ran", "for", "the", "CCF", "in", "the", "1945", "Canadian", "federal", "election", "and", "1949", "Canadian", "federal", "election", "federal", "elections", "and", "in", "a", "federal", "byelection", "in", "1948", ",", "and", "for", "the", "NDP", "in", "the", "1974", "Canadian", "federal", "election", "federal", "election", ",", "but", "was", "never", "elected", "to", "the", "House", "of", "Commons", "of", "Canada", "."], "labels": ["B-politician", "O", "O", "O", "O", "B-organization", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, country, event, politician, person, election, political party, location and O.\nSentence: Shaw himself ran for the CCF in the 1945 Canadian federal election and 1949 Canadian federal election federal elections and in a federal byelection in 1948 , and for the NDP in the 1974 Canadian federal election federal election , but was never elected to the House of Commons of Canada .", "prompt_labels": "Shaw(B-politician) himself(O) ran(O) for(O) the(O) CCF(B-organization) in(O) the(O) 1945(B-election) Canadian(I-election) federal(I-election) election(I-election) and(O) 1949(B-election) Canadian(I-election) federal(I-election) election(I-election) federal(O) elections(O) and(O) in(O) a(O) federal(O) byelection(O) in(O) 1948(O) ,(O) and(O) for(O) the(O) NDP(B-political party) in(O) the(O) 1974(B-election) Canadian(I-election) federal(I-election) election(I-election) federal(O) election(O) ,(O) but(O) was(O) never(O) elected(O) to(O) the(O) House(B-organization) of(I-organization) Commons(I-organization) of(I-organization) Canada(I-organization) .(O)"}, "label_list": ["organization", "country", "event", "politician", "person", "election", "political party", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 3224, 11, 1567, 11, 37038, 11, 1732, 11, 6355, 11, 5054, 4717, 11, 3813, 323, 507, 627, 85664, 25, 36285, 5678, 10837, 369, 279, 356, 9847, 304, 279, 220, 6393, 20, 12152, 6918, 6355, 323, 220, 6393, 24, 12152, 6918, 6355, 6918, 16374, 323, 304, 264, 6918, 54141, 1191, 304, 220, 6393, 23, 1174, 323, 369, 279, 54750, 304, 279, 220, 4468, 19, 12152, 6918, 6355, 6918, 6355, 1174, 719, 574, 2646, 16689, 311, 279, 4783, 315, 26667, 315, 7008, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1346", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) can(O) i(O) get(O) starbucks(B-Restaurant Name) around(B-Location) me(I-Location)", "instance": {"id": "1346", "words": ["where", "can", "i", "get", "starbucks", "around", "me"], "labels": ["O", "O", "O", "O", "B-Restaurant Name", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Hours, Restaurant Name, Dish, Rating, Amenity, Price, Location and O.\nSentence: where can i get starbucks around me", "prompt_labels": "where(O) can(O) i(O) get(O) starbucks(B-Restaurant Name) around(B-Location) me(I-Location)"}, "label_list": ["Cuisine", "Hours", "Restaurant Name", "Dish", "Rating", "Amenity", "Price", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 30192, 11, 26568, 4076, 11, 49268, 11, 19767, 11, 3383, 56685, 11, 8650, 11, 10067, 323, 507, 627, 85664, 25, 1405, 649, 602, 636, 6917, 40888, 2212, 757, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "320", "dataset": "crossner_science", "split": "dev", "prediction": "The(O) society(O) has(O) published(O) articles(O) in(O) journals(O) such(O) as(O) Acta(B-academic journal) Chemica(I-academic journal) Scandinavia(I-academic journal) and(O),(O) since(O) 2000(O),(O) British(O) journals(O) including(O) Dalton(B-academic journal) Transactions(I-academic journal) ((O) Inorganic(B-discipline) Chemistry(I-discipline) )(O) and(O) Perkin(B-academic journal) Transactions(I-academic journal) ((O) Organic(B-discipline) Chemistry(I-discipline) )(O).(O)", "instance": {"id": "320", "words": ["The", "society", "has", "published", "articles", "in", "journals", "such", "as", "Acta", "Chemica", "Scandinavia", "and", ",", "since", "2000", ",", "British", "journals", "including", "Dalton", "Transactions", "(", "Inorganic", "Chemistry", ")", "and", "Perkin", "Transactions", "(", "Organic", "Chemistry", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-academic journal", "I-academic journal", "I-academic journal", "O", "O", "O", "O", "O", "O", "O", "O", "B-academic journal", "I-academic journal", "O", "B-discipline", "I-discipline", "O", "O", "B-academic journal", "I-academic journal", "O", "B-discipline", "I-discipline", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: academic journal, chemical element, university, enzyme, astronomical object, person, discipline, chemical compound, organization, theory, award, protein, location, scientist, country, event and O.\nSentence: The society has published articles in journals such as Acta Chemica Scandinavia and , since 2000 , British journals including Dalton Transactions ( Inorganic Chemistry ) and Perkin Transactions ( Organic Chemistry ) .", "prompt_labels": "The(O) society(O) has(O) published(O) articles(O) in(O) journals(O) such(O) as(O) Acta(B-academic journal) Chemica(I-academic journal) Scandinavia(I-academic journal) and(O) ,(O) since(O) 2000(O) ,(O) British(O) journals(O) including(O) Dalton(B-academic journal) Transactions(I-academic journal) ((O) Inorganic(B-discipline) Chemistry(I-discipline) )(O) and(O) Perkin(B-academic journal) Transactions(I-academic journal) ((O) Organic(B-discipline) Chemistry(I-discipline) )(O) .(O)"}, "label_list": ["academic journal", "chemical element", "university", "enzyme", "astronomical object", "person", "discipline", "chemical compound", "organization", "theory", "award", "protein", "location", "scientist", "country", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 14584, 8486, 11, 11742, 2449, 11, 12374, 11, 49242, 11, 87283, 1665, 11, 1732, 11, 26434, 11, 11742, 24549, 11, 7471, 11, 10334, 11, 10292, 11, 13128, 11, 3813, 11, 28568, 11, 3224, 11, 1567, 323, 507, 627, 85664, 25, 578, 8396, 706, 4756, 9908, 304, 42780, 1778, 439, 3298, 64, 19531, 3074, 60280, 35102, 323, 1174, 2533, 220, 1049, 15, 1174, 8013, 42780, 2737, 72554, 56385, 320, 763, 61694, 42846, 883, 323, 3700, 8148, 56385, 320, 44037, 42846, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "108", "dataset": "crossner_ai", "split": "dev", "prediction": "In(O) 1857(O),(O) at(O) the(O) request(O) of(O) the(O) Tokugawa(O) Shogunate(O),(O) a(O) group(O) of(O) Dutch(O) engineers(O) began(O) work(O) on(O) the(O) Nagasaki(B-location) Yotetsusho(I-location),(O) a(O) modern(O),(O) Western-style(O) foundry(O) and(O) shipyard(O) near(O) the(O) Dutch(O) settlement(O) of(O) Dejima(B-location),(O) at(O) Nagasaki(B-location).(O)", "instance": {"id": "108", "words": ["In", "1857", ",", "at", "the", "request", "of", "the", "Tokugawa", "Shogunate", ",", "a", "group", "of", "Dutch", "engineers", "began", "work", "on", "the", "Nagasaki", "Yotetsusho", ",", "a", "modern", ",", "Western-style", "foundry", "and", "shipyard", "near", "the", "Dutch", "settlement", "of", "Dejima", ",", "at", "Nagasaki", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-country", "I-country", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, conference, field, algorithm, task, product, university, person, researcher, country, metric, programming language, organization and O.\nSentence: In 1857 , at the request of the Tokugawa Shogunate , a group of Dutch engineers began work on the Nagasaki Yotetsusho , a modern , Western-style foundry and shipyard near the Dutch settlement of Dejima , at Nagasaki .", "prompt_labels": "In(O) 1857(O) ,(O) at(O) the(O) request(O) of(O) the(O) Tokugawa(B-country) Shogunate(I-country) ,(O) a(O) group(O) of(O) Dutch(O) engineers(O) began(O) work(O) on(O) the(O) Nagasaki(O) Yotetsusho(O) ,(O) a(O) modern(O) ,(O) Western-style(O) foundry(O) and(O) shipyard(O) near(O) the(O) Dutch(O) settlement(O) of(O) Dejima(O) ,(O) at(O) Nagasaki(O) .(O)"}, "label_list": ["location", "conference", "field", "algorithm", "task", "product", "university", "person", "researcher", "country", "metric", "programming language", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 10017, 11, 2115, 11, 12384, 11, 3465, 11, 2027, 11, 12374, 11, 1732, 11, 32185, 11, 3224, 11, 18767, 11, 15840, 4221, 11, 7471, 323, 507, 627, 85664, 25, 763, 220, 9741, 22, 1174, 520, 279, 1715, 315, 279, 22164, 773, 14406, 1443, 540, 22518, 1174, 264, 1912, 315, 24113, 25175, 6137, 990, 389, 279, 30162, 57509, 816, 354, 1441, 1136, 78, 1174, 264, 6617, 1174, 11104, 11549, 1766, 894, 323, 8448, 17884, 3221, 279, 24113, 17516, 315, 1611, 73, 7675, 1174, 520, 30162, 57509, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "362", "dataset": "crossner_music", "split": "dev", "prediction": "In(O) 2013(O) Blood(B-title) Brothers(I-title) was(O) produced(O) by(O) the(O) Harvest(B-organization) Rain(I-organization) Theatre(I-organization) Company(I-organization) of(I-organization) Brisbane(I-organization) playing(O) the(O) Cremorne(B-location) Theatre(I-location) August(O) 3-17(O) :(O) directed(O) by(O) Tim(B-director) O(I-director) 'Connor(I-director),(O) the(O) production(O) featured(O) Amanda(B-musical artist) Muggleton(I-musical artist) in(O) the(O) role(O) of(O) Mrs(B-character) Johnstone(I-character).(O) 2011(O).(O)", "instance": {"id": "362", "words": ["In", "2013", "Blood", "Brothers", "was", "produced", "by", "the", "Harvest", "Rain", "Theatre", "Company", "of", "Brisbane", "playing", "the", "Cremorne", "Theatre", "August", "3-17", ":", "directed", "by", "Tim", "O", "'Connor", ",", "the", "production", "featured", "Amanda", "Muggleton", "in", "the", "role", "of", "Mrs.", "Johnstone.2011", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "I-location", "I-location", "O", "B-location", "O", "O", "B-location", "I-location", "O", "O", "O", "O", "O", "B-person", "I-person", "I-person", "O", "O", "O", "O", "B-person", "I-person", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, person, music genre, event, location, band, musical instrument, country, song, musical artist, award, album and O.\nSentence: In 2013 Blood Brothers was produced by the Harvest Rain Theatre Company of Brisbane playing the Cremorne Theatre August 3-17 : directed by Tim O 'Connor , the production featured Amanda Muggleton in the role of Mrs. Johnstone.2011 .", "prompt_labels": "In(O) 2013(O) Blood(O) Brothers(O) was(O) produced(O) by(O) the(O) Harvest(B-location) Rain(I-location) Theatre(I-location) Company(I-location) of(O) Brisbane(B-location) playing(O) the(O) Cremorne(B-location) Theatre(I-location) August(O) 3-17(O) :(O) directed(O) by(O) Tim(B-person) O(I-person) 'Connor(I-person) ,(O) the(O) production(O) featured(O) Amanda(B-person) Muggleton(I-person) in(O) the(O) role(O) of(O) Mrs.(O) Johnstone.2011(O) .(O)"}, "label_list": ["organization", "person", "music genre", "event", "location", "band", "musical instrument", "country", "song", "musical artist", "award", "album"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 1732, 11, 4731, 17779, 11, 1567, 11, 3813, 11, 7200, 11, 18273, 14473, 11, 3224, 11, 5609, 11, 18273, 10255, 11, 10292, 11, 8176, 323, 507, 627, 85664, 25, 763, 220, 679, 18, 20671, 34179, 574, 9124, 555, 279, 56935, 22674, 27315, 8351, 315, 47335, 5737, 279, 356, 1864, 17334, 27315, 6287, 220, 18, 12, 1114, 551, 15910, 555, 9538, 507, 364, 57987, 1174, 279, 5788, 15109, 42859, 386, 2661, 15989, 304, 279, 3560, 315, 18083, 13, 3842, 11046, 13, 679, 16, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "788", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) was(O) the(O) hit(B-song) song(I-song) from(O) the(O) movie(O) armageddon(B-title)", "instance": {"id": "788", "words": ["what", "was", "the", "hit", "song", "from", "the", "movie", "armageddon"], "labels": ["O", "O", "O", "B-song", "I-song", "O", "O", "O", "B-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, actor, title, director, review, plot, year, average ratings, character, song, trailer, rating and O.\nSentence: what was the hit song from the movie armageddon", "prompt_labels": "what(O) was(O) the(O) hit(B-song) song(I-song) from(O) the(O) movie(O) armageddon(B-title)"}, "label_list": ["genre", "actor", "title", "director", "review", "plot", "year", "average ratings", "character", "song", "trailer", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 12360, 11, 2316, 11, 7690, 11, 3477, 11, 7234, 11, 1060, 11, 5578, 18594, 11, 3752, 11, 5609, 11, 19809, 11, 10959, 323, 507, 627, 85664, 25, 1148, 574, 279, 4295, 5609, 505, 279, 5818, 6916, 3359, 15357, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "56", "dataset": "crossner_science", "split": "dev", "prediction": "UCSI(B-university) University(I-university),(O) Sarawak(B-location) Campus(I-location),(O) University(B-university) College(I-university) of(I-university) Technology(I-university) Sarawak(I-university) ((O) UCTS(B-university) )(O) Tunku(B-university) Abdul(I-university) Rahman(I-university) University(I-university) College(I-university) of(I-university) Technology(I-university) Sarawak(I-university) ((O) Sabah(B-location) campus(I-location) )(O),(O) International(B-university) University(I-university) College(I-university) Of(I-university) Technology(I-university) Twintech(I-university) ((O) Sabah(B-location) campus(I-location) )(O),(O) and(O) Open(B-university) University(I-university) Malaysia(I-university) ((O) Sabah(B-location) campus(I-location) )(O) have(O) local(O) private(O) university(O) branch(O) campuses(O) in(O) East(B-location) Malaysia(I-location).(O)", "instance": {"id": "56", "words": ["UCSI", "University", ",", "Sarawak", "Campus", ",", "University", "College", "of", "Technology", "Sarawak", "(", "UCTS", ")", "Tunku", "Abdul", "Rahman", "University", "College", "(", "Sabah", "campus", ")", ",", "International", "University", "College", "Of", "Technology", "Twintech", "(", "Sabah", "campus", ")", ",", "and", "Open", "University", "Malaysia", "(", "Sabah", "campus", ")", "have", "local", "private", "university", "branch", "campuses", "in", "East", "Malaysia", "."], "labels": ["B-university", "I-university", "I-university", "I-university", "I-university", "O", "B-university", "I-university", "I-university", "I-university", "I-university", "O", "B-university", "O", "B-university", "I-university", "I-university", "I-university", "I-university", "I-university", "I-university", "I-university", "I-university", "O", "B-university", "I-university", "I-university", "I-university", "I-university", "I-university", "I-university", "I-university", "I-university", "I-university", "O", "O", "B-university", "I-university", "I-university", "I-university", "I-university", "I-university", "I-university", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, location, organization, person, event, enzyme, theory, academic journal, chemical compound, chemical element, award, protein, university, discipline, astronomical object, scientist and O.\nSentence: UCSI University , Sarawak Campus , University College of Technology Sarawak ( UCTS ) Tunku Abdul Rahman University College ( Sabah campus ) , International University College Of Technology Twintech ( Sabah campus ) , and Open University Malaysia ( Sabah campus ) have local private university branch campuses in East Malaysia .", "prompt_labels": "UCSI(B-university) University(I-university) ,(I-university) Sarawak(I-university) Campus(I-university) ,(O) University(B-university) College(I-university) of(I-university) Technology(I-university) Sarawak(I-university) ((O) UCTS(B-university) )(O) Tunku(B-university) Abdul(I-university) Rahman(I-university) University(I-university) College(I-university) ((I-university) Sabah(I-university) campus(I-university) )(I-university) ,(O) International(B-university) University(I-university) College(I-university) Of(I-university) Technology(I-university) Twintech(I-university) ((I-university) Sabah(I-university) campus(I-university) )(I-university) ,(O) and(O) Open(B-university) University(I-university) Malaysia(I-university) ((I-university) Sabah(I-university) campus(I-university) )(I-university) have(O) local(O) private(O) university(O) branch(O) campuses(O) in(O) East(B-location) Malaysia(I-location) .(O)"}, "label_list": ["country", "location", "organization", "person", "event", "enzyme", "theory", "academic journal", "chemical compound", "chemical element", "award", "protein", "university", "discipline", "astronomical object", "scientist"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 3813, 11, 7471, 11, 1732, 11, 1567, 11, 49242, 11, 10334, 11, 14584, 8486, 11, 11742, 24549, 11, 11742, 2449, 11, 10292, 11, 13128, 11, 12374, 11, 26434, 11, 87283, 1665, 11, 28568, 323, 507, 627, 85664, 25, 549, 49507, 3907, 1174, 13951, 675, 587, 39680, 1174, 3907, 9304, 315, 12053, 13951, 675, 587, 320, 549, 95837, 883, 350, 3200, 84, 52698, 98376, 3907, 9304, 320, 21252, 1494, 15679, 883, 1174, 7327, 3907, 9304, 5046, 12053, 12015, 396, 4842, 320, 21252, 1494, 15679, 883, 1174, 323, 5377, 3907, 28796, 320, 21252, 1494, 15679, 883, 617, 2254, 879, 12374, 9046, 53008, 304, 6460, 28796, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "407", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) a(O) quentin(B-director) tarantino(I-director) film(O) with(O) uma(B-actor) thurman(I-actor)", "instance": {"id": "407", "words": ["show", "me", "a", "quentin", "tarantino", "film", "with", "uma", "thurman"], "labels": ["O", "O", "O", "B-director", "I-director", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, actor, director, song, trailer, character, rating, average ratings, plot, review, title, genre and O.\nSentence: show me a quentin tarantino film with uma thurman", "prompt_labels": "show(O) me(O) a(O) quentin(B-director) tarantino(I-director) film(O) with(O) uma(B-actor) thurman(I-actor)"}, "label_list": ["year", "actor", "director", "song", "trailer", "character", "rating", "average ratings", "plot", "review", "title", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 12360, 11, 7690, 11, 5609, 11, 19809, 11, 3752, 11, 10959, 11, 5578, 18594, 11, 7234, 11, 3477, 11, 2316, 11, 17779, 323, 507, 627, 85664, 25, 1501, 757, 264, 934, 44509, 12460, 96464, 4632, 449, 10832, 270, 324, 1543, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1962", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) good(B-average ratings) government(B-plot) documentary(B-genre) can(O) i(O) watch(O) for(O) a(O) research(B-plot) project(I-plot) about(O) republicans(B-plot)", "instance": {"id": "1962", "words": ["what", "good", "government", "documentary", "can", "i", "watch", "for", "a", "research", "project", "about", "republicans"], "labels": ["O", "O", "B-plot", "B-genre", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, plot, director, review, song, trailer, character, year, actor, title, average ratings, genre and O.\nSentence: what good government documentary can i watch for a research project about republicans", "prompt_labels": "what(O) good(O) government(B-plot) documentary(B-genre) can(O) i(O) watch(O) for(O) a(O) research(O) project(O) about(O) republicans(O)"}, "label_list": ["rating", "plot", "director", "review", "song", "trailer", "character", "year", "actor", "title", "average ratings", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 7234, 11, 7690, 11, 3477, 11, 5609, 11, 19809, 11, 3752, 11, 1060, 11, 12360, 11, 2316, 11, 5578, 18594, 11, 17779, 323, 507, 627, 85664, 25, 1148, 1695, 3109, 25999, 649, 602, 3821, 369, 264, 3495, 2447, 922, 35544, 598, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "314", "dataset": "crossner_literature", "split": "dev", "prediction": "Good(B-book) Omens(I-book) :(O) The(B-book) Nice(I-book) and(I-book) Accurate(I-book) Prophecies(I-book) of(I-book) Agnes(I-book) Nutter(I-book),(O) Witch(O) ((O) 1990(O) )(O) is(O) a(O) World(B-award) Fantasy(I-award) Award(I-award) -nominated(O) novel(O) written(O) as(O) a(O) collaboration(O) between(O) the(O) English(O) authors(O) Terry(B-writer) Pratchett(I-writer) and(O) Neil(B-writer) Gaiman(I-writer).(O)", "instance": {"id": "314", "words": ["Good", "Omens", ":", "The", "Nice", "and", "Accurate", "Prophecies", "of", "Agnes", "Nutter", ",", "Witch", "(", "1990", ")", "is", "a", "World", "Fantasy", "Award", "-nominated", "novel", "written", "as", "a", "collaboration", "between", "the", "English", "authors", "Terry", "Pratchett", "and", "Neil", "Gaiman", "."], "labels": ["B-book", "I-book", "I-book", "I-book", "I-book", "I-book", "I-book", "I-book", "I-book", "I-book", "I-book", "I-book", "I-book", "O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "O", "B-literary genre", "O", "O", "O", "O", "O", "O", "O", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, magazine, location, person, event, writer, organization, award, poem, book, country and O.\nSentence: Good Omens : The Nice and Accurate Prophecies of Agnes Nutter , Witch ( 1990 ) is a World Fantasy Award -nominated novel written as a collaboration between the English authors Terry Pratchett and Neil Gaiman .", "prompt_labels": "Good(B-book) Omens(I-book) :(I-book) The(I-book) Nice(I-book) and(I-book) Accurate(I-book) Prophecies(I-book) of(I-book) Agnes(I-book) Nutter(I-book) ,(I-book) Witch(I-book) ((O) 1990(O) )(O) is(O) a(O) World(B-award) Fantasy(I-award) Award(I-award) -nominated(O) novel(B-literary genre) written(O) as(O) a(O) collaboration(O) between(O) the(O) English(O) authors(O) Terry(B-writer) Pratchett(I-writer) and(O) Neil(B-writer) Gaiman(I-writer) .(O)"}, "label_list": ["literary genre", "magazine", "location", "person", "event", "writer", "organization", "award", "poem", "book", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 32465, 17779, 11, 14756, 11, 3813, 11, 1732, 11, 1567, 11, 7061, 11, 7471, 11, 10292, 11, 33894, 11, 2363, 11, 3224, 323, 507, 627, 85664, 25, 7839, 19116, 729, 551, 578, 29959, 323, 11683, 62259, 3998, 42750, 552, 315, 4701, 4978, 452, 6339, 1174, 39450, 320, 220, 2550, 15, 883, 374, 264, 4435, 27582, 17768, 482, 77, 50615, 11775, 5439, 439, 264, 20632, 1990, 279, 6498, 12283, 32618, 2394, 759, 7211, 323, 34221, 480, 2706, 276, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "101", "dataset": "crossner_literature", "split": "dev", "prediction": "Nimzowitsch(B-writer)'s(O) vanity(O) and(O) faith(O) in(O) his(O) ideas(O) of(O) overprotection(O) provoked(O) Hans(B-writer) Kmoch(I-writer) to(O) write(O) a(O) parody(O) about(O) him(O) in(O) February(O) 1928(O) in(O) the(O) Wiener(B-magazine) Schachzeitung(I-magazine).(O)", "instance": {"id": "101", "words": ["Nimzowitsch", "'s", "vanity", "and", "faith", "in", "his", "ideas", "of", "overprotection", "provoked", "Hans", "Kmoch", "to", "write", "a", "parody", "about", "him", "in", "February", "1928", "in", "the", "Wiener", "Schachzeitung", "."], "labels": ["B-person", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-magazine", "I-magazine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, poem, writer, award, book, organization, person, event, literary genre, country, location and O.\nSentence: Nimzowitsch 's vanity and faith in his ideas of overprotection provoked Hans Kmoch to write a parody about him in February 1928 in the Wiener Schachzeitung .", "prompt_labels": "Nimzowitsch(B-person) 's(O) vanity(O) and(O) faith(O) in(O) his(O) ideas(O) of(O) overprotection(O) provoked(O) Hans(B-person) Kmoch(I-person) to(O) write(O) a(O) parody(O) about(O) him(O) in(O) February(O) 1928(O) in(O) the(O) Wiener(B-magazine) Schachzeitung(I-magazine) .(O)"}, "label_list": ["magazine", "poem", "writer", "award", "book", "organization", "person", "event", "literary genre", "country", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 14756, 11, 33894, 11, 7061, 11, 10292, 11, 2363, 11, 7471, 11, 1732, 11, 1567, 11, 32465, 17779, 11, 3224, 11, 3813, 323, 507, 627, 85664, 25, 47683, 89, 363, 1220, 331, 364, 82, 52671, 323, 10082, 304, 813, 6848, 315, 927, 782, 40241, 76566, 25844, 93582, 5059, 311, 3350, 264, 67265, 922, 1461, 304, 7552, 220, 5926, 23, 304, 279, 17664, 804, 5124, 613, 30513, 2234, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "622", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) want(O) a(O) greek(B-Dish) sandwich(I-Dish) with(I-Dish) goat(I-Dish) cheese(I-Dish)", "instance": {"id": "622", "words": ["i", "want", "a", "greek", "sandwich", "with", "goat", "cheese"], "labels": ["O", "O", "O", "B-Cuisine", "B-Dish", "I-Dish", "I-Dish", "I-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Location, Amenity, Restaurant Name, Cuisine, Dish, Hours, Price and O.\nSentence: i want a greek sandwich with goat cheese", "prompt_labels": "i(O) want(O) a(O) greek(B-Cuisine) sandwich(B-Dish) with(I-Dish) goat(I-Dish) cheese(I-Dish)"}, "label_list": ["Rating", "Location", "Amenity", "Restaurant Name", "Cuisine", "Dish", "Hours", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 10067, 11, 3383, 56685, 11, 26568, 4076, 11, 81961, 11, 49268, 11, 30192, 11, 8650, 323, 507, 627, 85664, 25, 602, 1390, 264, 342, 10957, 28974, 449, 54392, 17604, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "96", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) type(O) of(O) movie(O) is(O) nine(B-title)", "instance": {"id": "96", "words": ["what", "type", "of", "movie", "is", "nine"], "labels": ["O", "O", "O", "O", "O", "B-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, rating, review, plot, actor, character, title, director, average ratings, year, genre, song and O.\nSentence: what type of movie is nine", "prompt_labels": "what(O) type(O) of(O) movie(O) is(O) nine(B-title)"}, "label_list": ["trailer", "rating", "review", "plot", "actor", "character", "title", "director", "average ratings", "year", "genre", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 10959, 11, 3477, 11, 7234, 11, 12360, 11, 3752, 11, 2316, 11, 7690, 11, 5578, 18594, 11, 1060, 11, 17779, 11, 5609, 323, 507, 627, 85664, 25, 1148, 955, 315, 5818, 374, 11888, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1254", "dataset": "mit-movie", "split": "dev", "prediction": "had(O) david(B-director) lynch(I-director) ever(O) directed(O) an(O) avant(B-genre) garde(I-genre) movie(O) that(O) is(O) rated(O) r(B-rating)", "instance": {"id": "1254", "words": ["had", "david", "lynch", "ever", "directed", "an", "avant", "garde", "movie", "that", "is", "rated", "r"], "labels": ["O", "B-director", "I-director", "O", "O", "O", "B-genre", "I-genre", "O", "O", "O", "O", "B-rating"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, song, title, trailer, plot, director, genre, year, character, actor, review, rating and O.\nSentence: had david lynch ever directed an avant garde movie that is rated r", "prompt_labels": "had(O) david(B-director) lynch(I-director) ever(O) directed(O) an(O) avant(B-genre) garde(I-genre) movie(O) that(O) is(O) rated(O) r(B-rating)"}, "label_list": ["average ratings", "song", "title", "trailer", "plot", "director", "genre", "year", "character", "actor", "review", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 5609, 11, 2316, 11, 19809, 11, 7234, 11, 7690, 11, 17779, 11, 1060, 11, 3752, 11, 12360, 11, 3477, 11, 10959, 323, 507, 627, 85664, 25, 1047, 55046, 326, 69581, 3596, 15910, 459, 33670, 7515, 451, 5818, 430, 374, 22359, 436, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "334", "dataset": "crossner_science", "split": "dev", "prediction": "Starch(B-chemical compound) ; ((O) fermentation(O) )(O) ;(O) Lactic(B-chemical compound) acid(I-chemical compound) ;(O) Polylactic(B-chemical compound) acid(I-chemical compound) ((O) PLA(B-chemical compound) )(O).(O)", "instance": {"id": "334", "words": ["Starch", ";", "(", "fermentation", ")", ";", "Lactic", "acid", ";", "Polylactic", "acid", "(", "PLA", ")", "."], "labels": ["B-chemical compound", "O", "O", "O", "O", "O", "B-chemical compound", "I-chemical compound", "O", "B-chemical compound", "I-chemical compound", "O", "B-chemical compound", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: astronomical object, enzyme, award, scientist, chemical compound, academic journal, theory, organization, discipline, event, country, person, chemical element, protein, university, location and O.\nSentence: Starch ; ( fermentation ) ; Lactic acid ; Polylactic acid ( PLA ) .", "prompt_labels": "Starch(B-chemical compound) ;(O) ((O) fermentation(O) )(O) ;(O) Lactic(B-chemical compound) acid(I-chemical compound) ;(O) Polylactic(B-chemical compound) acid(I-chemical compound) ((O) PLA(B-chemical compound) )(O) .(O)"}, "label_list": ["astronomical object", "enzyme", "award", "scientist", "chemical compound", "academic journal", "theory", "organization", "discipline", "event", "country", "person", "chemical element", "protein", "university", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 87283, 1665, 11, 49242, 11, 10292, 11, 28568, 11, 11742, 24549, 11, 14584, 8486, 11, 10334, 11, 7471, 11, 26434, 11, 1567, 11, 3224, 11, 1732, 11, 11742, 2449, 11, 13128, 11, 12374, 11, 3813, 323, 507, 627, 85664, 25, 800, 1132, 2652, 320, 74454, 883, 2652, 445, 24045, 13935, 2652, 3735, 4010, 24045, 13935, 320, 98066, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1519", "dataset": "mit-restaurant", "split": "dev", "prediction": "yes(O) we(O) need(O) some(O) chicken(B-Dish) for(O) our(O) new(O) diet(O) so(O) chik(O) fa(O) lay(O) it(O) is(O)", "instance": {"id": "1519", "words": ["yes", "we", "need", "some", "chicken", "for", "our", "new", "diet", "so", "chik", "fa", "lay", "it", "is"], "labels": ["O", "O", "O", "O", "B-Dish", "O", "O", "O", "O", "O", "B-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Dish, Restaurant Name, Amenity, Hours, Rating, Location, Price and O.\nSentence: yes we need some chicken for our new diet so chik fa lay it is", "prompt_labels": "yes(O) we(O) need(O) some(O) chicken(B-Dish) for(O) our(O) new(O) diet(O) so(O) chik(B-Restaurant Name) fa(I-Restaurant Name) lay(I-Restaurant Name) it(O) is(O)"}, "label_list": ["Cuisine", "Dish", "Restaurant Name", "Amenity", "Hours", "Rating", "Location", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 49268, 11, 26568, 4076, 11, 3383, 56685, 11, 30192, 11, 19767, 11, 10067, 11, 8650, 323, 507, 627, 85664, 25, 10035, 584, 1205, 1063, 16553, 369, 1057, 502, 10173, 779, 523, 1609, 2267, 11203, 433, 374, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "96", "dataset": "mit-restaurant", "split": "dev", "prediction": "are(O) there(O) any(O) vegetarian(B-Cuisine) restaurants(O) in(B-Location) this(I-Location) town(I-Location)", "instance": {"id": "96", "words": ["are", "there", "any", "vegetarian", "restaurants", "in", "this", "town"], "labels": ["O", "O", "O", "B-Cuisine", "O", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Rating, Dish, Cuisine, Amenity, Restaurant Name, Hours, Price and O.\nSentence: are there any vegetarian restaurants in this town", "prompt_labels": "are(O) there(O) any(O) vegetarian(B-Cuisine) restaurants(O) in(B-Location) this(I-Location) town(I-Location)"}, "label_list": ["Location", "Rating", "Dish", "Cuisine", "Amenity", "Restaurant Name", "Hours", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 19767, 11, 49268, 11, 81961, 11, 3383, 56685, 11, 26568, 4076, 11, 30192, 11, 8650, 323, 507, 627, 85664, 25, 527, 1070, 904, 46482, 15926, 304, 420, 6424, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "999", "dataset": "mit-restaurant", "split": "dev", "prediction": "mexican(B-Cuisine) food(O)", "instance": {"id": "999", "words": ["mexican", "food"], "labels": ["B-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Price, Cuisine, Location, Amenity, Hours, Restaurant Name, Dish and O.\nSentence: mexican food", "prompt_labels": "mexican(B-Cuisine) food(O)"}, "label_list": ["Rating", "Price", "Cuisine", "Location", "Amenity", "Hours", "Restaurant Name", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 8650, 11, 81961, 11, 10067, 11, 3383, 56685, 11, 30192, 11, 26568, 4076, 11, 49268, 323, 507, 627, 85664, 25, 38049, 7210, 3691, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1393", "dataset": "mit-movie", "split": "dev", "prediction": "in(O) 1970(B-year) was(O) deidre(B-actor) hall(I-actor) in(O) an(O) unrated(B-rating) short(B-genre) film(O)", "instance": {"id": "1393", "words": ["in", "1970", "was", "deidre", "hall", "in", "an", "unrated", "short", "film"], "labels": ["O", "B-year", "O", "B-actor", "I-actor", "O", "O", "B-rating", "B-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, trailer, song, year, actor, character, review, genre, average ratings, director, title, plot and O.\nSentence: in 1970 was deidre hall in an unrated short film", "prompt_labels": "in(O) 1970(B-year) was(O) deidre(B-actor) hall(I-actor) in(O) an(O) unrated(B-rating) short(B-genre) film(O)"}, "label_list": ["rating", "trailer", "song", "year", "actor", "character", "review", "genre", "average ratings", "director", "title", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 19809, 11, 5609, 11, 1060, 11, 12360, 11, 3752, 11, 3477, 11, 17779, 11, 5578, 18594, 11, 7690, 11, 2316, 11, 7234, 323, 507, 627, 85664, 25, 304, 220, 4468, 15, 574, 409, 307, 265, 14321, 304, 459, 41480, 660, 2875, 4632, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "375", "dataset": "crossner_literature", "split": "dev", "prediction": "He(O) even(O) writes(O) a(O) book(O) about(O) mystery(B-literary genre) fiction(I-literary genre) in(O) which(O) he(O) deals(O) sternly(O) with(O) Edgar(B-writer) Allan(I-writer) Poe(I-writer) and(O) Wilkie(B-writer) Collins(I-writer).(O)", "instance": {"id": "375", "words": ["He", "even", "writes", "a", "book", "about", "mystery", "fiction", "in", "which", "he", "deals", "sternly", "with", "Edgar", "Allan", "Poe", "and", "Wilkie", "Collins", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-literary genre", "I-literary genre", "O", "O", "O", "O", "O", "O", "B-writer", "I-writer", "I-writer", "O", "B-writer", "I-writer", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, poem, location, book, event, literary genre, magazine, organization, person, country, writer and O.\nSentence: He even writes a book about mystery fiction in which he deals sternly with Edgar Allan Poe and Wilkie Collins .", "prompt_labels": "He(O) even(O) writes(O) a(O) book(O) about(O) mystery(B-literary genre) fiction(I-literary genre) in(O) which(O) he(O) deals(O) sternly(O) with(O) Edgar(B-writer) Allan(I-writer) Poe(I-writer) and(O) Wilkie(B-writer) Collins(I-writer) .(O)"}, "label_list": ["award", "poem", "location", "book", "event", "literary genre", "magazine", "organization", "person", "country", "writer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10292, 11, 33894, 11, 3813, 11, 2363, 11, 1567, 11, 32465, 17779, 11, 14756, 11, 7471, 11, 1732, 11, 3224, 11, 7061, 323, 507, 627, 85664, 25, 1283, 1524, 14238, 264, 2363, 922, 23347, 17422, 304, 902, 568, 12789, 58644, 398, 449, 60091, 61325, 82695, 323, 10785, 31422, 29770, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1810", "dataset": "mit-movie", "split": "dev", "prediction": "was(O) there(O) a(O) decent(B-average ratings) watchable(I-average ratings) romance(B-genre) in(O) the(O) past(B-year) year(I-year) that(O) starred(O) tim(B-actor) roth(I-actor)", "instance": {"id": "1810", "words": ["was", "there", "a", "decent", "watchable", "romance", "in", "the", "past", "year", "that", "starred", "tim", "roth"], "labels": ["O", "O", "O", "O", "B-average ratings", "B-genre", "O", "O", "B-year", "I-year", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, rating, title, review, plot, director, genre, year, average ratings, character, song, trailer and O.\nSentence: was there a decent watchable romance in the past year that starred tim roth", "prompt_labels": "was(O) there(O) a(O) decent(O) watchable(B-average ratings) romance(B-genre) in(O) the(O) past(B-year) year(I-year) that(O) starred(O) tim(B-actor) roth(I-actor)"}, "label_list": ["actor", "rating", "title", "review", "plot", "director", "genre", "year", "average ratings", "character", "song", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 10959, 11, 2316, 11, 3477, 11, 7234, 11, 7690, 11, 17779, 11, 1060, 11, 5578, 18594, 11, 3752, 11, 5609, 11, 19809, 323, 507, 627, 85664, 25, 574, 1070, 264, 15326, 3821, 481, 30363, 304, 279, 3347, 1060, 430, 59335, 6935, 938, 339, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1050", "dataset": "mit-movie", "split": "dev", "prediction": "name(O) the(O) last(O) charlie(B-actor) boyer(I-actor) movie(O)", "instance": {"id": "1050", "words": ["name", "the", "last", "charlie", "boyer", "movie"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, rating, average ratings, review, actor, trailer, song, plot, title, genre, year, director and O.\nSentence: name the last charlie boyer movie", "prompt_labels": "name(O) the(O) last(O) charlie(B-actor) boyer(I-actor) movie(O)"}, "label_list": ["character", "rating", "average ratings", "review", "actor", "trailer", "song", "plot", "title", "genre", "year", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 10959, 11, 5578, 18594, 11, 3477, 11, 12360, 11, 19809, 11, 5609, 11, 7234, 11, 2316, 11, 17779, 11, 1060, 11, 7690, 323, 507, 627, 85664, 25, 836, 279, 1566, 1181, 11828, 8334, 261, 5818, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "161", "dataset": "crossner_ai", "split": "dev", "prediction": "Popular(O) loss(O) functions(O) include(O) the(O) hinge(B-metric) loss(I-metric) ((O) for(O) linear(B-algorithm) SVMs(I-algorithm) )(O) and(O) the(O) log(B-metric) loss(I-metric) ((O) for(O) logistic(B-algorithm) regression(I-algorithm) )(O).(O)", "instance": {"id": "161", "words": ["Popular", "loss", "functions", "include", "the", "hinge", "loss", "(", "for", "linear", "SVMs", ")", "and", "the", "log", "loss", "(", "for", "logistic", "regression", ")", "."], "labels": ["O", "O", "O", "O", "O", "B-metric", "I-metric", "O", "O", "B-algorithm", "I-algorithm", "O", "O", "O", "B-metric", "I-metric", "O", "O", "B-algorithm", "I-algorithm", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, programming language, researcher, location, conference, person, organization, metric, algorithm, country, product, task, university and O.\nSentence: Popular loss functions include the hinge loss ( for linear SVMs ) and the log loss ( for logistic regression ) .", "prompt_labels": "Popular(O) loss(O) functions(O) include(O) the(O) hinge(B-metric) loss(I-metric) ((O) for(O) linear(B-algorithm) SVMs(I-algorithm) )(O) and(O) the(O) log(B-metric) loss(I-metric) ((O) for(O) logistic(B-algorithm) regression(I-algorithm) )(O) .(O)"}, "label_list": ["field", "programming language", "researcher", "location", "conference", "person", "organization", "metric", "algorithm", "country", "product", "task", "university"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2115, 11, 15840, 4221, 11, 32185, 11, 3813, 11, 10017, 11, 1732, 11, 7471, 11, 18767, 11, 12384, 11, 3224, 11, 2027, 11, 3465, 11, 12374, 323, 507, 627, 85664, 25, 32495, 4814, 5865, 2997, 279, 76693, 4814, 320, 369, 13790, 91109, 82, 883, 323, 279, 1515, 4814, 320, 369, 72810, 31649, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1829", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) 1990(B-year) s(I-year) animation(B-genre) film(O) was(O) rated(O) g(B-rating)", "instance": {"id": "1829", "words": ["what", "1990", "s", "animation", "film", "was", "rated", "g"], "labels": ["O", "B-year", "I-year", "B-genre", "O", "O", "O", "B-rating"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, rating, average ratings, review, plot, song, director, actor, genre, title, trailer, year and O.\nSentence: what 1990 s animation film was rated g", "prompt_labels": "what(O) 1990(B-year) s(I-year) animation(B-genre) film(O) was(O) rated(O) g(B-rating)"}, "label_list": ["character", "rating", "average ratings", "review", "plot", "song", "director", "actor", "genre", "title", "trailer", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 10959, 11, 5578, 18594, 11, 3477, 11, 7234, 11, 5609, 11, 7690, 11, 12360, 11, 17779, 11, 2316, 11, 19809, 11, 1060, 323, 507, 627, 85664, 25, 1148, 220, 2550, 15, 274, 10571, 4632, 574, 22359, 342, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2436", "dataset": "mit-movie", "split": "dev", "prediction": "play(O) the(O) trailer(B-trailer) of(O) dark(B-title) of(I-title) the(I-title) moon(I-title)", "instance": {"id": "2436", "words": ["play", "the", "trailer", "of", "dark", "of", "the", "moon"], "labels": ["O", "O", "B-trailer", "O", "B-title", "I-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, title, genre, actor, plot, director, song, trailer, character, review, rating, average ratings and O.\nSentence: play the trailer of dark of the moon", "prompt_labels": "play(O) the(O) trailer(B-trailer) of(O) dark(B-title) of(I-title) the(I-title) moon(I-title)"}, "label_list": ["year", "title", "genre", "actor", "plot", "director", "song", "trailer", "character", "review", "rating", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 2316, 11, 17779, 11, 12360, 11, 7234, 11, 7690, 11, 5609, 11, 19809, 11, 3752, 11, 3477, 11, 10959, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1514, 279, 19809, 315, 6453, 315, 279, 18266, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1931", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) are(O) the(O) titles(O) of(O) some(O) films(O) about(O) history(B-genre) from(O) the(O) past(B-year) three(I-year) years(I-year) directed(O) by(O) josh(B-director) rubin(I-director)", "instance": {"id": "1931", "words": ["what", "are", "the", "titles", "of", "some", "films", "about", "history", "from", "the", "past", "three", "years", "directed", "by", "josh", "rubin"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-genre", "O", "O", "B-year", "I-year", "I-year", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, review, average ratings, song, genre, plot, year, trailer, actor, rating, character, director and O.\nSentence: what are the titles of some films about history from the past three years directed by josh rubin", "prompt_labels": "what(O) are(O) the(O) titles(O) of(O) some(O) films(O) about(O) history(B-genre) from(O) the(O) past(B-year) three(I-year) years(I-year) directed(O) by(O) josh(B-director) rubin(I-director)"}, "label_list": ["title", "review", "average ratings", "song", "genre", "plot", "year", "trailer", "actor", "rating", "character", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 3477, 11, 5578, 18594, 11, 5609, 11, 17779, 11, 7234, 11, 1060, 11, 19809, 11, 12360, 11, 10959, 11, 3752, 11, 7690, 323, 507, 627, 85664, 25, 1148, 527, 279, 15671, 315, 1063, 12631, 922, 3925, 505, 279, 3347, 2380, 1667, 15910, 555, 503, 9451, 10485, 258, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "732", "dataset": "mit-restaurant", "split": "dev", "prediction": "im(O) looking(O) for(O) a(O) 5(B-Rating) star(I-Rating) restaurant(O) whats(O) the(O) closest(B-Location) one(I-Location)", "instance": {"id": "732", "words": ["im", "looking", "for", "a", "5", "star", "restaurant", "whats", "the", "closest", "one"], "labels": ["O", "O", "O", "O", "B-Rating", "I-Rating", "O", "O", "O", "B-Location", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Location, Dish, Restaurant Name, Hours, Cuisine, Rating, Price and O.\nSentence: im looking for a 5 star restaurant whats the closest one", "prompt_labels": "im(O) looking(O) for(O) a(O) 5(B-Rating) star(I-Rating) restaurant(O) whats(O) the(O) closest(B-Location) one(O)"}, "label_list": ["Amenity", "Location", "Dish", "Restaurant Name", "Hours", "Cuisine", "Rating", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 10067, 11, 49268, 11, 26568, 4076, 11, 30192, 11, 81961, 11, 19767, 11, 8650, 323, 507, 627, 85664, 25, 737, 3411, 369, 264, 220, 20, 6917, 10960, 41209, 279, 18585, 832, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "127", "dataset": "mit-restaurant", "split": "dev", "prediction": "can(O) i(O) get(O) sushi(B-Dish) on(O) a(O) prix(B-Amenity) fixe(I-Amenity) menu(I-Amenity) with(O) reasonable(B-Price) prices(O)", "instance": {"id": "127", "words": ["can", "i", "get", "sushi", "on", "a", "prix", "fixe", "menu", "with", "reasonable", "prices"], "labels": ["O", "O", "O", "B-Dish", "O", "O", "B-Amenity", "I-Amenity", "I-Amenity", "O", "B-Price", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Dish, Hours, Rating, Cuisine, Price, Location, Restaurant Name and O.\nSentence: can i get sushi on a prix fixe menu with reasonable prices", "prompt_labels": "can(O) i(O) get(O) sushi(B-Dish) on(O) a(O) prix(B-Amenity) fixe(I-Amenity) menu(I-Amenity) with(O) reasonable(B-Price) prices(O)"}, "label_list": ["Amenity", "Dish", "Hours", "Rating", "Cuisine", "Price", "Location", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 49268, 11, 30192, 11, 19767, 11, 81961, 11, 8650, 11, 10067, 11, 26568, 4076, 323, 507, 627, 85664, 25, 649, 602, 636, 67322, 389, 264, 38847, 5155, 68, 5130, 449, 13579, 7729, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "231", "dataset": "crossner_science", "split": "dev", "prediction": "Schweickart(B-scientist) is(O) a(O) Fellow(O) of(O) the(O) American(B-organization) Astronautical(I-organization) Society(I-organization),(O) the(O) International(B-organization) Academy(I-organization) of(I-organization) Astronautics(I-organization) and(O) the(O) California(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization),(O) as(O) well(O) as(O) an(O) Associate(O) Fellow(O) of(O) the(O) American(B-organization) Institute(I-organization) of(I-organization) Aeronautics(I-organization) and(I-organization) Astronautics(I-organization).(O)", "instance": {"id": "231", "words": ["Schweickart", "is", "a", "Fellow", "of", "the", "American", "Astronautical", "Society", ",", "the", "International", "Academy", "of", "Astronautics", "and", "the", "California", "Academy", "of", "Sciences", ",", "as", "well", "as", "an", "Associate", "Fellow", "of", "the", "American", "Institute", "of", "Aeronautics", "and", "Astronautics", "."], "labels": ["B-scientist", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, chemical compound, location, person, event, protein, astronomical object, discipline, academic journal, organization, scientist, university, award, chemical element, theory, enzyme and O.\nSentence: Schweickart is a Fellow of the American Astronautical Society , the International Academy of Astronautics and the California Academy of Sciences , as well as an Associate Fellow of the American Institute of Aeronautics and Astronautics .", "prompt_labels": "Schweickart(B-scientist) is(O) a(O) Fellow(B-award) of(I-award) the(I-award) American(I-award) Astronautical(I-award) Society(I-award) ,(O) the(O) International(B-organization) Academy(I-organization) of(I-organization) Astronautics(I-organization) and(O) the(O) California(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) ,(O) as(O) well(O) as(O) an(O) Associate(O) Fellow(O) of(O) the(O) American(B-organization) Institute(I-organization) of(I-organization) Aeronautics(I-organization) and(I-organization) Astronautics(I-organization) .(O)"}, "label_list": ["country", "chemical compound", "location", "person", "event", "protein", "astronomical object", "discipline", "academic journal", "organization", "scientist", "university", "award", "chemical element", "theory", "enzyme"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 11742, 24549, 11, 3813, 11, 1732, 11, 1567, 11, 13128, 11, 87283, 1665, 11, 26434, 11, 14584, 8486, 11, 7471, 11, 28568, 11, 12374, 11, 10292, 11, 11742, 2449, 11, 10334, 11, 49242, 323, 507, 627, 85664, 25, 56834, 875, 472, 374, 264, 37946, 315, 279, 3778, 39616, 37164, 950, 13581, 1174, 279, 7327, 16192, 315, 39616, 37164, 1233, 323, 279, 7188, 16192, 315, 23199, 1174, 439, 1664, 439, 459, 33468, 37946, 315, 279, 3778, 10181, 315, 362, 20110, 2784, 1233, 323, 39616, 37164, 1233, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "198", "dataset": "crossner_literature", "split": "dev", "prediction": "When(O) Martin(B-writer) Gardner(I-writer) retired(O) from(O) writing(O) his(O) Mathematical(B-writer) Games(I-writer) column(O) for(O) Scientific(B-magazine) American(I-magazine) magazine(O),(O) Hofstadter(B-writer) succeeded(O) him(O) in(O) 1981-1983(O) with(O) a(O) column(O) titled(O) Metamagical(B-writer) Themas(I-writer) ((O) an(O) anagram(O) of(O) Mathematical(B-writer) Games(I-writer) )(O).(O)", "instance": {"id": "198", "words": ["When", "Martin", "Gardner", "retired", "from", "writing", "his", "Mathematical", "Games", "column", "for", "Scientific", "American", "magazine", ",", "Hofstadter", "succeeded", "him", "in", "1981-1983", "with", "a", "column", "titled", "Metamagical", "Themas", "(", "an", "anagram", "of", "Mathematical", "Games", ")", "."], "labels": ["O", "B-writer", "I-writer", "O", "O", "O", "O", "B-book", "I-book", "O", "O", "B-magazine", "I-magazine", "O", "O", "B-writer", "O", "O", "O", "O", "O", "O", "O", "O", "B-book", "I-book", "O", "O", "O", "O", "B-book", "I-book", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, location, person, writer, literary genre, award, event, poem, book, country, organization and O.\nSentence: When Martin Gardner retired from writing his Mathematical Games column for Scientific American magazine , Hofstadter succeeded him in 1981-1983 with a column titled Metamagical Themas ( an anagram of Mathematical Games ) .", "prompt_labels": "When(O) Martin(B-writer) Gardner(I-writer) retired(O) from(O) writing(O) his(O) Mathematical(B-book) Games(I-book) column(O) for(O) Scientific(B-magazine) American(I-magazine) magazine(O) ,(O) Hofstadter(B-writer) succeeded(O) him(O) in(O) 1981-1983(O) with(O) a(O) column(O) titled(O) Metamagical(B-book) Themas(I-book) ((O) an(O) anagram(O) of(O) Mathematical(B-book) Games(I-book) )(O) .(O)"}, "label_list": ["magazine", "location", "person", "writer", "literary genre", "award", "event", "poem", "book", "country", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 14756, 11, 3813, 11, 1732, 11, 7061, 11, 32465, 17779, 11, 10292, 11, 1567, 11, 33894, 11, 2363, 11, 3224, 11, 7471, 323, 507, 627, 85664, 25, 3277, 11826, 57729, 22311, 505, 4477, 813, 92102, 11871, 3330, 369, 38130, 3778, 14756, 1174, 72812, 47940, 466, 26399, 1461, 304, 220, 3753, 16, 12, 3753, 18, 449, 264, 3330, 25891, 6344, 309, 351, 950, 666, 35262, 320, 459, 459, 5864, 315, 92102, 11871, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "961", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) critics(O) rate(O) any(O) of(O) the(O) alien(B-title) movies(O) as(O) must(B-average ratings) see(I-average ratings)", "instance": {"id": "961", "words": ["did", "critics", "rate", "any", "of", "the", "alien", "movies", "as", "must", "see"], "labels": ["O", "B-average ratings", "I-average ratings", "O", "O", "O", "B-title", "O", "O", "B-review", "I-review"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, rating, title, character, trailer, director, average ratings, year, song, review, plot, actor and O.\nSentence: did critics rate any of the alien movies as must see", "prompt_labels": "did(O) critics(B-average ratings) rate(I-average ratings) any(O) of(O) the(O) alien(B-title) movies(O) as(O) must(B-review) see(I-review)"}, "label_list": ["genre", "rating", "title", "character", "trailer", "director", "average ratings", "year", "song", "review", "plot", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 10959, 11, 2316, 11, 3752, 11, 19809, 11, 7690, 11, 5578, 18594, 11, 1060, 11, 5609, 11, 3477, 11, 7234, 11, 12360, 323, 507, 627, 85664, 25, 1550, 23531, 4478, 904, 315, 279, 20167, 9698, 439, 2011, 1518, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "52", "dataset": "crossner_ai", "split": "dev", "prediction": "In(O) computer(B-field) vision(I-field) and(O) image(B-field) processing(I-field),(O) the(O) notion(O) of(O) scale(B-algorithm) space(I-algorithm) representation(I-algorithm) and(O) Gaussian(B-algorithm) derivative(I-algorithm) operators(I-algorithm) is(O) as(O) a(O) canonical(O) multi-scale(O) representation(O).(O)", "instance": {"id": "52", "words": ["In", "computer", "vision", "and", "image", "processing", ",", "the", "notion", "of", "scale", "space", "representation", "and", "Gaussian", "derivative", "operators", "is", "as", "a", "canonical", "multi-scale", "representation", "."], "labels": ["O", "B-field", "I-field", "O", "B-field", "I-field", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, metric, person, country, product, programming language, location, university, organization, task, algorithm, field, researcher and O.\nSentence: In computer vision and image processing , the notion of scale space representation and Gaussian derivative operators is as a canonical multi-scale representation .", "prompt_labels": "In(O) computer(B-field) vision(I-field) and(O) image(B-field) processing(I-field) ,(O) the(O) notion(O) of(O) scale(O) space(O) representation(O) and(O) Gaussian(O) derivative(O) operators(O) is(O) as(O) a(O) canonical(O) multi-scale(O) representation(O) .(O)"}, "label_list": ["conference", "metric", "person", "country", "product", "programming language", "location", "university", "organization", "task", "algorithm", "field", "researcher"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10017, 11, 18767, 11, 1732, 11, 3224, 11, 2027, 11, 15840, 4221, 11, 3813, 11, 12374, 11, 7471, 11, 3465, 11, 12384, 11, 2115, 11, 32185, 323, 507, 627, 85664, 25, 763, 6500, 11376, 323, 2217, 8863, 1174, 279, 23035, 315, 5569, 3634, 13340, 323, 49668, 32905, 20197, 374, 439, 264, 43553, 7447, 13230, 13340, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1495", "dataset": "mit-restaurant", "split": "dev", "prediction": "which(O) restaurants(O) are(O) considered(O) vegetarian(B-Cuisine) in(B-Location) my(I-Location) city(I-Location)", "instance": {"id": "1495", "words": ["which", "restaurants", "are", "considered", "vegetarian", "in", "my", "city"], "labels": ["O", "O", "O", "O", "B-Cuisine", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Cuisine, Dish, Price, Rating, Amenity, Hours, Location and O.\nSentence: which restaurants are considered vegetarian in my city", "prompt_labels": "which(O) restaurants(O) are(O) considered(O) vegetarian(B-Cuisine) in(B-Location) my(I-Location) city(I-Location)"}, "label_list": ["Restaurant Name", "Cuisine", "Dish", "Price", "Rating", "Amenity", "Hours", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 81961, 11, 49268, 11, 8650, 11, 19767, 11, 3383, 56685, 11, 30192, 11, 10067, 323, 507, 627, 85664, 25, 902, 15926, 527, 6646, 46482, 304, 856, 3363, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "633", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) all(O) the(O) movies(O) zac(B-actor) efron(I-actor) has(O) been(O) in(O)", "instance": {"id": "633", "words": ["show", "me", "all", "the", "movies", "zac", "efron", "has", "been", "in"], "labels": ["O", "O", "O", "O", "O", "B-actor", "I-actor", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, title, review, plot, year, genre, song, director, average ratings, rating, trailer, actor and O.\nSentence: show me all the movies zac efron has been in", "prompt_labels": "show(O) me(O) all(O) the(O) movies(O) zac(B-actor) efron(I-actor) has(O) been(O) in(O)"}, "label_list": ["character", "title", "review", "plot", "year", "genre", "song", "director", "average ratings", "rating", "trailer", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 2316, 11, 3477, 11, 7234, 11, 1060, 11, 17779, 11, 5609, 11, 7690, 11, 5578, 18594, 11, 10959, 11, 19809, 11, 12360, 323, 507, 627, 85664, 25, 1501, 757, 682, 279, 9698, 1167, 582, 384, 1658, 263, 706, 1027, 304, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "292", "dataset": "crossner_science", "split": "dev", "prediction": "The(O) citric(B-chemical compound) acid(I-chemical compound) cycle(I-chemical compound) produces(O) Nicotinamide(B-chemical compound) adenine(I-chemical compound) dinucleide(I-chemical compound) and(O) Flavin(B-chemical compound) adenine(I-chemical compound) dinucleide(I-chemical compound) through(O) oxidation(O) that(O) will(O) be(O) reduced(O) in(O) oxidative(B-enzyme) phosphorylation(I-enzyme) to(O) produce(O) Adenosine(B-chemical compound) triphosphate(I-chemical compound).(O)", "instance": {"id": "292", "words": ["The", "citric", "acid", "cycle", "produces", "Nicotinamide", "adenine", "dinucleotide", "and", "Flavin", "adenine", "dinucleotide", "through", "oxidation", "that", "will", "be", "reduced", "in", "oxidative", "phosphorylation", "to", "produce", "Adenosine", "triphosphate", "."], "labels": ["O", "B-chemical compound", "I-chemical compound", "O", "O", "B-chemical compound", "I-chemical compound", "I-chemical compound", "O", "B-chemical compound", "I-chemical compound", "I-chemical compound", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-chemical compound", "I-chemical compound", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, location, protein, event, chemical compound, theory, enzyme, university, award, organization, astronomical object, country, discipline, chemical element, academic journal, scientist and O.\nSentence: The citric acid cycle produces Nicotinamide adenine dinucleotide and Flavin adenine dinucleotide through oxidation that will be reduced in oxidative phosphorylation to produce Adenosine triphosphate .", "prompt_labels": "The(O) citric(B-chemical compound) acid(I-chemical compound) cycle(O) produces(O) Nicotinamide(B-chemical compound) adenine(I-chemical compound) dinucleotide(I-chemical compound) and(O) Flavin(B-chemical compound) adenine(I-chemical compound) dinucleotide(I-chemical compound) through(O) oxidation(O) that(O) will(O) be(O) reduced(O) in(O) oxidative(O) phosphorylation(O) to(O) produce(O) Adenosine(B-chemical compound) triphosphate(I-chemical compound) .(O)"}, "label_list": ["person", "location", "protein", "event", "chemical compound", "theory", "enzyme", "university", "award", "organization", "astronomical object", "country", "discipline", "chemical element", "academic journal", "scientist"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 3813, 11, 13128, 11, 1567, 11, 11742, 24549, 11, 10334, 11, 49242, 11, 12374, 11, 10292, 11, 7471, 11, 87283, 1665, 11, 3224, 11, 26434, 11, 11742, 2449, 11, 14584, 8486, 11, 28568, 323, 507, 627, 85664, 25, 578, 6681, 2265, 13935, 11008, 19159, 18011, 354, 258, 66796, 100213, 483, 11884, 22935, 69044, 323, 3061, 35716, 100213, 483, 11884, 22935, 69044, 1555, 71162, 430, 690, 387, 11293, 304, 79401, 95089, 2354, 311, 8356, 2467, 71970, 483, 2463, 764, 93473, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "296", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) there(O) any(O) iron(B-title) man(I-title) 3(I-title)", "instance": {"id": "296", "words": ["is", "there", "any", "iron", "man", "3"], "labels": ["O", "O", "O", "B-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, rating, title, average ratings, review, character, trailer, year, song, plot, actor, genre and O.\nSentence: is there any iron man 3", "prompt_labels": "is(O) there(O) any(O) iron(B-title) man(I-title) 3(I-title)"}, "label_list": ["director", "rating", "title", "average ratings", "review", "character", "trailer", "year", "song", "plot", "actor", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 10959, 11, 2316, 11, 5578, 18594, 11, 3477, 11, 3752, 11, 19809, 11, 1060, 11, 5609, 11, 7234, 11, 12360, 11, 17779, 323, 507, 627, 85664, 25, 374, 1070, 904, 11245, 893, 220, 18, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "395", "dataset": "crossner_politics", "split": "dev", "prediction": "Despite(O) Bob(B-politician) Dole(I-politician) '(O) s(O) victory(O) over(O) Bill(B-politician) Clinton(I-politician) and(O) Ross(B-politician) Perot(I-politician) in(O) the(O) state(O) 1996(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) in(I-election) Montana(I-election) in(O) the(O) presidential(O) election(O),(O) Baucus(B-politician) managed(O) to(O) narrowly(O) win(O) re-election(O) over(O) Rehberg(B-politician) to(O) secure(O) a(O) fourth(O) term(O) in(O) the(O) Senate(O).(O)", "instance": {"id": "395", "words": ["Despite", "Bob", "Dole", "'", "s", "victory", "over", "Bill", "Clinton", "and", "Ross", "Perot", "in", "the", "state", "1996", "United", "States", "presidential", "election", "in", "Montana", "in", "the", "presidential", "election", ",", "Baucus", "managed", "to", "narrowly", "win", "re-election", "over", "Rehberg", "to", "secure", "a", "fourth", "term", "in", "the", "Senate", "."], "labels": ["O", "B-politician", "I-politician", "O", "O", "O", "O", "B-politician", "I-politician", "O", "B-politician", "I-politician", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "B-politician", "O", "O", "O", "O", "O", "O", "B-location", "O", "O", "O", "O", "O", "O", "O", "B-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, politician, person, organization, event, election, location, country and O.\nSentence: Despite Bob Dole ' s victory over Bill Clinton and Ross Perot in the state 1996 United States presidential election in Montana in the presidential election , Baucus managed to narrowly win re-election over Rehberg to secure a fourth term in the Senate .", "prompt_labels": "Despite(O) Bob(B-politician) Dole(I-politician) '(O) s(O) victory(O) over(O) Bill(B-politician) Clinton(I-politician) and(O) Ross(B-politician) Perot(I-politician) in(O) the(O) state(O) 1996(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) in(I-election) Montana(I-election) in(O) the(O) presidential(O) election(O) ,(O) Baucus(B-politician) managed(O) to(O) narrowly(O) win(O) re-election(O) over(O) Rehberg(B-location) to(O) secure(O) a(O) fourth(O) term(O) in(O) the(O) Senate(B-organization) .(O)"}, "label_list": ["political party", "politician", "person", "organization", "event", "election", "location", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5054, 4717, 11, 37038, 11, 1732, 11, 7471, 11, 1567, 11, 6355, 11, 3813, 11, 3224, 323, 507, 627, 85664, 25, 18185, 14596, 423, 1286, 364, 274, 12845, 927, 8766, 8283, 323, 21116, 3700, 354, 304, 279, 1614, 220, 2550, 21, 3723, 4273, 13621, 6355, 304, 37105, 304, 279, 13621, 6355, 1174, 14659, 38601, 9152, 311, 65047, 3243, 312, 43733, 927, 1050, 71, 7881, 311, 9966, 264, 11999, 4751, 304, 279, 10092, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1061", "dataset": "mit-restaurant", "split": "dev", "prediction": "show(O) me(O) the(O) moderately(B-Price) priced(O) japanese(B-Cuisine) restaurants(O) in(B-Location) a(I-Location) ten(I-Location) mile(I-Location) radius(I-Location)", "instance": {"id": "1061", "words": ["show", "me", "the", "moderately", "priced", "japanese", "restaurants", "in", "a", "ten", "mile", "radius"], "labels": ["O", "O", "O", "B-Price", "O", "B-Cuisine", "O", "O", "O", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Amenity, Dish, Cuisine, Restaurant Name, Hours, Price, Location and O.\nSentence: show me the moderately priced japanese restaurants in a ten mile radius", "prompt_labels": "show(O) me(O) the(O) moderately(B-Price) priced(O) japanese(B-Cuisine) restaurants(O) in(O) a(O) ten(B-Location) mile(I-Location) radius(I-Location)"}, "label_list": ["Rating", "Amenity", "Dish", "Cuisine", "Restaurant Name", "Hours", "Price", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 3383, 56685, 11, 49268, 11, 81961, 11, 26568, 4076, 11, 30192, 11, 8650, 11, 10067, 323, 507, 627, 85664, 25, 1501, 757, 279, 70351, 33705, 54048, 15926, 304, 264, 5899, 14929, 10801, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "511", "dataset": "mit-restaurant", "split": "dev", "prediction": "how(O) far(O) away(O) is(O) the(O) nearest(B-Location) applebees(B-Restaurant Name)", "instance": {"id": "511", "words": ["how", "far", "away", "is", "the", "nearest", "applebees"], "labels": ["O", "O", "O", "O", "O", "B-Location", "B-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Dish, Rating, Hours, Location, Cuisine, Price, Restaurant Name and O.\nSentence: how far away is the nearest applebees", "prompt_labels": "how(O) far(O) away(O) is(O) the(O) nearest(B-Location) applebees(B-Restaurant Name)"}, "label_list": ["Amenity", "Dish", "Rating", "Hours", "Location", "Cuisine", "Price", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 49268, 11, 19767, 11, 30192, 11, 10067, 11, 81961, 11, 8650, 11, 26568, 4076, 323, 507, 627, 85664, 25, 1268, 3117, 3201, 374, 279, 24379, 24149, 1395, 288, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1045", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) josh(B-director) radnor(I-director) direct(O) any(O) pg(B-rating) 13(I-rating) movies(O)", "instance": {"id": "1045", "words": ["did", "josh", "radnor", "direct", "any", "pg", "13", "movies"], "labels": ["O", "B-director", "I-director", "O", "O", "B-rating", "I-rating", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, actor, plot, director, rating, trailer, song, average ratings, character, genre, year, review and O.\nSentence: did josh radnor direct any pg 13 movies", "prompt_labels": "did(O) josh(B-director) radnor(I-director) direct(O) any(O) pg(B-rating) 13(I-rating) movies(O)"}, "label_list": ["title", "actor", "plot", "director", "rating", "trailer", "song", "average ratings", "character", "genre", "year", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 12360, 11, 7234, 11, 7690, 11, 10959, 11, 19809, 11, 5609, 11, 5578, 18594, 11, 3752, 11, 17779, 11, 1060, 11, 3477, 323, 507, 627, 85664, 25, 1550, 503, 9451, 9038, 45807, 2167, 904, 17953, 220, 1032, 9698, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "450", "dataset": "mit-movie", "split": "dev", "prediction": "i(O) want(O) to(O) see(O) a(O) action(B-genre) comedy(I-genre)", "instance": {"id": "450", "words": ["i", "want", "to", "see", "a", "action", "comedy"], "labels": ["O", "O", "O", "O", "O", "B-genre", "I-genre"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, rating, director, song, year, character, plot, title, actor, review, genre, average ratings and O.\nSentence: i want to see a action comedy", "prompt_labels": "i(O) want(O) to(O) see(O) a(O) action(B-genre) comedy(I-genre)"}, "label_list": ["trailer", "rating", "director", "song", "year", "character", "plot", "title", "actor", "review", "genre", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 10959, 11, 7690, 11, 5609, 11, 1060, 11, 3752, 11, 7234, 11, 2316, 11, 12360, 11, 3477, 11, 17779, 11, 5578, 18594, 323, 507, 627, 85664, 25, 602, 1390, 311, 1518, 264, 1957, 23160, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2374", "dataset": "mit-movie", "split": "dev", "prediction": "name(O) a(O) science(B-genre) fiction(I-genre) with(O) artificial(B-plot) intelligence(I-plot) from(O) the(O) 2010(B-year) s(I-year)", "instance": {"id": "2374", "words": ["name", "a", "science", "fiction", "with", "artificial", "intelligence", "from", "the", "2010", "s"], "labels": ["O", "O", "B-genre", "I-genre", "O", "B-plot", "I-plot", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, genre, year, trailer, average ratings, review, plot, director, title, character, actor, rating and O.\nSentence: name a science fiction with artificial intelligence from the 2010 s", "prompt_labels": "name(O) a(O) science(B-genre) fiction(I-genre) with(O) artificial(B-plot) intelligence(I-plot) from(O) the(O) 2010(B-year) s(I-year)"}, "label_list": ["song", "genre", "year", "trailer", "average ratings", "review", "plot", "director", "title", "character", "actor", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 17779, 11, 1060, 11, 19809, 11, 5578, 18594, 11, 3477, 11, 7234, 11, 7690, 11, 2316, 11, 3752, 11, 12360, 11, 10959, 323, 507, 627, 85664, 25, 836, 264, 8198, 17422, 449, 21075, 11478, 505, 279, 220, 679, 15, 274, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "708", "dataset": "mit-restaurant", "split": "dev", "prediction": "id(O) like(O) to(O) find(O) a(O) breakfast(B-Cuisine) place(O)", "instance": {"id": "708", "words": ["id", "like", "to", "find", "a", "breakfast", "place"], "labels": ["O", "O", "O", "O", "O", "B-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Dish, Rating, Amenity, Cuisine, Price, Location, Hours and O.\nSentence: id like to find a breakfast place", "prompt_labels": "id(O) like(O) to(O) find(O) a(O) breakfast(B-Cuisine) place(O)"}, "label_list": ["Restaurant Name", "Dish", "Rating", "Amenity", "Cuisine", "Price", "Location", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 49268, 11, 19767, 11, 3383, 56685, 11, 81961, 11, 8650, 11, 10067, 11, 30192, 323, 507, 627, 85664, 25, 887, 1093, 311, 1505, 264, 17954, 2035, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1763", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) information(O) about(O) prime(B-title)", "instance": {"id": "1763", "words": ["show", "me", "information", "about", "prime"], "labels": ["O", "O", "O", "O", "B-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, character, song, genre, review, trailer, actor, plot, average ratings, year, director, rating and O.\nSentence: show me information about prime", "prompt_labels": "show(O) me(O) information(O) about(O) prime(B-title)"}, "label_list": ["title", "character", "song", "genre", "review", "trailer", "actor", "plot", "average ratings", "year", "director", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 3752, 11, 5609, 11, 17779, 11, 3477, 11, 19809, 11, 12360, 11, 7234, 11, 5578, 18594, 11, 1060, 11, 7690, 11, 10959, 323, 507, 627, 85664, 25, 1501, 757, 2038, 922, 10461, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "272", "dataset": "crossner_literature", "split": "dev", "prediction": "Because(O) of(O) this(O),(O) United(B-country) Kingdom(I-country) lacks(O) the(O) charismatic(O) leader(O) needed(O) to(O) keep(O) the(O) country(O) together(O) and(O) Nazi(B-country) Germany(I-country) successfully(O) conquers(O) Great(B-country) Britain(I-country) via(O) Operation(B-event) Sea(I-event) Lion(I-event) in(O) 1940(O).(O)", "instance": {"id": "272", "words": ["Because", "of", "this", ",", "United", "Kingdom", "lacks", "the", "charismatic", "leader", "needed", "to", "keep", "the", "country", "together", "and", "Nazi", "Germany", "successfully", "conquers", "Great", "Britain", "via", "Operation", "Sea", "Lion", "in", "1940", "."], "labels": ["O", "O", "O", "O", "B-country", "I-country", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-country", "I-country", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, location, literary genre, award, country, person, poem, book, organization, event, writer and O.\nSentence: Because of this , United Kingdom lacks the charismatic leader needed to keep the country together and Nazi Germany successfully conquers Great Britain via Operation Sea Lion in 1940 .", "prompt_labels": "Because(O) of(O) this(O) ,(O) United(B-country) Kingdom(I-country) lacks(O) the(O) charismatic(O) leader(O) needed(O) to(O) keep(O) the(O) country(O) together(O) and(O) Nazi(B-country) Germany(I-country) successfully(O) conquers(O) Great(O) Britain(O) via(O) Operation(B-event) Sea(I-event) Lion(I-event) in(O) 1940(O) .(O)"}, "label_list": ["magazine", "location", "literary genre", "award", "country", "person", "poem", "book", "organization", "event", "writer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 14756, 11, 3813, 11, 32465, 17779, 11, 10292, 11, 3224, 11, 1732, 11, 33894, 11, 2363, 11, 7471, 11, 1567, 11, 7061, 323, 507, 627, 85664, 25, 9393, 315, 420, 1174, 3723, 15422, 37856, 279, 79323, 7808, 4460, 311, 2567, 279, 3224, 3871, 323, 32527, 10057, 7946, 39879, 388, 8681, 13527, 4669, 17145, 15379, 33199, 304, 220, 6393, 15, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "749", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movie(O) is(O) r2d2(B-character) in(O)", "instance": {"id": "749", "words": ["what", "movie", "is", "r2d2", "in"], "labels": ["O", "O", "O", "B-character", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, genre, trailer, plot, song, review, character, actor, director, year, rating, average ratings and O.\nSentence: what movie is r2d2 in", "prompt_labels": "what(O) movie(O) is(O) r2d2(B-character) in(O)"}, "label_list": ["title", "genre", "trailer", "plot", "song", "review", "character", "actor", "director", "year", "rating", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 17779, 11, 19809, 11, 7234, 11, 5609, 11, 3477, 11, 3752, 11, 12360, 11, 7690, 11, 1060, 11, 10959, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1148, 5818, 374, 436, 17, 67, 17, 304, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "84", "dataset": "crossner_literature", "split": "dev", "prediction": "In(O) New(B-location) York(I-location),(O) he(O) socialized(O) at(O) the(O) Hydra(B-location) Club(I-location),(O) an(O) organization(O) of(O) New(B-location) York(I-location)'s(O) science(B-literary genre) fiction(I-literary genre) writers(O),(O) including(O) such(O) luminaries(O) as(O) Isaac(B-writer) Asimov(I-writer),(O) James(B-writer) Blish(I-writer),(O) Anthony(B-writer) Boucher(I-writer),(O) Avram(B-writer) Davidson(I-writer),(O) Judith(B-writer) Merril(I-writer),(O) and(O) Theodore(B-writer) Sturgeon(I-writer).(O)", "instance": {"id": "84", "words": ["In", "New", "York", ",", "he", "socialized", "at", "the", "Hydra", "Club", ",", "an", "organization", "of", "New", "York", "'s", "science", "fiction", "writers", ",", "including", "such", "luminaries", "as", "Isaac", "Asimov", ",", "James", "Blish", ",", "Anthony", "Boucher", ",", "Avram", "Davidson", ",", "Judith", "Merril", ",", "and", "Theodore", "Sturgeon", "."], "labels": ["O", "B-location", "I-location", "O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "O", "O", "O", "B-location", "I-location", "O", "B-literary genre", "I-literary genre", "O", "O", "O", "O", "O", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "O", "B-writer", "I-writer", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, poem, country, writer, magazine, book, event, award, organization, location, person and O.\nSentence: In New York , he socialized at the Hydra Club , an organization of New York 's science fiction writers , including such luminaries as Isaac Asimov , James Blish , Anthony Boucher , Avram Davidson , Judith Merril , and Theodore Sturgeon .", "prompt_labels": "In(O) New(B-location) York(I-location) ,(O) he(O) socialized(O) at(O) the(O) Hydra(B-organization) Club(I-organization) ,(O) an(O) organization(O) of(O) New(B-location) York(I-location) 's(O) science(B-literary genre) fiction(I-literary genre) writers(O) ,(O) including(O) such(O) luminaries(O) as(O) Isaac(B-writer) Asimov(I-writer) ,(O) James(B-writer) Blish(I-writer) ,(O) Anthony(B-writer) Boucher(I-writer) ,(O) Avram(B-writer) Davidson(I-writer) ,(O) Judith(B-writer) Merril(I-writer) ,(O) and(O) Theodore(B-writer) Sturgeon(I-writer) .(O)"}, "label_list": ["literary genre", "poem", "country", "writer", "magazine", "book", "event", "award", "organization", "location", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 32465, 17779, 11, 33894, 11, 3224, 11, 7061, 11, 14756, 11, 2363, 11, 1567, 11, 10292, 11, 7471, 11, 3813, 11, 1732, 323, 507, 627, 85664, 25, 763, 1561, 4356, 1174, 568, 3674, 1534, 520, 279, 87961, 10349, 1174, 459, 7471, 315, 1561, 4356, 364, 82, 8198, 17422, 16483, 1174, 2737, 1778, 46058, 5548, 439, 42608, 1666, 318, 869, 1174, 7957, 426, 1706, 1174, 21353, 426, 24889, 1174, 7671, 2453, 54345, 1174, 79193, 48961, 321, 1174, 323, 77449, 800, 81562, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "563", "dataset": "mit-movie", "split": "dev", "prediction": "i(O) want(O) a(O) preview(B-trailer) for(O) a(O) horror(B-genre) comedy(I-genre)", "instance": {"id": "563", "words": ["i", "want", "a", "preview", "for", "a", "horror", "comedy"], "labels": ["O", "O", "O", "B-trailer", "O", "O", "B-genre", "I-genre"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, rating, review, plot, actor, genre, title, trailer, year, director, average ratings, song and O.\nSentence: i want a preview for a horror comedy", "prompt_labels": "i(O) want(O) a(O) preview(B-trailer) for(O) a(O) horror(B-genre) comedy(I-genre)"}, "label_list": ["character", "rating", "review", "plot", "actor", "genre", "title", "trailer", "year", "director", "average ratings", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 10959, 11, 3477, 11, 7234, 11, 12360, 11, 17779, 11, 2316, 11, 19809, 11, 1060, 11, 7690, 11, 5578, 18594, 11, 5609, 323, 507, 627, 85664, 25, 602, 1390, 264, 17562, 369, 264, 22169, 23160, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "49", "dataset": "crossner_ai", "split": "dev", "prediction": "It(O) had(O) over(O) 30(O) locations(O) in(O) the(O) U.S.(B-country),(O) Canada(B-country),(O) Mexico(B-country),(O) Brazil(B-country) and(O) Argentina(B-country).(O)", "instance": {"id": "49", "words": ["It", "had", "over", "30", "locations", "in", "the", "U.S.", ",", "Canada", ",", "Mexico", ",", "Brazil", "and", "Argentina", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-country", "O", "B-country", "O", "B-country", "O", "B-country", "O", "B-country", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: metric, organization, product, field, location, country, programming language, algorithm, conference, task, university, researcher, person and O.\nSentence: It had over 30 locations in the U.S. , Canada , Mexico , Brazil and Argentina .", "prompt_labels": "It(O) had(O) over(O) 30(O) locations(O) in(O) the(O) U.S.(B-country) ,(O) Canada(B-country) ,(O) Mexico(B-country) ,(O) Brazil(B-country) and(O) Argentina(B-country) .(O)"}, "label_list": ["metric", "organization", "product", "field", "location", "country", "programming language", "algorithm", "conference", "task", "university", "researcher", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18767, 11, 7471, 11, 2027, 11, 2115, 11, 3813, 11, 3224, 11, 15840, 4221, 11, 12384, 11, 10017, 11, 3465, 11, 12374, 11, 32185, 11, 1732, 323, 507, 627, 85664, 25, 1102, 1047, 927, 220, 966, 10687, 304, 279, 549, 815, 13, 1174, 7008, 1174, 12550, 1174, 16327, 323, 32164, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "145", "dataset": "crossner_politics", "split": "dev", "prediction": "Christian(B-political party) Voice(I-political party) was(O) the(O) first(O) of(O) the(O) Christian(B-political party) Right(I-political party) groups(O),(O) pre-dating(O) the(O) Christian(B-political party) Coalition(I-political party) of(I-political party) America(I-political party),(O) American(B-political party) Coalition(I-political party) for(I-political party) Traditional(I-political party) Values(I-political party),(O) Concerned(B-political party) Women(I-political party) for(I-political party) America(I-political party),(O) Moral(B-political party) Majority(I-political party),(O) Family(B-political party) Research(I-political party) Council(I-political party),(O) and(O) other(O) Christian(O) political(O) groups(O).(O)", "instance": {"id": "145", "words": ["Christian", "Voice", "was", "the", "first", "of", "the", "Christian", "Right", "groups", ",", "pre-dating", "the", "Christian", "Coalition", "of", "America", ",", "American", "Coalition", "for", "Traditional", "Values", ",", "Concerned", "Women", "for", "America", ",", "Moral", "Majority", ",", "Family", "Research", "Council", ",", "and", "other", "Christian", "political", "groups", "."], "labels": ["B-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "I-organization", "O", "B-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, event, political party, location, politician, organization, person, country and O.\nSentence: Christian Voice was the first of the Christian Right groups , pre-dating the Christian Coalition of America , American Coalition for Traditional Values , Concerned Women for America , Moral Majority , Family Research Council , and other Christian political groups .", "prompt_labels": "Christian(B-organization) Voice(I-organization) was(O) the(O) first(O) of(O) the(O) Christian(O) Right(O) groups(O) ,(O) pre-dating(O) the(O) Christian(B-organization) Coalition(I-organization) of(I-organization) America(I-organization) ,(O) American(B-organization) Coalition(I-organization) for(I-organization) Traditional(I-organization) Values(I-organization) ,(O) Concerned(B-organization) Women(I-organization) for(I-organization) America(I-organization) ,(O) Moral(B-organization) Majority(I-organization) ,(O) Family(B-organization) Research(I-organization) Council(I-organization) ,(O) and(O) other(O) Christian(O) political(O) groups(O) .(O)"}, "label_list": ["election", "event", "political party", "location", "politician", "organization", "person", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 6355, 11, 1567, 11, 5054, 4717, 11, 3813, 11, 37038, 11, 7471, 11, 1732, 11, 3224, 323, 507, 627, 85664, 25, 9052, 29030, 574, 279, 1176, 315, 279, 9052, 10291, 5315, 1174, 864, 1773, 1113, 279, 9052, 36892, 315, 5270, 1174, 3778, 36892, 369, 46560, 26028, 1174, 52347, 291, 11215, 369, 5270, 1174, 89606, 55135, 1174, 12517, 8483, 9251, 1174, 323, 1023, 9052, 5054, 5315, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "437", "dataset": "mit-restaurant", "split": "dev", "prediction": "find(O) me(O) the(O) nearest(B-Location) placed(I-Location) to(O) eat(O)", "instance": {"id": "437", "words": ["find", "me", "the", "nearest", "placed", "to", "eat"], "labels": ["O", "O", "O", "B-Location", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Dish, Cuisine, Amenity, Hours, Location, Restaurant Name, Rating and O.\nSentence: find me the nearest placed to eat", "prompt_labels": "find(O) me(O) the(O) nearest(B-Location) placed(O) to(O) eat(O)"}, "label_list": ["Price", "Dish", "Cuisine", "Amenity", "Hours", "Location", "Restaurant Name", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 49268, 11, 81961, 11, 3383, 56685, 11, 30192, 11, 10067, 11, 26568, 4076, 11, 19767, 323, 507, 627, 85664, 25, 1505, 757, 279, 24379, 9277, 311, 8343, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "185", "dataset": "crossner_politics", "split": "dev", "prediction": "The(O) Australian(B-political party) Greens(I-political party) in(O) Queensland(B-location) have(O) traditionally(O) polled(O) strongest(O) in(O) the(O) usually(O) Labor(B-political party) -(O) held(O) seats(O) of(O) Mount(B-location) Coot-tha(I-location) and(O) South(B-location) Brisbane(I-location),(O) as(O) well(O) as(O) the(O) usually(O) Liberal(B-political party) National(I-political party) Party(I-political party) of(I-political party) Queensland(I-political party) -(O) held(O) seat(O) of(O) Noosa(B-location),(O) polling(O) over(O) 20(O) %(O) of(O) the(O) primary(O) vote(O) in(O) these(O) seats(O) at(O) the(O) 2015(B-election) Queensland(I-election) state(I-election) election(I-election).(O)", "instance": {"id": "185", "words": ["The", "Australian", "Greens", "in", "Queensland", "have", "traditionally", "polled", "strongest", "in", "the", "usually", "Labor", "-held", "seats", "of", "Mount", "Coot-tha", "and", "South", "Brisbane", ",", "as", "well", "as", "the", "usually", "Liberal", "National", "Party", "of", "Queensland", "-held", "seat", "of", "Noosa", ",", "polling", "over", "20", "%", "of", "the", "primary", "vote", "in", "these", "seats", "at", "the", "2015", "Queensland", "state", "election", "."], "labels": ["O", "B-political party", "I-political party", "O", "B-location", "O", "O", "O", "O", "O", "O", "O", "B-political party", "O", "O", "O", "B-location", "I-location", "O", "B-location", "I-location", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O", "B-location", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, country, election, politician, political party, event, person, organization and O.\nSentence: The Australian Greens in Queensland have traditionally polled strongest in the usually Labor -held seats of Mount Coot-tha and South Brisbane , as well as the usually Liberal National Party of Queensland -held seat of Noosa , polling over 20 % of the primary vote in these seats at the 2015 Queensland state election .", "prompt_labels": "The(O) Australian(B-political party) Greens(I-political party) in(O) Queensland(B-location) have(O) traditionally(O) polled(O) strongest(O) in(O) the(O) usually(O) Labor(B-political party) -held(O) seats(O) of(O) Mount(B-location) Coot-tha(I-location) and(O) South(B-location) Brisbane(I-location) ,(O) as(O) well(O) as(O) the(O) usually(O) Liberal(B-political party) National(I-political party) Party(I-political party) of(I-political party) Queensland(I-political party) -held(O) seat(O) of(O) Noosa(B-location) ,(O) polling(O) over(O) 20(O) %(O) of(O) the(O) primary(O) vote(O) in(O) these(O) seats(O) at(O) the(O) 2015(B-election) Queensland(I-election) state(I-election) election(I-election) .(O)"}, "label_list": ["location", "country", "election", "politician", "political party", "event", "person", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 3224, 11, 6355, 11, 37038, 11, 5054, 4717, 11, 1567, 11, 1732, 11, 7471, 323, 507, 627, 85664, 25, 578, 13673, 42691, 304, 41306, 617, 36342, 84721, 31005, 304, 279, 6118, 15277, 482, 28708, 16712, 315, 10640, 356, 1944, 7716, 64, 323, 4987, 47335, 1174, 439, 1664, 439, 279, 6118, 31158, 5165, 8722, 315, 41306, 482, 28708, 10954, 315, 2360, 12252, 1174, 31744, 927, 220, 508, 1034, 315, 279, 6156, 7055, 304, 1521, 16712, 520, 279, 220, 679, 20, 41306, 1614, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "127", "dataset": "crossner_music", "split": "dev", "prediction": "This(O) period(O) on(O) the(O) RCA(B-album) label(O) ((O) 1971-75(O) )(O) produced(O) Muswell(B-album) Hillbillies(I-album),(O) Everybody(B-album)'s(I-album) in(I-album) Show-Biz(I-album),(O) Preservation(B-album) Act(I-album) 1(I-album) and(O) Preservation(B-album) Act(I-album) 2(I-album),(O) Soap(B-album) Opera(I-album) and(O) Schoolboys(B-album) in(I-album) Disgrace(I-album).(O)", "instance": {"id": "127", "words": ["This", "period", "on", "the", "RCA", "label", "(", "1971-75", ")", "produced", "Muswell", "Hillbillies", ",", "Everybody", "'s", "in", "Show-Biz", ",", "Preservation", "Act", "1", "and", "Preservation", "Act", "2", ",", "Soap", "Opera", "and", "Schoolboys", "in", "Disgrace", "."], "labels": ["O", "O", "O", "O", "B-organization", "I-organization", "O", "O", "O", "O", "B-album", "I-album", "O", "B-album", "I-album", "I-album", "I-album", "O", "B-album", "I-album", "I-album", "O", "B-album", "I-album", "I-album", "O", "B-album", "I-album", "O", "B-album", "I-album", "I-album", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, band, song, country, event, organization, location, musical instrument, award, person, music genre, album and O.\nSentence: This period on the RCA label ( 1971-75 ) produced Muswell Hillbillies , Everybody 's in Show-Biz , Preservation Act 1 and Preservation Act 2 , Soap Opera and Schoolboys in Disgrace .", "prompt_labels": "This(O) period(O) on(O) the(O) RCA(B-organization) label(I-organization) ((O) 1971-75(O) )(O) produced(O) Muswell(B-album) Hillbillies(I-album) ,(O) Everybody(B-album) 's(I-album) in(I-album) Show-Biz(I-album) ,(O) Preservation(B-album) Act(I-album) 1(I-album) and(O) Preservation(B-album) Act(I-album) 2(I-album) ,(O) Soap(B-album) Opera(I-album) and(O) Schoolboys(B-album) in(I-album) Disgrace(I-album) .(O)"}, "label_list": ["musical artist", "band", "song", "country", "event", "organization", "location", "musical instrument", "award", "person", "music genre", "album"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18273, 10255, 11, 7200, 11, 5609, 11, 3224, 11, 1567, 11, 7471, 11, 3813, 11, 18273, 14473, 11, 10292, 11, 1732, 11, 4731, 17779, 11, 8176, 323, 507, 627, 85664, 25, 1115, 4261, 389, 279, 99431, 2440, 320, 220, 4468, 16, 12, 2075, 883, 9124, 5444, 9336, 8270, 30742, 552, 1174, 51898, 364, 82, 304, 7073, 7826, 450, 1174, 92041, 3298, 220, 16, 323, 92041, 3298, 220, 17, 1174, 61731, 39679, 323, 6150, 30123, 304, 4185, 911, 580, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "610", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) need(O) to(O) find(O) a(O) place(O) that(O) is(O) open(B-Hours) every(I-Hours) day(I-Hours)", "instance": {"id": "610", "words": ["i", "need", "to", "find", "a", "place", "that", "is", "open", "every", "day"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-Hours", "I-Hours", "I-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Location, Restaurant Name, Price, Rating, Hours, Amenity, Dish and O.\nSentence: i need to find a place that is open every day", "prompt_labels": "i(O) need(O) to(O) find(O) a(O) place(O) that(O) is(O) open(B-Hours) every(I-Hours) day(I-Hours)"}, "label_list": ["Cuisine", "Location", "Restaurant Name", "Price", "Rating", "Hours", "Amenity", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 10067, 11, 26568, 4076, 11, 8650, 11, 19767, 11, 30192, 11, 3383, 56685, 11, 49268, 323, 507, 627, 85664, 25, 602, 1205, 311, 1505, 264, 2035, 430, 374, 1825, 1475, 1938, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "568", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) a(O) comedy(B-genre) about(O) a(O) football(B-plot) team(I-plot)", "instance": {"id": "568", "words": ["show", "me", "a", "comedy", "about", "a", "football", "team"], "labels": ["O", "O", "O", "B-genre", "O", "O", "B-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, genre, title, average ratings, song, rating, actor, director, trailer, character, year, review and O.\nSentence: show me a comedy about a football team", "prompt_labels": "show(O) me(O) a(O) comedy(B-genre) about(O) a(O) football(B-plot) team(I-plot)"}, "label_list": ["plot", "genre", "title", "average ratings", "song", "rating", "actor", "director", "trailer", "character", "year", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 17779, 11, 2316, 11, 5578, 18594, 11, 5609, 11, 10959, 11, 12360, 11, 7690, 11, 19809, 11, 3752, 11, 1060, 11, 3477, 323, 507, 627, 85664, 25, 1501, 757, 264, 23160, 922, 264, 9141, 2128, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "191", "dataset": "mit-restaurant", "split": "dev", "prediction": "can(O) you(O) locate(O) a(O) diner(O) that(O) has(O) a(O) smoking(B-Amenity) section(I-Amenity) in(O) this(B-Location) area(I-Location)", "instance": {"id": "191", "words": ["can", "you", "locate", "a", "diner", "that", "has", "a", "smoking", "section", "in", "this", "area"], "labels": ["O", "O", "O", "O", "B-Cuisine", "O", "O", "O", "B-Amenity", "I-Amenity", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Restaurant Name, Amenity, Hours, Dish, Price, Rating, Cuisine and O.\nSentence: can you locate a diner that has a smoking section in this area", "prompt_labels": "can(O) you(O) locate(O) a(O) diner(B-Cuisine) that(O) has(O) a(O) smoking(B-Amenity) section(I-Amenity) in(O) this(B-Location) area(I-Location)"}, "label_list": ["Location", "Restaurant Name", "Amenity", "Hours", "Dish", "Price", "Rating", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 26568, 4076, 11, 3383, 56685, 11, 30192, 11, 49268, 11, 8650, 11, 19767, 11, 81961, 323, 507, 627, 85664, 25, 649, 499, 25539, 264, 89206, 430, 706, 264, 20149, 3857, 304, 420, 3158, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "441", "dataset": "crossner_politics", "split": "dev", "prediction": "The(O) group(O) was(O) one(O) of(O) a(O) number(O) of(O) far-right(O) Islamophobic(O) groups(O),(O) including(O) the(O) Q(B-political party) Society(I-political party),(O) Reclaim(B-political party) Australia(I-political party),(O) TRUE(B-political party) Blue(I-political party) Crew(I-political party) and(O) the(O) United(B-political party) Patriots(I-political party) Front(I-political party),(O) that(O) opposed(O) the(O) construction(O) of(O) a(O) $(O) 3(O) million(O) mosque(O) and(O) Islamic(O) community(O) centre(O) in(O) Bendigo(B-location),(O) Victoria(B-location).(O)", "instance": {"id": "441", "words": ["The", "group", "was", "one", "of", "a", "number", "of", "far-right", "Islamophobic", "groups", ",", "including", "the", "Q", "Society", ",", "Reclaim", "Australia", ",", "TRUE", "Blue", "Crew", "and", "the", "United", "Patriots", "Front", ",", "that", "opposed", "the", "construction", "of", "a", "$", "3", "million", "mosque", "and", "Islamic", "community", "centre", "in", "Bendigo", ",", "Victoria", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "O", "O", "O", "O", "B-organization", "I-organization", "O", "B-organization", "I-organization", "O", "B-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "O", "B-location", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, event, politician, location, person, organization, political party, election and O.\nSentence: The group was one of a number of far-right Islamophobic groups , including the Q Society , Reclaim Australia , TRUE Blue Crew and the United Patriots Front , that opposed the construction of a $ 3 million mosque and Islamic community centre in Bendigo , Victoria .", "prompt_labels": "The(O) group(O) was(O) one(O) of(O) a(O) number(O) of(O) far-right(O) Islamophobic(B-organization) groups(O) ,(O) including(O) the(O) Q(B-organization) Society(I-organization) ,(O) Reclaim(B-organization) Australia(I-organization) ,(O) TRUE(B-organization) Blue(I-organization) Crew(I-organization) and(O) the(O) United(B-organization) Patriots(I-organization) Front(I-organization) ,(O) that(O) opposed(O) the(O) construction(O) of(O) a(O) $(O) 3(O) million(O) mosque(O) and(O) Islamic(O) community(O) centre(O) in(O) Bendigo(B-location) ,(O) Victoria(B-location) .(O)"}, "label_list": ["country", "event", "politician", "location", "person", "organization", "political party", "election"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 1567, 11, 37038, 11, 3813, 11, 1732, 11, 7471, 11, 5054, 4717, 11, 6355, 323, 507, 627, 85664, 25, 578, 1912, 574, 832, 315, 264, 1396, 315, 3117, 6840, 15256, 61800, 5315, 1174, 2737, 279, 1229, 13581, 1174, 1050, 8017, 8494, 1174, 8378, 8868, 36037, 323, 279, 3723, 33617, 15248, 1174, 430, 16475, 279, 8246, 315, 264, 400, 220, 18, 3610, 51112, 323, 15558, 4029, 12541, 304, 48838, 7992, 1174, 23225, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "372", "dataset": "crossner_literature", "split": "dev", "prediction": "He(O) wrote(O) for(O) many(O) publications(O),(O) including(O) Rolling(B-magazine) Stone(I-magazine),(O) Esquire(B-magazine),(O) The(B-magazine) Boston(I-magazine) Globe(I-magazine),(O) Chicago(B-magazine) Tribune(I-magazine),(O) The(B-magazine) New(I-magazine) York(I-magazine) Times(I-magazine),(O) The(B-magazine) San(I-magazine) Francisco(I-magazine) Examiner(I-magazine),(O) Time(B-magazine),(O) Vanity(B-magazine) Fair(I-magazine),(O) The(B-magazine) San(I-magazine) Juan(I-magazine) Star(I-magazine),(O) and(O) Playboy(B-magazine).(O)", "instance": {"id": "372", "words": ["He", "wrote", "for", "many", "publications", ",", "including", "Rolling", "Stone", ",", "Esquire", ",", "The", "Boston", "Globe", ",", "Chicago", "Tribune", ",", "The", "New", "York", "Times", ",", "The", "San", "Francisco", "Examiner", ",", "Time", ",", "Vanity", "Fair", ",", "The", "San", "Juan", "Star", ",", "and", "Playboy", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-magazine", "I-magazine", "O", "B-magazine", "O", "B-organization", "I-organization", "I-organization", "O", "B-organization", "I-organization", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "B-magazine", "O", "B-magazine", "I-magazine", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-magazine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, location, event, literary genre, country, poem, book, person, writer, award, organization and O.\nSentence: He wrote for many publications , including Rolling Stone , Esquire , The Boston Globe , Chicago Tribune , The New York Times , The San Francisco Examiner , Time , Vanity Fair , The San Juan Star , and Playboy .", "prompt_labels": "He(O) wrote(O) for(O) many(O) publications(O) ,(O) including(O) Rolling(B-magazine) Stone(I-magazine) ,(O) Esquire(B-magazine) ,(O) The(B-organization) Boston(I-organization) Globe(I-organization) ,(O) Chicago(B-organization) Tribune(I-organization) ,(O) The(B-organization) New(I-organization) York(I-organization) Times(I-organization) ,(O) The(B-organization) San(I-organization) Francisco(I-organization) Examiner(I-organization) ,(O) Time(B-magazine) ,(O) Vanity(B-magazine) Fair(I-magazine) ,(O) The(B-organization) San(I-organization) Juan(I-organization) Star(I-organization) ,(O) and(O) Playboy(B-magazine) .(O)"}, "label_list": ["magazine", "location", "event", "literary genre", "country", "poem", "book", "person", "writer", "award", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 14756, 11, 3813, 11, 1567, 11, 32465, 17779, 11, 3224, 11, 33894, 11, 2363, 11, 1732, 11, 7061, 11, 10292, 11, 7471, 323, 507, 627, 85664, 25, 1283, 6267, 369, 1690, 29085, 1174, 2737, 46048, 14637, 1174, 9419, 999, 1174, 578, 10406, 41910, 1174, 10780, 41439, 1174, 578, 1561, 4356, 8691, 1174, 578, 5960, 13175, 79346, 1174, 4212, 1174, 69494, 14930, 1174, 578, 5960, 29604, 7834, 1174, 323, 91079, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "123", "dataset": "mit-restaurant", "split": "dev", "prediction": "can(O) i(O) get(O) a(O) list(O) of(O) close(B-Location) fast(B-Cuisine) food(I-Cuisine) places(O)", "instance": {"id": "123", "words": ["can", "i", "get", "a", "list", "of", "close", "fast", "food", "places"], "labels": ["O", "O", "O", "O", "O", "O", "B-Location", "B-Cuisine", "I-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Price, Restaurant Name, Hours, Rating, Dish, Amenity, Location and O.\nSentence: can i get a list of close fast food places", "prompt_labels": "can(O) i(O) get(O) a(O) list(O) of(O) close(B-Location) fast(B-Cuisine) food(I-Cuisine) places(O)"}, "label_list": ["Cuisine", "Price", "Restaurant Name", "Hours", "Rating", "Dish", "Amenity", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 8650, 11, 26568, 4076, 11, 30192, 11, 19767, 11, 49268, 11, 3383, 56685, 11, 10067, 323, 507, 627, 85664, 25, 649, 602, 636, 264, 1160, 315, 3345, 5043, 3691, 7634, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2303", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) directed(O) heat(B-title) wave(I-title)", "instance": {"id": "2303", "words": ["who", "directed", "heat", "wave"], "labels": ["O", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, genre, actor, song, rating, review, year, plot, director, character, title, average ratings and O.\nSentence: who directed heat wave", "prompt_labels": "who(O) directed(O) heat(B-title) wave(I-title)"}, "label_list": ["trailer", "genre", "actor", "song", "rating", "review", "year", "plot", "director", "character", "title", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 17779, 11, 12360, 11, 5609, 11, 10959, 11, 3477, 11, 1060, 11, 7234, 11, 7690, 11, 3752, 11, 2316, 11, 5578, 18594, 323, 507, 627, 85664, 25, 889, 15910, 8798, 12330, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "615", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) all(O) the(O) tom(B-actor) cruise(I-actor) movies(O) from(O) 2000s(B-year)", "instance": {"id": "615", "words": ["list", "all", "the", "tom", "cruise", "movies", "from", "2000s"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, year, average ratings, review, character, title, plot, song, rating, director, trailer, genre and O.\nSentence: list all the tom cruise movies from 2000s", "prompt_labels": "list(O) all(O) the(O) tom(B-actor) cruise(I-actor) movies(O) from(O) 2000s(B-year)"}, "label_list": ["actor", "year", "average ratings", "review", "character", "title", "plot", "song", "rating", "director", "trailer", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 1060, 11, 5578, 18594, 11, 3477, 11, 3752, 11, 2316, 11, 7234, 11, 5609, 11, 10959, 11, 7690, 11, 19809, 11, 17779, 323, 507, 627, 85664, 25, 1160, 682, 279, 10390, 31551, 9698, 505, 220, 1049, 15, 82, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "359", "dataset": "crossner_politics", "split": "dev", "prediction": "Tassi(B-politician)'s(O) first(O) run(O) for(O) elective(O) office(O) was(O) as(O) a(O) candidate(O) for(O) the(O) Ontario(B-political party) Liberal(I-political party) Party(I-political party) in(O) the(O) 1995(B-election) Ontario(I-election) general(I-election) election(I-election),(O) where(O) she(O) finished(O) a(O) narrow(O) second(O) to(O) Ontario(B-political party) New(I-political party) Democratic(I-political party) Party(I-political party) incumbent(O) David(B-politician) Christopherson(I-politician).(O)", "instance": {"id": "359", "words": ["Tassi", "'s", "first", "run", "for", "elective", "office", "was", "as", "a", "candidate", "for", "the", "Ontario", "Liberal", "Party", "in", "the", "1995", "Ontario", "general", "election", ",", "where", "she", "finished", "a", "narrow", "second", "to", "Ontario", "New", "Democratic", "Party", "incumbent", "David", "Christopherson", "."], "labels": ["B-politician", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "B-politician", "I-politician", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, politician, event, country, political party, organization, person, location and O.\nSentence: Tassi 's first run for elective office was as a candidate for the Ontario Liberal Party in the 1995 Ontario general election , where she finished a narrow second to Ontario New Democratic Party incumbent David Christopherson .", "prompt_labels": "Tassi(B-politician) 's(O) first(O) run(O) for(O) elective(O) office(O) was(O) as(O) a(O) candidate(O) for(O) the(O) Ontario(B-political party) Liberal(I-political party) Party(I-political party) in(O) the(O) 1995(B-election) Ontario(I-election) general(I-election) election(I-election) ,(O) where(O) she(O) finished(O) a(O) narrow(O) second(O) to(O) Ontario(B-political party) New(I-political party) Democratic(I-political party) Party(I-political party) incumbent(O) David(B-politician) Christopherson(I-politician) .(O)"}, "label_list": ["election", "politician", "event", "country", "political party", "organization", "person", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 6355, 11, 37038, 11, 1567, 11, 3224, 11, 5054, 4717, 11, 7471, 11, 1732, 11, 3813, 323, 507, 627, 85664, 25, 350, 82643, 364, 82, 1176, 1629, 369, 98590, 5274, 574, 439, 264, 9322, 369, 279, 21193, 31158, 8722, 304, 279, 220, 2550, 20, 21193, 4689, 6355, 1174, 1405, 1364, 8220, 264, 15376, 2132, 311, 21193, 1561, 11650, 8722, 51382, 6941, 95693, 1293, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "271", "dataset": "mit-restaurant", "split": "dev", "prediction": "do(O) you(O) think(O) the(B-Restaurant Name) noodle(I-Restaurant Name) bar(I-Restaurant Name) is(O) open(O)", "instance": {"id": "271", "words": ["do", "you", "think", "the", "noodle", "bar", "is", "open"], "labels": ["O", "O", "O", "O", "B-Restaurant Name", "I-Restaurant Name", "O", "B-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Amenity, Cuisine, Dish, Location, Price, Rating, Restaurant Name and O.\nSentence: do you think the noodle bar is open", "prompt_labels": "do(O) you(O) think(O) the(O) noodle(B-Restaurant Name) bar(I-Restaurant Name) is(O) open(B-Hours)"}, "label_list": ["Hours", "Amenity", "Cuisine", "Dish", "Location", "Price", "Rating", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 3383, 56685, 11, 81961, 11, 49268, 11, 10067, 11, 8650, 11, 19767, 11, 26568, 4076, 323, 507, 627, 85664, 25, 656, 499, 1781, 279, 46895, 273, 3703, 374, 1825, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1528", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) there(O) a(O) movie(O) with(O) six(B-average ratings) stars(I-average ratings) rated(O) r(B-rating) with(O) fantasy(B-genre)", "instance": {"id": "1528", "words": ["is", "there", "a", "movie", "with", "six", "stars", "rated", "r", "with", "fantasy"], "labels": ["O", "O", "O", "O", "O", "B-average ratings", "I-average ratings", "O", "B-rating", "O", "B-genre"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, plot, average ratings, rating, character, genre, review, director, year, title, trailer, actor and O.\nSentence: is there a movie with six stars rated r with fantasy", "prompt_labels": "is(O) there(O) a(O) movie(O) with(O) six(B-average ratings) stars(I-average ratings) rated(O) r(B-rating) with(O) fantasy(B-genre)"}, "label_list": ["song", "plot", "average ratings", "rating", "character", "genre", "review", "director", "year", "title", "trailer", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 7234, 11, 5578, 18594, 11, 10959, 11, 3752, 11, 17779, 11, 3477, 11, 7690, 11, 1060, 11, 2316, 11, 19809, 11, 12360, 323, 507, 627, 85664, 25, 374, 1070, 264, 5818, 449, 4848, 9958, 22359, 436, 449, 18884, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "100", "dataset": "crossner_music", "split": "dev", "prediction": "Taylor(B-musical artist) Momsen(I-musical artist),(O) Marcus(B-musical artist) Durant(I-musical artist),(O) Brandi(B-musical artist) Carlile(I-musical artist) and(O) Taylor(B-musical artist) Hawkins(I-musical artist) contributed(O) vocals(O) to(O) Soundgarden(B-album),(O) who(O) performed(O) Rusty(B-song) Cage(I-song),(O) Flower(B-song),(O) Outshined(B-song),(O) Drawing(B-song) Flies(I-song),(O) Loud(B-song) Love(I-song),(O) I(B-song) Awake(I-song),(O) The(B-song) Day(I-song) I(I-song) Tried(I-song) to(I-song) Live(I-song) and(O) Black(B-song) Hole(I-song) Sun(I-song),(O) making(O) this(O) their(O) only(O) performance(O) since(O) Cornell(B-musical artist)'s(O) death(O).(O)", "instance": {"id": "100", "words": ["Taylor", "Momsen", ",", "Marcus", "Durant", ",", "Brandi", "Carlile", "and", "Taylor", "Hawkins", "contributed", "vocals", "to", "Soundgarden", ",", "who", "performed", "Rusty", "Cage", ",", "Flower", ",", "Outshined", ",", "Drawing", "Flies", ",", "Loud", "Love", ",", "I", "Awake", ",", "The", "Day", "I", "Tried", "to", "Live", "and", "Black", "Hole", "Sun", ",", "making", "this", "their", "only", "performance", "since", "Cornell", "'s", "death", "."], "labels": ["B-musical artist", "I-musical artist", "O", "B-band", "I-band", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "O", "O", "B-band", "O", "O", "O", "B-song", "I-song", "O", "B-song", "O", "B-song", "O", "B-song", "I-song", "O", "B-song", "I-song", "O", "B-song", "I-song", "O", "B-song", "I-song", "I-song", "I-song", "I-song", "I-song", "O", "B-song", "I-song", "I-song", "O", "O", "O", "O", "O", "O", "O", "B-musical artist", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, location, music genre, event, award, band, album, song, country, organization, musical artist, person and O.\nSentence: Taylor Momsen , Marcus Durant , Brandi Carlile and Taylor Hawkins contributed vocals to Soundgarden , who performed Rusty Cage , Flower , Outshined , Drawing Flies , Loud Love , I Awake , The Day I Tried to Live and Black Hole Sun , making this their only performance since Cornell 's death .", "prompt_labels": "Taylor(B-musical artist) Momsen(I-musical artist) ,(O) Marcus(B-band) Durant(I-band) ,(O) Brandi(B-musical artist) Carlile(I-musical artist) and(O) Taylor(B-musical artist) Hawkins(I-musical artist) contributed(O) vocals(O) to(O) Soundgarden(B-band) ,(O) who(O) performed(O) Rusty(B-song) Cage(I-song) ,(O) Flower(B-song) ,(O) Outshined(B-song) ,(O) Drawing(B-song) Flies(I-song) ,(O) Loud(B-song) Love(I-song) ,(O) I(B-song) Awake(I-song) ,(O) The(B-song) Day(I-song) I(I-song) Tried(I-song) to(I-song) Live(I-song) and(O) Black(B-song) Hole(I-song) Sun(I-song) ,(O) making(O) this(O) their(O) only(O) performance(O) since(O) Cornell(B-musical artist) 's(O) death(O) .(O)"}, "label_list": ["musical instrument", "location", "music genre", "event", "award", "band", "album", "song", "country", "organization", "musical artist", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18273, 14473, 11, 3813, 11, 4731, 17779, 11, 1567, 11, 10292, 11, 7200, 11, 8176, 11, 5609, 11, 3224, 11, 7471, 11, 18273, 10255, 11, 1732, 323, 507, 627, 85664, 25, 16844, 84395, 268, 1174, 36783, 67440, 1174, 16835, 72, 22770, 458, 323, 16844, 70687, 20162, 47196, 311, 14936, 70, 8506, 1174, 889, 10887, 34889, 88, 58989, 1174, 43786, 1174, 4470, 939, 1619, 1174, 38859, 3061, 552, 1174, 80648, 10919, 1174, 358, 42322, 1174, 578, 6187, 358, 85183, 311, 11406, 323, 5348, 52029, 8219, 1174, 3339, 420, 872, 1193, 5178, 2533, 56819, 364, 82, 4648, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "499", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) hans(B-director) zimmer(I-director) write(O) the(O) music(B-song) for(O) pirates(B-title) of(I-title) the(I-title) carribean(I-title)", "instance": {"id": "499", "words": ["did", "hans", "zimmer", "write", "the", "music", "for", "pirates", "of", "the", "carribean"], "labels": ["O", "B-song", "I-song", "O", "O", "O", "O", "B-song", "I-song", "I-song", "I-song"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, plot, title, director, rating, review, genre, trailer, actor, year, character, average ratings and O.\nSentence: did hans zimmer write the music for pirates of the carribean", "prompt_labels": "did(O) hans(B-song) zimmer(I-song) write(O) the(O) music(O) for(O) pirates(B-song) of(I-song) the(I-song) carribean(I-song)"}, "label_list": ["song", "plot", "title", "director", "rating", "review", "genre", "trailer", "actor", "year", "character", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 7234, 11, 2316, 11, 7690, 11, 10959, 11, 3477, 11, 17779, 11, 19809, 11, 12360, 11, 1060, 11, 3752, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1550, 88644, 1167, 19519, 3350, 279, 4731, 369, 62575, 315, 279, 1841, 462, 17937, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "335", "dataset": "crossner_literature", "split": "dev", "prediction": "Several(O) of(O) Du(B-writer) Maurier(I-writer)'s(O) other(O) novels(B-literary genre) have(O) also(O) been(O) adapted(O) for(O) the(O) screen(O),(O) including(O) Jamaica(B-book) Inn(I-book),(O) Frenchman(B-book)'s(I-book) Creek(I-book),(O) Hungry(B-book) Hill(I-book),(O) and(O) My(B-book) Cousin(I-book) Rachel(I-book).(O)", "instance": {"id": "335", "words": ["Several", "of", "Du", "Maurier", "'s", "other", "novels", "have", "also", "been", "adapted", "for", "the", "screen", ",", "including", "Jamaica", "Inn", ",", "Frenchman", "'s", "Creek", ",", "Hungry", "Hill", ",", "and", "My", "Cousin", "Rachel", "."], "labels": ["O", "O", "B-writer", "I-writer", "O", "O", "B-literary genre", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-book", "I-book", "O", "B-book", "I-book", "I-book", "O", "B-book", "I-book", "O", "O", "B-book", "I-book", "I-book", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: writer, award, person, country, magazine, organization, event, poem, location, literary genre, book and O.\nSentence: Several of Du Maurier 's other novels have also been adapted for the screen , including Jamaica Inn , Frenchman 's Creek , Hungry Hill , and My Cousin Rachel .", "prompt_labels": "Several(O) of(O) Du(B-writer) Maurier(I-writer) 's(O) other(O) novels(B-literary genre) have(O) also(O) been(O) adapted(O) for(O) the(O) screen(O) ,(O) including(O) Jamaica(B-book) Inn(I-book) ,(O) Frenchman(B-book) 's(I-book) Creek(I-book) ,(O) Hungry(B-book) Hill(I-book) ,(O) and(O) My(B-book) Cousin(I-book) Rachel(I-book) .(O)"}, "label_list": ["writer", "award", "person", "country", "magazine", "organization", "event", "poem", "location", "literary genre", "book"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7061, 11, 10292, 11, 1732, 11, 3224, 11, 14756, 11, 7471, 11, 1567, 11, 33894, 11, 3813, 11, 32465, 17779, 11, 2363, 323, 507, 627, 85664, 25, 26778, 315, 16062, 34492, 1291, 364, 82, 1023, 32963, 617, 1101, 1027, 30464, 369, 279, 4264, 1174, 2737, 57275, 17382, 1174, 8753, 1543, 364, 82, 24076, 1174, 26604, 894, 8270, 1174, 323, 3092, 61569, 258, 32532, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "895", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movies(O) from(O) the(O) 90s(B-year) did(O) clint(B-director) eastwood(I-director) direct(O)", "instance": {"id": "895", "words": ["what", "movies", "from", "the", "90s", "did", "clint", "eastwood", "direct"], "labels": ["O", "O", "O", "O", "B-year", "O", "B-director", "I-director", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, song, year, average ratings, genre, actor, plot, character, director, trailer, review, rating and O.\nSentence: what movies from the 90s did clint eastwood direct", "prompt_labels": "what(O) movies(O) from(O) the(O) 90s(B-year) did(O) clint(B-director) eastwood(I-director) direct(O)"}, "label_list": ["title", "song", "year", "average ratings", "genre", "actor", "plot", "character", "director", "trailer", "review", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 5609, 11, 1060, 11, 5578, 18594, 11, 17779, 11, 12360, 11, 7234, 11, 3752, 11, 7690, 11, 19809, 11, 3477, 11, 10959, 323, 507, 627, 85664, 25, 1148, 9698, 505, 279, 220, 1954, 82, 1550, 1206, 396, 11226, 6798, 2167, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1354", "dataset": "mit-movie", "split": "dev", "prediction": "im(O) looking(O) for(O) a(O) pg(B-rating) movie(O) featuring(O) animation(B-genre) and(O) starring(O) michael(B-actor) gross(I-actor) that(O) rated(O) an(O) average(O) of(O) nine(B-average ratings)", "instance": {"id": "1354", "words": ["im", "looking", "for", "a", "pg", "movie", "featuring", "animation", "and", "starring", "michael", "gross", "that", "rated", "an", "average", "of", "nine"], "labels": ["O", "O", "O", "O", "B-rating", "O", "O", "B-genre", "O", "O", "B-actor", "I-actor", "O", "O", "O", "O", "O", "B-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, actor, rating, song, title, review, year, character, plot, average ratings, trailer, director and O.\nSentence: im looking for a pg movie featuring animation and starring michael gross that rated an average of nine", "prompt_labels": "im(O) looking(O) for(O) a(O) pg(B-rating) movie(O) featuring(O) animation(B-genre) and(O) starring(O) michael(B-actor) gross(I-actor) that(O) rated(O) an(O) average(O) of(O) nine(B-average ratings)"}, "label_list": ["genre", "actor", "rating", "song", "title", "review", "year", "character", "plot", "average ratings", "trailer", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 12360, 11, 10959, 11, 5609, 11, 2316, 11, 3477, 11, 1060, 11, 3752, 11, 7234, 11, 5578, 18594, 11, 19809, 11, 7690, 323, 507, 627, 85664, 25, 737, 3411, 369, 264, 17953, 5818, 16850, 10571, 323, 40500, 89006, 20547, 430, 22359, 459, 5578, 315, 11888, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2346", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) christopher(B-director) nolan(I-director) direct(O) a(O) pg(B-rating) 13(I-rating) disaster(B-genre) film(O)", "instance": {"id": "2346", "words": ["did", "christopher", "nolan", "direct", "a", "pg", "13", "disaster", "film"], "labels": ["O", "B-director", "I-director", "O", "O", "B-rating", "I-rating", "B-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, review, character, genre, actor, song, rating, trailer, title, plot, year, director and O.\nSentence: did christopher nolan direct a pg 13 disaster film", "prompt_labels": "did(O) christopher(B-director) nolan(I-director) direct(O) a(O) pg(B-rating) 13(I-rating) disaster(B-genre) film(O)"}, "label_list": ["average ratings", "review", "character", "genre", "actor", "song", "rating", "trailer", "title", "plot", "year", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 3477, 11, 3752, 11, 17779, 11, 12360, 11, 5609, 11, 10959, 11, 19809, 11, 2316, 11, 7234, 11, 1060, 11, 7690, 323, 507, 627, 85664, 25, 1550, 26853, 17370, 308, 38872, 2167, 264, 17953, 220, 1032, 21426, 4632, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2228", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) was(O) the(O) name(O) of(O) the(O) nc(B-rating) 17(I-rating) kathrine(B-actor) windfeld(I-actor) movie(O) about(O) companionship(B-plot) that(O) has(O) a(O) ratings(O) average(O) of(O) nine(B-average ratings)", "instance": {"id": "2228", "words": ["what", "was", "the", "name", "of", "the", "nc", "17", "kathrine", "windfeld", "movie", "about", "companionship", "that", "has", "a", "ratings", "average", "of", "nine"], "labels": ["O", "O", "O", "O", "O", "O", "B-rating", "I-rating", "B-director", "I-director", "O", "O", "B-plot", "O", "O", "O", "O", "O", "O", "B-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, genre, director, year, character, actor, review, average ratings, title, plot, song, trailer and O.\nSentence: what was the name of the nc 17 kathrine windfeld movie about companionship that has a ratings average of nine", "prompt_labels": "what(O) was(O) the(O) name(O) of(O) the(O) nc(B-rating) 17(I-rating) kathrine(B-director) windfeld(I-director) movie(O) about(O) companionship(B-plot) that(O) has(O) a(O) ratings(O) average(O) of(O) nine(B-average ratings)"}, "label_list": ["rating", "genre", "director", "year", "character", "actor", "review", "average ratings", "title", "plot", "song", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 17779, 11, 7690, 11, 1060, 11, 3752, 11, 12360, 11, 3477, 11, 5578, 18594, 11, 2316, 11, 7234, 11, 5609, 11, 19809, 323, 507, 627, 85664, 25, 1148, 574, 279, 836, 315, 279, 26183, 220, 1114, 597, 589, 40101, 10160, 31202, 5818, 922, 41957, 2200, 430, 706, 264, 18594, 5578, 315, 11888, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1389", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) is(O) good(B-Rating) ethnic(B-Cuisine) food(O)", "instance": {"id": "1389", "words": ["where", "is", "good", "ethnic", "food"], "labels": ["O", "O", "O", "B-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Price, Rating, Dish, Amenity, Hours, Cuisine, Location and O.\nSentence: where is good ethnic food", "prompt_labels": "where(O) is(O) good(O) ethnic(B-Cuisine) food(O)"}, "label_list": ["Restaurant Name", "Price", "Rating", "Dish", "Amenity", "Hours", "Cuisine", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 8650, 11, 19767, 11, 49268, 11, 3383, 56685, 11, 30192, 11, 81961, 11, 10067, 323, 507, 627, 85664, 25, 1405, 374, 1695, 22277, 3691, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "25", "dataset": "crossner_politics", "split": "dev", "prediction": "When(O) the(O) seat(O) was(O) created(O) it(O) was(O) nominally(O) held(O) by(O) the(O) Democratic(B-political party) Unionist(I-political party) Party(I-political party) ((O) DUP(B-political party) )(O),(O) based(O) on(O) mapping(O) the(O) 1992(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) results(O) onto(O) the(O) new(O) boundaries(O),(O) but(O) this(O) was(O) because(O) the(O) Ulster(B-political party) Unionist(I-political party) Party(I-political party) ((O) UUP(B-political party) )(O) had(O) not(O) contested(O) the(O) equivalent(O) area(O).(O)", "instance": {"id": "25", "words": ["When", "the", "seat", "was", "created", "it", "was", "nominally", "held", "by", "the", "Democratic", "Unionist", "Party", "(", "DUP", ")", ",", "based", "on", "mapping", "the", "1992", "United", "Kingdom", "general", "election", "results", "onto", "the", "new", "boundaries", ",", "but", "this", "was", "because", "the", "Ulster", "Unionist", "Party", "(", "UUP", ")", "had", "not", "contested", "the", "equivalent", "area", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "O", "B-political party", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "O", "B-political party", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, location, politician, event, election, person, organization, country and O.\nSentence: When the seat was created it was nominally held by the Democratic Unionist Party ( DUP ) , based on mapping the 1992 United Kingdom general election results onto the new boundaries , but this was because the Ulster Unionist Party ( UUP ) had not contested the equivalent area .", "prompt_labels": "When(O) the(O) seat(O) was(O) created(O) it(O) was(O) nominally(O) held(O) by(O) the(O) Democratic(B-political party) Unionist(I-political party) Party(I-political party) ((O) DUP(B-political party) )(O) ,(O) based(O) on(O) mapping(O) the(O) 1992(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) results(O) onto(O) the(O) new(O) boundaries(O) ,(O) but(O) this(O) was(O) because(O) the(O) Ulster(B-political party) Unionist(I-political party) Party(I-political party) ((O) UUP(B-political party) )(O) had(O) not(O) contested(O) the(O) equivalent(O) area(O) .(O)"}, "label_list": ["political party", "location", "politician", "event", "election", "person", "organization", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5054, 4717, 11, 3813, 11, 37038, 11, 1567, 11, 6355, 11, 1732, 11, 7471, 11, 3224, 323, 507, 627, 85664, 25, 3277, 279, 10954, 574, 3549, 433, 574, 25194, 750, 5762, 555, 279, 11650, 9323, 380, 8722, 320, 88624, 883, 1174, 3196, 389, 13021, 279, 220, 2550, 17, 3723, 15422, 4689, 6355, 3135, 8800, 279, 502, 23546, 1174, 719, 420, 574, 1606, 279, 16991, 3751, 9323, 380, 8722, 320, 549, 3202, 883, 1047, 539, 57310, 279, 13890, 3158, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "130", "dataset": "mit-restaurant", "split": "dev", "prediction": "can(O) i(O) valet(B-Amenity) park(I-Amenity) at(O) the(O) blue(B-Restaurant Name) coyote(I-Restaurant Name) grill(I-Restaurant Name)", "instance": {"id": "130", "words": ["can", "i", "valet", "park", "at", "the", "blue", "coyote", "grill"], "labels": ["O", "O", "B-Amenity", "I-Amenity", "O", "O", "B-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Rating, Hours, Amenity, Dish, Cuisine, Restaurant Name, Price and O.\nSentence: can i valet park at the blue coyote grill", "prompt_labels": "can(O) i(O) valet(B-Amenity) park(I-Amenity) at(O) the(O) blue(B-Restaurant Name) coyote(I-Restaurant Name) grill(I-Restaurant Name)"}, "label_list": ["Location", "Rating", "Hours", "Amenity", "Dish", "Cuisine", "Restaurant Name", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 19767, 11, 30192, 11, 3383, 56685, 11, 49268, 11, 81961, 11, 26568, 4076, 11, 8650, 323, 507, 627, 85664, 25, 649, 602, 11412, 1169, 6246, 520, 279, 6437, 75709, 1295, 40158, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "889", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) an(O) environmentally(B-Amenity) friendly(I-Amenity) restaurant(O) nearby(B-Location)", "instance": {"id": "889", "words": ["is", "there", "an", "environmentally", "friendly", "restaurant", "nearby"], "labels": ["O", "O", "O", "B-Amenity", "I-Amenity", "O", "B-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Amenity, Hours, Rating, Location, Dish, Price, Restaurant Name and O.\nSentence: is there an environmentally friendly restaurant nearby", "prompt_labels": "is(O) there(O) an(O) environmentally(B-Amenity) friendly(I-Amenity) restaurant(O) nearby(B-Location)"}, "label_list": ["Cuisine", "Amenity", "Hours", "Rating", "Location", "Dish", "Price", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 3383, 56685, 11, 30192, 11, 19767, 11, 10067, 11, 49268, 11, 8650, 11, 26568, 4076, 323, 507, 627, 85664, 25, 374, 1070, 459, 57340, 11919, 10960, 14373, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "85", "dataset": "mit-restaurant", "split": "dev", "prediction": "are(O) there(O) any(O) restaurants(O) with(O) valet(B-Amenity) parking(I-Amenity) and(O) a(O) multilingual(B-Amenity) staff(I-Amenity) near(B-Location) here(I-Location)", "instance": {"id": "85", "words": ["are", "there", "any", "restaurants", "with", "valet", "parking", "and", "a", "multilingual", "staff", "near", "here"], "labels": ["O", "O", "O", "O", "O", "B-Amenity", "I-Amenity", "O", "O", "B-Amenity", "I-Amenity", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Cuisine, Restaurant Name, Location, Rating, Amenity, Dish, Hours and O.\nSentence: are there any restaurants with valet parking and a multilingual staff near here", "prompt_labels": "are(O) there(O) any(O) restaurants(O) with(O) valet(B-Amenity) parking(I-Amenity) and(O) a(O) multilingual(B-Amenity) staff(I-Amenity) near(B-Location) here(I-Location)"}, "label_list": ["Price", "Cuisine", "Restaurant Name", "Location", "Rating", "Amenity", "Dish", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 81961, 11, 26568, 4076, 11, 10067, 11, 19767, 11, 3383, 56685, 11, 49268, 11, 30192, 323, 507, 627, 85664, 25, 527, 1070, 904, 15926, 449, 11412, 1169, 13217, 323, 264, 2814, 50923, 5687, 3221, 1618, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "977", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) there(O) a(O) documentary(B-genre) about(O) a(O) kiss(B-plot) tribute(I-plot) band(I-plot)", "instance": {"id": "977", "words": ["is", "there", "a", "documentary", "about", "a", "kiss", "tribute", "band"], "labels": ["O", "O", "O", "B-genre", "B-plot", "I-plot", "I-plot", "I-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, year, character, average ratings, rating, plot, title, director, genre, actor, review, song and O.\nSentence: is there a documentary about a kiss tribute band", "prompt_labels": "is(O) there(O) a(O) documentary(B-genre) about(B-plot) a(I-plot) kiss(I-plot) tribute(I-plot) band(I-plot)"}, "label_list": ["trailer", "year", "character", "average ratings", "rating", "plot", "title", "director", "genre", "actor", "review", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 1060, 11, 3752, 11, 5578, 18594, 11, 10959, 11, 7234, 11, 2316, 11, 7690, 11, 17779, 11, 12360, 11, 3477, 11, 5609, 323, 507, 627, 85664, 25, 374, 1070, 264, 25999, 922, 264, 21735, 35491, 7200, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1496", "dataset": "mit-restaurant", "split": "dev", "prediction": "which(O) restaurants(O) are(O) open(B-Hours) after(I-Hours) midnight(I-Hours) on(O) a(O) wednesday(B-Hours)", "instance": {"id": "1496", "words": ["which", "restaurants", "are", "open", "after", "midnight", "on", "a", "wednesday"], "labels": ["O", "O", "O", "B-Hours", "I-Hours", "I-Hours", "I-Hours", "I-Hours", "I-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Dish, Location, Rating, Restaurant Name, Hours, Amenity, Cuisine and O.\nSentence: which restaurants are open after midnight on a wednesday", "prompt_labels": "which(O) restaurants(O) are(O) open(B-Hours) after(I-Hours) midnight(I-Hours) on(I-Hours) a(I-Hours) wednesday(I-Hours)"}, "label_list": ["Price", "Dish", "Location", "Rating", "Restaurant Name", "Hours", "Amenity", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 49268, 11, 10067, 11, 19767, 11, 26568, 4076, 11, 30192, 11, 3383, 56685, 11, 81961, 323, 507, 627, 85664, 25, 902, 15926, 527, 1825, 1306, 33433, 389, 264, 11077, 7465, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1297", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) can(O) i(O) find(O) somewhere(O) relaxed(B-Amenity) thats(O) open(B-Hours) in(I-Hours) the(I-Hours) morning(I-Hours) around(B-Location) beacon(I-Location) hill(I-Location)", "instance": {"id": "1297", "words": ["where", "can", "i", "find", "somewhere", "relaxed", "thats", "open", "in", "the", "morning", "around", "beacon", "hill"], "labels": ["O", "O", "O", "O", "O", "B-Amenity", "O", "B-Hours", "I-Hours", "I-Hours", "I-Hours", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Amenity, Restaurant Name, Hours, Location, Cuisine, Dish, Rating and O.\nSentence: where can i find somewhere relaxed thats open in the morning around beacon hill", "prompt_labels": "where(O) can(O) i(O) find(O) somewhere(O) relaxed(B-Amenity) thats(O) open(B-Hours) in(I-Hours) the(I-Hours) morning(I-Hours) around(B-Location) beacon(I-Location) hill(I-Location)"}, "label_list": ["Price", "Amenity", "Restaurant Name", "Hours", "Location", "Cuisine", "Dish", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 3383, 56685, 11, 26568, 4076, 11, 30192, 11, 10067, 11, 81961, 11, 49268, 11, 19767, 323, 507, 627, 85664, 25, 1405, 649, 602, 1505, 15038, 31467, 41136, 1825, 304, 279, 6693, 2212, 52402, 24898, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "152", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) terry(B-actor) gilliam(I-actor) movies(O) starring(O) jeff(B-actor) bridges(I-actor)", "instance": {"id": "152", "words": ["show", "me", "terry", "gilliam", "movies", "starring", "jeff", "bridges"], "labels": ["O", "O", "B-director", "I-director", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, review, genre, year, plot, trailer, actor, song, title, character, average ratings, rating and O.\nSentence: show me terry gilliam movies starring jeff bridges", "prompt_labels": "show(O) me(O) terry(B-director) gilliam(I-director) movies(O) starring(O) jeff(B-actor) bridges(I-actor)"}, "label_list": ["director", "review", "genre", "year", "plot", "trailer", "actor", "song", "title", "character", "average ratings", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 3477, 11, 17779, 11, 1060, 11, 7234, 11, 19809, 11, 12360, 11, 5609, 11, 2316, 11, 3752, 11, 5578, 18594, 11, 10959, 323, 507, 627, 85664, 25, 1501, 757, 259, 5515, 342, 484, 5038, 9698, 40500, 4864, 544, 40073, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2274", "dataset": "mit-movie", "split": "dev", "prediction": "where(O) can(O) i(O) find(O) a(O) biography(B-genre) containing(O) people(O) famous(O) in(O) the(O) 1990(B-year) s(I-year)", "instance": {"id": "2274", "words": ["where", "can", "i", "find", "a", "biography", "containing", "people", "famous", "in", "the", "1990", "s"], "labels": ["O", "O", "O", "O", "O", "B-genre", "O", "O", "O", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, rating, genre, review, trailer, title, song, year, actor, average ratings, plot, character and O.\nSentence: where can i find a biography containing people famous in the 1990 s", "prompt_labels": "where(O) can(O) i(O) find(O) a(O) biography(B-genre) containing(O) people(O) famous(O) in(O) the(O) 1990(B-year) s(I-year)"}, "label_list": ["director", "rating", "genre", "review", "trailer", "title", "song", "year", "actor", "average ratings", "plot", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 10959, 11, 17779, 11, 3477, 11, 19809, 11, 2316, 11, 5609, 11, 1060, 11, 12360, 11, 5578, 18594, 11, 7234, 11, 3752, 323, 507, 627, 85664, 25, 1405, 649, 602, 1505, 264, 48345, 8649, 1274, 11495, 304, 279, 220, 2550, 15, 274, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "333", "dataset": "crossner_music", "split": "dev", "prediction": "It(O) won(O) Gabriel(B-musical artist) a(O) Grammy(B-award) Award(I-award) for(O) Grammy(B-award) Award(I-award) for(I-award) Best(I-award) New(I-award) Age(I-award) Album(I-award) and(O) a(O) nomination(O) for(O) a(O) Golden(B-award) Globe(I-award) for(O) Golden(B-award) Globe(I-award) Award(I-award) for(I-award) Best(I-award) Original(I-award) Score(I-award).(O)", "instance": {"id": "333", "words": ["It", "won", "Gabriel", "a", "Grammy", "Award", "for", "Grammy", "Award", "for", "Best", "New", "Age", "Album", "and", "a", "nomination", "for", "a", "Golden", "Globe", "for", "Golden", "Globe", "Award", "for", "Best", "Original", "Score", "."], "labels": ["O", "O", "B-musical artist", "O", "B-award", "I-award", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O", "O", "O", "O", "O", "B-award", "I-award", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, band, musical instrument, musical artist, music genre, album, country, organization, event, person, location, song and O.\nSentence: It won Gabriel a Grammy Award for Grammy Award for Best New Age Album and a nomination for a Golden Globe for Golden Globe Award for Best Original Score .", "prompt_labels": "It(O) won(O) Gabriel(B-musical artist) a(O) Grammy(B-award) Award(I-award) for(O) Grammy(B-award) Award(I-award) for(I-award) Best(I-award) New(I-award) Age(I-award) Album(I-award) and(O) a(O) nomination(O) for(O) a(O) Golden(B-award) Globe(I-award) for(O) Golden(B-award) Globe(I-award) Award(I-award) for(I-award) Best(I-award) Original(I-award) Score(I-award) .(O)"}, "label_list": ["award", "band", "musical instrument", "musical artist", "music genre", "album", "country", "organization", "event", "person", "location", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10292, 11, 7200, 11, 18273, 14473, 11, 18273, 10255, 11, 4731, 17779, 11, 8176, 11, 3224, 11, 7471, 11, 1567, 11, 1732, 11, 3813, 11, 5609, 323, 507, 627, 85664, 25, 1102, 2834, 39843, 264, 74679, 17768, 369, 74679, 17768, 369, 7252, 1561, 13381, 26749, 323, 264, 29804, 369, 264, 18288, 41910, 369, 18288, 41910, 17768, 369, 7252, 17674, 18607, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2165", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) nuclear(B-plot) war(I-plot) movies(O) are(O) rated(O) pg(B-rating) 13(I-rating)", "instance": {"id": "2165", "words": ["what", "nuclear", "war", "movies", "are", "rated", "pg", "13"], "labels": ["O", "B-plot", "I-plot", "O", "O", "O", "B-rating", "I-rating"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, song, rating, director, average ratings, plot, actor, year, character, title, trailer, review and O.\nSentence: what nuclear war movies are rated pg 13", "prompt_labels": "what(O) nuclear(B-plot) war(I-plot) movies(O) are(O) rated(O) pg(B-rating) 13(I-rating)"}, "label_list": ["genre", "song", "rating", "director", "average ratings", "plot", "actor", "year", "character", "title", "trailer", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 5609, 11, 10959, 11, 7690, 11, 5578, 18594, 11, 7234, 11, 12360, 11, 1060, 11, 3752, 11, 2316, 11, 19809, 11, 3477, 323, 507, 627, 85664, 25, 1148, 11499, 4208, 9698, 527, 22359, 17953, 220, 1032, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "172", "dataset": "crossner_music", "split": "dev", "prediction": "Bands(O) like(O) Flogging(B-band) Molly(I-band),(O) Black(B-band) 47(I-band),(O) Dropkick(B-band) Murphys(I-band),(O) The(B-band) Young(I-band) Dubliners(I-band),(O) The(B-band) Tossers(I-band) introduced(O) a(O) hybrid(O) of(O) Celtic(B-music genre) rock(I-music genre),(O) Punk(B-music genre) rock(I-music genre),(O) reggae(B-music genre),(O) Hardcore(B-music genre) punk(I-music genre) and(O) other(O) elements(O) in(O) the(O) 1990s(O) that(O) has(O) become(O) popular(O) with(O) Irish-American(O) youth(O).(O)", "instance": {"id": "172", "words": ["Bands", "like", "Flogging", "Molly", ",", "Black", "47", ",", "Dropkick", "Murphys", ",", "The", "Young", "Dubliners", ",", "The", "Tossers", "introduced", "a", "hybrid", "of", "Celtic", "rock", ",", "Punk", "rock", ",", "reggae", ",", "Hardcore", "punk", "and", "other", "elements", "in", "the", "1990s", "that", "has", "become", "popular", "with", "Irish-American", "youth", "."], "labels": ["O", "O", "B-band", "I-band", "O", "B-band", "I-band", "O", "B-band", "I-band", "O", "B-band", "I-band", "I-band", "O", "B-band", "I-band", "O", "O", "O", "O", "B-music genre", "I-music genre", "O", "B-music genre", "I-music genre", "O", "B-music genre", "O", "B-music genre", "I-music genre", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, song, music genre, musical instrument, album, event, musical artist, country, organization, award, band, person and O.\nSentence: Bands like Flogging Molly , Black 47 , Dropkick Murphys , The Young Dubliners , The Tossers introduced a hybrid of Celtic rock , Punk rock , reggae , Hardcore punk and other elements in the 1990s that has become popular with Irish-American youth .", "prompt_labels": "Bands(O) like(O) Flogging(B-band) Molly(I-band) ,(O) Black(B-band) 47(I-band) ,(O) Dropkick(B-band) Murphys(I-band) ,(O) The(B-band) Young(I-band) Dubliners(I-band) ,(O) The(B-band) Tossers(I-band) introduced(O) a(O) hybrid(O) of(O) Celtic(B-music genre) rock(I-music genre) ,(O) Punk(B-music genre) rock(I-music genre) ,(O) reggae(B-music genre) ,(O) Hardcore(B-music genre) punk(I-music genre) and(O) other(O) elements(O) in(O) the(O) 1990s(O) that(O) has(O) become(O) popular(O) with(O) Irish-American(O) youth(O) .(O)"}, "label_list": ["location", "song", "music genre", "musical instrument", "album", "event", "musical artist", "country", "organization", "award", "band", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 5609, 11, 4731, 17779, 11, 18273, 14473, 11, 8176, 11, 1567, 11, 18273, 10255, 11, 3224, 11, 7471, 11, 10292, 11, 7200, 11, 1732, 323, 507, 627, 85664, 25, 88402, 1093, 435, 26330, 58500, 1174, 5348, 220, 2618, 1174, 16110, 56893, 15356, 42305, 1174, 578, 13566, 33977, 388, 1174, 578, 350, 3746, 388, 11784, 264, 26038, 315, 55764, 7091, 1174, 52433, 7091, 1174, 1239, 67378, 1174, 60650, 36858, 323, 1023, 5540, 304, 279, 220, 2550, 15, 82, 430, 706, 3719, 5526, 449, 18088, 24145, 12822, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "371", "dataset": "crossner_literature", "split": "dev", "prediction": "He(O) won(O) the(O) Nebula(B-award) Award(I-award) three(O) times(O) ((O) out(O) of(O) 14(O) nominations(O) )(O) and(O) the(O) Hugo(B-award) Award(I-award) six(O) times(O) ((O) also(O) out(O) of(O) 14(O) nominations(O) )(O),(O) including(O) two(O) Hugos(B-award) for(O) novels(B-literary genre) :(O) the(O) serialized(O) novel(B-literary genre)...(O) And(B-book) Call(I-book) Me(I-book) Conrad(I-book) ((O) 1965(O) )(O),(O) subsequently(O) published(O) under(O) the(O) title(O) This(B-book) Immortal(I-book) ((O) 1966(O) )(O) and(O) then(O) the(O) novel(B-literary genre) Lord(B-book) of(I-book) Light(I-book) ((O) 1967(O) )(O).(O)", "instance": {"id": "371", "words": ["He", "won", "the", "Nebula", "Award", "three", "times", "(", "out", "of", "14", "nominations", ")", "and", "the", "Hugo", "Award", "six", "times", "(", "also", "out", "of", "14", "nominations", ")", ",", "including", "two", "Hugos", "for", "novels", ":", "the", "serialized", "novel", "...", "And", "Call", "Me", "Conrad", "(", "1965", ")", ",", "subsequently", "published", "under", "the", "title", "This", "Immortal", "(", "1966", ")", "and", "then", "the", "novel", "Lord", "of", "Light", "(", "1967", ")", "."], "labels": ["O", "O", "O", "B-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-award", "O", "B-literary genre", "O", "O", "O", "B-literary genre", "O", "B-book", "I-book", "I-book", "I-book", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-book", "I-book", "O", "O", "O", "O", "O", "O", "B-literary genre", "B-book", "I-book", "I-book", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, person, writer, organization, location, magazine, literary genre, poem, book, event, award and O.\nSentence: He won the Nebula Award three times ( out of 14 nominations ) and the Hugo Award six times ( also out of 14 nominations ) , including two Hugos for novels : the serialized novel ... And Call Me Conrad ( 1965 ) , subsequently published under the title This Immortal ( 1966 ) and then the novel Lord of Light ( 1967 ) .", "prompt_labels": "He(O) won(O) the(O) Nebula(B-award) Award(I-award) three(O) times(O) ((O) out(O) of(O) 14(O) nominations(O) )(O) and(O) the(O) Hugo(B-award) Award(I-award) six(O) times(O) ((O) also(O) out(O) of(O) 14(O) nominations(O) )(O) ,(O) including(O) two(O) Hugos(B-award) for(O) novels(B-literary genre) :(O) the(O) serialized(O) novel(B-literary genre) ...(O) And(B-book) Call(I-book) Me(I-book) Conrad(I-book) ((O) 1965(O) )(O) ,(O) subsequently(O) published(O) under(O) the(O) title(O) This(B-book) Immortal(I-book) ((O) 1966(O) )(O) and(O) then(O) the(O) novel(B-literary genre) Lord(B-book) of(I-book) Light(I-book) ((O) 1967(O) )(O) .(O)"}, "label_list": ["country", "person", "writer", "organization", "location", "magazine", "literary genre", "poem", "book", "event", "award"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 1732, 11, 7061, 11, 7471, 11, 3813, 11, 14756, 11, 32465, 17779, 11, 33894, 11, 2363, 11, 1567, 11, 10292, 323, 507, 627, 85664, 25, 1283, 2834, 279, 52809, 5724, 17768, 2380, 3115, 320, 704, 315, 220, 975, 60698, 883, 323, 279, 52194, 17768, 4848, 3115, 320, 1101, 704, 315, 220, 975, 60698, 883, 1174, 2737, 1403, 473, 773, 437, 369, 32963, 551, 279, 34016, 11775, 2564, 1628, 7290, 2206, 77089, 320, 220, 5162, 20, 883, 1174, 28520, 4756, 1234, 279, 2316, 1115, 15695, 34472, 320, 220, 5162, 21, 883, 323, 1243, 279, 11775, 10425, 315, 8828, 320, 220, 5162, 22, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "919", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) mpaa(O) rating(O) for(O) necessary(B-title) roughness(I-title)", "instance": {"id": "919", "words": ["what", "is", "the", "mpaa", "rating", "for", "necessary", "roughness"], "labels": ["O", "O", "O", "O", "O", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, year, genre, song, title, review, director, actor, rating, trailer, plot, average ratings and O.\nSentence: what is the mpaa rating for necessary roughness", "prompt_labels": "what(O) is(O) the(O) mpaa(O) rating(O) for(O) necessary(B-title) roughness(I-title)"}, "label_list": ["character", "year", "genre", "song", "title", "review", "director", "actor", "rating", "trailer", "plot", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 1060, 11, 17779, 11, 5609, 11, 2316, 11, 3477, 11, 7690, 11, 12360, 11, 10959, 11, 19809, 11, 7234, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1148, 374, 279, 10710, 5418, 10959, 369, 5995, 11413, 2136, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "174", "dataset": "crossner_literature", "split": "dev", "prediction": "Caravaggio(B-person) was(O) entered(O) into(O) the(O) 36th(B-event) Berlin(I-event) International(I-event) Film(I-event) Festival(I-event),(O) where(O) it(O) won(O) the(O) Silver(B-award) Bear(I-award) for(I-award) an(I-award) outstanding(I-award) single(I-award) achievement(I-award).(O)", "instance": {"id": "174", "words": ["Caravaggio", "was", "entered", "into", "the", "36th", "Berlin", "International", "Film", "Festival", ",", "where", "it", "won", "the", "Silver", "Bear", "for", "an", "outstanding", "single", "achievement", "."], "labels": ["O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "I-event", "I-event", "O", "O", "O", "O", "O", "B-award", "I-award", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, location, event, award, writer, book, magazine, person, country, poem, literary genre and O.\nSentence: Caravaggio was entered into the 36th Berlin International Film Festival , where it won the Silver Bear for an outstanding single achievement .", "prompt_labels": "Caravaggio(O) was(O) entered(O) into(O) the(O) 36th(B-event) Berlin(I-event) International(I-event) Film(I-event) Festival(I-event) ,(O) where(O) it(O) won(O) the(O) Silver(B-award) Bear(I-award) for(O) an(O) outstanding(O) single(O) achievement(O) .(O)"}, "label_list": ["organization", "location", "event", "award", "writer", "book", "magazine", "person", "country", "poem", "literary genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 3813, 11, 1567, 11, 10292, 11, 7061, 11, 2363, 11, 14756, 11, 1732, 11, 3224, 11, 33894, 11, 32465, 17779, 323, 507, 627, 85664, 25, 3341, 402, 35259, 574, 10862, 1139, 279, 220, 1927, 339, 20437, 7327, 17042, 17772, 1174, 1405, 433, 2834, 279, 15347, 24941, 369, 459, 19310, 3254, 26501, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "90", "dataset": "crossner_politics", "split": "dev", "prediction": "Other(O) political(O) parties(O) that(O) have(O) practiced(O) fusion(B-political party) include(O) the(O) Conservative(B-political party) Party(I-political party) of(I-political party) New(I-political party) York(I-political party) State(I-political party),(O) the(O) Working(B-political party) Families(I-political party) Party(I-political party) and(O) the(O) Liberal(B-political party) Party(I-political party) of(I-political party) New(I-political party) York(I-political party).(O)", "instance": {"id": "90", "words": ["Other", "political", "parties", "that", "have", "practiced", "fusion", "include", "the", "Conservative", "Party", "of", "New", "York", "State", ",", "the", "Working", "Families", "Party", "and", "the", "Liberal", "Party", "of", "New", "York", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, event, location, organization, election, political party, person, country and O.\nSentence: Other political parties that have practiced fusion include the Conservative Party of New York State , the Working Families Party and the Liberal Party of New York .", "prompt_labels": "Other(O) political(O) parties(O) that(O) have(O) practiced(O) fusion(O) include(O) the(O) Conservative(B-political party) Party(I-political party) of(I-political party) New(I-political party) York(I-political party) State(I-political party) ,(O) the(O) Working(B-political party) Families(I-political party) Party(I-political party) and(O) the(O) Liberal(B-political party) Party(I-political party) of(I-political party) New(I-political party) York(I-political party) .(O)"}, "label_list": ["politician", "event", "location", "organization", "election", "political party", "person", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 37038, 11, 1567, 11, 3813, 11, 7471, 11, 6355, 11, 5054, 4717, 11, 1732, 11, 3224, 323, 507, 627, 85664, 25, 7089, 5054, 9875, 430, 617, 44664, 37608, 2997, 279, 30071, 8722, 315, 1561, 4356, 3314, 1174, 279, 22938, 50556, 8722, 323, 279, 31158, 8722, 315, 1561, 4356, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "157", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movies(O) have(O) batman(B-title) and(I-title) robin(I-title)", "instance": {"id": "157", "words": ["what", "movies", "have", "batman", "and", "robin"], "labels": ["O", "O", "O", "B-plot", "I-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, director, plot, average ratings, actor, song, trailer, review, genre, title, rating, character and O.\nSentence: what movies have batman and robin", "prompt_labels": "what(O) movies(O) have(O) batman(B-plot) and(I-plot) robin(I-plot)"}, "label_list": ["year", "director", "plot", "average ratings", "actor", "song", "trailer", "review", "genre", "title", "rating", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 7690, 11, 7234, 11, 5578, 18594, 11, 12360, 11, 5609, 11, 19809, 11, 3477, 11, 17779, 11, 2316, 11, 10959, 11, 3752, 323, 507, 627, 85664, 25, 1148, 9698, 617, 16120, 1543, 323, 99685, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1256", "dataset": "mit-movie", "split": "dev", "prediction": "has(O) billy(B-director) wilder(I-director) directed(O) and(O) rated(O) r(B-rating) horror(B-genre) films(O)", "instance": {"id": "1256", "words": ["has", "billy", "wilder", "directed", "and", "rated", "r", "horror", "films"], "labels": ["O", "B-director", "I-director", "O", "O", "O", "B-rating", "B-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, review, character, trailer, genre, song, title, actor, director, plot, rating, average ratings and O.\nSentence: has billy wilder directed and rated r horror films", "prompt_labels": "has(O) billy(B-director) wilder(I-director) directed(O) and(O) rated(O) r(B-rating) horror(B-genre) films(O)"}, "label_list": ["year", "review", "character", "trailer", "genre", "song", "title", "actor", "director", "plot", "rating", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 3477, 11, 3752, 11, 19809, 11, 17779, 11, 5609, 11, 2316, 11, 12360, 11, 7690, 11, 7234, 11, 10959, 11, 5578, 18594, 323, 507, 627, 85664, 25, 706, 293, 14722, 8545, 261, 15910, 323, 22359, 436, 22169, 12631, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "603", "dataset": "mit-movie", "split": "dev", "prediction": "find(O) me(O) a(O) movie(O) suitable(O) for(O) kids(B-genre)", "instance": {"id": "603", "words": ["find", "me", "a", "movie", "suitable", "for", "kids"], "labels": ["O", "O", "O", "O", "B-review", "O", "B-genre"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, trailer, song, review, actor, average ratings, plot, character, director, genre, title, rating and O.\nSentence: find me a movie suitable for kids", "prompt_labels": "find(O) me(O) a(O) movie(O) suitable(B-review) for(O) kids(B-genre)"}, "label_list": ["year", "trailer", "song", "review", "actor", "average ratings", "plot", "character", "director", "genre", "title", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 19809, 11, 5609, 11, 3477, 11, 12360, 11, 5578, 18594, 11, 7234, 11, 3752, 11, 7690, 11, 17779, 11, 2316, 11, 10959, 323, 507, 627, 85664, 25, 1505, 757, 264, 5818, 14791, 369, 6980, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1702", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) the(O) animation(B-genre) films(O) that(O) were(O) rated(O) five(B-average ratings) stars(I-average ratings)", "instance": {"id": "1702", "words": ["list", "the", "animation", "films", "that", "were", "rated", "five", "stars"], "labels": ["O", "O", "B-genre", "O", "O", "O", "O", "B-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, title, actor, plot, trailer, genre, rating, director, review, song, year, character and O.\nSentence: list the animation films that were rated five stars", "prompt_labels": "list(O) the(O) animation(B-genre) films(O) that(O) were(O) rated(O) five(B-average ratings) stars(I-average ratings)"}, "label_list": ["average ratings", "title", "actor", "plot", "trailer", "genre", "rating", "director", "review", "song", "year", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 2316, 11, 12360, 11, 7234, 11, 19809, 11, 17779, 11, 10959, 11, 7690, 11, 3477, 11, 5609, 11, 1060, 11, 3752, 323, 507, 627, 85664, 25, 1160, 279, 10571, 12631, 430, 1051, 22359, 4330, 9958, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "240", "dataset": "crossner_politics", "split": "dev", "prediction": "196(O) He(O) retained(O) the(O) seat(O) in(O) 2001(B-election) Northern(I-election) Ireland(I-election) local(I-election) elections(I-election) but(O) lost(O) it(O) in(O) 2005(B-election) Northern(I-election) Ireland(I-election) local(I-election) elections(I-election) to(O) Fred(B-politician) Cobain(I-politician) of(O) the(O) Ulster(B-political party) Unionist(I-political party) Party(I-political party).(O)", "instance": {"id": "240", "words": ["196", "He", "retained", "the", "seat", "in", "2001", "Northern", "Ireland", "local", "elections", "but", "lost", "it", "in", "2005", "Northern", "Ireland", "local", "elections", "to", "Fred", "Cobain", "of", "the", "Ulster", "Unionist", "Party", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "B-politician", "I-politician", "O", "O", "B-political party", "I-political party", "I-political party", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, country, person, election, politician, location, organization, event and O.\nSentence: 196 He retained the seat in 2001 Northern Ireland local elections but lost it in 2005 Northern Ireland local elections to Fred Cobain of the Ulster Unionist Party .", "prompt_labels": "196(O) He(O) retained(O) the(O) seat(O) in(O) 2001(B-election) Northern(I-election) Ireland(I-election) local(I-election) elections(I-election) but(O) lost(O) it(O) in(O) 2005(B-election) Northern(I-election) Ireland(I-election) local(I-election) elections(I-election) to(O) Fred(B-politician) Cobain(I-politician) of(O) the(O) Ulster(B-political party) Unionist(I-political party) Party(I-political party) .(O)"}, "label_list": ["political party", "country", "person", "election", "politician", "location", "organization", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5054, 4717, 11, 3224, 11, 1732, 11, 6355, 11, 37038, 11, 3813, 11, 7471, 11, 1567, 323, 507, 627, 85664, 25, 220, 5162, 1283, 35363, 279, 10954, 304, 220, 1049, 16, 17355, 14990, 2254, 16374, 719, 5675, 433, 304, 220, 1049, 20, 17355, 14990, 2254, 16374, 311, 28588, 47051, 467, 315, 279, 16991, 3751, 9323, 380, 8722, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "169", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) joe(B-director) pesci(I-director) direct(O) any(O) films(O)", "instance": {"id": "169", "words": ["did", "joe", "pesci", "direct", "any", "films"], "labels": ["O", "B-director", "I-director", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, trailer, review, year, plot, title, genre, song, average ratings, rating, actor, character and O.\nSentence: did joe pesci direct any films", "prompt_labels": "did(O) joe(B-director) pesci(I-director) direct(O) any(O) films(O)"}, "label_list": ["director", "trailer", "review", "year", "plot", "title", "genre", "song", "average ratings", "rating", "actor", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 19809, 11, 3477, 11, 1060, 11, 7234, 11, 2316, 11, 17779, 11, 5609, 11, 5578, 18594, 11, 10959, 11, 12360, 11, 3752, 323, 507, 627, 85664, 25, 1550, 94441, 281, 3380, 72, 2167, 904, 12631, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "67", "dataset": "crossner_ai", "split": "dev", "prediction": "In(O) machine(B-field) learning(I-field),(O) the(O) perceptron(B-algorithm) is(O) an(O) algorithm(O) for(O) supervised(B-field) learning(I-field) of(O) binary(B-task) classification(I-task).(O)", "instance": {"id": "67", "words": ["In", "machine", "learning", ",", "the", "perceptron", "is", "an", "algorithm", "for", "supervised", "learning", "of", "binary", "classification", "."], "labels": ["O", "B-field", "I-field", "O", "O", "B-algorithm", "O", "O", "O", "O", "B-field", "I-field", "O", "B-task", "I-task", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, person, organization, country, programming language, location, university, researcher, metric, field, algorithm, task, product and O.\nSentence: In machine learning , the perceptron is an algorithm for supervised learning of binary classification .", "prompt_labels": "In(O) machine(B-field) learning(I-field) ,(O) the(O) perceptron(B-algorithm) is(O) an(O) algorithm(O) for(O) supervised(B-field) learning(I-field) of(O) binary(B-task) classification(I-task) .(O)"}, "label_list": ["conference", "person", "organization", "country", "programming language", "location", "university", "researcher", "metric", "field", "algorithm", "task", "product"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10017, 11, 1732, 11, 7471, 11, 3224, 11, 15840, 4221, 11, 3813, 11, 12374, 11, 32185, 11, 18767, 11, 2115, 11, 12384, 11, 3465, 11, 2027, 323, 507, 627, 85664, 25, 763, 5780, 6975, 1174, 279, 62822, 95810, 374, 459, 12384, 369, 60089, 6975, 315, 8026, 24790, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1611", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) a(O) drama(B-genre) film(O) within(O) the(O) last(B-year) four(I-year) decades(I-year) with(O) actor(O) curly(B-actor) howard(I-actor)", "instance": {"id": "1611", "words": ["list", "a", "drama", "film", "within", "the", "last", "four", "decades", "with", "actor", "curly", "howard"], "labels": ["O", "O", "B-genre", "O", "O", "O", "B-year", "I-year", "I-year", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, song, year, actor, genre, plot, trailer, average ratings, character, title, rating, director and O.\nSentence: list a drama film within the last four decades with actor curly howard", "prompt_labels": "list(O) a(O) drama(B-genre) film(O) within(O) the(O) last(B-year) four(I-year) decades(I-year) with(O) actor(O) curly(B-actor) howard(I-actor)"}, "label_list": ["review", "song", "year", "actor", "genre", "plot", "trailer", "average ratings", "character", "title", "rating", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 5609, 11, 1060, 11, 12360, 11, 17779, 11, 7234, 11, 19809, 11, 5578, 18594, 11, 3752, 11, 2316, 11, 10959, 11, 7690, 323, 507, 627, 85664, 25, 1160, 264, 20156, 4632, 2949, 279, 1566, 3116, 11026, 449, 12360, 69203, 1268, 569, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "171", "dataset": "crossner_science", "split": "dev", "prediction": "The(O) discipline(O) emerged(O) after(O) 2010(O) following(O) the(O) development(O) of(O) genome(O) editing(O) technology(O) including(O) TALENS(B-protein) and(O) CRISPR(B-protein).(O)", "instance": {"id": "171", "words": ["The", "discipline", "emerged", "after", "2010", "following", "the", "development", "of", "genome", "editing", "technology", "including", "TALENS", "and", "CRISPR", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, theory, protein, university, organization, academic journal, discipline, country, scientist, award, chemical compound, chemical element, astronomical object, enzyme, location, event and O.\nSentence: The discipline emerged after 2010 following the development of genome editing technology including TALENS and CRISPR .", "prompt_labels": "The(O) discipline(O) emerged(O) after(O) 2010(O) following(O) the(O) development(O) of(O) genome(O) editing(O) technology(O) including(O) TALENS(O) and(O) CRISPR(O) .(O)"}, "label_list": ["person", "theory", "protein", "university", "organization", "academic journal", "discipline", "country", "scientist", "award", "chemical compound", "chemical element", "astronomical object", "enzyme", "location", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 10334, 11, 13128, 11, 12374, 11, 7471, 11, 14584, 8486, 11, 26434, 11, 3224, 11, 28568, 11, 10292, 11, 11742, 24549, 11, 11742, 2449, 11, 87283, 1665, 11, 49242, 11, 3813, 11, 1567, 323, 507, 627, 85664, 25, 578, 26434, 22763, 1306, 220, 679, 15, 2768, 279, 4500, 315, 33869, 16039, 5557, 2737, 350, 25940, 2507, 323, 12904, 1669, 6616, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "250", "dataset": "crossner_politics", "split": "dev", "prediction": "In(O) Northern(B-location) Ireland(I-location),(O) the(O) term(O) is(O) not(O) used(O) by(O) the(O) Social(B-political party) Democratic(I-political party) and(I-political party) Labour(I-political party) Party(I-political party),(O) or(O) by(O) those(O) parties(O) which(O) are(O) not(O) Irish-nationalist(O) in(O) outlook(O),(O) such(O) as(O) the(O) Alliance(B-political party) Party(I-political party) of(I-political party) Northern(I-political party) Ireland(I-political party) and(O) Democratic(B-political party) Unionist(I-political party) Party(I-political party).(O)", "instance": {"id": "250", "words": ["In", "Northern", "Ireland", ",", "the", "term", "is", "not", "used", "by", "the", "Social", "Democratic", "and", "Labour", "Party", ",", "or", "by", "those", "parties", "which", "are", "not", "Irish-nationalist", "in", "outlook", ",", "such", "as", "the", "Alliance", "Party", "of", "Northern", "Ireland", "and", "Democratic", "Unionist", "Party", "."], "labels": ["O", "B-country", "I-country", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "B-political party", "I-political party", "I-political party", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, event, location, political party, politician, election, organization, person and O.\nSentence: In Northern Ireland , the term is not used by the Social Democratic and Labour Party , or by those parties which are not Irish-nationalist in outlook , such as the Alliance Party of Northern Ireland and Democratic Unionist Party .", "prompt_labels": "In(O) Northern(B-country) Ireland(I-country) ,(O) the(O) term(O) is(O) not(O) used(O) by(O) the(O) Social(B-political party) Democratic(I-political party) and(I-political party) Labour(I-political party) Party(I-political party) ,(O) or(O) by(O) those(O) parties(O) which(O) are(O) not(O) Irish-nationalist(O) in(O) outlook(O) ,(O) such(O) as(O) the(O) Alliance(B-political party) Party(I-political party) of(I-political party) Northern(I-political party) Ireland(I-political party) and(O) Democratic(B-political party) Unionist(I-political party) Party(I-political party) .(O)"}, "label_list": ["country", "event", "location", "political party", "politician", "election", "organization", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 1567, 11, 3813, 11, 5054, 4717, 11, 37038, 11, 6355, 11, 7471, 11, 1732, 323, 507, 627, 85664, 25, 763, 17355, 14990, 1174, 279, 4751, 374, 539, 1511, 555, 279, 9983, 11650, 323, 18993, 8722, 1174, 477, 555, 1884, 9875, 902, 527, 539, 18088, 75629, 380, 304, 36721, 1174, 1778, 439, 279, 23590, 8722, 315, 17355, 14990, 323, 11650, 9323, 380, 8722, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "470", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) funny(B-review) movie(O) has(O) danny(B-actor) devito(I-actor) in(O) it(O)", "instance": {"id": "470", "words": ["what", "funny", "movie", "has", "danny", "devito", "in", "it"], "labels": ["O", "B-review", "O", "O", "B-actor", "I-actor", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, year, character, rating, review, genre, director, title, plot, trailer, average ratings, song and O.\nSentence: what funny movie has danny devito in it", "prompt_labels": "what(O) funny(B-review) movie(O) has(O) danny(B-actor) devito(I-actor) in(O) it(O)"}, "label_list": ["actor", "year", "character", "rating", "review", "genre", "director", "title", "plot", "trailer", "average ratings", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 1060, 11, 3752, 11, 10959, 11, 3477, 11, 17779, 11, 7690, 11, 2316, 11, 7234, 11, 19809, 11, 5578, 18594, 11, 5609, 323, 507, 627, 85664, 25, 1148, 15526, 5818, 706, 294, 13184, 3567, 6491, 304, 433, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "24", "dataset": "crossner_ai", "split": "dev", "prediction": "He(O) received(O) a(O) PhD(O) in(O) Radio(B-field) Physics(I-field) and(I-field) Electronics(I-field) from(O) the(O) Rajabazar(B-university) Science(I-university) College(I-university) campus(O) of(O) University(B-university) of(I-university) Calcutta(I-university) in(O) 1979(O) as(O) a(O) student(O) of(O) Indian(B-researcher) Statistical(I-researcher) Institute(I-researcher),(O) and(O) another(O) PhD(O) in(O) Electrical(B-field) Engineering(I-field) along(O) with(O) Diploma(O) of(O) the(O) Imperial(B-university) College(I-university) from(O) Imperial(B-university) College(I-university),(O) University(B-university) of(I-university) London(I-university),(O) in(O) 1982(O).(O)", "instance": {"id": "24", "words": ["He", "received", "a", "PhD", "in", "Radio", "Physics", "and", "Electronics", "from", "the", "Rajabazar", "Science", "College", "campus", "of", "University", "of", "Calcutta", "in", "1979", "as", "a", "student", "of", "Indian", "Statistical", "Institute", ",", "and", "another", "PhD", "in", "Electrical", "Engineering", "along", "with", "Diploma", "of", "the", "Imperial", "College", "from", "Imperial", "College", ",", "University", "of", "London", ",", "in", "1982", "."], "labels": ["O", "O", "O", "O", "O", "B-field", "I-field", "O", "B-field", "O", "O", "B-university", "I-university", "I-university", "O", "O", "B-university", "I-university", "I-university", "O", "O", "O", "O", "O", "O", "B-university", "I-university", "I-university", "O", "O", "O", "O", "O", "B-field", "I-field", "O", "O", "O", "O", "O", "O", "O", "O", "B-university", "I-university", "O", "B-university", "I-university", "I-university", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: task, metric, programming language, conference, researcher, country, algorithm, location, field, product, person, university, organization and O.\nSentence: He received a PhD in Radio Physics and Electronics from the Rajabazar Science College campus of University of Calcutta in 1979 as a student of Indian Statistical Institute , and another PhD in Electrical Engineering along with Diploma of the Imperial College from Imperial College , University of London , in 1982 .", "prompt_labels": "He(O) received(O) a(O) PhD(O) in(O) Radio(B-field) Physics(I-field) and(O) Electronics(B-field) from(O) the(O) Rajabazar(B-university) Science(I-university) College(I-university) campus(O) of(O) University(B-university) of(I-university) Calcutta(I-university) in(O) 1979(O) as(O) a(O) student(O) of(O) Indian(B-university) Statistical(I-university) Institute(I-university) ,(O) and(O) another(O) PhD(O) in(O) Electrical(B-field) Engineering(I-field) along(O) with(O) Diploma(O) of(O) the(O) Imperial(O) College(O) from(O) Imperial(B-university) College(I-university) ,(O) University(B-university) of(I-university) London(I-university) ,(O) in(O) 1982(O) .(O)"}, "label_list": ["task", "metric", "programming language", "conference", "researcher", "country", "algorithm", "location", "field", "product", "person", "university", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3465, 11, 18767, 11, 15840, 4221, 11, 10017, 11, 32185, 11, 3224, 11, 12384, 11, 3813, 11, 2115, 11, 2027, 11, 1732, 11, 12374, 11, 7471, 323, 507, 627, 85664, 25, 1283, 4036, 264, 30661, 304, 13792, 28415, 323, 38784, 505, 279, 26291, 370, 34144, 10170, 9304, 15679, 315, 3907, 315, 3400, 10453, 2629, 304, 220, 4468, 24, 439, 264, 5575, 315, 7904, 66794, 10181, 1174, 323, 2500, 30661, 304, 45034, 17005, 3235, 449, 77131, 315, 279, 31013, 9304, 505, 31013, 9304, 1174, 3907, 315, 7295, 1174, 304, 220, 3753, 17, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1044", "dataset": "mit-movie", "split": "dev", "prediction": "find(O) me(O) the(O) movie(O) that(O) has(O) darth(B-character) vader(I-character) in(O) it(O)", "instance": {"id": "1044", "words": ["find", "me", "the", "movie", "that", "has", "darth", "vader", "in", "it"], "labels": ["O", "O", "O", "O", "O", "O", "B-character", "I-character", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, trailer, average ratings, director, title, rating, song, character, actor, year, review, genre and O.\nSentence: find me the movie that has darth vader in it", "prompt_labels": "find(O) me(O) the(O) movie(O) that(O) has(O) darth(B-character) vader(I-character) in(O) it(O)"}, "label_list": ["plot", "trailer", "average ratings", "director", "title", "rating", "song", "character", "actor", "year", "review", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 19809, 11, 5578, 18594, 11, 7690, 11, 2316, 11, 10959, 11, 5609, 11, 3752, 11, 12360, 11, 1060, 11, 3477, 11, 17779, 323, 507, 627, 85664, 25, 1505, 757, 279, 5818, 430, 706, 15627, 339, 348, 1013, 304, 433, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1345", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) can(O) i(O) get(O) something(O) inexpensive(B-Price) to(O) eat(O) near(B-Location) my(I-Location) current(I-Location) location(I-Location)", "instance": {"id": "1345", "words": ["where", "can", "i", "get", "something", "inexpensive", "to", "eat", "near", "my", "current", "location"], "labels": ["O", "O", "O", "O", "O", "B-Price", "O", "O", "B-Location", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Rating, Cuisine, Dish, Hours, Amenity, Location, Restaurant Name and O.\nSentence: where can i get something inexpensive to eat near my current location", "prompt_labels": "where(O) can(O) i(O) get(O) something(O) inexpensive(B-Price) to(O) eat(O) near(B-Location) my(O) current(B-Location) location(I-Location)"}, "label_list": ["Price", "Rating", "Cuisine", "Dish", "Hours", "Amenity", "Location", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 19767, 11, 81961, 11, 49268, 11, 30192, 11, 3383, 56685, 11, 10067, 11, 26568, 4076, 323, 507, 627, 85664, 25, 1405, 649, 602, 636, 2555, 44252, 311, 8343, 3221, 856, 1510, 3813, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "986", "dataset": "mit-restaurant", "split": "dev", "prediction": "looking(O) for(O) the(O) cheapest(B-Price) place(O) to(O) eat(O) im(O) on(O) a(O) budget(B-Price)", "instance": {"id": "986", "words": ["looking", "for", "the", "cheapest", "place", "to", "eat", "im", "on", "a", "budget"], "labels": ["O", "O", "O", "B-Price", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Hours, Price, Cuisine, Rating, Dish, Location, Restaurant Name and O.\nSentence: looking for the cheapest place to eat im on a budget", "prompt_labels": "looking(O) for(O) the(O) cheapest(B-Price) place(O) to(O) eat(O) im(O) on(O) a(O) budget(O)"}, "label_list": ["Amenity", "Hours", "Price", "Cuisine", "Rating", "Dish", "Location", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 30192, 11, 8650, 11, 81961, 11, 19767, 11, 49268, 11, 10067, 11, 26568, 4076, 323, 507, 627, 85664, 25, 3411, 369, 279, 43149, 2035, 311, 8343, 737, 389, 264, 8199, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "3", "dataset": "crossner_politics", "split": "dev", "prediction": "The(B-political party) MRE(I-political party) took(O) part(O) to(O) the(O) consolidation(O) of(O) The(B-location) Olive(I-location) Tree(I-location) as(O) a(O) joint(O) electoral(O) list(O) both(O) for(O) the(O) 2004(B-election) European(I-election) Parliament(I-election) election(I-election) and(O) the(O) 2006(B-election) Italian(I-election) general(I-election) election(I-election),(O) along(O) with(O) the(O) Democrats(B-political party) of(I-political party) the(I-political party) Left(I-political party) and(O) Democracy(B-political party) is(I-political party) Freedom(I-political party) -(O) The(B-political party) Daisy(I-political party).(O)", "instance": {"id": "3", "words": ["The", "MRE", "took", "part", "to", "the", "consolidation", "of", "The", "Olive", "Tree", "as", "a", "joint", "electoral", "list", "both", "for", "the", "2004", "European", "Parliament", "election", "and", "the", "2006", "Italian", "general", "election", ",", "along", "with", "the", "Democrats", "of", "the", "Left", "and", "Democracy", "is", "Freedom", "-", "The", "Daisy", "."], "labels": ["O", "B-political party", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, political party, person, country, location, election, event, politician and O.\nSentence: The MRE took part to the consolidation of The Olive Tree as a joint electoral list both for the 2004 European Parliament election and the 2006 Italian general election , along with the Democrats of the Left and Democracy is Freedom - The Daisy .", "prompt_labels": "The(O) MRE(B-political party) took(O) part(O) to(O) the(O) consolidation(O) of(O) The(B-organization) Olive(I-organization) Tree(I-organization) as(O) a(O) joint(O) electoral(O) list(O) both(O) for(O) the(O) 2004(B-election) European(I-election) Parliament(I-election) election(I-election) and(O) the(O) 2006(B-election) Italian(I-election) general(I-election) election(I-election) ,(O) along(O) with(O) the(O) Democrats(B-political party) of(I-political party) the(I-political party) Left(I-political party) and(O) Democracy(B-political party) is(I-political party) Freedom(I-political party) -(I-political party) The(I-political party) Daisy(I-political party) .(O)"}, "label_list": ["organization", "political party", "person", "country", "location", "election", "event", "politician"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 5054, 4717, 11, 1732, 11, 3224, 11, 3813, 11, 6355, 11, 1567, 11, 37038, 323, 507, 627, 85664, 25, 578, 386, 793, 3952, 961, 311, 279, 60732, 315, 578, 47814, 9119, 439, 264, 10496, 34941, 1160, 2225, 369, 279, 220, 1049, 19, 7665, 20302, 6355, 323, 279, 220, 1049, 21, 15155, 4689, 6355, 1174, 3235, 449, 279, 12643, 315, 279, 14043, 323, 48189, 374, 25320, 482, 578, 71264, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "457", "dataset": "crossner_politics", "split": "dev", "prediction": "The(O) Suffragette(O) Oak(O) on(O) Kelvinway(B-location) was(O) planted(O) in(O) 1918(O) to(O) celebrate(O) women(O)'s(O) first(O) opportunity(O) to(O) vote(O) in(O) a(O) general(O) election(O) and(O) stands(O) as(O) a(O) memorial(O) to(O) the(O) likes(O) of(O) Helen(B-person) Crawfurd(I-person),(O) Dorothea(B-person) Chalmers(I-person) Smith(I-person),(O) Jessie(B-person) Stephen(I-person) and(O) Frances(B-person) McPhun(I-person).(O)", "instance": {"id": "457", "words": ["The", "Suffragette", "Oak", "on", "Kelvinway", "was", "planted", "in", "1918", "to", "celebrate", "women", "'s", "first", "opportunity", "to", "vote", "in", "a", "general", "election", "and", "stands", "as", "a", "memorial", "to", "the", "likes", "of", "Helen", "Crawfurd", ",", "Dorothea", "Chalmers", "Smith", ",", "Jessie", "Stephen", "and", "Frances", "McPhun", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "B-person", "I-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, location, politician, organization, event, political party, person, election and O.\nSentence: The Suffragette Oak on Kelvinway was planted in 1918 to celebrate women 's first opportunity to vote in a general election and stands as a memorial to the likes of Helen Crawfurd , Dorothea Chalmers Smith , Jessie Stephen and Frances McPhun .", "prompt_labels": "The(O) Suffragette(O) Oak(O) on(O) Kelvinway(O) was(O) planted(O) in(O) 1918(O) to(O) celebrate(O) women(O) 's(O) first(O) opportunity(O) to(O) vote(O) in(O) a(O) general(O) election(O) and(O) stands(O) as(O) a(O) memorial(O) to(O) the(O) likes(O) of(O) Helen(B-person) Crawfurd(I-person) ,(O) Dorothea(B-person) Chalmers(I-person) Smith(I-person) ,(O) Jessie(B-person) Stephen(I-person) and(O) Frances(B-person) McPhun(I-person) .(O)"}, "label_list": ["country", "location", "politician", "organization", "event", "political party", "person", "election"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 3813, 11, 37038, 11, 7471, 11, 1567, 11, 5054, 4717, 11, 1732, 11, 6355, 323, 507, 627, 85664, 25, 578, 60363, 4193, 6672, 18787, 389, 92073, 3195, 574, 39441, 304, 220, 7529, 23, 311, 18890, 3278, 364, 82, 1176, 6776, 311, 7055, 304, 264, 4689, 6355, 323, 13656, 439, 264, 39017, 311, 279, 13452, 315, 43881, 44766, 69, 16468, 1174, 423, 18812, 1820, 64, 921, 7828, 388, 9259, 1174, 80217, 18587, 323, 43833, 4584, 3438, 359, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "235", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) was(O) the(O) name(O) of(O) clive(B-actor) owens(I-actor) character(O) in(O) sin(B-title) city(I-title)", "instance": {"id": "235", "words": ["what", "was", "the", "name", "of", "clive", "owens", "character", "in", "sin", "city"], "labels": ["O", "O", "O", "O", "O", "B-actor", "I-actor", "O", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, actor, average ratings, review, year, trailer, genre, character, song, title, rating, plot and O.\nSentence: what was the name of clive owens character in sin city", "prompt_labels": "what(O) was(O) the(O) name(O) of(O) clive(B-actor) owens(I-actor) character(O) in(O) sin(B-title) city(I-title)"}, "label_list": ["director", "actor", "average ratings", "review", "year", "trailer", "genre", "character", "song", "title", "rating", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 12360, 11, 5578, 18594, 11, 3477, 11, 1060, 11, 19809, 11, 17779, 11, 3752, 11, 5609, 11, 2316, 11, 10959, 11, 7234, 323, 507, 627, 85664, 25, 1148, 574, 279, 836, 315, 1206, 535, 15941, 729, 3752, 304, 7589, 3363, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "226", "dataset": "crossner_ai", "split": "dev", "prediction": "In(O) 2007(O),(O) at(O) the(O) International(B-conference) Conference(I-conference) on(I-conference) Computer(I-conference) Vision(I-conference),(O) Terzopoulos(B-researcher) was(O) awarded(O) the(O) inaugural(O) IEEE(B-award) PAMI(I-award) Computer(I-award) Vision(I-award) Distinguished(I-award) Researcher(I-award) Award(I-award) for(O) pioneering(O) and(O) sustained(O) research(O) on(O) deformable(B-field) models(I-field) and(O) their(O) applications(O).(O)", "instance": {"id": "226", "words": ["In", "2007", ",", "at", "the", "International", "Conference", "on", "Computer", "Vision", ",", "Terzopoulos", "was", "awarded", "the", "inaugural", "IEEE", "PAMI", "Computer", "Vision", "Distinguished", "Researcher", "Award", "for", "pioneering", "and", "sustained", "research", "on", "deformable", "models", "and", "their", "applications", "."], "labels": ["O", "O", "O", "O", "O", "B-conference", "I-conference", "I-conference", "I-conference", "I-conference", "O", "B-researcher", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, university, product, researcher, location, person, organization, country, field, algorithm, task, conference, metric and O.\nSentence: In 2007 , at the International Conference on Computer Vision , Terzopoulos was awarded the inaugural IEEE PAMI Computer Vision Distinguished Researcher Award for pioneering and sustained research on deformable models and their applications .", "prompt_labels": "In(O) 2007(O) ,(O) at(O) the(O) International(B-conference) Conference(I-conference) on(I-conference) Computer(I-conference) Vision(I-conference) ,(O) Terzopoulos(B-researcher) was(O) awarded(O) the(O) inaugural(O) IEEE(O) PAMI(O) Computer(O) Vision(O) Distinguished(O) Researcher(O) Award(O) for(O) pioneering(O) and(O) sustained(O) research(O) on(O) deformable(O) models(O) and(O) their(O) applications(O) .(O)"}, "label_list": ["programming language", "university", "product", "researcher", "location", "person", "organization", "country", "field", "algorithm", "task", "conference", "metric"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 15840, 4221, 11, 12374, 11, 2027, 11, 32185, 11, 3813, 11, 1732, 11, 7471, 11, 3224, 11, 2115, 11, 12384, 11, 3465, 11, 10017, 11, 18767, 323, 507, 627, 85664, 25, 763, 220, 1049, 22, 1174, 520, 279, 7327, 15217, 389, 17863, 31541, 1174, 10335, 89, 57995, 574, 22034, 279, 54559, 40135, 393, 67668, 17863, 31541, 423, 80382, 8483, 261, 17768, 369, 71674, 323, 29759, 3495, 389, 79212, 481, 4211, 323, 872, 8522, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "453", "dataset": "crossner_politics", "split": "dev", "prediction": "Celebrities(O) such(O) as(O) Rosario(B-actor) Dawson(I-actor),(O) Dolores(B-actor) Huerta(I-actor),(O) Gina(B-actor) Belafonte(I-actor),(O) Van(B-actor) Jones(I-actor),(O) Jesse(B-actor) Williams(I-actor),(O) Robert(B-politician) A.(I-politician) Nakamura(I-politician) and(O) Karen(B-actor) L.(I-actor) Ishizuka(I-actor),(O) Kiran(B-actor) Gandhi(I-actor),(O) Michael(B-actor) Ealy(I-actor),(O) Saul(B-actor) Williams(I-actor),(O) Rodney(B-actor) Barnette(I-actor),(O) and(O) others(O) were(O) included(O) in(O) the(O) reinterpretations(O).(O)", "instance": {"id": "453", "words": ["Celebrities", "such", "as", "Rosario", "Dawson", ",", "Dolores", "Huerta", ",", "Gina", "Belafonte", ",", "Van", "Jones", ",", "Jesse", "Williams", ",", "Robert", "A.", "Nakamura", "and", "Karen", "L.", "Ishizuka", ",", "Kiran", "Gandhi", ",", "Michael", "Ealy", ",", "Saul", "Williams", ",", "Rodney", "Barnette", ",", "and", "others", "were", "included", "in", "the", "reinterpretations", "."], "labels": ["O", "O", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "I-person", "O", "B-person", "I-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, person, event, organization, country, political party, election, politician and O.\nSentence: Celebrities such as Rosario Dawson , Dolores Huerta , Gina Belafonte , Van Jones , Jesse Williams , Robert A. Nakamura and Karen L. Ishizuka , Kiran Gandhi , Michael Ealy , Saul Williams , Rodney Barnette , and others were included in the reinterpretations .", "prompt_labels": "Celebrities(O) such(O) as(O) Rosario(B-person) Dawson(I-person) ,(O) Dolores(B-person) Huerta(I-person) ,(O) Gina(B-person) Belafonte(I-person) ,(O) Van(B-person) Jones(I-person) ,(O) Jesse(B-person) Williams(I-person) ,(O) Robert(B-person) A.(I-person) Nakamura(I-person) and(O) Karen(B-person) L.(I-person) Ishizuka(I-person) ,(O) Kiran(B-person) Gandhi(I-person) ,(O) Michael(B-person) Ealy(I-person) ,(O) Saul(B-person) Williams(I-person) ,(O) Rodney(B-person) Barnette(I-person) ,(O) and(O) others(O) were(O) included(O) in(O) the(O) reinterpretations(O) .(O)"}, "label_list": ["location", "person", "event", "organization", "country", "political party", "election", "politician"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 1732, 11, 1567, 11, 7471, 11, 3224, 11, 5054, 4717, 11, 6355, 11, 37038, 323, 507, 627, 85664, 25, 23519, 35795, 1778, 439, 16870, 3370, 67312, 1174, 25227, 4692, 22546, 23463, 1174, 77312, 7984, 2642, 53377, 1174, 13000, 12201, 1174, 40271, 13926, 1174, 8563, 362, 13, 44329, 84817, 323, 35745, 445, 13, 57704, 450, 26261, 1174, 26608, 276, 48994, 1174, 8096, 469, 5893, 1174, 68624, 13926, 1174, 76043, 23229, 6672, 1174, 323, 3885, 1051, 5343, 304, 279, 26250, 811, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "195", "dataset": "crossner_literature", "split": "dev", "prediction": "Big(B-character) Brother(I-character) is(O) a(O) fictional(O) character(O) and(O) symbol(O) in(O) George(B-writer) Orwell(I-writer) '(O) s(O) dystopian(O) novel(O) Nineteen(B-book) Eighty-Four(I-book),(O) published(O) in(O) 1949(O).(O)", "instance": {"id": "195", "words": ["Big", "Brother", "is", "a", "fictional", "character", "and", "symbol", "in", "George", "Orwell", "'", "s", "dystopian", "novel", "Nineteen", "Eighty-Four", ",", "published", "in", "1949", "."], "labels": ["B-person", "I-person", "O", "O", "O", "O", "O", "O", "O", "B-writer", "I-writer", "O", "O", "B-literary genre", "I-literary genre", "B-book", "I-book", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, award, magazine, event, person, organization, writer, country, book, poem, literary genre and O.\nSentence: Big Brother is a fictional character and symbol in George Orwell ' s dystopian novel Nineteen Eighty-Four , published in 1949 .", "prompt_labels": "Big(B-person) Brother(I-person) is(O) a(O) fictional(O) character(O) and(O) symbol(O) in(O) George(B-writer) Orwell(I-writer) '(O) s(O) dystopian(B-literary genre) novel(I-literary genre) Nineteen(B-book) Eighty-Four(I-book) ,(O) published(O) in(O) 1949(O) .(O)"}, "label_list": ["location", "award", "magazine", "event", "person", "organization", "writer", "country", "book", "poem", "literary genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 10292, 11, 14756, 11, 1567, 11, 1732, 11, 7471, 11, 7061, 11, 3224, 11, 2363, 11, 33894, 11, 32465, 17779, 323, 507, 627, 85664, 25, 6295, 27445, 374, 264, 44682, 3752, 323, 7891, 304, 10058, 83853, 364, 274, 69110, 48748, 11775, 27825, 7870, 268, 36944, 88, 7424, 414, 1174, 4756, 304, 220, 6393, 24, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1010", "dataset": "mit-restaurant", "split": "dev", "prediction": "nearest(B-Location) fast(B-Cuisine) food(I-Cuisine) restaurant(O)", "instance": {"id": "1010", "words": ["nearest", "fast", "food", "restaurant"], "labels": ["B-Location", "B-Cuisine", "I-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Amenity, Restaurant Name, Location, Cuisine, Price, Hours, Rating and O.\nSentence: nearest fast food restaurant", "prompt_labels": "nearest(B-Location) fast(B-Cuisine) food(I-Cuisine) restaurant(O)"}, "label_list": ["Dish", "Amenity", "Restaurant Name", "Location", "Cuisine", "Price", "Hours", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 3383, 56685, 11, 26568, 4076, 11, 10067, 11, 81961, 11, 8650, 11, 30192, 11, 19767, 323, 507, 627, 85664, 25, 24379, 5043, 3691, 10960, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "70", "dataset": "crossner_science", "split": "dev", "prediction": "FastPP(O) can(O) be(O) used(O) on(O) unpurified(O),(O) complex(O) mixtures(O) of(O) proteins(O) and(O) proteins(O) fused(O) with(O) other(O) proteins(O),(O) such(O) as(O) Glutathione(B-protein) S-transferase(I-protein) or(O) Green(B-protein) fluorescent(I-protein) protein(I-protein),(O) as(O) long(O) as(O) the(O) sequence(O) that(O) is(O) the(O) target(O) of(O) the(O) western(B-protein) blot(I-protein),(O) e.g.(O),(O) His-tag(O),(O) is(O) directly(O) linked(O) to(O) the(O) protein(O) of(O) interest(O).(O)", "instance": {"id": "70", "words": ["FastPP", "can", "be", "used", "on", "unpurified", ",", "complex", "mixtures", "of", "proteins", "and", "proteins", "fused", "with", "other", "proteins", ",", "such", "as", "Glutathione", "S-transferase", "or", "Green", "fluorescent", "protein", ",", "as", "long", "as", "the", "sequence", "that", "is", "the", "target", "of", "the", "western", "blot", ",", "e.g.", ",", "His-tag", ",", "is", "directly", "linked", "to", "the", "protein", "of", "interest", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-protein", "I-protein", "O", "B-protein", "I-protein", "I-protein", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, event, award, chemical element, discipline, person, location, scientist, university, academic journal, chemical compound, protein, enzyme, astronomical object, theory, country and O.\nSentence: FastPP can be used on unpurified , complex mixtures of proteins and proteins fused with other proteins , such as Glutathione S-transferase or Green fluorescent protein , as long as the sequence that is the target of the western blot , e.g. , His-tag , is directly linked to the protein of interest .", "prompt_labels": "FastPP(O) can(O) be(O) used(O) on(O) unpurified(O) ,(O) complex(O) mixtures(O) of(O) proteins(O) and(O) proteins(O) fused(O) with(O) other(O) proteins(O) ,(O) such(O) as(O) Glutathione(B-protein) S-transferase(I-protein) or(O) Green(B-protein) fluorescent(I-protein) protein(I-protein) ,(O) as(O) long(O) as(O) the(O) sequence(O) that(O) is(O) the(O) target(O) of(O) the(O) western(O) blot(O) ,(O) e.g.(O) ,(O) His-tag(O) ,(O) is(O) directly(O) linked(O) to(O) the(O) protein(O) of(O) interest(O) .(O)"}, "label_list": ["organization", "event", "award", "chemical element", "discipline", "person", "location", "scientist", "university", "academic journal", "chemical compound", "protein", "enzyme", "astronomical object", "theory", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 1567, 11, 10292, 11, 11742, 2449, 11, 26434, 11, 1732, 11, 3813, 11, 28568, 11, 12374, 11, 14584, 8486, 11, 11742, 24549, 11, 13128, 11, 49242, 11, 87283, 1665, 11, 10334, 11, 3224, 323, 507, 627, 85664, 25, 17737, 4505, 649, 387, 1511, 389, 22355, 324, 1908, 1174, 6485, 6651, 19020, 315, 28896, 323, 28896, 75754, 449, 1023, 28896, 1174, 1778, 439, 8444, 332, 589, 6473, 328, 93791, 521, 477, 7997, 74864, 13128, 1174, 439, 1317, 439, 279, 8668, 430, 374, 279, 2218, 315, 279, 19001, 81982, 1174, 384, 1326, 13, 1174, 5414, 39304, 1174, 374, 6089, 10815, 311, 279, 13128, 315, 2802, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1457", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) there(O) a(O) john(B-actor) travolta(I-actor) comedy(B-genre) from(O) the(O) past(B-year) two(I-year) years(I-year)", "instance": {"id": "1457", "words": ["is", "there", "a", "john", "travolta", "comedy", "from", "the", "past", "two", "years"], "labels": ["O", "O", "O", "B-actor", "I-actor", "B-genre", "O", "O", "B-year", "I-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, rating, character, review, plot, average ratings, song, genre, actor, director, year, title and O.\nSentence: is there a john travolta comedy from the past two years", "prompt_labels": "is(O) there(O) a(O) john(B-actor) travolta(I-actor) comedy(B-genre) from(O) the(O) past(B-year) two(I-year) years(I-year)"}, "label_list": ["trailer", "rating", "character", "review", "plot", "average ratings", "song", "genre", "actor", "director", "year", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 10959, 11, 3752, 11, 3477, 11, 7234, 11, 5578, 18594, 11, 5609, 11, 17779, 11, 12360, 11, 7690, 11, 1060, 11, 2316, 323, 507, 627, 85664, 25, 374, 1070, 264, 40742, 10346, 60954, 23160, 505, 279, 3347, 1403, 1667, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2197", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) unrated(B-rating) movies(O) has(O) lena(B-actor) horne(I-actor) acted(O) in(O) within(O) the(O) last(B-year) six(I-year) decades(I-year)", "instance": {"id": "2197", "words": ["what", "unrated", "movies", "has", "lena", "horne", "acted", "in", "within", "the", "last", "six", "decades"], "labels": ["O", "B-rating", "O", "O", "B-actor", "I-actor", "O", "O", "O", "O", "B-year", "I-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, average ratings, actor, song, genre, director, trailer, year, title, plot, review, character and O.\nSentence: what unrated movies has lena horne acted in within the last six decades", "prompt_labels": "what(O) unrated(B-rating) movies(O) has(O) lena(B-actor) horne(I-actor) acted(O) in(O) within(O) the(O) last(B-year) six(I-year) decades(I-year)"}, "label_list": ["rating", "average ratings", "actor", "song", "genre", "director", "trailer", "year", "title", "plot", "review", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 5578, 18594, 11, 12360, 11, 5609, 11, 17779, 11, 7690, 11, 19809, 11, 1060, 11, 2316, 11, 7234, 11, 3477, 11, 3752, 323, 507, 627, 85664, 25, 1148, 41480, 660, 9698, 706, 2479, 64, 4917, 818, 31532, 304, 2949, 279, 1566, 4848, 11026, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1179", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) restaurant(O) is(O) expensive(B-Price) and(O) has(O) entertainment(B-Amenity)", "instance": {"id": "1179", "words": ["what", "restaurant", "is", "expensive", "and", "has", "entertainment"], "labels": ["O", "O", "O", "B-Price", "O", "O", "B-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Price, Hours, Rating, Amenity, Cuisine, Location, Dish and O.\nSentence: what restaurant is expensive and has entertainment", "prompt_labels": "what(O) restaurant(O) is(O) expensive(B-Price) and(O) has(O) entertainment(B-Amenity)"}, "label_list": ["Restaurant Name", "Price", "Hours", "Rating", "Amenity", "Cuisine", "Location", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 8650, 11, 30192, 11, 19767, 11, 3383, 56685, 11, 81961, 11, 10067, 11, 49268, 323, 507, 627, 85664, 25, 1148, 10960, 374, 11646, 323, 706, 16924, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "624", "dataset": "mit-movie", "split": "dev", "prediction": "which(O) actor(O) played(O) captain(B-character) january(I-character)", "instance": {"id": "624", "words": ["which", "actor", "played", "captain", "january"], "labels": ["O", "O", "O", "B-character", "I-character"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, year, trailer, director, review, character, song, genre, average ratings, rating, actor, title and O.\nSentence: which actor played captain january", "prompt_labels": "which(O) actor(O) played(O) captain(B-character) january(I-character)"}, "label_list": ["plot", "year", "trailer", "director", "review", "character", "song", "genre", "average ratings", "rating", "actor", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 1060, 11, 19809, 11, 7690, 11, 3477, 11, 3752, 11, 5609, 11, 17779, 11, 5578, 18594, 11, 10959, 11, 12360, 11, 2316, 323, 507, 627, 85664, 25, 902, 12360, 6476, 24862, 33962, 3620, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "198", "dataset": "mit-movie", "split": "dev", "prediction": "are(O) there(O) any(O) five(B-average ratings) star(I-average ratings) kevin(B-actor) bacon(I-actor) movies(O)", "instance": {"id": "198", "words": ["are", "there", "any", "five", "star", "kevin", "bacon", "movies"], "labels": ["O", "O", "O", "B-average ratings", "I-average ratings", "B-actor", "I-actor", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, average ratings, director, plot, character, rating, trailer, actor, year, review, title, song and O.\nSentence: are there any five star kevin bacon movies", "prompt_labels": "are(O) there(O) any(O) five(B-average ratings) star(I-average ratings) kevin(B-actor) bacon(I-actor) movies(O)"}, "label_list": ["genre", "average ratings", "director", "plot", "character", "rating", "trailer", "actor", "year", "review", "title", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 5578, 18594, 11, 7690, 11, 7234, 11, 3752, 11, 10959, 11, 19809, 11, 12360, 11, 1060, 11, 3477, 11, 2316, 11, 5609, 323, 507, 627, 85664, 25, 527, 1070, 904, 4330, 6917, 2004, 9799, 41452, 9698, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1157", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) robby(B-director) benson(I-director) direct(O) a(O) short(B-genre) movie(O) that(O) was(O) rated(O) eight(B-average ratings) stars(I-average ratings) in(O) 1990(B-year)", "instance": {"id": "1157", "words": ["did", "robby", "benson", "direct", "a", "short", "movie", "that", "was", "rated", "eight", "stars", "in", "1990"], "labels": ["O", "B-director", "I-director", "O", "O", "B-genre", "O", "O", "O", "O", "B-average ratings", "I-average ratings", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, rating, review, average ratings, director, trailer, year, title, genre, actor, character, song and O.\nSentence: did robby benson direct a short movie that was rated eight stars in 1990", "prompt_labels": "did(O) robby(B-director) benson(I-director) direct(O) a(O) short(B-genre) movie(O) that(O) was(O) rated(O) eight(B-average ratings) stars(I-average ratings) in(O) 1990(B-year)"}, "label_list": ["plot", "rating", "review", "average ratings", "director", "trailer", "year", "title", "genre", "actor", "character", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 10959, 11, 3477, 11, 5578, 18594, 11, 7690, 11, 19809, 11, 1060, 11, 2316, 11, 17779, 11, 12360, 11, 3752, 11, 5609, 323, 507, 627, 85664, 25, 1550, 10773, 1729, 293, 34237, 2167, 264, 2875, 5818, 430, 574, 22359, 8223, 9958, 304, 220, 2550, 15, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "392", "dataset": "mit-restaurant", "split": "dev", "prediction": "find(O) me(O) a(O) restaurant(O) near(B-Location) a(I-Location) movie(I-Location) theater(I-Location) thats(O) open(B-Hours) at(I-Hours) 6(I-Hours) pm(I-Hours) on(O) saturday(B-Hours)", "instance": {"id": "392", "words": ["find", "me", "a", "restaurant", "near", "a", "movie", "theater", "thats", "open", "at", "6", "pm", "on", "saturday"], "labels": ["O", "O", "O", "O", "B-Location", "I-Location", "I-Location", "I-Location", "O", "B-Hours", "I-Hours", "I-Hours", "I-Hours", "I-Hours", "I-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Amenity, Location, Restaurant Name, Rating, Dish, Cuisine, Price and O.\nSentence: find me a restaurant near a movie theater thats open at 6 pm on saturday", "prompt_labels": "find(O) me(O) a(O) restaurant(O) near(B-Location) a(I-Location) movie(I-Location) theater(I-Location) thats(O) open(B-Hours) at(I-Hours) 6(I-Hours) pm(I-Hours) on(I-Hours) saturday(I-Hours)"}, "label_list": ["Hours", "Amenity", "Location", "Restaurant Name", "Rating", "Dish", "Cuisine", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 3383, 56685, 11, 10067, 11, 26568, 4076, 11, 19767, 11, 49268, 11, 81961, 11, 8650, 323, 507, 627, 85664, 25, 1505, 757, 264, 10960, 3221, 264, 5818, 27803, 41136, 1825, 520, 220, 21, 9012, 389, 274, 7115, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1094", "dataset": "mit-movie", "split": "dev", "prediction": "are(O) there(O) any(O) movies(O) starring(O) stan(B-actor) laurel(I-actor) and(O) oliver(B-actor) hardy(I-actor) from(O) the(O) last(B-year) two(I-year) years(I-year) available(O)", "instance": {"id": "1094", "words": ["are", "there", "any", "movies", "starring", "stan", "laurel", "and", "oliver", "hardy", "from", "the", "last", "two", "years", "available"], "labels": ["O", "O", "O", "O", "O", "B-actor", "I-actor", "I-actor", "I-actor", "I-actor", "O", "O", "B-year", "I-year", "I-year", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, director, trailer, rating, song, plot, title, review, year, genre, actor, average ratings and O.\nSentence: are there any movies starring stan laurel and oliver hardy from the last two years available", "prompt_labels": "are(O) there(O) any(O) movies(O) starring(O) stan(B-actor) laurel(I-actor) and(I-actor) oliver(I-actor) hardy(I-actor) from(O) the(O) last(B-year) two(I-year) years(I-year) available(O)"}, "label_list": ["character", "director", "trailer", "rating", "song", "plot", "title", "review", "year", "genre", "actor", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 7690, 11, 19809, 11, 10959, 11, 5609, 11, 7234, 11, 2316, 11, 3477, 11, 1060, 11, 17779, 11, 12360, 11, 5578, 18594, 323, 507, 627, 85664, 25, 527, 1070, 904, 9698, 40500, 46294, 67185, 75, 323, 8492, 1553, 2653, 88, 505, 279, 1566, 1403, 1667, 2561, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1035", "dataset": "mit-movie", "split": "dev", "prediction": "the(O) song(O) hold(B-song) on(I-song) by(O) 90s(O) band(O) wilson(O) phillips(O) is(O) used(O) in(O) which(O) film(O) soundtracks(O)", "instance": {"id": "1035", "words": ["the", "song", "hold", "on", "by", "90s", "band", "wilson", "phillips", "is", "used", "in", "which", "film", "soundtracks"], "labels": ["O", "O", "B-song", "I-song", "O", "B-year", "O", "B-song", "I-song", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, trailer, average ratings, year, genre, review, director, character, rating, plot, song, title and O.\nSentence: the song hold on by 90s band wilson phillips is used in which film soundtracks", "prompt_labels": "the(O) song(O) hold(B-song) on(I-song) by(O) 90s(B-year) band(O) wilson(B-song) phillips(I-song) is(O) used(O) in(O) which(O) film(O) soundtracks(O)"}, "label_list": ["actor", "trailer", "average ratings", "year", "genre", "review", "director", "character", "rating", "plot", "song", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 19809, 11, 5578, 18594, 11, 1060, 11, 17779, 11, 3477, 11, 7690, 11, 3752, 11, 10959, 11, 7234, 11, 5609, 11, 2316, 323, 507, 627, 85664, 25, 279, 5609, 3412, 389, 555, 220, 1954, 82, 7200, 31331, 942, 1343, 484, 3153, 374, 1511, 304, 902, 4632, 5222, 50424, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1249", "dataset": "mit-restaurant", "split": "dev", "prediction": "when(O) does(O) pizza(B-Restaurant Name) patron(I-Restaurant Name) open(O)", "instance": {"id": "1249", "words": ["when", "does", "pizza", "patron", "open"], "labels": ["O", "O", "B-Restaurant Name", "I-Restaurant Name", "B-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Hours, Rating, Dish, Amenity, Price, Location, Cuisine and O.\nSentence: when does pizza patron open", "prompt_labels": "when(O) does(O) pizza(B-Restaurant Name) patron(I-Restaurant Name) open(B-Hours)"}, "label_list": ["Restaurant Name", "Hours", "Rating", "Dish", "Amenity", "Price", "Location", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 30192, 11, 19767, 11, 49268, 11, 3383, 56685, 11, 8650, 11, 10067, 11, 81961, 323, 507, 627, 85664, 25, 994, 1587, 23317, 36380, 1825, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "853", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) all(O) independent(B-genre) films(O) starring(O) a(O) list(O) celebrities(O)", "instance": {"id": "853", "words": ["show", "all", "independent", "films", "starring", "a", "list", "celebrities"], "labels": ["O", "O", "B-genre", "I-genre", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, actor, character, review, average ratings, trailer, song, genre, director, year, plot, title and O.\nSentence: show all independent films starring a list celebrities", "prompt_labels": "show(O) all(O) independent(B-genre) films(I-genre) starring(O) a(O) list(O) celebrities(O)"}, "label_list": ["rating", "actor", "character", "review", "average ratings", "trailer", "song", "genre", "director", "year", "plot", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 12360, 11, 3752, 11, 3477, 11, 5578, 18594, 11, 19809, 11, 5609, 11, 17779, 11, 7690, 11, 1060, 11, 7234, 11, 2316, 323, 507, 627, 85664, 25, 1501, 682, 9678, 12631, 40500, 264, 1160, 40501, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "498", "dataset": "crossner_politics", "split": "dev", "prediction": "He(O) also(O) served(O) as(O) campaign(O) chairman(O),(O) campaign(O) manager(O) and(O) senior(O) consultant(O) to(O) Dan(B-politician) Lungren(I-politician) for(O) his(O) two(O) victories(O) as(O) Attorney(O) General(O) and(O) to(O) U.S.(B-country) Senate(O) candidate(O) Bruce(B-politician) Herschensohn(I-politician) -(O) engineering(O) come-from-behind(O) wins(O) for(O) Lungren(B-politician)'s(O) first(O) campaign(O) and(O) for(O) Herschensohn(B-politician)'s(O) primary(O) victory(O) in(O) 1992(O).(O)", "instance": {"id": "498", "words": ["He", "also", "served", "as", "campaign", "chairman", ",", "campaign", "manager", "and", "senior", "consultant", "to", "Dan", "Lungren", "for", "his", "two", "victories", "as", "Attorney", "General", "and", "to", "U.S.", "Senate", "candidate", "Bruce", "Herschensohn", "-", "engineering", "come-from-behind", "wins", "for", "Lungren", "'s", "first", "campaign", "and", "for", "Herschensohn", "'s", "primary", "victory", "in", "1992", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-politician", "I-politician", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "B-politician", "I-politician", "O", "O", "O", "O", "O", "B-politician", "O", "O", "O", "O", "O", "B-politician", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, location, organization, political party, country, politician, event, person and O.\nSentence: He also served as campaign chairman , campaign manager and senior consultant to Dan Lungren for his two victories as Attorney General and to U.S. Senate candidate Bruce Herschensohn - engineering come-from-behind wins for Lungren 's first campaign and for Herschensohn 's primary victory in 1992 .", "prompt_labels": "He(O) also(O) served(O) as(O) campaign(O) chairman(O) ,(O) campaign(O) manager(O) and(O) senior(O) consultant(O) to(O) Dan(B-politician) Lungren(I-politician) for(O) his(O) two(O) victories(O) as(O) Attorney(O) General(O) and(O) to(O) U.S.(B-organization) Senate(I-organization) candidate(O) Bruce(B-politician) Herschensohn(I-politician) -(O) engineering(O) come-from-behind(O) wins(O) for(O) Lungren(B-politician) 's(O) first(O) campaign(O) and(O) for(O) Herschensohn(B-politician) 's(O) primary(O) victory(O) in(O) 1992(O) .(O)"}, "label_list": ["election", "location", "organization", "political party", "country", "politician", "event", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 6355, 11, 3813, 11, 7471, 11, 5054, 4717, 11, 3224, 11, 37038, 11, 1567, 11, 1732, 323, 507, 627, 85664, 25, 1283, 1101, 10434, 439, 4901, 21892, 1174, 4901, 6783, 323, 10195, 31760, 311, 11824, 78336, 1466, 369, 813, 1403, 46146, 439, 18919, 3331, 323, 311, 549, 815, 13, 10092, 9322, 24785, 65466, 7674, 708, 25105, 482, 15009, 2586, 39151, 15502, 75038, 15160, 369, 78336, 1466, 364, 82, 1176, 4901, 323, 369, 65466, 7674, 708, 25105, 364, 82, 6156, 12845, 304, 220, 2550, 17, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1136", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) david(B-director) lean(I-director) ever(O) direct(O) a(O) drama(B-genre) in(O) the(O) 1980(B-year) s(I-year)", "instance": {"id": "1136", "words": ["did", "david", "lean", "ever", "direct", "a", "drama", "in", "the", "1980", "s"], "labels": ["O", "B-director", "I-director", "O", "O", "O", "B-genre", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, trailer, genre, average ratings, rating, title, year, plot, song, review, character, actor and O.\nSentence: did david lean ever direct a drama in the 1980 s", "prompt_labels": "did(O) david(B-director) lean(I-director) ever(O) direct(O) a(O) drama(B-genre) in(O) the(O) 1980(B-year) s(I-year)"}, "label_list": ["director", "trailer", "genre", "average ratings", "rating", "title", "year", "plot", "song", "review", "character", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 19809, 11, 17779, 11, 5578, 18594, 11, 10959, 11, 2316, 11, 1060, 11, 7234, 11, 5609, 11, 3477, 11, 3752, 11, 12360, 323, 507, 627, 85664, 25, 1550, 55046, 16025, 3596, 2167, 264, 20156, 304, 279, 220, 3753, 15, 274, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2007", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) a(O) g(B-rating) rated(O) film(O) animation(B-genre) film(O) that(O) was(O) released(O) within(O) the(O) past(B-year) six(I-year) years(I-year) and(O) has(O) a(O) ratings(O) average(O) of(O) six(B-average ratings) stars(I-average ratings)", "instance": {"id": "2007", "words": ["what", "is", "a", "g", "rated", "film", "animation", "film", "that", "was", "released", "within", "the", "past", "six", "years", "and", "has", "a", "ratings", "average", "of", "six", "stars"], "labels": ["O", "O", "O", "B-rating", "O", "O", "B-genre", "O", "O", "O", "O", "O", "O", "B-year", "I-year", "I-year", "O", "O", "O", "O", "O", "O", "B-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, year, character, average ratings, actor, song, rating, director, title, review, trailer, plot and O.\nSentence: what is a g rated film animation film that was released within the past six years and has a ratings average of six stars", "prompt_labels": "what(O) is(O) a(O) g(B-rating) rated(O) film(O) animation(B-genre) film(O) that(O) was(O) released(O) within(O) the(O) past(B-year) six(I-year) years(I-year) and(O) has(O) a(O) ratings(O) average(O) of(O) six(B-average ratings) stars(I-average ratings)"}, "label_list": ["genre", "year", "character", "average ratings", "actor", "song", "rating", "director", "title", "review", "trailer", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 1060, 11, 3752, 11, 5578, 18594, 11, 12360, 11, 5609, 11, 10959, 11, 7690, 11, 2316, 11, 3477, 11, 19809, 11, 7234, 323, 507, 627, 85664, 25, 1148, 374, 264, 342, 22359, 4632, 10571, 4632, 430, 574, 6004, 2949, 279, 3347, 4848, 1667, 323, 706, 264, 18594, 5578, 315, 4848, 9958, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "543", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) am(O) in(O) the(O) mood(O) for(O) shrimp(B-Dish) where(O) is(O) the(O) closet(B-Location) place(O) i(O) can(O) go(O)", "instance": {"id": "543", "words": ["i", "am", "in", "the", "mood", "for", "shrimp", "where", "is", "the", "closet", "place", "i", "can", "go"], "labels": ["O", "O", "O", "O", "O", "O", "B-Dish", "O", "O", "O", "B-Location", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Restaurant Name, Location, Price, Cuisine, Rating, Dish, Amenity and O.\nSentence: i am in the mood for shrimp where is the closet place i can go", "prompt_labels": "i(O) am(O) in(O) the(O) mood(O) for(O) shrimp(B-Dish) where(O) is(O) the(O) closet(B-Location) place(O) i(O) can(O) go(O)"}, "label_list": ["Hours", "Restaurant Name", "Location", "Price", "Cuisine", "Rating", "Dish", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 26568, 4076, 11, 10067, 11, 8650, 11, 81961, 11, 19767, 11, 49268, 11, 3383, 56685, 323, 507, 627, 85664, 25, 602, 1097, 304, 279, 20247, 369, 56626, 1405, 374, 279, 33044, 2035, 602, 649, 733, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "12", "dataset": "crossner_politics", "split": "dev", "prediction": "Examples(O) of(O) some(O) successful(O) testimonial(O) parties(O) are(O) the(O) Party(B-political party) for(I-political party) the(I-political party) Animals(I-political party),(O) the(O) Reformed(B-political party) Political(I-political party) Party(I-political party),(O) or(O) the(O) former(O) Pacifist(B-political party) Socialist(I-political party) Party(I-political party).(O)", "instance": {"id": "12", "words": ["Examples", "of", "some", "successful", "testimonial", "parties", "are", "the", "Party", "for", "the", "Animals", ",", "the", "Reformed", "Political", "Party", ",", "or", "the", "former", "Pacifist", "Socialist", "Party", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, political party, event, organization, location, person, politician, election and O.\nSentence: Examples of some successful testimonial parties are the Party for the Animals , the Reformed Political Party , or the former Pacifist Socialist Party .", "prompt_labels": "Examples(O) of(O) some(O) successful(O) testimonial(O) parties(O) are(O) the(O) Party(B-political party) for(I-political party) the(I-political party) Animals(I-political party) ,(O) the(O) Reformed(B-political party) Political(I-political party) Party(I-political party) ,(O) or(O) the(O) former(O) Pacifist(B-political party) Socialist(I-political party) Party(I-political party) .(O)"}, "label_list": ["country", "political party", "event", "organization", "location", "person", "politician", "election"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 5054, 4717, 11, 1567, 11, 7471, 11, 3813, 11, 1732, 11, 37038, 11, 6355, 323, 507, 627, 85664, 25, 26379, 315, 1063, 6992, 47762, 532, 9875, 527, 279, 8722, 369, 279, 47966, 1174, 279, 1050, 10365, 31597, 8722, 1174, 477, 279, 4846, 12925, 333, 380, 57210, 8722, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1129", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) is(O) the(O) dress(O) code(O) at(O) the(B-Restaurant Name) precinct(I-Restaurant Name)", "instance": {"id": "1129", "words": ["what", "is", "the", "dress", "code", "at", "the", "precinct"], "labels": ["O", "O", "O", "O", "O", "O", "B-Restaurant Name", "I-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Restaurant Name, Price, Dish, Location, Amenity, Cuisine, Hours and O.\nSentence: what is the dress code at the precinct", "prompt_labels": "what(O) is(O) the(O) dress(O) code(O) at(O) the(B-Restaurant Name) precinct(I-Restaurant Name)"}, "label_list": ["Rating", "Restaurant Name", "Price", "Dish", "Location", "Amenity", "Cuisine", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 26568, 4076, 11, 8650, 11, 49268, 11, 10067, 11, 3383, 56685, 11, 81961, 11, 30192, 323, 507, 627, 85664, 25, 1148, 374, 279, 8679, 2082, 520, 279, 68999, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1615", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) a(O) film(O) starring(O) della(B-actor) reese(I-actor)", "instance": {"id": "1615", "words": ["list", "a", "film", "starring", "della", "reese"], "labels": ["O", "O", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, actor, average ratings, genre, director, rating, trailer, plot, song, year, title, review and O.\nSentence: list a film starring della reese", "prompt_labels": "list(O) a(O) film(O) starring(O) della(B-actor) reese(I-actor)"}, "label_list": ["character", "actor", "average ratings", "genre", "director", "rating", "trailer", "plot", "song", "year", "title", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 12360, 11, 5578, 18594, 11, 17779, 11, 7690, 11, 10959, 11, 19809, 11, 7234, 11, 5609, 11, 1060, 11, 2316, 11, 3477, 323, 507, 627, 85664, 25, 1160, 264, 4632, 40500, 15587, 312, 2423, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "148", "dataset": "crossner_science", "split": "dev", "prediction": "The(O) amino(O) acid(O) sequence(O) of(O) arginine(B-protein) vasopressin(I-protein) ((O) argipressin(B-protein) )(O) is(O) Cys(B-protein) -(O) Tyr(B-protein) -(O) Phenylalanine(B-protein) -(O) Gln(B-protein) -(O) Asn(B-protein) -(O) Cysteine(B-protein) -(O) Pro(O) -(O) Arg(O) -(O) Gly(O) -(O) NHsub2(O) /(O) sub(O),(O) with(O) the(O) cysteine(O) residues(O) forming(O) a(O) disulfide(O) bond(O) and(O) the(O) C(O) -(O) terminus(O) of(O) the(O) sequence(O) converted(O) to(O) a(O) primary(O) amide(O).(O)", "instance": {"id": "148", "words": ["The", "amino", "acid", "sequence", "of", "arginine", "vasopressin", "(", "argipressin", ")", "is", "Cys", "-", "Tyr", "-", "Phenylalanine", "-", "Gln", "-", "Asn", "-", "Cysteine", "-", "Pro", "-", "Arg", "-", "Gly", "-NHsub2", "/", "sub", ",", "with", "the", "cysteine", "residues", "forming", "a", "disulfide", "bond", "and", "the", "C", "-terminus", "of", "the", "sequence", "converted", "to", "a", "primary", "amide", "."], "labels": ["O", "O", "O", "O", "O", "B-protein", "I-protein", "O", "B-protein", "O", "O", "B-chemical compound", "O", "B-chemical compound", "O", "B-chemical compound", "O", "B-chemical compound", "O", "B-chemical compound", "O", "B-chemical compound", "O", "B-chemical compound", "O", "B-chemical compound", "O", "B-chemical compound", "B-chemical compound", "I-chemical compound", "I-chemical compound", "O", "O", "O", "O", "O", "O", "O", "B-chemical compound", "I-chemical compound", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-chemical compound", "I-chemical compound", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, protein, theory, award, university, enzyme, astronomical object, person, country, organization, scientist, academic journal, discipline, location, chemical element, chemical compound and O.\nSentence: The amino acid sequence of arginine vasopressin ( argipressin ) is Cys - Tyr - Phenylalanine - Gln - Asn - Cysteine - Pro - Arg - Gly -NHsub2 / sub , with the cysteine residues forming a disulfide bond and the C -terminus of the sequence converted to a primary amide .", "prompt_labels": "The(O) amino(O) acid(O) sequence(O) of(O) arginine(B-protein) vasopressin(I-protein) ((O) argipressin(B-protein) )(O) is(O) Cys(B-chemical compound) -(O) Tyr(B-chemical compound) -(O) Phenylalanine(B-chemical compound) -(O) Gln(B-chemical compound) -(O) Asn(B-chemical compound) -(O) Cysteine(B-chemical compound) -(O) Pro(B-chemical compound) -(O) Arg(B-chemical compound) -(O) Gly(B-chemical compound) -NHsub2(B-chemical compound) /(I-chemical compound) sub(I-chemical compound) ,(O) with(O) the(O) cysteine(O) residues(O) forming(O) a(O) disulfide(B-chemical compound) bond(I-chemical compound) and(O) the(O) C(O) -terminus(O) of(O) the(O) sequence(O) converted(O) to(O) a(O) primary(B-chemical compound) amide(I-chemical compound) .(O)"}, "label_list": ["event", "protein", "theory", "award", "university", "enzyme", "astronomical object", "person", "country", "organization", "scientist", "academic journal", "discipline", "location", "chemical element", "chemical compound"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 13128, 11, 10334, 11, 10292, 11, 12374, 11, 49242, 11, 87283, 1665, 11, 1732, 11, 3224, 11, 7471, 11, 28568, 11, 14584, 8486, 11, 26434, 11, 3813, 11, 11742, 2449, 11, 11742, 24549, 323, 507, 627, 85664, 25, 578, 42500, 13935, 8668, 315, 1417, 83334, 44496, 454, 676, 258, 320, 1417, 575, 676, 258, 883, 374, 356, 1065, 482, 50595, 482, 69883, 4010, 33383, 483, 482, 480, 2312, 482, 1666, 77, 482, 356, 599, 68, 483, 482, 1322, 482, 7793, 482, 79183, 482, 52371, 2008, 17, 611, 1207, 1174, 449, 279, 63581, 68, 483, 71783, 30164, 264, 834, 14643, 579, 11049, 323, 279, 356, 482, 23827, 355, 315, 279, 8668, 16489, 311, 264, 6156, 1097, 579, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "113", "dataset": "crossner_ai", "split": "dev", "prediction": ")(O) In(O) addition(O) to(O) the(O) taxonomic(O) information(O) contained(O) in(O) OpenCyc(B-product),(O) ResearchCyc(B-product) includes(O) significantly(O) more(O) semantic(O) knowledge(O) ((O) i.e.(O),(O) additional(O) facts(O) and(O) rules(O) of(O) thumb(O) )(O) involving(O) the(O) concepts(O) in(O) its(O) knowledge(O) base(O) ;(O) it(O) also(O) includes(O) a(O) large(O) lexicon(O),(O) English(B-programming language) parsing(O) and(O) generation(O) tools(O),(O) and(O) Java(B-programming language) based(O) interfaces(O) for(O) knowledge(O) editing(O) and(O) querying(O).(O)", "instance": {"id": "113", "words": [")", "In", "addition", "to", "the", "taxonomic", "information", "contained", "in", "OpenCyc", ",", "ResearchCyc", "includes", "significantly", "more", "semantic", "knowledge", "(", "i.e.", ",", "additional", "facts", "and", "rules", "of", "thumb", ")", "involving", "the", "concepts", "in", "its", "knowledge", "base", ";", "it", "also", "includes", "a", "large", "lexicon", ",", "English", "parsing", "and", "generation", "tools", ",", "and", "Java", "based", "interfaces", "for", "knowledge", "editing", "and", "querying", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-product", "O", "B-product", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-product", "I-product", "I-product", "I-product", "I-product", "I-product", "I-product", "I-product", "O", "O", "B-programming language", "O", "B-product", "I-product", "I-product", "I-product", "I-product", "I-product", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, person, country, algorithm, university, product, field, metric, researcher, programming language, conference, organization, task and O.\nSentence: ) In addition to the taxonomic information contained in OpenCyc , ResearchCyc includes significantly more semantic knowledge ( i.e. , additional facts and rules of thumb ) involving the concepts in its knowledge base ; it also includes a large lexicon , English parsing and generation tools , and Java based interfaces for knowledge editing and querying .", "prompt_labels": ")(O) In(O) addition(O) to(O) the(O) taxonomic(O) information(O) contained(O) in(O) OpenCyc(B-product) ,(O) ResearchCyc(B-product) includes(O) significantly(O) more(O) semantic(O) knowledge(O) ((O) i.e.(O) ,(O) additional(O) facts(O) and(O) rules(O) of(O) thumb(O) )(O) involving(O) the(O) concepts(O) in(O) its(O) knowledge(O) base(O) ;(O) it(O) also(O) includes(O) a(O) large(B-product) lexicon(I-product) ,(I-product) English(I-product) parsing(I-product) and(I-product) generation(I-product) tools(I-product) ,(O) and(O) Java(B-programming language) based(O) interfaces(B-product) for(I-product) knowledge(I-product) editing(I-product) and(I-product) querying(I-product) .(O)"}, "label_list": ["location", "person", "country", "algorithm", "university", "product", "field", "metric", "researcher", "programming language", "conference", "organization", "task"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 1732, 11, 3224, 11, 12384, 11, 12374, 11, 2027, 11, 2115, 11, 18767, 11, 32185, 11, 15840, 4221, 11, 10017, 11, 7471, 11, 3465, 323, 507, 627, 85664, 25, 883, 763, 5369, 311, 279, 3827, 48228, 2038, 13282, 304, 5377, 34, 3418, 1174, 8483, 34, 3418, 5764, 12207, 810, 42833, 6677, 320, 602, 1770, 13, 1174, 5217, 13363, 323, 5718, 315, 25015, 883, 16239, 279, 19476, 304, 1202, 6677, 2385, 2652, 433, 1101, 5764, 264, 3544, 23237, 1965, 1174, 6498, 23115, 323, 9659, 7526, 1174, 323, 8102, 3196, 25066, 369, 6677, 16039, 323, 82198, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1473", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) there(O) a(O) crime(B-genre) movie(O) withing(O) the(O) last(B-year) eight(I-year) years(I-year) that(O) had(O) an(O) average(O) eight(B-average ratings) star(O) rating(O)", "instance": {"id": "1473", "words": ["is", "there", "a", "crime", "movie", "withing", "the", "last", "eight", "years", "that", "had", "an", "average", "eight", "star", "rating"], "labels": ["O", "O", "O", "B-genre", "O", "O", "O", "B-year", "I-year", "I-year", "O", "O", "O", "O", "B-average ratings", "I-average ratings", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, year, average ratings, trailer, director, actor, title, genre, rating, review, plot, character and O.\nSentence: is there a crime movie withing the last eight years that had an average eight star rating", "prompt_labels": "is(O) there(O) a(O) crime(B-genre) movie(O) withing(O) the(O) last(B-year) eight(I-year) years(I-year) that(O) had(O) an(O) average(O) eight(B-average ratings) star(I-average ratings) rating(O)"}, "label_list": ["song", "year", "average ratings", "trailer", "director", "actor", "title", "genre", "rating", "review", "plot", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 1060, 11, 5578, 18594, 11, 19809, 11, 7690, 11, 12360, 11, 2316, 11, 17779, 11, 10959, 11, 3477, 11, 7234, 11, 3752, 323, 507, 627, 85664, 25, 374, 1070, 264, 9977, 5818, 449, 287, 279, 1566, 8223, 1667, 430, 1047, 459, 5578, 8223, 6917, 10959, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1209", "dataset": "mit-movie", "split": "dev", "prediction": "do(O) you(O) have(O) the(O) movie(O) key(B-title) largo(I-title)", "instance": {"id": "1209", "words": ["do", "you", "have", "the", "movie", "key", "largo"], "labels": ["O", "O", "O", "O", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, plot, genre, character, director, rating, trailer, review, average ratings, year, song, actor and O.\nSentence: do you have the movie key largo", "prompt_labels": "do(O) you(O) have(O) the(O) movie(O) key(B-title) largo(I-title)"}, "label_list": ["title", "plot", "genre", "character", "director", "rating", "trailer", "review", "average ratings", "year", "song", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 7234, 11, 17779, 11, 3752, 11, 7690, 11, 10959, 11, 19809, 11, 3477, 11, 5578, 18594, 11, 1060, 11, 5609, 11, 12360, 323, 507, 627, 85664, 25, 656, 499, 617, 279, 5818, 1401, 65013, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1138", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) francis(B-director) ford(I-director) coppola(I-director) direct(O) a(O) thriller(B-genre) in(O) the(O) 1970(B-year) s(I-year)", "instance": {"id": "1138", "words": ["did", "francis", "ford", "coppola", "direct", "a", "thriller", "in", "the", "1970", "s"], "labels": ["O", "B-director", "I-director", "I-director", "O", "O", "B-genre", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, trailer, year, song, title, character, plot, genre, average ratings, rating, review, director and O.\nSentence: did francis ford coppola direct a thriller in the 1970 s", "prompt_labels": "did(O) francis(B-director) ford(I-director) coppola(I-director) direct(O) a(O) thriller(B-genre) in(O) the(O) 1970(B-year) s(I-year)"}, "label_list": ["actor", "trailer", "year", "song", "title", "character", "plot", "genre", "average ratings", "rating", "review", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 19809, 11, 1060, 11, 5609, 11, 2316, 11, 3752, 11, 7234, 11, 17779, 11, 5578, 18594, 11, 10959, 11, 3477, 11, 7690, 323, 507, 627, 85664, 25, 1550, 44579, 285, 45728, 57100, 8083, 2167, 264, 54461, 304, 279, 220, 4468, 15, 274, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "724", "dataset": "mit-movie", "split": "dev", "prediction": "find(O) any(O) musicals(B-genre) with(O) a(O) g(B-rating) rating(I-rating) on(O) today(O)", "instance": {"id": "724", "words": ["find", "any", "musicals", "with", "a", "g", "rating", "on", "today"], "labels": ["O", "O", "B-genre", "O", "O", "B-rating", "O", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, average ratings, song, director, rating, trailer, character, actor, genre, year, title, plot and O.\nSentence: find any musicals with a g rating on today", "prompt_labels": "find(O) any(O) musicals(B-genre) with(O) a(O) g(B-rating) rating(O) on(O) today(B-year)"}, "label_list": ["review", "average ratings", "song", "director", "rating", "trailer", "character", "actor", "genre", "year", "title", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 5578, 18594, 11, 5609, 11, 7690, 11, 10959, 11, 19809, 11, 3752, 11, 12360, 11, 17779, 11, 1060, 11, 2316, 11, 7234, 323, 507, 627, 85664, 25, 1505, 904, 18273, 82, 449, 264, 342, 10959, 389, 3432, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2289", "dataset": "mit-movie", "split": "dev", "prediction": "which(O) animation(B-genre) film(O) stars(O) dustin(B-actor) diamond(I-actor)", "instance": {"id": "2289", "words": ["which", "animation", "film", "stars", "dustin", "diamond"], "labels": ["O", "B-genre", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, genre, song, character, trailer, plot, average ratings, year, director, rating, title, review and O.\nSentence: which animation film stars dustin diamond", "prompt_labels": "which(O) animation(B-genre) film(O) stars(O) dustin(B-actor) diamond(I-actor)"}, "label_list": ["actor", "genre", "song", "character", "trailer", "plot", "average ratings", "year", "director", "rating", "title", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 17779, 11, 5609, 11, 3752, 11, 19809, 11, 7234, 11, 5578, 18594, 11, 1060, 11, 7690, 11, 10959, 11, 2316, 11, 3477, 323, 507, 627, 85664, 25, 902, 10571, 4632, 9958, 16174, 258, 22996, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1507", "dataset": "mit-restaurant", "split": "dev", "prediction": "who(O) has(O) the(O) best(B-Rating) pizza(B-Dish) that(O) takes(B-Amenity) credit(I-Amenity) cards(I-Amenity)", "instance": {"id": "1507", "words": ["who", "has", "the", "best", "pizza", "that", "takes", "credit", "cards"], "labels": ["O", "O", "O", "B-Rating", "B-Dish", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Hours, Restaurant Name, Amenity, Rating, Dish, Price, Location and O.\nSentence: who has the best pizza that takes credit cards", "prompt_labels": "who(O) has(O) the(O) best(B-Rating) pizza(B-Dish) that(O) takes(O) credit(B-Amenity) cards(I-Amenity)"}, "label_list": ["Cuisine", "Hours", "Restaurant Name", "Amenity", "Rating", "Dish", "Price", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 30192, 11, 26568, 4076, 11, 3383, 56685, 11, 19767, 11, 49268, 11, 8650, 11, 10067, 323, 507, 627, 85664, 25, 889, 706, 279, 1888, 23317, 430, 5097, 6807, 7563, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "801", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) a(O) breakfast(B-Cuisine) place(O) that(O) has(O) valet(B-Amenity) parking(I-Amenity)", "instance": {"id": "801", "words": ["is", "there", "a", "breakfast", "place", "that", "has", "valet", "parking"], "labels": ["O", "O", "O", "B-Hours", "O", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Location, Hours, Cuisine, Rating, Price, Amenity, Dish and O.\nSentence: is there a breakfast place that has valet parking", "prompt_labels": "is(O) there(O) a(O) breakfast(B-Hours) place(O) that(O) has(O) valet(B-Amenity) parking(I-Amenity)"}, "label_list": ["Restaurant Name", "Location", "Hours", "Cuisine", "Rating", "Price", "Amenity", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 10067, 11, 30192, 11, 81961, 11, 19767, 11, 8650, 11, 3383, 56685, 11, 49268, 323, 507, 627, 85664, 25, 374, 1070, 264, 17954, 2035, 430, 706, 11412, 1169, 13217, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2016", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) a(O) good(O) comedy(B-genre) that(O) was(O) made(O) in(O) the(O) 1970(B-year) s(I-year) besides(O) caddyshack(B-title)", "instance": {"id": "2016", "words": ["what", "is", "a", "good", "comedy", "that", "was", "made", "in", "the", "1970", "s", "besides", "caddyshack"], "labels": ["O", "O", "O", "O", "B-genre", "O", "O", "O", "O", "O", "B-year", "I-year", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, title, character, year, actor, trailer, director, review, rating, plot, genre, song and O.\nSentence: what is a good comedy that was made in the 1970 s besides caddyshack", "prompt_labels": "what(O) is(O) a(O) good(O) comedy(B-genre) that(O) was(O) made(O) in(O) the(O) 1970(B-year) s(I-year) besides(O) caddyshack(O)"}, "label_list": ["average ratings", "title", "character", "year", "actor", "trailer", "director", "review", "rating", "plot", "genre", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 2316, 11, 3752, 11, 1060, 11, 12360, 11, 19809, 11, 7690, 11, 3477, 11, 10959, 11, 7234, 11, 17779, 11, 5609, 323, 507, 627, 85664, 25, 1148, 374, 264, 1695, 23160, 430, 574, 1903, 304, 279, 220, 4468, 15, 274, 28858, 272, 23290, 939, 474, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2247", "dataset": "mit-movie", "split": "dev", "prediction": "whats(O) a(O) pg(B-rating) 13(I-rating) movie(O) about(O) a(O) pianist(B-plot) and(O) starring(O) katherine(B-actor) kelly(I-actor) that(O) got(O) seven(B-average ratings) stars(O)", "instance": {"id": "2247", "words": ["whats", "a", "pg", "13", "movie", "about", "a", "pianist", "and", "starring", "katherine", "kelly", "that", "got", "seven", "stars"], "labels": ["O", "O", "B-rating", "I-rating", "O", "O", "O", "B-plot", "O", "O", "B-actor", "I-actor", "O", "O", "B-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, year, average ratings, plot, character, genre, actor, title, song, rating, review, trailer and O.\nSentence: whats a pg 13 movie about a pianist and starring katherine kelly that got seven stars", "prompt_labels": "whats(O) a(O) pg(B-rating) 13(I-rating) movie(O) about(O) a(O) pianist(B-plot) and(O) starring(O) katherine(B-actor) kelly(I-actor) that(O) got(O) seven(B-average ratings) stars(I-average ratings)"}, "label_list": ["director", "year", "average ratings", "plot", "character", "genre", "actor", "title", "song", "rating", "review", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 1060, 11, 5578, 18594, 11, 7234, 11, 3752, 11, 17779, 11, 12360, 11, 2316, 11, 5609, 11, 10959, 11, 3477, 11, 19809, 323, 507, 627, 85664, 25, 41209, 264, 17953, 220, 1032, 5818, 922, 264, 60166, 380, 323, 40500, 597, 28107, 597, 12160, 430, 2751, 8254, 9958, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "305", "dataset": "crossner_politics", "split": "dev", "prediction": "She(O) was(O) the(O) Liberal(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) candidate(O) for(O) the(O) House(B-election) of(I-election) Commons(I-election) of(I-election) Canada(I-election) in(O) the(O) riding(O) of(O) Acadie(B-location) -(I-location) Bathurst(I-location) in(O) the(O) 2006(B-election) Canadian(I-election) federal(I-election) election(I-election),(O) but(O) finished(O) second(O) to(O) Yvon(B-politician) Godin(I-politician) of(O) the(O) New(B-political party) Democratic(I-political party) Party(I-political party).(O)", "instance": {"id": "305", "words": ["She", "was", "the", "Liberal", "Party", "of", "Canada", "candidate", "for", "the", "House", "of", "Commons", "of", "Canada", "in", "the", "riding", "of", "Acadie", "-", "Bathurst", "in", "the", "2006", "Canadian", "federal", "election", ",", "but", "finished", "second", "to", "Yvon", "Godin", "of", "the", "New", "Democratic", "Party", "."], "labels": ["O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "O", "O", "O", "B-location", "I-location", "I-location", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "B-politician", "I-politician", "O", "O", "B-political party", "I-political party", "I-political party", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, election, event, location, organization, political party, politician, country and O.\nSentence: She was the Liberal Party of Canada candidate for the House of Commons of Canada in the riding of Acadie - Bathurst in the 2006 Canadian federal election , but finished second to Yvon Godin of the New Democratic Party .", "prompt_labels": "She(O) was(O) the(O) Liberal(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) candidate(O) for(O) the(O) House(B-organization) of(I-organization) Commons(I-organization) of(I-organization) Canada(I-organization) in(O) the(O) riding(O) of(O) Acadie(B-location) -(I-location) Bathurst(I-location) in(O) the(O) 2006(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) but(O) finished(O) second(O) to(O) Yvon(B-politician) Godin(I-politician) of(O) the(O) New(B-political party) Democratic(I-political party) Party(I-political party) .(O)"}, "label_list": ["person", "election", "event", "location", "organization", "political party", "politician", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 6355, 11, 1567, 11, 3813, 11, 7471, 11, 5054, 4717, 11, 37038, 11, 3224, 323, 507, 627, 85664, 25, 3005, 574, 279, 31158, 8722, 315, 7008, 9322, 369, 279, 4783, 315, 26667, 315, 7008, 304, 279, 20427, 315, 12644, 648, 482, 19710, 33712, 304, 279, 220, 1049, 21, 12152, 6918, 6355, 1174, 719, 8220, 2132, 311, 816, 59270, 4359, 258, 315, 279, 1561, 11650, 8722, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "328", "dataset": "mit-restaurant", "split": "dev", "prediction": "dominos(B-Restaurant Name) pizza(I-Restaurant Name) joint(I-Restaurant Name) near(B-Location) my(I-Location) location(I-Location)", "instance": {"id": "328", "words": ["dominos", "pizza", "joint", "near", "my", "location"], "labels": ["B-Restaurant Name", "I-Restaurant Name", "O", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Restaurant Name, Hours, Location, Cuisine, Rating, Amenity, Dish and O.\nSentence: dominos pizza joint near my location", "prompt_labels": "dominos(B-Restaurant Name) pizza(I-Restaurant Name) joint(O) near(B-Location) my(I-Location) location(I-Location)"}, "label_list": ["Price", "Restaurant Name", "Hours", "Location", "Cuisine", "Rating", "Amenity", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 26568, 4076, 11, 30192, 11, 10067, 11, 81961, 11, 19767, 11, 3383, 56685, 11, 49268, 323, 507, 627, 85664, 25, 11358, 437, 23317, 10496, 3221, 856, 3813, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1332", "dataset": "mit-movie", "split": "dev", "prediction": "i(O) would(O) like(O) a(O) list(O) of(O) political(B-genre) films(O) that(O) were(O) rated(O) a(O) six(B-average ratings)", "instance": {"id": "1332", "words": ["i", "would", "like", "a", "list", "of", "political", "films", "that", "were", "rated", "a", "six"], "labels": ["O", "O", "O", "O", "O", "O", "B-genre", "O", "O", "O", "O", "O", "B-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, plot, review, rating, song, trailer, year, title, character, actor, average ratings, director and O.\nSentence: i would like a list of political films that were rated a six", "prompt_labels": "i(O) would(O) like(O) a(O) list(O) of(O) political(B-genre) films(O) that(O) were(O) rated(O) a(O) six(B-average ratings)"}, "label_list": ["genre", "plot", "review", "rating", "song", "trailer", "year", "title", "character", "actor", "average ratings", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 7234, 11, 3477, 11, 10959, 11, 5609, 11, 19809, 11, 1060, 11, 2316, 11, 3752, 11, 12360, 11, 5578, 18594, 11, 7690, 323, 507, 627, 85664, 25, 602, 1053, 1093, 264, 1160, 315, 5054, 12631, 430, 1051, 22359, 264, 4848, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "831", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) a(O) movie(O) with(O) the(O) song(O) somewhere(B-song) over(I-song) the(I-song) rainbow(I-song)", "instance": {"id": "831", "words": ["show", "me", "a", "movie", "with", "the", "song", "somewhere", "over", "the", "rainbow"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-song", "I-song", "I-song", "I-song"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, title, year, review, actor, rating, character, genre, song, director, plot, trailer and O.\nSentence: show me a movie with the song somewhere over the rainbow", "prompt_labels": "show(O) me(O) a(O) movie(O) with(O) the(O) song(O) somewhere(B-song) over(I-song) the(I-song) rainbow(I-song)"}, "label_list": ["average ratings", "title", "year", "review", "actor", "rating", "character", "genre", "song", "director", "plot", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 2316, 11, 1060, 11, 3477, 11, 12360, 11, 10959, 11, 3752, 11, 17779, 11, 5609, 11, 7690, 11, 7234, 11, 19809, 323, 507, 627, 85664, 25, 1501, 757, 264, 5818, 449, 279, 5609, 15038, 927, 279, 48713, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "222", "dataset": "mit-movie", "split": "dev", "prediction": "super(B-title) man(I-title)", "instance": {"id": "222", "words": ["super", "man"], "labels": ["B-character", "I-character"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, character, year, song, review, trailer, title, average ratings, actor, rating, genre, director and O.\nSentence: super man", "prompt_labels": "super(B-character) man(I-character)"}, "label_list": ["plot", "character", "year", "song", "review", "trailer", "title", "average ratings", "actor", "rating", "genre", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 3752, 11, 1060, 11, 5609, 11, 3477, 11, 19809, 11, 2316, 11, 5578, 18594, 11, 12360, 11, 10959, 11, 17779, 11, 7690, 323, 507, 627, 85664, 25, 2307, 893, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "40", "dataset": "crossner_ai", "split": "dev", "prediction": "He(O) has(O) also(O) received(O) honorary(O) doctorates(O) from(O) the(O) universities(O) of(O) Newcastle(B-university),(O) Surrey(B-university),(O) Tel(B-university) Aviv(I-university) University(I-university),(O),(O) Simon(B-university) Fraser(I-university) University(I-university) and(O) the(O) University(B-university) of(I-university) Troms\u00f8(I-university).(O)", "instance": {"id": "40", "words": ["He", "has", "also", "received", "honorary", "doctorates", "from", "the", "universities", "of", "Newcastle", ",", "Surrey", ",", "Tel", "Aviv", "University", ",", ",", "Simon", "Fraser", "University", "and", "the", "University", "of", "Troms\u00f8", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-university", "I-university", "I-university", "O", "B-university", "O", "B-university", "I-university", "I-university", "O", "O", "B-university", "I-university", "I-university", "O", "O", "B-university", "I-university", "I-university", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, field, metric, person, product, country, algorithm, researcher, task, organization, location, university, conference and O.\nSentence: He has also received honorary doctorates from the universities of Newcastle , Surrey , Tel Aviv University , , Simon Fraser University and the University of Troms\u00f8 .", "prompt_labels": "He(O) has(O) also(O) received(O) honorary(O) doctorates(O) from(O) the(O) universities(B-university) of(I-university) Newcastle(I-university) ,(O) Surrey(B-university) ,(O) Tel(B-university) Aviv(I-university) University(I-university) ,(O) ,(O) Simon(B-university) Fraser(I-university) University(I-university) and(O) the(O) University(B-university) of(I-university) Troms\u00f8(I-university) .(O)"}, "label_list": ["programming language", "field", "metric", "person", "product", "country", "algorithm", "researcher", "task", "organization", "location", "university", "conference"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 15840, 4221, 11, 2115, 11, 18767, 11, 1732, 11, 2027, 11, 3224, 11, 12384, 11, 32185, 11, 3465, 11, 7471, 11, 3813, 11, 12374, 11, 10017, 323, 507, 627, 85664, 25, 1283, 706, 1101, 4036, 99119, 10896, 988, 505, 279, 23978, 315, 44226, 1174, 68064, 1174, 23683, 66947, 3907, 1174, 1174, 22021, 56230, 3907, 323, 279, 3907, 315, 94467, 82, 6282, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2018", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) a(O) good(O) movie(O) about(O) the(O) military(B-genre) that(O) has(O) an(O) r(B-rating) rating(O)", "instance": {"id": "2018", "words": ["what", "is", "a", "good", "movie", "about", "the", "military", "that", "has", "an", "r", "rating"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-genre", "O", "O", "O", "B-rating", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, review, character, actor, plot, genre, rating, director, song, average ratings, title, year and O.\nSentence: what is a good movie about the military that has an r rating", "prompt_labels": "what(O) is(O) a(O) good(O) movie(O) about(O) the(O) military(B-genre) that(O) has(O) an(O) r(B-rating) rating(O)"}, "label_list": ["trailer", "review", "character", "actor", "plot", "genre", "rating", "director", "song", "average ratings", "title", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 3477, 11, 3752, 11, 12360, 11, 7234, 11, 17779, 11, 10959, 11, 7690, 11, 5609, 11, 5578, 18594, 11, 2316, 11, 1060, 323, 507, 627, 85664, 25, 1148, 374, 264, 1695, 5818, 922, 279, 6411, 430, 706, 459, 436, 10959, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "420", "dataset": "crossner_science", "split": "dev", "prediction": "Later(O) on(O),(O) objects(O) were(O) found(O) orbiting(O) near(O) the(O) Lagrangian(O) points(O) of(O) Neptune(B-astronomical object),(O) Mars(B-astronomical object),(O) Earth(B-astronomical object).(O)", "instance": {"id": "420", "words": ["Later", "on", ",", "objects", "were", "found", "orbiting", "near", "the", "Lagrangian", "points", "of", "Neptune", ",", "Mars", ",", "Earth", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-astronomical object", "O", "B-astronomical object", "O", "B-astronomical object", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, protein, scientist, university, person, location, discipline, award, chemical compound, chemical element, organization, academic journal, country, astronomical object, theory, enzyme and O.\nSentence: Later on , objects were found orbiting near the Lagrangian points of Neptune , Mars , Earth .", "prompt_labels": "Later(O) on(O) ,(O) objects(O) were(O) found(O) orbiting(O) near(O) the(O) Lagrangian(O) points(O) of(O) Neptune(B-astronomical object) ,(O) Mars(B-astronomical object) ,(O) Earth(B-astronomical object) .(O)"}, "label_list": ["event", "protein", "scientist", "university", "person", "location", "discipline", "award", "chemical compound", "chemical element", "organization", "academic journal", "country", "astronomical object", "theory", "enzyme"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 13128, 11, 28568, 11, 12374, 11, 1732, 11, 3813, 11, 26434, 11, 10292, 11, 11742, 24549, 11, 11742, 2449, 11, 7471, 11, 14584, 8486, 11, 3224, 11, 87283, 1665, 11, 10334, 11, 49242, 323, 507, 627, 85664, 25, 25929, 389, 1174, 6302, 1051, 1766, 27605, 287, 3221, 279, 33471, 93683, 1122, 3585, 315, 80724, 1174, 21725, 1174, 9420, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "310", "dataset": "crossner_ai", "split": "dev", "prediction": "QC(B-metric) has(O) not(O) been(O) evaluated(O) against(O) traditional(O) modern(O) clustering(O) algorithms(O),(O) aside(O) from(O) Jaccard(B-metric) index(I-metric).(O)", "instance": {"id": "310", "words": ["QC", "has", "not", "been", "evaluated", "against", "traditional", "modern", "clustering", "algorithms", ",", "aside", "from", "Jaccard", "index", "."], "labels": ["B-algorithm", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-metric", "I-metric", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, metric, algorithm, organization, conference, location, country, task, field, product, person, programming language, university and O.\nSentence: QC has not been evaluated against traditional modern clustering algorithms , aside from Jaccard index .", "prompt_labels": "QC(B-algorithm) has(O) not(O) been(O) evaluated(O) against(O) traditional(O) modern(O) clustering(O) algorithms(O) ,(O) aside(O) from(O) Jaccard(B-metric) index(I-metric) .(O)"}, "label_list": ["researcher", "metric", "algorithm", "organization", "conference", "location", "country", "task", "field", "product", "person", "programming language", "university"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 32185, 11, 18767, 11, 12384, 11, 7471, 11, 10017, 11, 3813, 11, 3224, 11, 3465, 11, 2115, 11, 2027, 11, 1732, 11, 15840, 4221, 11, 12374, 323, 507, 627, 85664, 25, 43707, 706, 539, 1027, 26126, 2403, 8776, 6617, 59454, 26249, 1174, 16038, 505, 622, 4575, 569, 1963, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "672", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) want(O) to(O) go(O) to(O) a(O) restaurant(O) with(O) a(O) high(B-Rating) zagats(I-Rating) rating(I-Rating) and(O) average(B-Price) plate(I-Price) cost(I-Price) of(O) less(B-Price) than(I-Price) 20(I-Price) nearby(I-Price)", "instance": {"id": "672", "words": ["i", "want", "to", "go", "to", "a", "restaurant", "with", "a", "high", "zagats", "rating", "and", "average", "plate", "cost", "of", "less", "than", "20", "nearby"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-Rating", "I-Rating", "I-Rating", "O", "B-Price", "I-Price", "I-Price", "O", "B-Price", "I-Price", "I-Price", "B-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Amenity, Rating, Cuisine, Dish, Hours, Price, Location and O.\nSentence: i want to go to a restaurant with a high zagats rating and average plate cost of less than 20 nearby", "prompt_labels": "i(O) want(O) to(O) go(O) to(O) a(O) restaurant(O) with(O) a(O) high(B-Rating) zagats(I-Rating) rating(I-Rating) and(O) average(B-Price) plate(I-Price) cost(I-Price) of(O) less(B-Price) than(I-Price) 20(I-Price) nearby(B-Location)"}, "label_list": ["Restaurant Name", "Amenity", "Rating", "Cuisine", "Dish", "Hours", "Price", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 3383, 56685, 11, 19767, 11, 81961, 11, 49268, 11, 30192, 11, 8650, 11, 10067, 323, 507, 627, 85664, 25, 602, 1390, 311, 733, 311, 264, 10960, 449, 264, 1579, 90119, 1900, 10959, 323, 5578, 12235, 2853, 315, 2753, 1109, 220, 508, 14373, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "270", "dataset": "mit-restaurant", "split": "dev", "prediction": "do(O) you(O) know(O) where(O) they(O) sell(O) hummus(B-Dish)", "instance": {"id": "270", "words": ["do", "you", "know", "where", "they", "sell", "hummus"], "labels": ["O", "O", "O", "O", "O", "O", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Cuisine, Restaurant Name, Location, Price, Hours, Amenity, Rating and O.\nSentence: do you know where they sell hummus", "prompt_labels": "do(O) you(O) know(O) where(O) they(O) sell(O) hummus(B-Dish)"}, "label_list": ["Dish", "Cuisine", "Restaurant Name", "Location", "Price", "Hours", "Amenity", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 81961, 11, 26568, 4076, 11, 10067, 11, 8650, 11, 30192, 11, 3383, 56685, 11, 19767, 323, 507, 627, 85664, 25, 656, 499, 1440, 1405, 814, 4662, 2854, 38827, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "642", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) want(O) tacos(B-Dish)", "instance": {"id": "642", "words": ["i", "want", "tacos"], "labels": ["O", "O", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Hours, Dish, Amenity, Price, Restaurant Name, Location, Rating and O.\nSentence: i want tacos", "prompt_labels": "i(O) want(O) tacos(B-Dish)"}, "label_list": ["Cuisine", "Hours", "Dish", "Amenity", "Price", "Restaurant Name", "Location", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 30192, 11, 49268, 11, 3383, 56685, 11, 8650, 11, 26568, 4076, 11, 10067, 11, 19767, 323, 507, 627, 85664, 25, 602, 1390, 85501, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2008", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) a(O) german(B-plot) army(I-plot) documentary(B-genre) directed(O) by(O) adam(B-director) tierney(I-director)", "instance": {"id": "2008", "words": ["what", "is", "a", "german", "army", "documentary", "directed", "by", "adam", "tierney"], "labels": ["O", "O", "O", "B-plot", "I-plot", "B-genre", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, average ratings, actor, review, director, title, plot, song, trailer, year, character, rating and O.\nSentence: what is a german army documentary directed by adam tierney", "prompt_labels": "what(O) is(O) a(O) german(B-plot) army(I-plot) documentary(B-genre) directed(O) by(O) adam(B-director) tierney(I-director)"}, "label_list": ["genre", "average ratings", "actor", "review", "director", "title", "plot", "song", "trailer", "year", "character", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 5578, 18594, 11, 12360, 11, 3477, 11, 7690, 11, 2316, 11, 7234, 11, 5609, 11, 19809, 11, 1060, 11, 3752, 11, 10959, 323, 507, 627, 85664, 25, 1148, 374, 264, 43627, 13695, 25999, 15910, 555, 50066, 27087, 3520, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "127", "dataset": "crossner_politics", "split": "dev", "prediction": "They(O) would(O) win(O) a(O) small(O) 12-seat(O) majority(O) in(O) 2015(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) only(O) to(O) lose(O) it(O) again(O) at(O) the(O) 2017(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) but(O) would(O) win(O) in(O) a(O) landslide(O) in(O) the(O) 2019(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election).(O)", "instance": {"id": "127", "words": ["They", "would", "win", "a", "small", "12-seat", "majority", "in", "2015", "United", "Kingdom", "general", "election", ",", "only", "to", "lose", "it", "again", "at", "the", "2017", "United", "Kingdom", "general", "election", "but", "would", "win", "in", "a", "landslide", "in", "the", "2019", "United", "Kingdom", "general", "election", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, election, event, country, politician, location, political party, organization and O.\nSentence: They would win a small 12-seat majority in 2015 United Kingdom general election , only to lose it again at the 2017 United Kingdom general election but would win in a landslide in the 2019 United Kingdom general election .", "prompt_labels": "They(O) would(O) win(O) a(O) small(O) 12-seat(O) majority(O) in(O) 2015(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) only(O) to(O) lose(O) it(O) again(O) at(O) the(O) 2017(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) but(O) would(O) win(O) in(O) a(O) landslide(O) in(O) the(O) 2019(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)"}, "label_list": ["person", "election", "event", "country", "politician", "location", "political party", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 6355, 11, 1567, 11, 3224, 11, 37038, 11, 3813, 11, 5054, 4717, 11, 7471, 323, 507, 627, 85664, 25, 2435, 1053, 3243, 264, 2678, 220, 717, 79181, 8857, 304, 220, 679, 20, 3723, 15422, 4689, 6355, 1174, 1193, 311, 9229, 433, 1578, 520, 279, 220, 679, 22, 3723, 15422, 4689, 6355, 719, 1053, 3243, 304, 264, 96802, 304, 279, 220, 679, 24, 3723, 15422, 4689, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "168", "dataset": "crossner_ai", "split": "dev", "prediction": "Headquartered(O) in(O) Rochester(B-location) Hills(I-location),(O) Michigan(B-location),(O) the(O) company(O) had(O) 10(O) regional(O) locations(O) in(O) the(O) U.S.(B-country),(O) Canada(B-country),(O) Mexico(B-country) and(O) Brazil(B-country).(O)", "instance": {"id": "168", "words": ["Headquartered", "in", "Rochester", "Hills", ",", "Michigan", ",", "the", "company", "had", "10", "regional", "locations", "in", "the", "U.S.", ",", "Canada", ",", "Mexico", "and", "Brazil", "."], "labels": ["O", "O", "B-location", "I-location", "O", "B-location", "O", "O", "O", "O", "O", "O", "O", "O", "B-country", "I-country", "O", "B-country", "O", "B-country", "O", "B-country", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, university, country, task, researcher, product, field, person, organization, location, programming language, conference, metric and O.\nSentence: Headquartered in Rochester Hills , Michigan , the company had 10 regional locations in the U.S. , Canada , Mexico and Brazil .", "prompt_labels": "Headquartered(O) in(O) Rochester(B-location) Hills(I-location) ,(O) Michigan(B-location) ,(O) the(O) company(O) had(O) 10(O) regional(O) locations(O) in(O) the(B-country) U.S.(I-country) ,(O) Canada(B-country) ,(O) Mexico(B-country) and(O) Brazil(B-country) .(O)"}, "label_list": ["algorithm", "university", "country", "task", "researcher", "product", "field", "person", "organization", "location", "programming language", "conference", "metric"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12384, 11, 12374, 11, 3224, 11, 3465, 11, 32185, 11, 2027, 11, 2115, 11, 1732, 11, 7471, 11, 3813, 11, 15840, 4221, 11, 10017, 11, 18767, 323, 507, 627, 85664, 25, 11452, 68720, 304, 53468, 25964, 1174, 14972, 1174, 279, 2883, 1047, 220, 605, 15481, 10687, 304, 279, 549, 815, 13, 1174, 7008, 1174, 12550, 323, 16327, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "941", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) will(O) replace(O) johnny(B-actor) depp(I-actor) in(O) the(O) pirates(B-title) of(I-title) the(I-title) carribean(I-title) movies(O)", "instance": {"id": "941", "words": ["who", "will", "replace", "johnny", "depp", "in", "the", "pirates", "of", "the", "carribean", "movies"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O", "O", "B-title", "I-title", "I-title", "I-title", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, rating, title, review, plot, actor, song, average ratings, year, trailer, character, director and O.\nSentence: who will replace johnny depp in the pirates of the carribean movies", "prompt_labels": "who(O) will(O) replace(O) johnny(B-actor) depp(I-actor) in(O) the(O) pirates(B-title) of(I-title) the(I-title) carribean(I-title) movies(O)"}, "label_list": ["genre", "rating", "title", "review", "plot", "actor", "song", "average ratings", "year", "trailer", "character", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 10959, 11, 2316, 11, 3477, 11, 7234, 11, 12360, 11, 5609, 11, 5578, 18594, 11, 1060, 11, 19809, 11, 3752, 11, 7690, 323, 507, 627, 85664, 25, 889, 690, 8454, 40742, 3919, 409, 604, 304, 279, 62575, 315, 279, 1841, 462, 17937, 9698, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "39", "dataset": "crossner_literature", "split": "dev", "prediction": "In(O) an(O) autobiographical(O) essay(O) published(O) in(O) the(O) 1950s(O),(O) Pasternak(B-writer) described(O) the(O) execution(O) of(O) Tabidze(B-poem) and(O) the(O) suicides(O) of(O) Marina(B-writer) Tsvetaeva(I-writer) and(O) Paolo(B-writer) Iashvili(I-writer) as(O) the(O) greatest(O) heartbreaks(O) of(O) his(O) life(O).(O)", "instance": {"id": "39", "words": ["In", "an", "autobiographical", "essay", "published", "in", "the", "1950s", ",", "Pasternak", "described", "the", "execution", "of", "Tabidze", "and", "the", "suicides", "of", "Marina", "Tsvetaeva", "and", "Paolo", "Iashvili", "as", "the", "greatest", "heartbreaks", "of", "his", "life", "."], "labels": ["O", "O", "B-literary genre", "I-literary genre", "O", "O", "O", "O", "O", "B-writer", "O", "O", "O", "O", "B-writer", "O", "O", "O", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, award, poem, country, event, location, organization, writer, magazine, literary genre, book and O.\nSentence: In an autobiographical essay published in the 1950s , Pasternak described the execution of Tabidze and the suicides of Marina Tsvetaeva and Paolo Iashvili as the greatest heartbreaks of his life .", "prompt_labels": "In(O) an(O) autobiographical(B-literary genre) essay(I-literary genre) published(O) in(O) the(O) 1950s(O) ,(O) Pasternak(B-writer) described(O) the(O) execution(O) of(O) Tabidze(B-writer) and(O) the(O) suicides(O) of(O) Marina(B-writer) Tsvetaeva(I-writer) and(O) Paolo(B-writer) Iashvili(I-writer) as(O) the(O) greatest(O) heartbreaks(O) of(O) his(O) life(O) .(O)"}, "label_list": ["person", "award", "poem", "country", "event", "location", "organization", "writer", "magazine", "literary genre", "book"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 10292, 11, 33894, 11, 3224, 11, 1567, 11, 3813, 11, 7471, 11, 7061, 11, 14756, 11, 32465, 17779, 11, 2363, 323, 507, 627, 85664, 25, 763, 459, 68165, 32277, 9071, 4756, 304, 279, 220, 6280, 15, 82, 1174, 24561, 944, 587, 7633, 279, 11572, 315, 15490, 307, 3059, 323, 279, 85049, 315, 52636, 350, 3576, 1955, 74518, 323, 84469, 358, 1003, 85, 4008, 439, 279, 12474, 4851, 9137, 82, 315, 813, 2324, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2055", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) some(O) high(B-average ratings) rated(I-average ratings) thrillers(B-genre)", "instance": {"id": "2055", "words": ["what", "is", "some", "high", "rated", "thrillers"], "labels": ["O", "O", "O", "O", "O", "B-genre"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, actor, title, trailer, review, average ratings, year, genre, rating, character, director, plot and O.\nSentence: what is some high rated thrillers", "prompt_labels": "what(O) is(O) some(O) high(O) rated(O) thrillers(B-genre)"}, "label_list": ["song", "actor", "title", "trailer", "review", "average ratings", "year", "genre", "rating", "character", "director", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 12360, 11, 2316, 11, 19809, 11, 3477, 11, 5578, 18594, 11, 1060, 11, 17779, 11, 10959, 11, 3752, 11, 7690, 11, 7234, 323, 507, 627, 85664, 25, 1148, 374, 1063, 1579, 22359, 54904, 388, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "405", "dataset": "mit-restaurant", "split": "dev", "prediction": "find(O) me(O) a(O) southwestern(B-Cuisine) restaurant(O) that(O) serves(O) breakfast(B-Hours) and(O) is(O) located(B-Location) nearby(I-Location)", "instance": {"id": "405", "words": ["find", "me", "a", "southwestern", "restaurant", "that", "serves", "breakfast", "and", "is", "located", "nearby"], "labels": ["O", "O", "O", "B-Cuisine", "O", "O", "O", "B-Hours", "O", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Restaurant Name, Amenity, Location, Rating, Cuisine, Hours, Price and O.\nSentence: find me a southwestern restaurant that serves breakfast and is located nearby", "prompt_labels": "find(O) me(O) a(O) southwestern(B-Cuisine) restaurant(O) that(O) serves(O) breakfast(B-Hours) and(O) is(O) located(B-Location) nearby(I-Location)"}, "label_list": ["Dish", "Restaurant Name", "Amenity", "Location", "Rating", "Cuisine", "Hours", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 26568, 4076, 11, 3383, 56685, 11, 10067, 11, 19767, 11, 81961, 11, 30192, 11, 8650, 323, 507, 627, 85664, 25, 1505, 757, 264, 99911, 10960, 430, 17482, 17954, 323, 374, 7559, 14373, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1228", "dataset": "mit-restaurant", "split": "dev", "prediction": "whats(O) the(O) address(O) of(O) best(B-Rating) locally(B-Amenity) owned(I-Amenity) sub(B-Dish) sandwich(I-Dish) shop(O)", "instance": {"id": "1228", "words": ["whats", "the", "address", "of", "best", "locally", "owned", "sub", "sandwich", "shop"], "labels": ["O", "O", "O", "O", "B-Rating", "B-Location", "B-Amenity", "B-Cuisine", "I-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Amenity, Location, Cuisine, Restaurant Name, Price, Dish, Rating and O.\nSentence: whats the address of best locally owned sub sandwich shop", "prompt_labels": "whats(O) the(O) address(O) of(O) best(B-Rating) locally(B-Location) owned(B-Amenity) sub(B-Cuisine) sandwich(I-Cuisine) shop(O)"}, "label_list": ["Hours", "Amenity", "Location", "Cuisine", "Restaurant Name", "Price", "Dish", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 3383, 56685, 11, 10067, 11, 81961, 11, 26568, 4076, 11, 8650, 11, 49268, 11, 19767, 323, 507, 627, 85664, 25, 41209, 279, 2686, 315, 1888, 24392, 13234, 1207, 28974, 8221, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "14", "dataset": "mit-movie", "split": "dev", "prediction": "have(O) u(B-title) movie(I-title) hm(I-title) about(O) to(O) pg(B-rating) 18(I-rating)", "instance": {"id": "14", "words": ["have", "u", "movie", "hm", "about", "to", "pg", "18"], "labels": ["O", "O", "O", "O", "O", "O", "B-rating", "I-rating"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, plot, average ratings, character, actor, year, title, review, director, song, rating, trailer and O.\nSentence: have u movie hm about to pg 18", "prompt_labels": "have(O) u(O) movie(O) hm(O) about(O) to(O) pg(B-rating) 18(I-rating)"}, "label_list": ["genre", "plot", "average ratings", "character", "actor", "year", "title", "review", "director", "song", "rating", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 7234, 11, 5578, 18594, 11, 3752, 11, 12360, 11, 1060, 11, 2316, 11, 3477, 11, 7690, 11, 5609, 11, 10959, 11, 19809, 323, 507, 627, 85664, 25, 617, 577, 5818, 50462, 922, 311, 17953, 220, 972, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "0", "dataset": "mit-restaurant", "split": "dev", "prediction": "a(O) four(B-Rating) star(I-Rating) restaurant(O) with(O) a(O) bar(B-Amenity)", "instance": {"id": "0", "words": ["a", "four", "star", "restaurant", "with", "a", "bar"], "labels": ["O", "B-Rating", "I-Rating", "O", "B-Location", "I-Location", "B-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Amenity, Location, Hours, Cuisine, Rating, Price, Dish and O.\nSentence: a four star restaurant with a bar", "prompt_labels": "a(O) four(B-Rating) star(I-Rating) restaurant(O) with(B-Location) a(I-Location) bar(B-Amenity)"}, "label_list": ["Restaurant Name", "Amenity", "Location", "Hours", "Cuisine", "Rating", "Price", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 3383, 56685, 11, 10067, 11, 30192, 11, 81961, 11, 19767, 11, 8650, 11, 49268, 323, 507, 627, 85664, 25, 264, 3116, 6917, 10960, 449, 264, 3703, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1020", "dataset": "mit-restaurant", "split": "dev", "prediction": "please(O) find(O) a(O) taco(B-Dish) place(O) near(B-Location) my(I-Location) house(I-Location)", "instance": {"id": "1020", "words": ["please", "find", "a", "taco", "place", "near", "my", "house"], "labels": ["O", "O", "O", "B-Cuisine", "O", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Dish, Hours, Restaurant Name, Rating, Cuisine, Amenity, Price and O.\nSentence: please find a taco place near my house", "prompt_labels": "please(O) find(O) a(O) taco(B-Cuisine) place(O) near(B-Location) my(I-Location) house(I-Location)"}, "label_list": ["Location", "Dish", "Hours", "Restaurant Name", "Rating", "Cuisine", "Amenity", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 49268, 11, 30192, 11, 26568, 4076, 11, 19767, 11, 81961, 11, 3383, 56685, 11, 8650, 323, 507, 627, 85664, 25, 4587, 1505, 264, 91941, 2035, 3221, 856, 3838, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "271", "dataset": "crossner_ai", "split": "dev", "prediction": "It(O) comes(O) with(O) 3(O) Java(B-programming language) games(O) that(O) are(O) controlled(O) with(O) the(O) remote(O) control(O) and(O) displayed(O) to(O) its(O) LCD(B-product) screen(I-product).(O)", "instance": {"id": "271", "words": ["It", "comes", "with", "3", "Java", "games", "that", "are", "controlled", "with", "the", "remote", "control", "and", "displayed", "to", "its", "LCD", "screen", "."], "labels": ["O", "O", "O", "O", "B-programming language", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-product", "I-product", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, researcher, university, person, field, location, algorithm, conference, organization, metric, product, task, programming language and O.\nSentence: It comes with 3 Java games that are controlled with the remote control and displayed to its LCD screen .", "prompt_labels": "It(O) comes(O) with(O) 3(O) Java(B-programming language) games(O) that(O) are(O) controlled(O) with(O) the(O) remote(O) control(O) and(O) displayed(O) to(O) its(O) LCD(B-product) screen(I-product) .(O)"}, "label_list": ["country", "researcher", "university", "person", "field", "location", "algorithm", "conference", "organization", "metric", "product", "task", "programming language"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 32185, 11, 12374, 11, 1732, 11, 2115, 11, 3813, 11, 12384, 11, 10017, 11, 7471, 11, 18767, 11, 2027, 11, 3465, 11, 15840, 4221, 323, 507, 627, 85664, 25, 1102, 4131, 449, 220, 18, 8102, 3953, 430, 527, 14400, 449, 279, 8870, 2585, 323, 12882, 311, 1202, 22745, 4264, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "356", "dataset": "crossner_science", "split": "dev", "prediction": "He(O) has(O) also(O) received(O) a(O) MacArthur(B-award) Fellowship(I-award) and(O) is(O) an(O) honorary(O) member(O) of(O) the(O) American(B-organization) Institute(I-organization) of(I-organization) Architects(I-organization) ((O) AIA(B-organization) )(O),(O) a(O) Foreign(O) Member(O) of(O) the(O) Royal(B-organization) Swedish(I-organization) Academy(I-organization) of(I-organization) Engineering(I-organization) Sciences(I-organization),(O) and(O) an(O) Honorary(O) Senior(O) Fellow(O) of(O) the(O) Design(B-organization) Futures(I-organization) Council(I-organization).(O)", "instance": {"id": "356", "words": ["He", "has", "also", "received", "a", "MacArthur", "Fellowship", "and", "is", "an", "honorary", "member", "of", "the", "American", "Institute", "of", "Architects", "(", "AIA", ")", ",", "a", "Foreign", "Member", "of", "the", "Royal", "Swedish", "Academy", "of", "Engineering", "Sciences", ",", "and", "an", "Honorary", "Senior", "Fellow", "of", "the", "Design", "Futures", "Council", "."], "labels": ["O", "O", "O", "O", "O", "B-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, event, astronomical object, location, organization, academic journal, chemical element, university, discipline, award, person, chemical compound, theory, enzyme, protein, country and O.\nSentence: He has also received a MacArthur Fellowship and is an honorary member of the American Institute of Architects ( AIA ) , a Foreign Member of the Royal Swedish Academy of Engineering Sciences , and an Honorary Senior Fellow of the Design Futures Council .", "prompt_labels": "He(O) has(O) also(O) received(O) a(O) MacArthur(B-award) Fellowship(I-award) and(O) is(O) an(O) honorary(O) member(O) of(O) the(O) American(B-organization) Institute(I-organization) of(I-organization) Architects(I-organization) ((O) AIA(B-organization) )(O) ,(O) a(O) Foreign(O) Member(O) of(O) the(O) Royal(B-organization) Swedish(I-organization) Academy(I-organization) of(I-organization) Engineering(I-organization) Sciences(I-organization) ,(O) and(O) an(O) Honorary(O) Senior(O) Fellow(B-award) of(I-award) the(I-award) Design(I-award) Futures(I-award) Council(I-award) .(O)"}, "label_list": ["scientist", "event", "astronomical object", "location", "organization", "academic journal", "chemical element", "university", "discipline", "award", "person", "chemical compound", "theory", "enzyme", "protein", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 28568, 11, 1567, 11, 87283, 1665, 11, 3813, 11, 7471, 11, 14584, 8486, 11, 11742, 2449, 11, 12374, 11, 26434, 11, 10292, 11, 1732, 11, 11742, 24549, 11, 10334, 11, 49242, 11, 13128, 11, 3224, 323, 507, 627, 85664, 25, 1283, 706, 1101, 4036, 264, 7553, 60762, 65742, 323, 374, 459, 99119, 4562, 315, 279, 3778, 10181, 315, 78113, 320, 362, 5987, 883, 1174, 264, 19620, 12308, 315, 279, 16591, 31209, 16192, 315, 17005, 23199, 1174, 323, 459, 16958, 7746, 19903, 37946, 315, 279, 7127, 77367, 9251, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "395", "dataset": "mit-restaurant", "split": "dev", "prediction": "find(O) me(O) a(O) restaurant(O) that(O) is(O) quick(B-Amenity) and(O) cheap(B-Price)", "instance": {"id": "395", "words": ["find", "me", "a", "restaurant", "that", "is", "quick", "and", "cheap"], "labels": ["O", "O", "O", "O", "O", "O", "B-Amenity", "O", "B-Price"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Location, Hours, Amenity, Restaurant Name, Cuisine, Price, Dish and O.\nSentence: find me a restaurant that is quick and cheap", "prompt_labels": "find(O) me(O) a(O) restaurant(O) that(O) is(O) quick(B-Amenity) and(O) cheap(B-Price)"}, "label_list": ["Rating", "Location", "Hours", "Amenity", "Restaurant Name", "Cuisine", "Price", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 10067, 11, 30192, 11, 3383, 56685, 11, 26568, 4076, 11, 81961, 11, 8650, 11, 49268, 323, 507, 627, 85664, 25, 1505, 757, 264, 10960, 430, 374, 4062, 323, 12136, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1689", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) rated(O) r(B-rating) comedy(B-genre) within(O) last(B-year) seven(I-year) years(I-year)", "instance": {"id": "1689", "words": ["list", "rated", "r", "comedy", "within", "last", "seven", "years"], "labels": ["O", "O", "B-rating", "B-genre", "O", "B-year", "I-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, review, title, genre, average ratings, year, rating, song, trailer, character, director, plot and O.\nSentence: list rated r comedy within last seven years", "prompt_labels": "list(O) rated(O) r(B-rating) comedy(B-genre) within(O) last(B-year) seven(I-year) years(I-year)"}, "label_list": ["actor", "review", "title", "genre", "average ratings", "year", "rating", "song", "trailer", "character", "director", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 3477, 11, 2316, 11, 17779, 11, 5578, 18594, 11, 1060, 11, 10959, 11, 5609, 11, 19809, 11, 3752, 11, 7690, 11, 7234, 323, 507, 627, 85664, 25, 1160, 22359, 436, 23160, 2949, 1566, 8254, 1667, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "686", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) would(O) like(O) find(O) where(O) all(O) the(O) nearby(B-Location) food(B-Cuisine) trucks(I-Cuisine) are(O)", "instance": {"id": "686", "words": ["i", "would", "like", "find", "where", "all", "the", "nearby", "food", "trucks", "are"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-Location", "B-Cuisine", "I-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Hours, Dish, Restaurant Name, Price, Amenity, Rating, Cuisine and O.\nSentence: i would like find where all the nearby food trucks are", "prompt_labels": "i(O) would(O) like(O) find(O) where(O) all(O) the(O) nearby(B-Location) food(B-Cuisine) trucks(I-Cuisine) are(O)"}, "label_list": ["Location", "Hours", "Dish", "Restaurant Name", "Price", "Amenity", "Rating", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 30192, 11, 49268, 11, 26568, 4076, 11, 8650, 11, 3383, 56685, 11, 19767, 11, 81961, 323, 507, 627, 85664, 25, 602, 1053, 1093, 1505, 1405, 682, 279, 14373, 3691, 27861, 527, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1645", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) a(O) suspense(B-genre) movie(O) within(O) the(O) past(B-year) three(I-year) years(I-year)", "instance": {"id": "1645", "words": ["list", "a", "suspense", "movie", "within", "the", "past", "three", "years"], "labels": ["O", "O", "B-genre", "O", "O", "O", "B-year", "I-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, review, plot, rating, average ratings, actor, character, director, trailer, year, title, song and O.\nSentence: list a suspense movie within the past three years", "prompt_labels": "list(O) a(O) suspense(B-genre) movie(O) within(O) the(O) past(B-year) three(I-year) years(I-year)"}, "label_list": ["genre", "review", "plot", "rating", "average ratings", "actor", "character", "director", "trailer", "year", "title", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 3477, 11, 7234, 11, 10959, 11, 5578, 18594, 11, 12360, 11, 3752, 11, 7690, 11, 19809, 11, 1060, 11, 2316, 11, 5609, 323, 507, 627, 85664, 25, 1160, 264, 72930, 5818, 2949, 279, 3347, 2380, 1667, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "820", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) the(O) movie(O) about(O) strange(B-plot) men(I-plot) who(I-plot) repossess(I-plot) cars(I-plot) starring(O) emilio(B-actor) estevez(I-actor)", "instance": {"id": "820", "words": ["show", "me", "the", "movie", "about", "strange", "men", "who", "repossess", "cars", "starring", "emilio", "estevez"], "labels": ["B-plot", "I-plot", "I-plot", "I-plot", "I-plot", "I-plot", "I-plot", "I-plot", "I-plot", "I-plot", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, year, genre, review, character, trailer, rating, average ratings, plot, actor, song, title and O.\nSentence: show me the movie about strange men who repossess cars starring emilio estevez", "prompt_labels": "show(B-plot) me(I-plot) the(I-plot) movie(I-plot) about(I-plot) strange(I-plot) men(I-plot) who(I-plot) repossess(I-plot) cars(I-plot) starring(O) emilio(B-actor) estevez(I-actor)"}, "label_list": ["director", "year", "genre", "review", "character", "trailer", "rating", "average ratings", "plot", "actor", "song", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 1060, 11, 17779, 11, 3477, 11, 3752, 11, 19809, 11, 10959, 11, 5578, 18594, 11, 7234, 11, 12360, 11, 5609, 11, 2316, 323, 507, 627, 85664, 25, 1501, 757, 279, 5818, 922, 15234, 3026, 889, 312, 9007, 434, 9515, 40500, 991, 34429, 10566, 19610, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "9", "dataset": "mit-restaurant", "split": "dev", "prediction": "any(O) place(O) along(B-Location) the(I-Location) road(I-Location) has(O) a(O) good(B-Rating) beer(B-Dish) selection(O) that(O) also(O) serves(O) ribs(B-Dish)", "instance": {"id": "9", "words": ["any", "place", "along", "the", "road", "has", "a", "good", "beer", "selection", "that", "also", "serves", "ribs"], "labels": ["O", "O", "B-Location", "I-Location", "I-Location", "O", "O", "B-Rating", "B-Dish", "O", "O", "O", "O", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Rating, Amenity, Restaurant Name, Hours, Location, Cuisine, Dish and O.\nSentence: any place along the road has a good beer selection that also serves ribs", "prompt_labels": "any(O) place(O) along(B-Location) the(I-Location) road(I-Location) has(O) a(O) good(B-Rating) beer(B-Dish) selection(O) that(O) also(O) serves(O) ribs(B-Dish)"}, "label_list": ["Price", "Rating", "Amenity", "Restaurant Name", "Hours", "Location", "Cuisine", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 19767, 11, 3383, 56685, 11, 26568, 4076, 11, 30192, 11, 10067, 11, 81961, 11, 49268, 323, 507, 627, 85664, 25, 904, 2035, 3235, 279, 5754, 706, 264, 1695, 13179, 6727, 430, 1101, 17482, 56249, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1435", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) george(B-director) lucas(I-director) the(O) director(O) of(O) the(O) science(B-genre) fiction(I-genre) movie(O) star(B-title) wars(I-title)", "instance": {"id": "1435", "words": ["is", "george", "lucas", "the", "director", "of", "the", "science", "fiction", "movie", "star", "wars"], "labels": ["O", "B-director", "I-director", "O", "O", "O", "O", "B-genre", "I-genre", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, title, year, actor, character, genre, review, rating, director, trailer, song, average ratings and O.\nSentence: is george lucas the director of the science fiction movie star wars", "prompt_labels": "is(O) george(B-director) lucas(I-director) the(O) director(O) of(O) the(O) science(B-genre) fiction(I-genre) movie(O) star(O) wars(O)"}, "label_list": ["plot", "title", "year", "actor", "character", "genre", "review", "rating", "director", "trailer", "song", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 2316, 11, 1060, 11, 12360, 11, 3752, 11, 17779, 11, 3477, 11, 10959, 11, 7690, 11, 19809, 11, 5609, 11, 5578, 18594, 323, 507, 627, 85664, 25, 374, 3980, 6809, 27016, 300, 279, 7690, 315, 279, 8198, 17422, 5818, 6917, 25981, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1201", "dataset": "mit-movie", "split": "dev", "prediction": "do(O) you(O) have(O) any(O) sci(B-genre) fi(I-genre) movies(O) that(O) were(O) directed(O) by(O) jon(B-director) knautz(I-director) from(O) this(B-year) year(I-year)", "instance": {"id": "1201", "words": ["do", "you", "have", "any", "sci", "fi", "movies", "that", "were", "directed", "by", "jon", "knautz", "from", "this", "year"], "labels": ["O", "O", "O", "O", "B-genre", "I-genre", "O", "O", "O", "O", "O", "B-director", "I-director", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, plot, trailer, rating, review, director, genre, year, song, average ratings, actor, title and O.\nSentence: do you have any sci fi movies that were directed by jon knautz from this year", "prompt_labels": "do(O) you(O) have(O) any(O) sci(B-genre) fi(I-genre) movies(O) that(O) were(O) directed(O) by(O) jon(B-director) knautz(I-director) from(O) this(B-year) year(I-year)"}, "label_list": ["character", "plot", "trailer", "rating", "review", "director", "genre", "year", "song", "average ratings", "actor", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 7234, 11, 19809, 11, 10959, 11, 3477, 11, 7690, 11, 17779, 11, 1060, 11, 5609, 11, 5578, 18594, 11, 12360, 11, 2316, 323, 507, 627, 85664, 25, 656, 499, 617, 904, 39074, 9314, 9698, 430, 1051, 15910, 555, 89604, 1168, 2784, 89, 505, 420, 1060, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "150", "dataset": "crossner_music", "split": "dev", "prediction": "These(O) included(O) depictions(O) of(O) local(O) Civil(B-organization) Defence(I-organization) during(O) World(B-event) War(I-event) II(I-event) including(O) St(B-organization) John(I-organization) Ambulance(I-organization),(O) the(O) British(B-organization) Red(I-organization) Cross(I-organization) and(O) the(O) fire(O) services(O) along(O) with(O) air(B-organization) raid(I-organization) wardens(I-organization),(O) police(O) officers(O),(O) the(O) Home(B-organization) Guard(I-organization) and(O) the(O) Royal(B-organization) Voluntary(I-organization) Service(I-organization).(O)", "instance": {"id": "150", "words": ["These", "included", "depictions", "of", "local", "Civil", "Defence", "during", "World", "War", "II", "including", "St.", "John", "Ambulance", ",", "the", "British", "Red", "Cross", "and", "the", "fire", "services", "along", "with", "air", "raid", "wardens", ",", "police", "officers", ",", "the", "Home", "Guard", "and", "the", "Royal", "Voluntary", "Service", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "O", "B-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, award, country, person, organization, band, song, location, musical artist, event, album, music genre and O.\nSentence: These included depictions of local Civil Defence during World War II including St. John Ambulance , the British Red Cross and the fire services along with air raid wardens , police officers , the Home Guard and the Royal Voluntary Service .", "prompt_labels": "These(O) included(O) depictions(O) of(O) local(O) Civil(O) Defence(O) during(O) World(B-event) War(I-event) II(I-event) including(O) St.(B-organization) John(I-organization) Ambulance(I-organization) ,(O) the(O) British(B-organization) Red(I-organization) Cross(I-organization) and(O) the(O) fire(O) services(O) along(O) with(O) air(O) raid(O) wardens(O) ,(O) police(O) officers(O) ,(O) the(O) Home(B-organization) Guard(I-organization) and(O) the(O) Royal(B-organization) Voluntary(I-organization) Service(I-organization) .(O)"}, "label_list": ["musical instrument", "award", "country", "person", "organization", "band", "song", "location", "musical artist", "event", "album", "music genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18273, 14473, 11, 10292, 11, 3224, 11, 1732, 11, 7471, 11, 7200, 11, 5609, 11, 3813, 11, 18273, 10255, 11, 1567, 11, 8176, 11, 4731, 17779, 323, 507, 627, 85664, 25, 4314, 5343, 2219, 22155, 315, 2254, 16803, 40007, 2391, 4435, 5111, 8105, 2737, 800, 13, 3842, 20423, 41932, 1174, 279, 8013, 3816, 11511, 323, 279, 4027, 3600, 3235, 449, 3805, 25834, 26741, 729, 1174, 4379, 9808, 1174, 279, 5492, 12542, 323, 279, 16591, 11119, 60056, 5475, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "163", "dataset": "crossner_literature", "split": "dev", "prediction": "His(O) poem(B-literary genre),(O) Jai(B-poem) Jai(I-poem) Garavi(I-poem) Gujarat(I-poem),(O) ((O) 1873(O) )(O) is(O) used(O) as(O) a(O) de(O) facto(O) state(O) song(O) of(O) Gujarat(B-location).(O)", "instance": {"id": "163", "words": ["His", "poem", ",", "Jai", "Jai", "Garavi", "Gujarat", ",", "(", "1873", ")", "is", "used", "as", "a", "de", "facto", "state", "song", "of", "Gujarat", "."], "labels": ["O", "B-literary genre", "O", "B-poem", "I-poem", "I-poem", "I-poem", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-poem", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, event, writer, location, poem, organization, person, literary genre, book, magazine, country and O.\nSentence: His poem , Jai Jai Garavi Gujarat , ( 1873 ) is used as a de facto state song of Gujarat .", "prompt_labels": "His(O) poem(B-literary genre) ,(O) Jai(B-poem) Jai(I-poem) Garavi(I-poem) Gujarat(I-poem) ,(O) ((O) 1873(O) )(O) is(O) used(O) as(O) a(O) de(O) facto(O) state(O) song(O) of(O) Gujarat(B-poem) .(O)"}, "label_list": ["award", "event", "writer", "location", "poem", "organization", "person", "literary genre", "book", "magazine", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10292, 11, 1567, 11, 7061, 11, 3813, 11, 33894, 11, 7471, 11, 1732, 11, 32465, 17779, 11, 2363, 11, 14756, 11, 3224, 323, 507, 627, 85664, 25, 5414, 33894, 1174, 622, 2192, 622, 2192, 12471, 6321, 62953, 1174, 320, 220, 9674, 18, 883, 374, 1511, 439, 264, 409, 61596, 1614, 5609, 315, 62953, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1816", "dataset": "mit-movie", "split": "dev", "prediction": "was(O) there(O) ever(O) a(O) movie(O) about(O) a(O) magic(B-plot) book(I-plot) that(O) was(O) rated(O) nc(B-rating) 17(I-rating)", "instance": {"id": "1816", "words": ["was", "there", "ever", "a", "movie", "about", "a", "magic", "book", "that", "was", "rated", "nc", "17"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-plot", "I-plot", "O", "O", "O", "B-rating", "I-rating"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, character, director, genre, average ratings, review, song, year, rating, actor, title, trailer and O.\nSentence: was there ever a movie about a magic book that was rated nc 17", "prompt_labels": "was(O) there(O) ever(O) a(O) movie(O) about(O) a(O) magic(B-plot) book(I-plot) that(O) was(O) rated(O) nc(B-rating) 17(I-rating)"}, "label_list": ["plot", "character", "director", "genre", "average ratings", "review", "song", "year", "rating", "actor", "title", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 3752, 11, 7690, 11, 17779, 11, 5578, 18594, 11, 3477, 11, 5609, 11, 1060, 11, 10959, 11, 12360, 11, 2316, 11, 19809, 323, 507, 627, 85664, 25, 574, 1070, 3596, 264, 5818, 922, 264, 11204, 2363, 430, 574, 22359, 26183, 220, 1114, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "459", "dataset": "crossner_politics", "split": "dev", "prediction": "As(O) Bangladesh(B-country)'s(O) representative(O),(O) he(O) spearheaded(O) the(O) country(O)'s(O) entry(O) into(O) the(O) World(B-organization) Bank(I-organization),(O) International(B-organization) Monetary(I-organization) Fund(I-organization) and(O) Asian(B-organization) Development(I-organization) Bank(I-organization).(O)", "instance": {"id": "459", "words": ["As", "Bangladesh", "'s", "representative", ",", "he", "spearheaded", "the", "country", "'s", "entry", "into", "the", "World", "Bank", ",", "International", "Monetary", "Fund", "and", "Asian", "Development", "Bank", "."], "labels": ["O", "B-country", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "B-organization", "I-organization", "I-organization", "O", "B-organization", "I-organization", "I-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, event, organization, politician, person, country, political party, location and O.\nSentence: As Bangladesh 's representative , he spearheaded the country 's entry into the World Bank , International Monetary Fund and Asian Development Bank .", "prompt_labels": "As(O) Bangladesh(B-country) 's(O) representative(O) ,(O) he(O) spearheaded(O) the(O) country(O) 's(O) entry(O) into(O) the(O) World(B-organization) Bank(I-organization) ,(O) International(B-organization) Monetary(I-organization) Fund(I-organization) and(O) Asian(B-organization) Development(I-organization) Bank(I-organization) .(O)"}, "label_list": ["election", "event", "organization", "politician", "person", "country", "political party", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 6355, 11, 1567, 11, 7471, 11, 37038, 11, 1732, 11, 3224, 11, 5054, 4717, 11, 3813, 323, 507, 627, 85664, 25, 1666, 39601, 364, 82, 18740, 1174, 568, 41963, 63600, 279, 3224, 364, 82, 4441, 1139, 279, 4435, 8715, 1174, 7327, 74214, 13492, 323, 14875, 11050, 8715, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2384", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movie(O) can(O) be(O) called(O) a(O) thriller(B-genre)", "instance": {"id": "2384", "words": ["what", "movie", "can", "be", "called", "a", "thriller"], "labels": ["O", "O", "O", "O", "O", "O", "B-genre"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, trailer, genre, average ratings, actor, director, review, year, rating, title, song, plot and O.\nSentence: what movie can be called a thriller", "prompt_labels": "what(O) movie(O) can(O) be(O) called(O) a(O) thriller(B-genre)"}, "label_list": ["character", "trailer", "genre", "average ratings", "actor", "director", "review", "year", "rating", "title", "song", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 19809, 11, 17779, 11, 5578, 18594, 11, 12360, 11, 7690, 11, 3477, 11, 1060, 11, 10959, 11, 2316, 11, 5609, 11, 7234, 323, 507, 627, 85664, 25, 1148, 5818, 649, 387, 2663, 264, 54461, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "54", "dataset": "mit-restaurant", "split": "dev", "prediction": "are(O) there(O) any(O) kid(B-Amenity) friendly(I-Amenity) restaurants(O) close(B-Location) by(I-Location)", "instance": {"id": "54", "words": ["are", "there", "any", "kid", "friendly", "restaurants", "close", "by"], "labels": ["O", "O", "O", "B-Amenity", "I-Amenity", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Dish, Location, Rating, Amenity, Hours, Restaurant Name, Price and O.\nSentence: are there any kid friendly restaurants close by", "prompt_labels": "are(O) there(O) any(O) kid(B-Amenity) friendly(I-Amenity) restaurants(O) close(B-Location) by(I-Location)"}, "label_list": ["Cuisine", "Dish", "Location", "Rating", "Amenity", "Hours", "Restaurant Name", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 49268, 11, 10067, 11, 19767, 11, 3383, 56685, 11, 30192, 11, 26568, 4076, 11, 8650, 323, 507, 627, 85664, 25, 527, 1070, 904, 10585, 11919, 15926, 3345, 555, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "102", "dataset": "mit-movie", "split": "dev", "prediction": "avatar(B-title) came(O) out(O) when(O) and(O) what(O) did(O) it(O) gross(O)", "instance": {"id": "102", "words": ["avatar", "came", "out", "when", "and", "what", "did", "it", "gross"], "labels": ["B-title", "O", "O", "B-year", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, review, average ratings, genre, plot, character, rating, director, actor, year, trailer, song and O.\nSentence: avatar came out when and what did it gross", "prompt_labels": "avatar(B-title) came(O) out(O) when(B-year) and(O) what(O) did(O) it(O) gross(O)"}, "label_list": ["title", "review", "average ratings", "genre", "plot", "character", "rating", "director", "actor", "year", "trailer", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 3477, 11, 5578, 18594, 11, 17779, 11, 7234, 11, 3752, 11, 10959, 11, 7690, 11, 12360, 11, 1060, 11, 19809, 11, 5609, 323, 507, 627, 85664, 25, 21359, 3782, 704, 994, 323, 1148, 1550, 433, 20547, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "901", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) any(O) chinese(B-Cuisine) food(O) nearby(B-Location)", "instance": {"id": "901", "words": ["is", "there", "any", "chinese", "food", "nearby"], "labels": ["O", "O", "O", "B-Cuisine", "O", "B-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Location, Rating, Restaurant Name, Dish, Hours, Cuisine, Amenity and O.\nSentence: is there any chinese food nearby", "prompt_labels": "is(O) there(O) any(O) chinese(B-Cuisine) food(O) nearby(B-Location)"}, "label_list": ["Price", "Location", "Rating", "Restaurant Name", "Dish", "Hours", "Cuisine", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 10067, 11, 19767, 11, 26568, 4076, 11, 49268, 11, 30192, 11, 81961, 11, 3383, 56685, 323, 507, 627, 85664, 25, 374, 1070, 904, 57487, 3691, 14373, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "285", "dataset": "crossner_politics", "split": "dev", "prediction": "The(O) result(O) was(O) a(O) national(O) unity(O) government(O) involving(O) eight(O) parties(O) ;(O) Labor(B-political party),(O) Likud(B-political party),(O) Shas(B-political party),(O) the(O) Centre(B-political party) Party(I-political party),(O) the(O) National(B-political party) Religious(I-political party) Party(I-political party),(O) United(B-political party) Torah(I-political party) Judaism(I-political party),(O) Yisrael(B-political party) BaAliyah(I-political party),(O) the(O) National(B-political party) Union(I-political party) and(O) Yisrael(B-political party) Beiteinu(I-political party).(O)", "instance": {"id": "285", "words": ["The", "result", "was", "a", "national", "unity", "government", "involving", "eight", "parties", ";", "Labor", ",", "Likud", ",", "Shas", ",", "the", "Centre", "Party", ",", "the", "National", "Religious", "Party", ",", "United", "Torah", "Judaism", ",", "Yisrael", "BaAliyah", ",", "the", "National", "Union", "and", "Yisrael", "Beiteinu", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "O", "B-political party", "O", "B-political party", "O", "O", "B-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "O", "B-political party", "I-political party", "I-political party", "O", "B-political party", "I-political party", "O", "O", "B-political party", "I-political party", "O", "B-political party", "I-political party", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, person, location, politician, election, organization, country, political party and O.\nSentence: The result was a national unity government involving eight parties ; Labor , Likud , Shas , the Centre Party , the National Religious Party , United Torah Judaism , Yisrael BaAliyah , the National Union and Yisrael Beiteinu .", "prompt_labels": "The(O) result(O) was(O) a(O) national(O) unity(O) government(O) involving(O) eight(O) parties(O) ;(O) Labor(B-political party) ,(O) Likud(B-political party) ,(O) Shas(B-political party) ,(O) the(O) Centre(B-political party) Party(I-political party) ,(O) the(O) National(B-political party) Religious(I-political party) Party(I-political party) ,(O) United(B-political party) Torah(I-political party) Judaism(I-political party) ,(O) Yisrael(B-political party) BaAliyah(I-political party) ,(O) the(O) National(B-political party) Union(I-political party) and(O) Yisrael(B-political party) Beiteinu(I-political party) .(O)"}, "label_list": ["event", "person", "location", "politician", "election", "organization", "country", "political party"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 1732, 11, 3813, 11, 37038, 11, 6355, 11, 7471, 11, 3224, 11, 5054, 4717, 323, 507, 627, 85664, 25, 578, 1121, 574, 264, 5426, 31426, 3109, 16239, 8223, 9875, 2652, 15277, 1174, 34029, 664, 1174, 1443, 300, 1174, 279, 14821, 8722, 1174, 279, 5165, 53176, 8722, 1174, 3723, 73050, 64283, 1174, 816, 285, 6327, 14659, 18129, 95780, 1174, 279, 5165, 9323, 323, 816, 285, 6327, 2893, 635, 102437, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1458", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) there(O) a(O) lea(B-actor) thompson(I-actor) movie(O) about(O) god(B-plot) that(O) took(O) place(O) in(O) the(O) 1950(B-year) s(I-year) with(O) an(O) average(O) rating(O) of(O) six(B-average ratings)", "instance": {"id": "1458", "words": ["is", "there", "a", "lea", "thompson", "movie", "about", "god", "that", "took", "place", "in", "the", "1950", "s", "with", "an", "average", "rating", "of", "six"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O", "O", "B-plot", "O", "O", "O", "O", "O", "B-year", "I-year", "O", "O", "O", "O", "O", "B-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, title, actor, director, character, plot, average ratings, song, genre, review, trailer, year and O.\nSentence: is there a lea thompson movie about god that took place in the 1950 s with an average rating of six", "prompt_labels": "is(O) there(O) a(O) lea(B-actor) thompson(I-actor) movie(O) about(O) god(B-plot) that(O) took(O) place(O) in(O) the(O) 1950(B-year) s(I-year) with(O) an(O) average(O) rating(O) of(O) six(B-average ratings)"}, "label_list": ["rating", "title", "actor", "director", "character", "plot", "average ratings", "song", "genre", "review", "trailer", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 2316, 11, 12360, 11, 7690, 11, 3752, 11, 7234, 11, 5578, 18594, 11, 5609, 11, 17779, 11, 3477, 11, 19809, 11, 1060, 323, 507, 627, 85664, 25, 374, 1070, 264, 514, 64, 270, 96101, 5818, 922, 10087, 430, 3952, 2035, 304, 279, 220, 6280, 15, 274, 449, 459, 5578, 10959, 315, 4848, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1465", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) there(O) a(O) pg(B-rating) 13(I-rating) mockumentary(B-genre) that(O) is(O) liked(B-average ratings) by(I-average ratings) many(I-average ratings) and(O) starring(O) nicolas(B-actor) cage(I-actor) from(O) the(O) last(B-year) nine(I-year) years(I-year)", "instance": {"id": "1465", "words": ["is", "there", "a", "pg", "13", "mockumentary", "that", "is", "liked", "by", "many", "and", "starring", "nicolas", "cage", "from", "the", "last", "nine", "years"], "labels": ["O", "O", "O", "B-rating", "I-rating", "B-genre", "O", "O", "B-average ratings", "I-average ratings", "I-average ratings", "O", "O", "B-actor", "I-actor", "O", "O", "B-year", "I-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, average ratings, year, plot, song, title, rating, trailer, review, character, actor, genre and O.\nSentence: is there a pg 13 mockumentary that is liked by many and starring nicolas cage from the last nine years", "prompt_labels": "is(O) there(O) a(O) pg(B-rating) 13(I-rating) mockumentary(B-genre) that(O) is(O) liked(B-average ratings) by(I-average ratings) many(I-average ratings) and(O) starring(O) nicolas(B-actor) cage(I-actor) from(O) the(O) last(B-year) nine(I-year) years(I-year)"}, "label_list": ["director", "average ratings", "year", "plot", "song", "title", "rating", "trailer", "review", "character", "actor", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 5578, 18594, 11, 1060, 11, 7234, 11, 5609, 11, 2316, 11, 10959, 11, 19809, 11, 3477, 11, 3752, 11, 12360, 11, 17779, 323, 507, 627, 85664, 25, 374, 1070, 264, 17953, 220, 1032, 8018, 1143, 661, 430, 374, 15262, 555, 1690, 323, 40500, 17778, 19736, 36460, 505, 279, 1566, 11888, 1667, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "231", "dataset": "crossner_literature", "split": "dev", "prediction": "A(B-book) Clockwork(I-book) Orange(I-book) is(O) a(O) dystopian(O) satirical(O) black(O) comedy(O) novel(O) by(O) English(O) writer(O) Anthony(B-writer) Burgess(I-writer),(O) published(O) in(O) 1962(O).(O)", "instance": {"id": "231", "words": ["A", "Clockwork", "Orange", "is", "a", "dystopian", "satirical", "black", "comedy", "novel", "by", "English", "writer", "Anthony", "Burgess", ",", "published", "in", "1962", "."], "labels": ["B-book", "I-book", "I-book", "O", "O", "B-literary genre", "I-literary genre", "I-literary genre", "I-literary genre", "I-literary genre", "O", "O", "O", "B-writer", "I-writer", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: book, writer, award, organization, country, person, literary genre, event, magazine, location, poem and O.\nSentence: A Clockwork Orange is a dystopian satirical black comedy novel by English writer Anthony Burgess , published in 1962 .", "prompt_labels": "A(B-book) Clockwork(I-book) Orange(I-book) is(O) a(O) dystopian(B-literary genre) satirical(I-literary genre) black(I-literary genre) comedy(I-literary genre) novel(I-literary genre) by(O) English(O) writer(O) Anthony(B-writer) Burgess(I-writer) ,(O) published(O) in(O) 1962(O) .(O)"}, "label_list": ["book", "writer", "award", "organization", "country", "person", "literary genre", "event", "magazine", "location", "poem"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2363, 11, 7061, 11, 10292, 11, 7471, 11, 3224, 11, 1732, 11, 32465, 17779, 11, 1567, 11, 14756, 11, 3813, 11, 33894, 323, 507, 627, 85664, 25, 362, 27234, 1816, 22725, 374, 264, 69110, 48748, 7731, 67966, 3776, 23160, 11775, 555, 6498, 7061, 21353, 98567, 1174, 4756, 304, 220, 5162, 17, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1403", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) is(O) the(O) best(B-Rating) korean(B-Cuisine) bbq(I-Cuisine)", "instance": {"id": "1403", "words": ["where", "is", "the", "best", "korean", "bbq"], "labels": ["O", "O", "O", "B-Rating", "B-Cuisine", "I-Cuisine"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Location, Restaurant Name, Rating, Hours, Cuisine, Price, Dish and O.\nSentence: where is the best korean bbq", "prompt_labels": "where(O) is(O) the(O) best(B-Rating) korean(B-Cuisine) bbq(I-Cuisine)"}, "label_list": ["Amenity", "Location", "Restaurant Name", "Rating", "Hours", "Cuisine", "Price", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 10067, 11, 26568, 4076, 11, 19767, 11, 30192, 11, 81961, 11, 8650, 11, 49268, 323, 507, 627, 85664, 25, 1405, 374, 279, 1888, 597, 46295, 16927, 80, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1831", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) 2010(B-year) pg(B-rating) rated(O) adventure(B-genre) film(O) stars(O) wayne(B-actor) a(O) harold(B-actor)", "instance": {"id": "1831", "words": ["what", "2010", "pg", "rated", "adventure", "film", "stars", "wayne", "a", "harold"], "labels": ["O", "B-year", "B-rating", "O", "B-genre", "O", "O", "B-director", "I-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, average ratings, title, song, rating, plot, year, review, actor, director, genre, trailer and O.\nSentence: what 2010 pg rated adventure film stars wayne a harold", "prompt_labels": "what(O) 2010(B-year) pg(B-rating) rated(O) adventure(B-genre) film(O) stars(O) wayne(B-director) a(I-director) harold(I-director)"}, "label_list": ["character", "average ratings", "title", "song", "rating", "plot", "year", "review", "actor", "director", "genre", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 5578, 18594, 11, 2316, 11, 5609, 11, 10959, 11, 7234, 11, 1060, 11, 3477, 11, 12360, 11, 7690, 11, 17779, 11, 19809, 323, 507, 627, 85664, 25, 1148, 220, 679, 15, 17953, 22359, 18427, 4632, 9958, 1648, 818, 264, 4960, 820, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "410", "dataset": "crossner_politics", "split": "dev", "prediction": "Bernie(B-politician) Sanders(I-politician),(O) the(O) Liberty(B-political party) Union(I-political party) Party(I-political party) candidate(O),(O) was(O) later(O) elected(O) to(O) this(O) seat(O) in(O) 2006(B-election) United(I-election) States(I-election) Senate(I-election) election(I-election) in(I-election) Vermont(I-election),(O) serving(O) as(O) an(O) Independent(O).(O)", "instance": {"id": "410", "words": ["Bernie", "Sanders", ",", "the", "Liberty", "Union", "Party", "candidate", ",", "was", "later", "elected", "to", "this", "seat", "in", "2006", "United", "States", "Senate", "election", "in", "Vermont", ",", "serving", "as", "an", "Independent", "."], "labels": ["B-politician", "I-politician", "O", "O", "B-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, politician, location, country, political party, organization, person, event and O.\nSentence: Bernie Sanders , the Liberty Union Party candidate , was later elected to this seat in 2006 United States Senate election in Vermont , serving as an Independent .", "prompt_labels": "Bernie(B-politician) Sanders(I-politician) ,(O) the(O) Liberty(B-political party) Union(I-political party) Party(I-political party) candidate(O) ,(O) was(O) later(O) elected(O) to(O) this(O) seat(O) in(O) 2006(B-election) United(I-election) States(I-election) Senate(I-election) election(I-election) in(I-election) Vermont(I-election) ,(O) serving(O) as(O) an(O) Independent(O) .(O)"}, "label_list": ["election", "politician", "location", "country", "political party", "organization", "person", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 6355, 11, 37038, 11, 3813, 11, 3224, 11, 5054, 4717, 11, 7471, 11, 1732, 11, 1567, 323, 507, 627, 85664, 25, 30324, 17284, 1174, 279, 32492, 9323, 8722, 9322, 1174, 574, 3010, 16689, 311, 420, 10954, 304, 220, 1049, 21, 3723, 4273, 10092, 6355, 304, 35739, 1174, 13788, 439, 459, 22765, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "411", "dataset": "crossner_politics", "split": "dev", "prediction": "International(O) lending(O) organizations(O) such(O) as(O) the(O) World(B-organization) Bank(I-organization),(O) the(O) International(B-organization) Monetary(I-organization) Fund(I-organization),(O) and(O) the(O) Inter-American(B-organization) Development(I-organization) Bank(I-organization) lent(O) vast(O) sums(O) anew(O).(O)", "instance": {"id": "411", "words": ["International", "lending", "organizations", "such", "as", "the", "World", "Bank", ",", "the", "International", "Monetary", "Fund", ",", "and", "the", "Inter-American", "Development", "Bank", "lent", "vast", "sums", "anew", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, election, organization, politician, country, person, political party, event and O.\nSentence: International lending organizations such as the World Bank , the International Monetary Fund , and the Inter-American Development Bank lent vast sums anew .", "prompt_labels": "International(O) lending(O) organizations(O) such(O) as(O) the(O) World(B-organization) Bank(I-organization) ,(O) the(O) International(B-organization) Monetary(I-organization) Fund(I-organization) ,(O) and(O) the(O) Inter-American(B-organization) Development(I-organization) Bank(I-organization) lent(O) vast(O) sums(O) anew(O) .(O)"}, "label_list": ["location", "election", "organization", "politician", "country", "person", "political party", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 6355, 11, 7471, 11, 37038, 11, 3224, 11, 1732, 11, 5054, 4717, 11, 1567, 323, 507, 627, 85664, 25, 7327, 40651, 11351, 1778, 439, 279, 4435, 8715, 1174, 279, 7327, 74214, 13492, 1174, 323, 279, 5783, 24145, 11050, 8715, 48907, 13057, 37498, 93392, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "126", "dataset": "crossner_politics", "split": "dev", "prediction": "For(O) the(O) 2018(B-election) Pakistani(I-election) general(I-election) election(I-election),(O) PML(B-political party) -I(I-political party) lead(O) a(O) new(O) coalition(O) named(O) Grand(B-political party) Democratic(I-political party) Alliance(I-political party) with(O) Awami(B-political party) Tahreek(I-political party),(O) National(B-political party) Peoples(I-political party) Party(I-political party),(O) Pakistan(B-political party) Peoples(I-political party) Party(I-political party) Workers(I-political party) and(O) Pakistan(B-political party) Peoples(I-political party) Muslim(I-political party) League(I-political party).(O)", "instance": {"id": "126", "words": ["For", "the", "2018", "Pakistani", "general", "election", ",", "PML-F", "lead", "a", "new", "coalition", "named", "Grand", "Democratic", "Alliance", "with", "Awami", "Tahreek", ",", "National", "Peoples", "Party", ",", "Pakistan", "Peoples", "Party", "Workers", "and", "Pakistan", "Peoples", "Muslim", "League", "."], "labels": ["O", "O", "B-election", "I-election", "I-election", "I-election", "O", "B-political party", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "O", "B-political party", "I-political party", "O", "B-political party", "I-political party", "I-political party", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, election, politician, country, organization, event, person, location and O.\nSentence: For the 2018 Pakistani general election , PML-F lead a new coalition named Grand Democratic Alliance with Awami Tahreek , National Peoples Party , Pakistan Peoples Party Workers and Pakistan Peoples Muslim League .", "prompt_labels": "For(O) the(O) 2018(B-election) Pakistani(I-election) general(I-election) election(I-election) ,(O) PML-F(B-political party) lead(O) a(O) new(O) coalition(O) named(O) Grand(B-political party) Democratic(I-political party) Alliance(I-political party) with(O) Awami(B-political party) Tahreek(I-political party) ,(O) National(B-political party) Peoples(I-political party) Party(I-political party) ,(O) Pakistan(B-political party) Peoples(I-political party) Party(I-political party) Workers(I-political party) and(O) Pakistan(B-political party) Peoples(I-political party) Muslim(I-political party) League(I-political party) .(O)"}, "label_list": ["political party", "election", "politician", "country", "organization", "event", "person", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5054, 4717, 11, 6355, 11, 37038, 11, 3224, 11, 7471, 11, 1567, 11, 1732, 11, 3813, 323, 507, 627, 85664, 25, 1789, 279, 220, 679, 23, 45552, 4689, 6355, 1174, 393, 2735, 7424, 3063, 264, 502, 26283, 7086, 10517, 11650, 23590, 449, 18371, 10830, 58087, 10957, 1174, 5165, 81398, 8722, 1174, 17076, 81398, 8722, 36798, 323, 17076, 81398, 10451, 9130, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "106", "dataset": "crossner_ai", "split": "dev", "prediction": "Since(O) 2009(O),(O) the(O) recurrent(B-algorithm) neural(I-algorithm) network(I-algorithm) s(O) and(O) deep(B-algorithm) feedforward(I-algorithm) neural(I-algorithm) networks(I-algorithm) developed(O) in(O) the(O) research(O) group(O) of(O) J\u00fcrgen(B-researcher) Schmidhuber(I-researcher) at(O) the(O) Swiss(B-organization) AI(I-organization) Lab(I-organization) IDSIA(I-organization) have(O) won(O) several(O) international(O) handwriting(B-task) competitions(I-task)..(O)", "instance": {"id": "106", "words": ["Since", "2009", ",", "the", "recurrent", "neural", "network", "s", "and", "deep", "feedforward", "neural", "networks", "developed", "in", "the", "research", "group", "of", "J\u00fcrgen", "Schmidhuber", "at", "the", "Swiss", "AI", "Lab", "IDSIA", "have", "won", "several", "international", "handwriting", "competitions", ".."], "labels": ["O", "O", "O", "O", "B-algorithm", "I-algorithm", "I-algorithm", "O", "O", "B-algorithm", "I-algorithm", "I-algorithm", "I-algorithm", "O", "O", "O", "O", "O", "O", "B-researcher", "I-researcher", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, organization, person, country, task, location, product, university, algorithm, conference, field, metric, researcher and O.\nSentence: Since 2009 , the recurrent neural network s and deep feedforward neural networks developed in the research group of J\u00fcrgen Schmidhuber at the Swiss AI Lab IDSIA have won several international handwriting competitions ..", "prompt_labels": "Since(O) 2009(O) ,(O) the(O) recurrent(B-algorithm) neural(I-algorithm) network(I-algorithm) s(O) and(O) deep(B-algorithm) feedforward(I-algorithm) neural(I-algorithm) networks(I-algorithm) developed(O) in(O) the(O) research(O) group(O) of(O) J\u00fcrgen(B-researcher) Schmidhuber(I-researcher) at(O) the(O) Swiss(B-organization) AI(I-organization) Lab(I-organization) IDSIA(I-organization) have(O) won(O) several(O) international(O) handwriting(O) competitions(O) ..(O)"}, "label_list": ["programming language", "organization", "person", "country", "task", "location", "product", "university", "algorithm", "conference", "field", "metric", "researcher"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 15840, 4221, 11, 7471, 11, 1732, 11, 3224, 11, 3465, 11, 3813, 11, 2027, 11, 12374, 11, 12384, 11, 10017, 11, 2115, 11, 18767, 11, 32185, 323, 507, 627, 85664, 25, 8876, 220, 1049, 24, 1174, 279, 65174, 30828, 4009, 274, 323, 5655, 5510, 13741, 30828, 14488, 8040, 304, 279, 3495, 1912, 315, 622, 2448, 2026, 268, 5124, 16497, 27780, 261, 520, 279, 30791, 15592, 11868, 40297, 5987, 617, 2834, 3892, 6625, 92809, 43682, 5354, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "714", "dataset": "mit-restaurant", "split": "dev", "prediction": "id(O) really(O) like(O) a(O) thai(B-Cuisine) restaurant(O) that(O) has(O) carryout(B-Amenity) do(O) you(O) know(O) of(O) one(O)", "instance": {"id": "714", "words": ["id", "really", "like", "a", "thai", "restaurant", "that", "has", "carryout", "do", "you", "know", "of", "one"], "labels": ["O", "O", "O", "O", "B-Cuisine", "O", "O", "O", "B-Amenity", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Price, Restaurant Name, Amenity, Hours, Rating, Cuisine, Dish and O.\nSentence: id really like a thai restaurant that has carryout do you know of one", "prompt_labels": "id(O) really(O) like(O) a(O) thai(B-Cuisine) restaurant(O) that(O) has(O) carryout(B-Amenity) do(O) you(O) know(O) of(O) one(O)"}, "label_list": ["Location", "Price", "Restaurant Name", "Amenity", "Hours", "Rating", "Cuisine", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 8650, 11, 26568, 4076, 11, 3383, 56685, 11, 30192, 11, 19767, 11, 81961, 11, 49268, 323, 507, 627, 85664, 25, 887, 2216, 1093, 264, 18420, 10960, 430, 706, 6920, 412, 656, 499, 1440, 315, 832, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2254", "dataset": "mit-movie", "split": "dev", "prediction": "whats(O) the(O) name(O) of(O) a(O) scary(B-genre) movie(O) with(O) michael(B-actor) dudikoff(I-actor) in(O) it(O)", "instance": {"id": "2254", "words": ["whats", "the", "name", "of", "a", "scary", "movie", "with", "michael", "dudikoff", "in", "it"], "labels": ["O", "O", "O", "O", "O", "B-genre", "O", "O", "B-actor", "I-actor", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, rating, character, actor, average ratings, director, genre, trailer, song, title, year, plot and O.\nSentence: whats the name of a scary movie with michael dudikoff in it", "prompt_labels": "whats(O) the(O) name(O) of(O) a(O) scary(B-genre) movie(O) with(O) michael(B-actor) dudikoff(I-actor) in(O) it(O)"}, "label_list": ["review", "rating", "character", "actor", "average ratings", "director", "genre", "trailer", "song", "title", "year", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 10959, 11, 3752, 11, 12360, 11, 5578, 18594, 11, 7690, 11, 17779, 11, 19809, 11, 5609, 11, 2316, 11, 1060, 11, 7234, 323, 507, 627, 85664, 25, 41209, 279, 836, 315, 264, 29565, 5818, 449, 89006, 294, 664, 1609, 1885, 304, 433, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1940", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) chick(B-genre) flicks(I-genre) has(O) michael(B-director) pare(I-director) done(O) in(O) the(O) past(B-year) nine(I-year) decades(I-year)", "instance": {"id": "1940", "words": ["what", "chick", "flicks", "has", "michael", "pare", "done", "in", "the", "past", "nine", "decades"], "labels": ["O", "B-genre", "O", "O", "B-actor", "I-actor", "O", "O", "O", "B-year", "I-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, plot, year, rating, title, average ratings, song, trailer, actor, director, review, genre and O.\nSentence: what chick flicks has michael pare done in the past nine decades", "prompt_labels": "what(O) chick(B-genre) flicks(O) has(O) michael(B-actor) pare(I-actor) done(O) in(O) the(O) past(B-year) nine(I-year) decades(I-year)"}, "label_list": ["character", "plot", "year", "rating", "title", "average ratings", "song", "trailer", "actor", "director", "review", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 7234, 11, 1060, 11, 10959, 11, 2316, 11, 5578, 18594, 11, 5609, 11, 19809, 11, 12360, 11, 7690, 11, 3477, 11, 17779, 323, 507, 627, 85664, 25, 1148, 31863, 29447, 82, 706, 89006, 24068, 2884, 304, 279, 3347, 11888, 11026, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "433", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) all(O) movies(O) staring(O) brad(B-actor) pitt(I-actor)", "instance": {"id": "433", "words": ["list", "all", "movies", "staring", "brad", "pitt"], "labels": ["O", "O", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, plot, title, genre, trailer, average ratings, review, year, director, actor, song, character and O.\nSentence: list all movies staring brad pitt", "prompt_labels": "list(O) all(O) movies(O) staring(O) brad(B-actor) pitt(I-actor)"}, "label_list": ["rating", "plot", "title", "genre", "trailer", "average ratings", "review", "year", "director", "actor", "song", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 7234, 11, 2316, 11, 17779, 11, 19809, 11, 5578, 18594, 11, 3477, 11, 1060, 11, 7690, 11, 12360, 11, 5609, 11, 3752, 323, 507, 627, 85664, 25, 1160, 682, 9698, 37874, 1437, 329, 281, 1468, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1620", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) a(O) highly(B-average ratings) liked(I-average ratings) horror(B-genre) film(O) that(O) is(O) rated(O) r(B-rating)", "instance": {"id": "1620", "words": ["list", "a", "highly", "liked", "horror", "film", "that", "is", "rated", "r"], "labels": ["O", "O", "B-average ratings", "I-average ratings", "B-genre", "O", "O", "O", "O", "B-rating"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, average ratings, title, review, director, plot, actor, trailer, genre, character, year, song and O.\nSentence: list a highly liked horror film that is rated r", "prompt_labels": "list(O) a(O) highly(B-average ratings) liked(I-average ratings) horror(B-genre) film(O) that(O) is(O) rated(O) r(B-rating)"}, "label_list": ["rating", "average ratings", "title", "review", "director", "plot", "actor", "trailer", "genre", "character", "year", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 5578, 18594, 11, 2316, 11, 3477, 11, 7690, 11, 7234, 11, 12360, 11, 19809, 11, 17779, 11, 3752, 11, 1060, 11, 5609, 323, 507, 627, 85664, 25, 1160, 264, 7701, 15262, 22169, 4632, 430, 374, 22359, 436, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "172", "dataset": "mit-movie", "split": "dev", "prediction": "kung(B-title) fu(I-title) panda(I-title) 2(I-title)", "instance": {"id": "172", "words": ["kung", "fu", "panda", "2"], "labels": ["B-title", "I-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, actor, title, review, rating, year, plot, song, trailer, average ratings, genre, character and O.\nSentence: kung fu panda 2", "prompt_labels": "kung(B-title) fu(I-title) panda(I-title) 2(I-title)"}, "label_list": ["director", "actor", "title", "review", "rating", "year", "plot", "song", "trailer", "average ratings", "genre", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 12360, 11, 2316, 11, 3477, 11, 10959, 11, 1060, 11, 7234, 11, 5609, 11, 19809, 11, 5578, 18594, 11, 17779, 11, 3752, 323, 507, 627, 85664, 25, 597, 2234, 18922, 89322, 220, 17, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "839", "dataset": "mit-movie", "split": "dev", "prediction": "find(O) the(O) movie(O) starring(O) jack(B-actor) lemmon(I-actor) and(O) alan(B-actor) arkin(I-actor) as(O) real(B-plot) estate(I-plot) salesmen(I-plot)", "instance": {"id": "839", "words": ["find", "the", "movie", "starring", "jack", "lemmon", "and", "alan", "arkin", "as", "real", "estate", "salesmen"], "labels": ["O", "O", "O", "O", "B-actor", "I-actor", "O", "B-actor", "I-actor", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, song, character, review, rating, director, genre, average ratings, plot, actor, trailer, title and O.\nSentence: find the movie starring jack lemmon and alan arkin as real estate salesmen", "prompt_labels": "find(O) the(O) movie(O) starring(O) jack(B-actor) lemmon(I-actor) and(O) alan(B-actor) arkin(I-actor) as(O) real(O) estate(O) salesmen(O)"}, "label_list": ["year", "song", "character", "review", "rating", "director", "genre", "average ratings", "plot", "actor", "trailer", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 5609, 11, 3752, 11, 3477, 11, 10959, 11, 7690, 11, 17779, 11, 5578, 18594, 11, 7234, 11, 12360, 11, 19809, 11, 2316, 323, 507, 627, 85664, 25, 1505, 279, 5818, 40500, 26128, 85074, 1677, 323, 73662, 802, 8148, 439, 1972, 12675, 6763, 5794, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1002", "dataset": "mit-restaurant", "split": "dev", "prediction": "moderately(B-Price) priced(O) seafood(B-Cuisine) restaurant(O)", "instance": {"id": "1002", "words": ["moderately", "priced", "seafood", "restaurant"], "labels": ["B-Price", "O", "B-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Hours, Restaurant Name, Cuisine, Location, Dish, Price, Amenity and O.\nSentence: moderately priced seafood restaurant", "prompt_labels": "moderately(B-Price) priced(O) seafood(B-Cuisine) restaurant(O)"}, "label_list": ["Rating", "Hours", "Restaurant Name", "Cuisine", "Location", "Dish", "Price", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 30192, 11, 26568, 4076, 11, 81961, 11, 10067, 11, 49268, 11, 8650, 11, 3383, 56685, 323, 507, 627, 85664, 25, 70351, 33705, 53405, 10960, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1348", "dataset": "mit-movie", "split": "dev", "prediction": "id(O) like(O) to(O) find(O) a(O) pg(B-rating) 13(I-rating) movie(O) about(O) promises(B-plot) that(O) was(O) directed(O) by(O) steven(B-director) silver(I-director)", "instance": {"id": "1348", "words": ["id", "like", "to", "find", "a", "pg", "13", "movie", "about", "promises", "that", "was", "directed", "by", "steven", "silver"], "labels": ["O", "O", "O", "O", "O", "B-rating", "I-rating", "O", "O", "B-plot", "O", "O", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, review, song, trailer, genre, title, director, plot, rating, average ratings, actor, character and O.\nSentence: id like to find a pg 13 movie about promises that was directed by steven silver", "prompt_labels": "id(O) like(O) to(O) find(O) a(O) pg(B-rating) 13(I-rating) movie(O) about(O) promises(B-plot) that(O) was(O) directed(O) by(O) steven(B-director) silver(I-director)"}, "label_list": ["year", "review", "song", "trailer", "genre", "title", "director", "plot", "rating", "average ratings", "actor", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 3477, 11, 5609, 11, 19809, 11, 17779, 11, 2316, 11, 7690, 11, 7234, 11, 10959, 11, 5578, 18594, 11, 12360, 11, 3752, 323, 507, 627, 85664, 25, 887, 1093, 311, 1505, 264, 17953, 220, 1032, 5818, 922, 21300, 430, 574, 15910, 555, 4179, 1055, 15310, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "146", "dataset": "crossner_politics", "split": "dev", "prediction": "In(O) Kota(B-location) Kinabalu(I-location),(O) United(B-political party) Pasokmomogun(I-political party) Kadazandusun(I-political party) Murut(I-political party) Organisation(I-political party) ((O) UPKO(B-political party) )(O) led(O) by(O) its(O) Secretary-General(O) Datuk(O) Wilfred(B-politician) Madius(I-politician) Tangau(I-politician),(O) on(O) 23(O) September(O) 2008(O),(O) joined(O) its(O) 3(O) other(O) Barisan(B-political party) Nasional(I-political party) ((O) BN(B-political party) )(O) counterparts(O) Malaysian(B-political party) Chinese(I-political party) Association(I-political party),(O) Parti(B-political party) Gerakan(I-political party) Rakyat(I-political party) Malaysia(I-political party) and(O) Malaysian(B-political party) Indian(I-political party) Congress(I-political party),(O) petitioning(O) Government(O) review(O) of(O) ISA(O).(O)", "instance": {"id": "146", "words": ["In", "Kota", "Kinabalu", ",", "United", "Pasokmomogun", "Kadazandusun", "Murut", "Organisation", "(", "UPKO", ")", "led", "by", "its", "Secretary-General", "Datuk", "Wilfred", "Madius", "Tangau", ",", "on", "23", "September", "2008", ",", "joined", "its", "3", "other", "Barisan", "Nasional", "(", "BN", ")", "counterparts", "Malaysian", "Chinese", "Association", ",", "Parti", "Gerakan", "Rakyat", "Malaysia", "and", "Malaysian", "Indian", "Congress", ",", "petitioning", "Government", "review", "of", "ISA", "."], "labels": ["O", "B-location", "I-location", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "B-political party", "O", "O", "O", "O", "O", "O", "B-politician", "I-politician", "I-politician", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "O", "B-political party", "O", "O", "B-political party", "I-political party", "I-political party", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "B-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, election, event, political party, politician, person, country, organization and O.\nSentence: In Kota Kinabalu , United Pasokmomogun Kadazandusun Murut Organisation ( UPKO ) led by its Secretary-General Datuk Wilfred Madius Tangau , on 23 September 2008 , joined its 3 other Barisan Nasional ( BN ) counterparts Malaysian Chinese Association , Parti Gerakan Rakyat Malaysia and Malaysian Indian Congress , petitioning Government review of ISA .", "prompt_labels": "In(O) Kota(B-location) Kinabalu(I-location) ,(O) United(B-political party) Pasokmomogun(I-political party) Kadazandusun(I-political party) Murut(I-political party) Organisation(I-political party) ((O) UPKO(B-political party) )(O) led(O) by(O) its(O) Secretary-General(O) Datuk(O) Wilfred(B-politician) Madius(I-politician) Tangau(I-politician) ,(O) on(O) 23(O) September(O) 2008(O) ,(O) joined(O) its(O) 3(O) other(O) Barisan(B-political party) Nasional(I-political party) ((O) BN(B-political party) )(O) counterparts(O) Malaysian(B-political party) Chinese(I-political party) Association(I-political party) ,(O) Parti(B-political party) Gerakan(I-political party) Rakyat(I-political party) Malaysia(I-political party) and(O) Malaysian(B-political party) Indian(I-political party) Congress(I-political party) ,(O) petitioning(O) Government(O) review(O) of(O) ISA(O) .(O)"}, "label_list": ["location", "election", "event", "political party", "politician", "person", "country", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 6355, 11, 1567, 11, 5054, 4717, 11, 37038, 11, 1732, 11, 3224, 11, 7471, 323, 507, 627, 85664, 25, 763, 93315, 31991, 370, 38086, 1174, 3723, 24971, 564, 61874, 540, 359, 74776, 1394, 438, 355, 359, 15356, 332, 47843, 320, 12250, 56047, 883, 6197, 555, 1202, 12667, 59082, 22362, 3178, 10785, 29093, 386, 4127, 41462, 2933, 1174, 389, 220, 1419, 6250, 220, 1049, 23, 1174, 11096, 1202, 220, 18, 1023, 4821, 17570, 39322, 4001, 320, 46416, 883, 38495, 66531, 8620, 10229, 1174, 113852, 20524, 19818, 432, 29200, 266, 28796, 323, 66531, 7904, 8151, 1174, 20984, 287, 10423, 3477, 315, 85390, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1313", "dataset": "mit-movie", "split": "dev", "prediction": "i(O) am(O) looking(O) for(O) a(O) thriller(B-genre) that(O) was(O) directed(O) by(O) alex(B-director) pires(I-director) sometime(O) in(O) the(O) past(B-year) five(I-year) years(I-year)", "instance": {"id": "1313", "words": ["i", "am", "looking", "for", "a", "thriller", "that", "was", "directed", "by", "alex", "pires", "sometime", "in", "the", "past", "five", "years"], "labels": ["O", "O", "O", "O", "O", "B-genre", "O", "O", "O", "O", "B-director", "I-director", "O", "O", "O", "B-year", "I-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, year, actor, title, rating, plot, review, director, genre, average ratings, trailer, song and O.\nSentence: i am looking for a thriller that was directed by alex pires sometime in the past five years", "prompt_labels": "i(O) am(O) looking(O) for(O) a(O) thriller(B-genre) that(O) was(O) directed(O) by(O) alex(B-director) pires(I-director) sometime(O) in(O) the(O) past(B-year) five(I-year) years(I-year)"}, "label_list": ["character", "year", "actor", "title", "rating", "plot", "review", "director", "genre", "average ratings", "trailer", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 1060, 11, 12360, 11, 2316, 11, 10959, 11, 7234, 11, 3477, 11, 7690, 11, 17779, 11, 5578, 18594, 11, 19809, 11, 5609, 323, 507, 627, 85664, 25, 602, 1097, 3411, 369, 264, 54461, 430, 574, 15910, 555, 57578, 281, 3946, 36113, 304, 279, 3347, 4330, 1667, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "66", "dataset": "crossner_politics", "split": "dev", "prediction": "The(O) party(O) upholds(O) close(O) relations(O) with(O) the(O) Popular(B-political party) Front(I-political party) for(I-political party) the(I-political party) Liberation(I-political party) of(I-political party) Palestine(I-political party),(O) the(O) Communist(B-political party) Party(I-political party) of(I-political party) the(I-political party) Philippines(I-political party),(O) the(O) Workers(B-political party) '(I-political party) Party(I-political party) of(I-political party) Belgium(I-political party),(O) the(O) Communist(B-political party) Party(I-political party) of(I-political party) Greece(I-political party),(O) the(O) Polisario(B-political party) Front(I-political party) and(O) others(O).(O)", "instance": {"id": "66", "words": ["The", "party", "upholds", "close", "relations", "with", "the", "Popular", "Front", "for", "the", "Liberation", "of", "Palestine", ",", "the", "Communist", "Party", "of", "the", "Philippines", ",", "the", "Workers", "'", "Party", "of", "Belgium", ",", "the", "Communist", "Party", "of", "Greece", ",", "the", "Polisario", "Front", "and", "others", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, politician, political party, event, organization, election, person, country and O.\nSentence: The party upholds close relations with the Popular Front for the Liberation of Palestine , the Communist Party of the Philippines , the Workers ' Party of Belgium , the Communist Party of Greece , the Polisario Front and others .", "prompt_labels": "The(O) party(O) upholds(O) close(O) relations(O) with(O) the(O) Popular(B-political party) Front(I-political party) for(I-political party) the(I-political party) Liberation(I-political party) of(I-political party) Palestine(I-political party) ,(O) the(O) Communist(B-political party) Party(I-political party) of(I-political party) the(I-political party) Philippines(I-political party) ,(O) the(O) Workers(B-political party) '(I-political party) Party(I-political party) of(I-political party) Belgium(I-political party) ,(O) the(O) Communist(B-political party) Party(I-political party) of(I-political party) Greece(I-political party) ,(O) the(O) Polisario(B-political party) Front(I-political party) and(O) others(O) .(O)"}, "label_list": ["location", "politician", "political party", "event", "organization", "election", "person", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 37038, 11, 5054, 4717, 11, 1567, 11, 7471, 11, 6355, 11, 1732, 11, 3224, 323, 507, 627, 85664, 25, 578, 4717, 709, 54219, 3345, 4398, 449, 279, 32495, 15248, 369, 279, 72984, 315, 42034, 1174, 279, 37961, 8722, 315, 279, 26363, 1174, 279, 36798, 364, 8722, 315, 34061, 1174, 279, 37961, 8722, 315, 25431, 1174, 279, 3735, 285, 3370, 15248, 323, 3885, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "262", "dataset": "crossner_literature", "split": "dev", "prediction": "Famous(O) Hopwood(B-award) award(I-award) winners(O) include(O) Robert(B-writer) Hayden(I-writer),(O) Marge(B-writer) Piercy(I-writer),(O) Arthur(B-writer) Miller(I-writer),(O) Betty(B-writer) Smith(I-writer),(O) Lawrence(B-writer) Kasdan(I-writer),(O) John(B-writer) Ciardi(I-writer),(O) Mary(B-writer) Gaitskill(I-writer),(O) Edmund(B-writer) White(I-writer),(O) Nancy(B-writer) Willard(I-writer),(O) Frank(B-writer) O(I-writer) 'Hara(I-writer),(O) and(O) I-writer(O) I-writer(O).(O)", "instance": {"id": "262", "words": ["Famous", "Hopwood", "award", "winners", "include", "Robert", "Hayden", ",", "Marge", "Piercy", ",", "Arthur", "Miller", ",", "Betty", "Smith", ",", "Lawrence", "Kasdan", ",", "John", "Ciardi", ",", "Mary", "Gaitskill", ",", "Edmund", "White", ",", "Nancy", "Willard", ",", "Frank", "O", "'Hara", ",", "and", "I-writer", "I-writer", "."], "labels": ["O", "B-award", "I-award", "O", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "I-writer", "O", "O", "B-writer", "I-writer", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: writer, magazine, poem, award, book, location, country, event, person, organization, literary genre and O.\nSentence: Famous Hopwood award winners include Robert Hayden , Marge Piercy , Arthur Miller , Betty Smith , Lawrence Kasdan , John Ciardi , Mary Gaitskill , Edmund White , Nancy Willard , Frank O 'Hara , and I-writer I-writer .", "prompt_labels": "Famous(O) Hopwood(B-award) award(I-award) winners(O) include(O) Robert(B-writer) Hayden(I-writer) ,(O) Marge(B-writer) Piercy(I-writer) ,(O) Arthur(B-writer) Miller(I-writer) ,(O) Betty(B-writer) Smith(I-writer) ,(O) Lawrence(B-writer) Kasdan(I-writer) ,(O) John(B-writer) Ciardi(I-writer) ,(O) Mary(B-writer) Gaitskill(I-writer) ,(O) Edmund(B-writer) White(I-writer) ,(O) Nancy(B-writer) Willard(I-writer) ,(O) Frank(B-writer) O(I-writer) 'Hara(I-writer) ,(O) and(O) I-writer(B-writer) I-writer(I-writer) .(O)"}, "label_list": ["writer", "magazine", "poem", "award", "book", "location", "country", "event", "person", "organization", "literary genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7061, 11, 14756, 11, 33894, 11, 10292, 11, 2363, 11, 3813, 11, 3224, 11, 1567, 11, 1732, 11, 7471, 11, 32465, 17779, 323, 507, 627, 85664, 25, 67888, 26634, 6798, 10292, 26526, 2997, 8563, 77285, 1174, 386, 2812, 21377, 11377, 1174, 28686, 17472, 1174, 56111, 9259, 1174, 28574, 38642, 36255, 1174, 3842, 32744, 37489, 1174, 10455, 18879, 1220, 11088, 1174, 71911, 5929, 1174, 35336, 4946, 569, 1174, 9454, 507, 364, 39, 5169, 1174, 323, 358, 2695, 2604, 358, 2695, 2604, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1199", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) route(O) should(O) i(O) take(O) in(O) order(O) to(O) get(O) to(O) the(O) closest(B-Location) fast(B-Cuisine) food(I-Cuisine) place(O)", "instance": {"id": "1199", "words": ["what", "route", "should", "i", "take", "in", "order", "to", "get", "to", "the", "closest", "fast", "food", "place"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-Location", "B-Cuisine", "I-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Hours, Dish, Location, Rating, Restaurant Name, Price, Cuisine and O.\nSentence: what route should i take in order to get to the closest fast food place", "prompt_labels": "what(O) route(O) should(O) i(O) take(O) in(O) order(O) to(O) get(O) to(O) the(O) closest(B-Location) fast(B-Cuisine) food(I-Cuisine) place(O)"}, "label_list": ["Amenity", "Hours", "Dish", "Location", "Rating", "Restaurant Name", "Price", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 30192, 11, 49268, 11, 10067, 11, 19767, 11, 26568, 4076, 11, 8650, 11, 81961, 323, 507, 627, 85664, 25, 1148, 6149, 1288, 602, 1935, 304, 2015, 311, 636, 311, 279, 18585, 5043, 3691, 2035, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1020", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) the(O) peter(B-director) greenaway(I-director) movie(O) based(O) on(O) the(O) tempest(B-plot)", "instance": {"id": "1020", "words": ["show", "me", "the", "peter", "greenaway", "movie", "based", "on", "the", "tempest"], "labels": ["O", "O", "O", "B-director", "I-director", "O", "O", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, year, genre, review, rating, plot, title, actor, trailer, director, song, character and O.\nSentence: show me the peter greenaway movie based on the tempest", "prompt_labels": "show(O) me(O) the(O) peter(B-director) greenaway(I-director) movie(O) based(O) on(O) the(B-title) tempest(I-title)"}, "label_list": ["average ratings", "year", "genre", "review", "rating", "plot", "title", "actor", "trailer", "director", "song", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 1060, 11, 17779, 11, 3477, 11, 10959, 11, 7234, 11, 2316, 11, 12360, 11, 19809, 11, 7690, 11, 5609, 11, 3752, 323, 507, 627, 85664, 25, 1501, 757, 279, 95087, 6307, 14075, 5818, 3196, 389, 279, 1592, 30223, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "359", "dataset": "crossner_literature", "split": "dev", "prediction": "Instead(O) he(O) wrote(O) several(O) fantasy(B-literary genre) novels(I-literary genre),(O) Elidor(B-book) ((O) 1965(O) )(O),(O) The(B-book) Owl(I-book) Service(I-book) ((O) 1967(O) )(O) and(O) Red(B-book) Shift(I-book) ((O) 1973(O) )(O).(O)", "instance": {"id": "359", "words": ["Instead", "he", "wrote", "several", "fantasy", "novels", ",", "Elidor", "(", "1965", ")", ",", "The", "Owl", "Service", "(", "1967", ")", "and", "Red", "Shift", "(", "1973", ")", "."], "labels": ["O", "O", "O", "O", "B-literary genre", "I-literary genre", "O", "B-book", "O", "O", "O", "O", "B-book", "I-book", "I-book", "O", "O", "O", "O", "B-book", "I-book", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, poem, book, organization, location, award, event, country, person, literary genre, writer and O.\nSentence: Instead he wrote several fantasy novels , Elidor ( 1965 ) , The Owl Service ( 1967 ) and Red Shift ( 1973 ) .", "prompt_labels": "Instead(O) he(O) wrote(O) several(O) fantasy(B-literary genre) novels(I-literary genre) ,(O) Elidor(B-book) ((O) 1965(O) )(O) ,(O) The(B-book) Owl(I-book) Service(I-book) ((O) 1967(O) )(O) and(O) Red(B-book) Shift(I-book) ((O) 1973(O) )(O) .(O)"}, "label_list": ["magazine", "poem", "book", "organization", "location", "award", "event", "country", "person", "literary genre", "writer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 14756, 11, 33894, 11, 2363, 11, 7471, 11, 3813, 11, 10292, 11, 1567, 11, 3224, 11, 1732, 11, 32465, 17779, 11, 7061, 323, 507, 627, 85664, 25, 12361, 568, 6267, 3892, 18884, 32963, 1174, 4072, 29856, 320, 220, 5162, 20, 883, 1174, 578, 74795, 5475, 320, 220, 5162, 22, 883, 323, 3816, 27608, 320, 220, 4468, 18, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "864", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) a(O) restaurant(O) on(O) waverly(B-Location) street(I-Location) that(O) is(O) priced(O) competitively(B-Price)", "instance": {"id": "864", "words": ["is", "there", "a", "restaurant", "on", "waverly", "street", "that", "is", "priced", "competitively"], "labels": ["O", "O", "O", "O", "O", "B-Location", "I-Location", "O", "O", "B-Price", "I-Price"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Rating, Restaurant Name, Amenity, Cuisine, Dish, Hours, Price and O.\nSentence: is there a restaurant on waverly street that is priced competitively", "prompt_labels": "is(O) there(O) a(O) restaurant(O) on(O) waverly(B-Location) street(I-Location) that(O) is(O) priced(B-Price) competitively(I-Price)"}, "label_list": ["Location", "Rating", "Restaurant Name", "Amenity", "Cuisine", "Dish", "Hours", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 19767, 11, 26568, 4076, 11, 3383, 56685, 11, 81961, 11, 49268, 11, 30192, 11, 8650, 323, 507, 627, 85664, 25, 374, 1070, 264, 10960, 389, 289, 7403, 398, 8761, 430, 374, 33705, 52304, 3210, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "122", "dataset": "mit-restaurant", "split": "dev", "prediction": "can(O) i(O) get(O) a(O) chefands(B-Restaurant Name) table(I-Restaurant Name) on(O) north(B-Location) bedford(I-Location) street(I-Location) very(B-Hours) late(I-Hours) at(I-Hours) night(I-Hours)", "instance": {"id": "122", "words": ["can", "i", "get", "a", "chefands", "table", "on", "north", "bedford", "street", "very", "late", "at", "night"], "labels": ["O", "O", "O", "O", "B-Amenity", "I-Amenity", "O", "B-Location", "I-Location", "I-Location", "B-Hours", "I-Hours", "I-Hours", "I-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Cuisine, Restaurant Name, Dish, Price, Hours, Rating, Amenity and O.\nSentence: can i get a chefands table on north bedford street very late at night", "prompt_labels": "can(O) i(O) get(O) a(O) chefands(B-Amenity) table(I-Amenity) on(O) north(B-Location) bedford(I-Location) street(I-Location) very(B-Hours) late(I-Hours) at(I-Hours) night(I-Hours)"}, "label_list": ["Location", "Cuisine", "Restaurant Name", "Dish", "Price", "Hours", "Rating", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 81961, 11, 26568, 4076, 11, 49268, 11, 8650, 11, 30192, 11, 19767, 11, 3383, 56685, 323, 507, 627, 85664, 25, 649, 602, 636, 264, 30806, 2914, 2007, 389, 10411, 4950, 8350, 8761, 1633, 3389, 520, 3814, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "383", "dataset": "crossner_literature", "split": "dev", "prediction": "In(O) 2003(O),(O) Van(B-director) Sant(I-director)'s(O) film(O) about(O) the(O) Columbine(B-event) High(I-event) School(I-event) massacre(I-event),(O) Elephant(B-book),(O) won(O) the(O) Palme(B-award) d(I-award) 'Or(I-award) at(O) the(O) Cannes(B-event) Film(I-event) Festival(I-event).(O)", "instance": {"id": "383", "words": ["In", "2003", ",", "Van", "Sant", "'s", "film", "about", "the", "Columbine", "High", "School", "massacre", ",", "Elephant", ",", "won", "the", "Palme", "d", "'Or", "at", "the", "Cannes", "Film", "Festival", "."], "labels": ["O", "O", "O", "B-person", "I-person", "O", "O", "O", "O", "B-event", "I-event", "I-event", "I-event", "O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "O", "O", "B-event", "I-event", "I-event", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, event, book, magazine, poem, literary genre, country, writer, award, location, person and O.\nSentence: In 2003 , Van Sant 's film about the Columbine High School massacre , Elephant , won the Palme d 'Or at the Cannes Film Festival .", "prompt_labels": "In(O) 2003(O) ,(O) Van(B-person) Sant(I-person) 's(O) film(O) about(O) the(O) Columbine(B-event) High(I-event) School(I-event) massacre(I-event) ,(O) Elephant(O) ,(O) won(O) the(O) Palme(B-award) d(I-award) 'Or(I-award) at(O) the(O) Cannes(B-event) Film(I-event) Festival(I-event) .(O)"}, "label_list": ["organization", "event", "book", "magazine", "poem", "literary genre", "country", "writer", "award", "location", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 1567, 11, 2363, 11, 14756, 11, 33894, 11, 32465, 17779, 11, 3224, 11, 7061, 11, 10292, 11, 3813, 11, 1732, 323, 507, 627, 85664, 25, 763, 220, 1049, 18, 1174, 13000, 23746, 364, 82, 4632, 922, 279, 14225, 47661, 5234, 6150, 49352, 1174, 79189, 1174, 2834, 279, 11165, 2727, 294, 364, 2244, 520, 279, 84620, 17042, 17772, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "392", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) movie(O) that(O) has(O) the(O) song(O) zip(B-song) a(I-song) dee(I-song) doo(I-song) dah(I-song)", "instance": {"id": "392", "words": ["what", "is", "the", "movie", "that", "has", "the", "song", "zip", "a", "dee", "doo", "dah"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-song", "I-song", "I-song", "I-song", "I-song"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, song, review, trailer, average ratings, year, rating, actor, plot, character, title, genre and O.\nSentence: what is the movie that has the song zip a dee doo dah", "prompt_labels": "what(O) is(O) the(O) movie(O) that(O) has(O) the(O) song(O) zip(B-song) a(I-song) dee(I-song) doo(I-song) dah(I-song)"}, "label_list": ["director", "song", "review", "trailer", "average ratings", "year", "rating", "actor", "plot", "character", "title", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 5609, 11, 3477, 11, 19809, 11, 5578, 18594, 11, 1060, 11, 10959, 11, 12360, 11, 7234, 11, 3752, 11, 2316, 11, 17779, 323, 507, 627, 85664, 25, 1148, 374, 279, 5818, 430, 706, 279, 5609, 10521, 264, 45833, 656, 78, 53588, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "245", "dataset": "mit-movie", "split": "dev", "prediction": "has(O) john(B-actor) candy(I-actor) made(O) any(O) must(O) see(O) movies(O)", "instance": {"id": "245", "words": ["has", "john", "candy", "made", "any", "must", "see", "movies"], "labels": ["O", "B-actor", "I-actor", "O", "O", "B-review", "I-review", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, song, actor, year, rating, trailer, review, title, genre, director, character, average ratings and O.\nSentence: has john candy made any must see movies", "prompt_labels": "has(O) john(B-actor) candy(I-actor) made(O) any(O) must(B-review) see(I-review) movies(O)"}, "label_list": ["plot", "song", "actor", "year", "rating", "trailer", "review", "title", "genre", "director", "character", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 5609, 11, 12360, 11, 1060, 11, 10959, 11, 19809, 11, 3477, 11, 2316, 11, 17779, 11, 7690, 11, 3752, 11, 5578, 18594, 323, 507, 627, 85664, 25, 706, 40742, 32656, 1903, 904, 2011, 1518, 9698, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1725", "dataset": "mit-movie", "split": "dev", "prediction": "name(O) a(O) dark(B-actor) peta(I-actor) wilson(I-actor) movie(O)", "instance": {"id": "1725", "words": ["name", "a", "dark", "peta", "wilson", "movie"], "labels": ["O", "O", "B-genre", "B-actor", "I-actor", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, director, average ratings, actor, title, year, trailer, rating, song, character, review, plot and O.\nSentence: name a dark peta wilson movie", "prompt_labels": "name(O) a(O) dark(B-genre) peta(B-actor) wilson(I-actor) movie(O)"}, "label_list": ["genre", "director", "average ratings", "actor", "title", "year", "trailer", "rating", "song", "character", "review", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 7690, 11, 5578, 18594, 11, 12360, 11, 2316, 11, 1060, 11, 19809, 11, 10959, 11, 5609, 11, 3752, 11, 3477, 11, 7234, 323, 507, 627, 85664, 25, 836, 264, 6453, 281, 1955, 31331, 942, 5818, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1220", "dataset": "mit-movie", "split": "dev", "prediction": "do(O) you(O) know(O) where(O) i(O) might(O) find(O) the(O) movie(O) must(B-title) love(I-title) death(I-title)", "instance": {"id": "1220", "words": ["do", "you", "know", "where", "i", "might", "find", "the", "movie", "must", "love", "death"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, rating, song, genre, review, title, plot, actor, character, average ratings, year, director and O.\nSentence: do you know where i might find the movie must love death", "prompt_labels": "do(O) you(O) know(O) where(O) i(O) might(O) find(O) the(O) movie(O) must(B-title) love(I-title) death(I-title)"}, "label_list": ["trailer", "rating", "song", "genre", "review", "title", "plot", "actor", "character", "average ratings", "year", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 10959, 11, 5609, 11, 17779, 11, 3477, 11, 2316, 11, 7234, 11, 12360, 11, 3752, 11, 5578, 18594, 11, 1060, 11, 7690, 323, 507, 627, 85664, 25, 656, 499, 1440, 1405, 602, 2643, 1505, 279, 5818, 2011, 3021, 4648, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "119", "dataset": "crossner_literature", "split": "dev", "prediction": "The(O) film(O) was(O) well(O) received(O) critically(O) in(O) the(O) festival(O) circuit(O),(O) winning(O) awards(O) at(O) the(O) 1997(B-event) Fantasia(I-event) Festival(I-event) in(O) Montr\u00e9al(B-location),(O) and(O) Fantasporto(B-event) Film(I-event) Festival(I-event) in(O) Portugal(B-country).(O)", "instance": {"id": "119", "words": ["The", "film", "was", "well", "received", "critically", "in", "the", "festival", "circuit", ",", "winning", "awards", "at", "the", "1997", "Fantasia", "Festival", "in", "Montr\u00e9al", ",", "and", "Fantasporto", "Film", "Festival", "in", "Portugal", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "O", "B-location", "O", "O", "B-event", "I-event", "I-event", "O", "B-location", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, organization, writer, location, poem, book, country, event, magazine, award, person and O.\nSentence: The film was well received critically in the festival circuit , winning awards at the 1997 Fantasia Festival in Montr\u00e9al , and Fantasporto Film Festival in Portugal .", "prompt_labels": "The(O) film(O) was(O) well(O) received(O) critically(O) in(O) the(O) festival(O) circuit(O) ,(O) winning(O) awards(O) at(O) the(O) 1997(O) Fantasia(B-event) Festival(I-event) in(O) Montr\u00e9al(B-location) ,(O) and(O) Fantasporto(B-event) Film(I-event) Festival(I-event) in(O) Portugal(B-location) .(O)"}, "label_list": ["literary genre", "organization", "writer", "location", "poem", "book", "country", "event", "magazine", "award", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 32465, 17779, 11, 7471, 11, 7061, 11, 3813, 11, 33894, 11, 2363, 11, 3224, 11, 1567, 11, 14756, 11, 10292, 11, 1732, 323, 507, 627, 85664, 25, 578, 4632, 574, 1664, 4036, 41440, 304, 279, 19309, 16622, 1174, 11230, 23146, 520, 279, 220, 2550, 22, 20239, 36259, 17772, 304, 3206, 99277, 1174, 323, 20239, 300, 93674, 17042, 17772, 304, 34411, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "445", "dataset": "crossner_science", "split": "dev", "prediction": "The(O) International(B-organization) Arctic(I-organization) Science(I-organization) Committee(I-organization),(O) hundreds(O) of(O) scientists(O) and(O) specialists(O) of(O) the(O) Arctic(B-organization) Council(I-organization),(O) and(O) the(O) Barents(B-organization) Euro-Arctic(I-organization) Council(I-organization) are(O) more(O) examples(O) of(O) collaborative(O) international(O) Arctic(B-discipline) research(O).(O)", "instance": {"id": "445", "words": ["The", "International", "Arctic", "Science", "Committee", ",", "hundreds", "of", "scientists", "and", "specialists", "of", "the", "Arctic", "Council", ",", "and", "the", "Barents", "Euro-Arctic", "Council", "are", "more", "examples", "of", "collaborative", "international", "Arctic", "research", "."], "labels": ["O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "B-location", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: theory, award, country, astronomical object, enzyme, discipline, organization, location, person, protein, chemical element, scientist, university, academic journal, chemical compound, event and O.\nSentence: The International Arctic Science Committee , hundreds of scientists and specialists of the Arctic Council , and the Barents Euro-Arctic Council are more examples of collaborative international Arctic research .", "prompt_labels": "The(O) International(B-organization) Arctic(I-organization) Science(I-organization) Committee(I-organization) ,(O) hundreds(O) of(O) scientists(O) and(O) specialists(O) of(O) the(O) Arctic(B-organization) Council(I-organization) ,(O) and(O) the(O) Barents(B-organization) Euro-Arctic(I-organization) Council(I-organization) are(O) more(O) examples(O) of(O) collaborative(O) international(O) Arctic(B-location) research(O) .(O)"}, "label_list": ["theory", "award", "country", "astronomical object", "enzyme", "discipline", "organization", "location", "person", "protein", "chemical element", "scientist", "university", "academic journal", "chemical compound", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10334, 11, 10292, 11, 3224, 11, 87283, 1665, 11, 49242, 11, 26434, 11, 7471, 11, 3813, 11, 1732, 11, 13128, 11, 11742, 2449, 11, 28568, 11, 12374, 11, 14584, 8486, 11, 11742, 24549, 11, 1567, 323, 507, 627, 85664, 25, 578, 7327, 37518, 10170, 10554, 1174, 11758, 315, 14248, 323, 35416, 315, 279, 37518, 9251, 1174, 323, 279, 426, 1415, 82, 20026, 6830, 81, 26636, 9251, 527, 810, 10507, 315, 40806, 6625, 37518, 3495, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "108", "dataset": "crossner_music", "split": "dev", "prediction": "The(O) accordion(O) has(O) been(O) used(O) by(O) tropipop(O) musicians(O) such(O) as(O) Carlos(B-musical artist) Vives(I-musical artist),(O) Andr\u00e9s(B-musical artist) Cabas(I-musical artist),(O) Fonseca(B-musical artist) ((O) singer(O) )(O) and(O) Bacilos(B-band),(O) as(O) well(O) as(O) rock(O) musicians(O) such(O) as(O) Juanes(B-musical artist) and(O) pop(O) musicians(O) as(O) Shakira(B-musical artist).(O)", "instance": {"id": "108", "words": ["The", "accordion", "has", "been", "used", "by", "tropipop", "musicians", "such", "as", "Carlos", "Vives", ",", "Andr\u00e9s", "Cabas", ",", "Fonseca", "(", "singer", ")", "and", "Bacilos", ",", "as", "well", "as", "rock", "musicians", "such", "as", "Juanes", "and", "pop", "musicians", "as", "Shakira", "."], "labels": ["O", "B-musical instrument", "O", "O", "O", "O", "B-music genre", "O", "O", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "O", "O", "O", "O", "B-band", "O", "O", "O", "O", "B-music genre", "O", "O", "O", "B-musical artist", "O", "B-music genre", "O", "O", "B-musical artist", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, event, music genre, band, person, album, musical instrument, location, song, country, organization, award and O.\nSentence: The accordion has been used by tropipop musicians such as Carlos Vives , Andr\u00e9s Cabas , Fonseca ( singer ) and Bacilos , as well as rock musicians such as Juanes and pop musicians as Shakira .", "prompt_labels": "The(O) accordion(B-musical instrument) has(O) been(O) used(O) by(O) tropipop(B-music genre) musicians(O) such(O) as(O) Carlos(B-musical artist) Vives(I-musical artist) ,(O) Andr\u00e9s(B-musical artist) Cabas(I-musical artist) ,(O) Fonseca(B-musical artist) ((O) singer(O) )(O) and(O) Bacilos(B-band) ,(O) as(O) well(O) as(O) rock(B-music genre) musicians(O) such(O) as(O) Juanes(B-musical artist) and(O) pop(B-music genre) musicians(O) as(O) Shakira(B-musical artist) .(O)"}, "label_list": ["musical artist", "event", "music genre", "band", "person", "album", "musical instrument", "location", "song", "country", "organization", "award"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18273, 10255, 11, 1567, 11, 4731, 17779, 11, 7200, 11, 1732, 11, 8176, 11, 18273, 14473, 11, 3813, 11, 5609, 11, 3224, 11, 7471, 11, 10292, 323, 507, 627, 85664, 25, 578, 88099, 706, 1027, 1511, 555, 21965, 80482, 32629, 1778, 439, 30397, 650, 1924, 1174, 78978, 5512, 27200, 300, 1174, 71593, 325, 936, 320, 23597, 883, 323, 69396, 90419, 1174, 439, 1664, 439, 7091, 32629, 1778, 439, 29604, 288, 323, 2477, 32629, 439, 87665, 9008, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "670", "dataset": "mit-movie", "split": "dev", "prediction": "find(O) an(O) action(B-genre) movie(I-genre) from(O) the(O) 1990s(B-year) with(O) nicolas(B-actor) cage(I-actor)", "instance": {"id": "670", "words": ["find", "an", "action", "movie", "from", "the", "1990s", "with", "nicolas", "cage"], "labels": ["O", "O", "B-genre", "O", "O", "O", "B-year", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, character, song, genre, trailer, actor, rating, title, plot, review, director, average ratings and O.\nSentence: find an action movie from the 1990s with nicolas cage", "prompt_labels": "find(O) an(O) action(B-genre) movie(O) from(O) the(O) 1990s(B-year) with(O) nicolas(B-actor) cage(I-actor)"}, "label_list": ["year", "character", "song", "genre", "trailer", "actor", "rating", "title", "plot", "review", "director", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 3752, 11, 5609, 11, 17779, 11, 19809, 11, 12360, 11, 10959, 11, 2316, 11, 7234, 11, 3477, 11, 7690, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1505, 459, 1957, 5818, 505, 279, 220, 2550, 15, 82, 449, 17778, 19736, 36460, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "45", "dataset": "mit-restaurant", "split": "dev", "prediction": "are(O) there(O) any(O) greek(B-Cuisine) restaurants(O) in(B-Location) the(I-Location) area(I-Location)", "instance": {"id": "45", "words": ["are", "there", "any", "greek", "restaurants", "in", "the", "area"], "labels": ["O", "O", "O", "B-Cuisine", "O", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Location, Restaurant Name, Price, Hours, Cuisine, Dish, Rating and O.\nSentence: are there any greek restaurants in the area", "prompt_labels": "are(O) there(O) any(O) greek(B-Cuisine) restaurants(O) in(B-Location) the(I-Location) area(I-Location)"}, "label_list": ["Amenity", "Location", "Restaurant Name", "Price", "Hours", "Cuisine", "Dish", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 10067, 11, 26568, 4076, 11, 8650, 11, 30192, 11, 81961, 11, 49268, 11, 19767, 323, 507, 627, 85664, 25, 527, 1070, 904, 342, 10957, 15926, 304, 279, 3158, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "343", "dataset": "mit-restaurant", "split": "dev", "prediction": "find(O) a(O) local(B-Location) fruit(B-Cuisine) stand(I-Cuisine)", "instance": {"id": "343", "words": ["find", "a", "local", "fruit", "stand"], "labels": ["O", "O", "B-Location", "B-Cuisine", "I-Cuisine"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Rating, Location, Dish, Price, Restaurant Name, Hours, Amenity and O.\nSentence: find a local fruit stand", "prompt_labels": "find(O) a(O) local(B-Location) fruit(B-Cuisine) stand(I-Cuisine)"}, "label_list": ["Cuisine", "Rating", "Location", "Dish", "Price", "Restaurant Name", "Hours", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 19767, 11, 10067, 11, 49268, 11, 8650, 11, 26568, 4076, 11, 30192, 11, 3383, 56685, 323, 507, 627, 85664, 25, 1505, 264, 2254, 14098, 2559, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "241", "dataset": "crossner_music", "split": "dev", "prediction": "On(O) 19(O) July(O) 2014(O),(O) Il(B-band) Divo(I-band) performed(O) before(O) a(O) capacity(O) crowd(O) at(O) Edinburgh(B-location) Castle(I-location) esplanade(I-location) where(O) a(O) pop(B-event) festival(I-event) took(O) place(O) ahead(O) of(O) the(O) 2014(B-event) Commonwealth(I-event) Games(I-event).(O)", "instance": {"id": "241", "words": ["On", "19", "July", "2014", ",", "Il", "Divo", "performed", "before", "a", "capacity", "crowd", "at", "Edinburgh", "Castle", "esplanade", "where", "a", "pop", "festival", "took", "place", "ahead", "of", "the", "2014", "Commonwealth", "Games", "."], "labels": ["O", "O", "O", "O", "O", "B-band", "I-band", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "I-location", "O", "O", "B-event", "I-event", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, song, location, country, musical artist, award, musical instrument, music genre, band, person, organization, event and O.\nSentence: On 19 July 2014 , Il Divo performed before a capacity crowd at Edinburgh Castle esplanade where a pop festival took place ahead of the 2014 Commonwealth Games .", "prompt_labels": "On(O) 19(O) July(O) 2014(O) ,(O) Il(B-band) Divo(I-band) performed(O) before(O) a(O) capacity(O) crowd(O) at(O) Edinburgh(B-location) Castle(I-location) esplanade(I-location) where(O) a(O) pop(B-event) festival(I-event) took(O) place(O) ahead(O) of(O) the(O) 2014(B-event) Commonwealth(I-event) Games(I-event) .(O)"}, "label_list": ["album", "song", "location", "country", "musical artist", "award", "musical instrument", "music genre", "band", "person", "organization", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8176, 11, 5609, 11, 3813, 11, 3224, 11, 18273, 10255, 11, 10292, 11, 18273, 14473, 11, 4731, 17779, 11, 7200, 11, 1732, 11, 7471, 11, 1567, 323, 507, 627, 85664, 25, 1952, 220, 777, 5887, 220, 679, 19, 1174, 7695, 423, 6632, 10887, 1603, 264, 8824, 13734, 520, 41406, 27987, 1560, 10609, 1037, 1405, 264, 2477, 19309, 3952, 2035, 8469, 315, 279, 220, 679, 19, 38298, 11871, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "504", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) pg(B-rating) 13(I-rating) movies(O) feature(O) goldie(B-actor) hawn(I-actor)", "instance": {"id": "504", "words": ["what", "pg", "13", "movies", "feature", "goldie", "hawn"], "labels": ["O", "B-rating", "I-rating", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, trailer, title, year, character, plot, rating, review, average ratings, genre, song, actor and O.\nSentence: what pg 13 movies feature goldie hawn", "prompt_labels": "what(O) pg(B-rating) 13(I-rating) movies(O) feature(O) goldie(B-actor) hawn(I-actor)"}, "label_list": ["director", "trailer", "title", "year", "character", "plot", "rating", "review", "average ratings", "genre", "song", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 19809, 11, 2316, 11, 1060, 11, 3752, 11, 7234, 11, 10959, 11, 3477, 11, 5578, 18594, 11, 17779, 11, 5609, 11, 12360, 323, 507, 627, 85664, 25, 1148, 17953, 220, 1032, 9698, 4668, 6761, 648, 305, 6513, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "690", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) edward(B-actor) norton(I-actor) star(O) in(O) a(O) drama(B-genre) called(O) american(B-title) history(I-title) x(I-title)", "instance": {"id": "690", "words": ["did", "edward", "norton", "star", "in", "a", "drama", "called", "american", "history", "x"], "labels": ["O", "B-actor", "I-actor", "O", "O", "O", "B-genre", "O", "B-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, character, plot, actor, rating, year, director, average ratings, review, genre, title, song and O.\nSentence: did edward norton star in a drama called american history x", "prompt_labels": "did(O) edward(B-actor) norton(I-actor) star(O) in(O) a(O) drama(B-genre) called(O) american(B-title) history(I-title) x(I-title)"}, "label_list": ["trailer", "character", "plot", "actor", "rating", "year", "director", "average ratings", "review", "genre", "title", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 3752, 11, 7234, 11, 12360, 11, 10959, 11, 1060, 11, 7690, 11, 5578, 18594, 11, 3477, 11, 17779, 11, 2316, 11, 5609, 323, 507, 627, 85664, 25, 1550, 1608, 1637, 308, 38200, 6917, 304, 264, 20156, 2663, 39542, 3925, 865, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "136", "dataset": "crossner_literature", "split": "dev", "prediction": "Investigative journalist(O) Michael(B-writer) Specter(I-writer),(O) in(O) an(O) article(O) in(O) The(B-magazine) New(I-magazine) Yorker(I-magazine) on(O) 25(O) August(O) 2014(O) entitled(O) Seeds(B-poem) of(I-poem) Doubt(I-poem),(O)", "instance": {"id": "136", "words": ["Investigative", "journalist", "Michael", "Specter", ",", "in", "an", "article", "in", "The", "New", "Yorker", "on", "25", "August", "2014", "entitled", "Seeds", "of", "Doubt", ","], "labels": ["O", "O", "B-writer", "I-writer", "O", "O", "O", "O", "O", "B-magazine", "I-magazine", "I-magazine", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, award, book, event, location, writer, poem, literary genre, organization, country, person and O.\nSentence: Investigative journalist Michael Specter , in an article in The New Yorker on 25 August 2014 entitled Seeds of Doubt ,", "prompt_labels": "Investigative(O) journalist(O) Michael(B-writer) Specter(I-writer) ,(O) in(O) an(O) article(O) in(O) The(B-magazine) New(I-magazine) Yorker(I-magazine) on(O) 25(O) August(O) 2014(O) entitled(O) Seeds(O) of(O) Doubt(O) ,(O)"}, "label_list": ["magazine", "award", "book", "event", "location", "writer", "poem", "literary genre", "organization", "country", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 14756, 11, 10292, 11, 2363, 11, 1567, 11, 3813, 11, 7061, 11, 33894, 11, 32465, 17779, 11, 7471, 11, 3224, 11, 1732, 323, 507, 627, 85664, 25, 33180, 1413, 23672, 8096, 27726, 261, 1174, 304, 459, 4652, 304, 578, 1561, 64874, 389, 220, 914, 6287, 220, 679, 19, 20458, 74089, 315, 55964, 83, 1174, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "481", "dataset": "mit-restaurant", "split": "dev", "prediction": "help(O) me(O) find(O) a(O) place(O) for(O) fast(B-Cuisine) food(I-Cuisine)", "instance": {"id": "481", "words": ["help", "me", "find", "a", "place", "for", "fast", "food"], "labels": ["O", "O", "O", "O", "O", "O", "B-Cuisine", "I-Cuisine"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Dish, Restaurant Name, Cuisine, Location, Price, Rating, Amenity and O.\nSentence: help me find a place for fast food", "prompt_labels": "help(O) me(O) find(O) a(O) place(O) for(O) fast(B-Cuisine) food(I-Cuisine)"}, "label_list": ["Hours", "Dish", "Restaurant Name", "Cuisine", "Location", "Price", "Rating", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 49268, 11, 26568, 4076, 11, 81961, 11, 10067, 11, 8650, 11, 19767, 11, 3383, 56685, 323, 507, 627, 85664, 25, 1520, 757, 1505, 264, 2035, 369, 5043, 3691, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1735", "dataset": "mit-movie", "split": "dev", "prediction": "name(O) all(O) pg(B-rating) 13(I-rating) movies(O) from(O) the(O) past(B-year) four(I-year) decades(I-year) starring(O) spencer(B-actor) tracey(I-actor)", "instance": {"id": "1735", "words": ["name", "all", "pg", "13", "movies", "from", "the", "past", "four", "decades", "starring", "spencer", "tracey"], "labels": ["O", "O", "B-rating", "I-rating", "O", "O", "O", "B-year", "I-year", "I-year", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, plot, trailer, director, average ratings, actor, review, title, character, song, year, genre and O.\nSentence: name all pg 13 movies from the past four decades starring spencer tracey", "prompt_labels": "name(O) all(O) pg(B-rating) 13(I-rating) movies(O) from(O) the(O) past(B-year) four(I-year) decades(I-year) starring(O) spencer(B-actor) tracey(I-actor)"}, "label_list": ["rating", "plot", "trailer", "director", "average ratings", "actor", "review", "title", "character", "song", "year", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 7234, 11, 19809, 11, 7690, 11, 5578, 18594, 11, 12360, 11, 3477, 11, 2316, 11, 3752, 11, 5609, 11, 1060, 11, 17779, 323, 507, 627, 85664, 25, 836, 682, 17953, 220, 1032, 9698, 505, 279, 3347, 3116, 11026, 40500, 993, 20099, 11917, 88, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "277", "dataset": "mit-movie", "split": "dev", "prediction": "whats(O) the(O) movie(O) with(O) the(O) line(O) home(O) is(O) where(O) you(O) hang(O) your(O) hat(O)", "instance": {"id": "277", "words": ["whats", "the", "movie", "with", "the", "line", "home", "is", "where", "you", "hang", "your", "hat"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, review, plot, character, trailer, genre, rating, director, title, actor, year, average ratings and O.\nSentence: whats the movie with the line home is where you hang your hat", "prompt_labels": "whats(O) the(O) movie(O) with(O) the(O) line(O) home(O) is(O) where(O) you(O) hang(O) your(O) hat(O)"}, "label_list": ["song", "review", "plot", "character", "trailer", "genre", "rating", "director", "title", "actor", "year", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 3477, 11, 7234, 11, 3752, 11, 19809, 11, 17779, 11, 10959, 11, 7690, 11, 2316, 11, 12360, 11, 1060, 11, 5578, 18594, 323, 507, 627, 85664, 25, 41209, 279, 5818, 449, 279, 1584, 2162, 374, 1405, 499, 15020, 701, 9072, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "149", "dataset": "mit-restaurant", "split": "dev", "prediction": "can(O) you(O) find(O) an(O) italian(B-Cuisine) restaurant(O) where(O) i(O) can(O) wear(B-Amenity) casual(I-Amenity) atire(I-Amenity)", "instance": {"id": "149", "words": ["can", "you", "find", "an", "italian", "restaurant", "where", "i", "can", "wear", "casual", "atire"], "labels": ["O", "O", "O", "O", "B-Cuisine", "O", "O", "O", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Location, Restaurant Name, Dish, Price, Cuisine, Hours, Amenity and O.\nSentence: can you find an italian restaurant where i can wear casual atire", "prompt_labels": "can(O) you(O) find(O) an(O) italian(B-Cuisine) restaurant(O) where(O) i(O) can(O) wear(O) casual(B-Amenity) atire(I-Amenity)"}, "label_list": ["Rating", "Location", "Restaurant Name", "Dish", "Price", "Cuisine", "Hours", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 10067, 11, 26568, 4076, 11, 49268, 11, 8650, 11, 81961, 11, 30192, 11, 3383, 56685, 323, 507, 627, 85664, 25, 649, 499, 1505, 459, 29048, 10960, 1405, 602, 649, 10051, 16736, 520, 556, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "297", "dataset": "mit-restaurant", "split": "dev", "prediction": "does(O) paymon(B-Restaurant Name) serves(O) white(B-Dish) wine(I-Dish)", "instance": {"id": "297", "words": ["does", "paymon", "serves", "white", "wine"], "labels": ["O", "B-Restaurant Name", "O", "B-Dish", "I-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Amenity, Dish, Cuisine, Restaurant Name, Price, Rating, Location and O.\nSentence: does paymon serves white wine", "prompt_labels": "does(O) paymon(B-Restaurant Name) serves(O) white(B-Dish) wine(I-Dish)"}, "label_list": ["Hours", "Amenity", "Dish", "Cuisine", "Restaurant Name", "Price", "Rating", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 3383, 56685, 11, 49268, 11, 81961, 11, 26568, 4076, 11, 8650, 11, 19767, 11, 10067, 323, 507, 627, 85664, 25, 1587, 2343, 1677, 17482, 4251, 13378, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "302", "dataset": "crossner_music", "split": "dev", "prediction": "Notably(O),(O) American(O) figure(O) skater(O) Evan(B-musical artist) Lysacek(I-musical artist) used(O) Scheherazade(O) in(O) his(O) free(O) skate(O) and(O) won(O) the(O) gold(O) medal(O) at(O) Figure(O) skating(O) at(O) the(O) 2010(B-event) Winter(I-event) Olympics(I-event) in(O) Vancouver(B-location).(O)", "instance": {"id": "302", "words": ["Notably", ",", "American", "figure", "skater", "Evan", "Lysacek", "used", "Scheherazade", "in", "his", "free", "skate", "and", "won", "the", "gold", "medal", "at", "Figure", "skating", "at", "the", "2010", "Winter", "Olympics", "in", "Vancouver", "."], "labels": ["O", "O", "O", "O", "O", "B-person", "I-person", "O", "B-song", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "O", "B-location", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, organization, album, song, location, music genre, award, person, musical artist, band, country, musical instrument and O.\nSentence: Notably , American figure skater Evan Lysacek used Scheherazade in his free skate and won the gold medal at Figure skating at the 2010 Winter Olympics in Vancouver .", "prompt_labels": "Notably(O) ,(O) American(O) figure(O) skater(O) Evan(B-person) Lysacek(I-person) used(O) Scheherazade(B-song) in(O) his(O) free(O) skate(O) and(O) won(O) the(O) gold(O) medal(O) at(O) Figure(O) skating(O) at(O) the(O) 2010(B-event) Winter(I-event) Olympics(I-event) in(O) Vancouver(B-location) .(O)"}, "label_list": ["event", "organization", "album", "song", "location", "music genre", "award", "person", "musical artist", "band", "country", "musical instrument"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 7471, 11, 8176, 11, 5609, 11, 3813, 11, 4731, 17779, 11, 10292, 11, 1732, 11, 18273, 10255, 11, 7200, 11, 3224, 11, 18273, 14473, 323, 507, 627, 85664, 25, 2876, 2915, 1174, 3778, 7216, 1940, 977, 45043, 445, 1065, 580, 74, 1511, 54772, 1964, 1394, 1037, 304, 813, 1949, 43878, 323, 2834, 279, 6761, 37712, 520, 19575, 65504, 520, 279, 220, 679, 15, 20704, 33063, 304, 23393, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1744", "dataset": "mit-movie", "split": "dev", "prediction": "notorious(B-title) is(O) an(O) instant(O) classic(O)", "instance": {"id": "1744", "words": ["notorious", "is", "an", "instant", "classic"], "labels": ["B-title", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, director, trailer, year, rating, song, average ratings, plot, character, actor, title, review and O.\nSentence: notorious is an instant classic", "prompt_labels": "notorious(B-title) is(O) an(O) instant(O) classic(O)"}, "label_list": ["genre", "director", "trailer", "year", "rating", "song", "average ratings", "plot", "character", "actor", "title", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 7690, 11, 19809, 11, 1060, 11, 10959, 11, 5609, 11, 5578, 18594, 11, 7234, 11, 3752, 11, 12360, 11, 2316, 11, 3477, 323, 507, 627, 85664, 25, 44081, 374, 459, 9888, 11670, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1211", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) time(B-Hours) does(O) sonic(B-Restaurant Name) open(B-Hours)", "instance": {"id": "1211", "words": ["what", "time", "does", "sonic", "open"], "labels": ["O", "O", "O", "B-Restaurant Name", "B-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Location, Price, Restaurant Name, Amenity, Dish, Rating, Hours and O.\nSentence: what time does sonic open", "prompt_labels": "what(O) time(O) does(O) sonic(B-Restaurant Name) open(B-Hours)"}, "label_list": ["Cuisine", "Location", "Price", "Restaurant Name", "Amenity", "Dish", "Rating", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 10067, 11, 8650, 11, 26568, 4076, 11, 3383, 56685, 11, 49268, 11, 19767, 11, 30192, 323, 507, 627, 85664, 25, 1148, 892, 1587, 72436, 1825, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1457", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) is(O) there(O) a(O) fatz(B-Amenity) with(O) interesting(B-Amenity) people(I-Amenity) around(O)", "instance": {"id": "1457", "words": ["where", "is", "there", "a", "fatz", "with", "interesting", "people", "around"], "labels": ["O", "O", "O", "O", "B-Restaurant Name", "O", "B-Amenity", "I-Amenity", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Hours, Dish, Rating, Price, Cuisine, Restaurant Name, Location and O.\nSentence: where is there a fatz with interesting people around", "prompt_labels": "where(O) is(O) there(O) a(O) fatz(B-Restaurant Name) with(O) interesting(B-Amenity) people(I-Amenity) around(O)"}, "label_list": ["Amenity", "Hours", "Dish", "Rating", "Price", "Cuisine", "Restaurant Name", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 30192, 11, 49268, 11, 19767, 11, 8650, 11, 81961, 11, 26568, 4076, 11, 10067, 323, 507, 627, 85664, 25, 1405, 374, 1070, 264, 8834, 89, 449, 7185, 1274, 2212, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "165", "dataset": "crossner_literature", "split": "dev", "prediction": "In(O) addition(O) to(O) receiving(O) a(O) star(O) on(O) the(O) Hollywood(B-location) Walk(I-location) of(I-location) Fame(I-location),(O) media(O) appearances(O) included(O) write-ups(O) in(O) CCM(B-magazine) Magazine(I-magazine),(O) and(O) a(O) performance(O) on(O) The(B-magazine) View(I-magazine).(O)", "instance": {"id": "165", "words": ["In", "addition", "to", "receiving", "a", "star", "on", "the", "Hollywood", "Walk", "of", "Fame", ",", "media", "appearances", "included", "write-ups", "in", "CCM", "Magazine", ",", "and", "a", "performance", "on", "The", "View", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "I-location", "I-location", "O", "O", "O", "O", "O", "O", "B-magazine", "I-magazine", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, poem, literary genre, event, writer, book, award, magazine, organization, location, country and O.\nSentence: In addition to receiving a star on the Hollywood Walk of Fame , media appearances included write-ups in CCM Magazine , and a performance on The View .", "prompt_labels": "In(O) addition(O) to(O) receiving(O) a(O) star(O) on(O) the(O) Hollywood(B-location) Walk(I-location) of(I-location) Fame(I-location) ,(O) media(O) appearances(O) included(O) write-ups(O) in(O) CCM(B-magazine) Magazine(I-magazine) ,(O) and(O) a(O) performance(O) on(O) The(O) View(O) .(O)"}, "label_list": ["person", "poem", "literary genre", "event", "writer", "book", "award", "magazine", "organization", "location", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 33894, 11, 32465, 17779, 11, 1567, 11, 7061, 11, 2363, 11, 10292, 11, 14756, 11, 7471, 11, 3813, 11, 3224, 323, 507, 627, 85664, 25, 763, 5369, 311, 12588, 264, 6917, 389, 279, 17681, 12839, 315, 39627, 1174, 3772, 27351, 5343, 3350, 27859, 304, 356, 10190, 22168, 1174, 323, 264, 5178, 389, 578, 2806, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1299", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) can(O) i(O) find(O) the(O) cheapest(B-Price) burgers(B-Dish) in(B-Location) town(I-Location)", "instance": {"id": "1299", "words": ["where", "can", "i", "find", "the", "cheapest", "burgers", "in", "town"], "labels": ["O", "O", "O", "O", "O", "B-Price", "B-Dish", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Location, Restaurant Name, Cuisine, Hours, Price, Dish, Rating and O.\nSentence: where can i find the cheapest burgers in town", "prompt_labels": "where(O) can(O) i(O) find(O) the(O) cheapest(B-Price) burgers(B-Dish) in(B-Location) town(I-Location)"}, "label_list": ["Amenity", "Location", "Restaurant Name", "Cuisine", "Hours", "Price", "Dish", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 10067, 11, 26568, 4076, 11, 81961, 11, 30192, 11, 8650, 11, 49268, 11, 19767, 323, 507, 627, 85664, 25, 1405, 649, 602, 1505, 279, 43149, 63452, 304, 6424, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1716", "dataset": "mit-movie", "split": "dev", "prediction": "name(O) a(O) 1950(B-year) wilderness(B-plot) film(O) for(O) children(B-genre)", "instance": {"id": "1716", "words": ["name", "a", "1950", "wilderness", "film", "for", "children"], "labels": ["O", "O", "B-year", "B-plot", "O", "O", "B-genre"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, trailer, character, director, actor, plot, genre, title, song, year, average ratings, review and O.\nSentence: name a 1950 wilderness film for children", "prompt_labels": "name(O) a(O) 1950(B-year) wilderness(B-plot) film(O) for(O) children(B-genre)"}, "label_list": ["rating", "trailer", "character", "director", "actor", "plot", "genre", "title", "song", "year", "average ratings", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 19809, 11, 3752, 11, 7690, 11, 12360, 11, 7234, 11, 17779, 11, 2316, 11, 5609, 11, 1060, 11, 5578, 18594, 11, 3477, 323, 507, 627, 85664, 25, 836, 264, 220, 6280, 15, 49362, 4632, 369, 2911, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1576", "dataset": "mit-movie", "split": "dev", "prediction": "june(B-actor) lockheart(I-actor) was(O) featured(O) in(O) this(O) unrated(B-rating) animation(B-genre) film(O) of(O) the(O) last(B-year) decade(I-year)", "instance": {"id": "1576", "words": ["june", "lockheart", "was", "featured", "in", "this", "unrated", "animation", "film", "of", "the", "last", "decade"], "labels": ["B-actor", "I-actor", "O", "O", "O", "O", "B-rating", "B-genre", "O", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, rating, plot, song, average ratings, year, review, title, actor, character, trailer, genre and O.\nSentence: june lockheart was featured in this unrated animation film of the last decade", "prompt_labels": "june(B-actor) lockheart(I-actor) was(O) featured(O) in(O) this(O) unrated(B-rating) animation(B-genre) film(O) of(O) the(O) last(B-year) decade(I-year)"}, "label_list": ["director", "rating", "plot", "song", "average ratings", "year", "review", "title", "actor", "character", "trailer", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 10959, 11, 7234, 11, 5609, 11, 5578, 18594, 11, 1060, 11, 3477, 11, 2316, 11, 12360, 11, 3752, 11, 19809, 11, 17779, 323, 507, 627, 85664, 25, 503, 2957, 5409, 18207, 574, 15109, 304, 420, 41480, 660, 10571, 4632, 315, 279, 1566, 13515, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "29", "dataset": "crossner_ai", "split": "dev", "prediction": "The(O) EM(B-algorithm) algorithm(I-algorithm) is(O) used(O) to(O) find(O) ((O) local(O) ) maximum(B-metric) likelihood(I-metric) parameters(O) of(O) a(O) statistical(O) model(O) in(O) cases(O) where(O) the(O) equations(O) cannot(O) be(O) solved(O) directly(O).(O)", "instance": {"id": "29", "words": ["The", "EM", "algorithm", "is", "used", "to", "find", "(", "local", ")", "maximum", "likelihood", "parameters", "of", "a", "statistical", "model", "in", "cases", "where", "the", "equations", "cannot", "be", "solved", "directly", "."], "labels": ["O", "B-algorithm", "I-algorithm", "O", "O", "O", "O", "O", "O", "O", "B-metric", "I-metric", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, field, algorithm, metric, task, product, country, university, location, conference, researcher, organization, programming language and O.\nSentence: The EM algorithm is used to find ( local ) maximum likelihood parameters of a statistical model in cases where the equations cannot be solved directly .", "prompt_labels": "The(O) EM(B-algorithm) algorithm(I-algorithm) is(O) used(O) to(O) find(O) ((O) local(O) )(O) maximum(B-metric) likelihood(I-metric) parameters(O) of(O) a(O) statistical(O) model(O) in(O) cases(O) where(O) the(O) equations(O) cannot(O) be(O) solved(O) directly(O) .(O)"}, "label_list": ["person", "field", "algorithm", "metric", "task", "product", "country", "university", "location", "conference", "researcher", "organization", "programming language"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 2115, 11, 12384, 11, 18767, 11, 3465, 11, 2027, 11, 3224, 11, 12374, 11, 3813, 11, 10017, 11, 32185, 11, 7471, 11, 15840, 4221, 323, 507, 627, 85664, 25, 578, 17329, 12384, 374, 1511, 311, 1505, 320, 2254, 883, 7340, 29736, 5137, 315, 264, 29564, 1646, 304, 5157, 1405, 279, 39006, 4250, 387, 29056, 6089, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1451", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) is(O) the(O) nearest(B-Location) tomacchios(B-Restaurant Name) with(O) patio(B-Amenity) seating(I-Amenity) located(O)", "instance": {"id": "1451", "words": ["where", "is", "the", "nearest", "tomacchios", "with", "patio", "seating", "located"], "labels": ["O", "O", "O", "B-Location", "B-Restaurant Name", "O", "B-Amenity", "I-Amenity", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Price, Cuisine, Hours, Dish, Location, Amenity, Rating and O.\nSentence: where is the nearest tomacchios with patio seating located", "prompt_labels": "where(O) is(O) the(O) nearest(B-Location) tomacchios(B-Restaurant Name) with(O) patio(B-Amenity) seating(I-Amenity) located(O)"}, "label_list": ["Restaurant Name", "Price", "Cuisine", "Hours", "Dish", "Location", "Amenity", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 8650, 11, 81961, 11, 30192, 11, 49268, 11, 10067, 11, 3383, 56685, 11, 19767, 323, 507, 627, 85664, 25, 1405, 374, 279, 24379, 10390, 582, 331, 3614, 449, 32278, 38399, 7559, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "773", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) panera(B-Restaurant Name) bread(I-Restaurant Name) open(B-Hours) for(I-Hours) breakfast(I-Hours)", "instance": {"id": "773", "words": ["is", "panera", "bread", "open", "for", "breakfast"], "labels": ["O", "B-Restaurant Name", "I-Restaurant Name", "O", "O", "B-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Rating, Location, Dish, Restaurant Name, Amenity, Cuisine, Hours and O.\nSentence: is panera bread open for breakfast", "prompt_labels": "is(O) panera(B-Restaurant Name) bread(I-Restaurant Name) open(O) for(O) breakfast(B-Hours)"}, "label_list": ["Price", "Rating", "Location", "Dish", "Restaurant Name", "Amenity", "Cuisine", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 19767, 11, 10067, 11, 49268, 11, 26568, 4076, 11, 3383, 56685, 11, 81961, 11, 30192, 323, 507, 627, 85664, 25, 374, 7363, 2473, 16385, 1825, 369, 17954, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "295", "dataset": "crossner_ai", "split": "dev", "prediction": "An(O) empirical(B-algorithm) whitening(I-algorithm) transform(I-algorithm) is(O) obtained(O) by(O) estimating(O) the(O) covariance(O) ((O) e.g.(O) by(O) maximum(B-metric) likelihood(I-metric) )(O) and(O) subsequently(O) constructing(O) a(O) corresponding(O) estimated(O) whitening(O) matrix(O) ((O) e.g.(O) by(O) Cholesky(B-algorithm) decomposition(I-algorithm) )(O).(O)", "instance": {"id": "295", "words": ["An", "empirical", "whitening", "transform", "is", "obtained", "by", "estimating", "the", "covariance", "(", "e.g.", "by", "maximum", "likelihood", ")", "and", "subsequently", "constructing", "a", "corresponding", "estimated", "whitening", "matrix", "(", "e.g.", "by", "Cholesky", "decomposition", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-algorithm", "I-algorithm", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-algorithm", "I-algorithm", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: task, person, conference, metric, product, university, programming language, country, researcher, location, algorithm, field, organization and O.\nSentence: An empirical whitening transform is obtained by estimating the covariance ( e.g. by maximum likelihood ) and subsequently constructing a corresponding estimated whitening matrix ( e.g. by Cholesky decomposition ) .", "prompt_labels": "An(O) empirical(O) whitening(O) transform(O) is(O) obtained(O) by(O) estimating(O) the(O) covariance(O) ((O) e.g.(O) by(O) maximum(B-algorithm) likelihood(I-algorithm) )(O) and(O) subsequently(O) constructing(O) a(O) corresponding(O) estimated(O) whitening(O) matrix(O) ((O) e.g.(O) by(O) Cholesky(B-algorithm) decomposition(I-algorithm) )(O) .(O)"}, "label_list": ["task", "person", "conference", "metric", "product", "university", "programming language", "country", "researcher", "location", "algorithm", "field", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3465, 11, 1732, 11, 10017, 11, 18767, 11, 2027, 11, 12374, 11, 15840, 4221, 11, 3224, 11, 32185, 11, 3813, 11, 12384, 11, 2115, 11, 7471, 323, 507, 627, 85664, 25, 1556, 46763, 34799, 6147, 5276, 374, 12457, 555, 77472, 279, 60408, 320, 384, 1326, 13, 555, 7340, 29736, 883, 323, 28520, 50453, 264, 12435, 13240, 34799, 6147, 6303, 320, 384, 1326, 13, 555, 921, 7298, 8050, 66266, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "23", "dataset": "crossner_ai", "split": "dev", "prediction": "However(O),(O) in(O) the(O) last(O) years(O),(O) one(O) can(O) observe(O) appearing(O) of(O) different(O) e-services(O) and(O) related(O) initiatives(O) in(O) developing(O) countries(O) such(O) as(O) Project(B-task) Nemmadi(I-task),(O) MCA21(B-conference) Mission Mode(O) Project(O) or(O) Digital(B-task) India(I-task) even(O) more(O),(O) in(O) India(B-country) ;(O) Electronic(B-organization) Government(I-organization) Directorate(I-organization) in(O) Pakistan(B-country) ;(O) etc(O).(O)", "instance": {"id": "23", "words": ["However", ",", "in", "the", "last", "years", ",", "one", "can", "observe", "appearing", "of", "different", "e-services", "and", "related", "initiatives", "in", "developing", "countries", "such", "as", "Project", "Nemmadi", ",", "MCA21", "Mission", "Mode", "Project", "or", "Digital", "India", "even", "more", ",", "in", "India", ";", "Electronic", "Government", "Directorate", "in", "Pakistan", ";", "etc", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-country", "O", "B-organization", "I-organization", "I-organization", "O", "B-country", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, conference, algorithm, task, country, metric, field, location, programming language, person, university, product, organization and O.\nSentence: However , in the last years , one can observe appearing of different e-services and related initiatives in developing countries such as Project Nemmadi , MCA21 Mission Mode Project or Digital India even more , in India ; Electronic Government Directorate in Pakistan ; etc .", "prompt_labels": "However(O) ,(O) in(O) the(O) last(O) years(O) ,(O) one(O) can(O) observe(O) appearing(O) of(O) different(O) e-services(O) and(O) related(O) initiatives(O) in(O) developing(O) countries(O) such(O) as(O) Project(O) Nemmadi(O) ,(O) MCA21(O) Mission(O) Mode(O) Project(O) or(O) Digital(O) India(O) even(O) more(O) ,(O) in(O) India(B-country) ;(O) Electronic(B-organization) Government(I-organization) Directorate(I-organization) in(O) Pakistan(B-country) ;(O) etc(O) .(O)"}, "label_list": ["researcher", "conference", "algorithm", "task", "country", "metric", "field", "location", "programming language", "person", "university", "product", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 32185, 11, 10017, 11, 12384, 11, 3465, 11, 3224, 11, 18767, 11, 2115, 11, 3813, 11, 15840, 4221, 11, 1732, 11, 12374, 11, 2027, 11, 7471, 323, 507, 627, 85664, 25, 4452, 1174, 304, 279, 1566, 1667, 1174, 832, 649, 23846, 26449, 315, 2204, 384, 59392, 323, 5552, 28271, 304, 11469, 5961, 1778, 439, 5907, 63268, 76, 2836, 1174, 386, 5158, 1691, 24098, 14904, 5907, 477, 14434, 6890, 1524, 810, 1174, 304, 6890, 2652, 35269, 10423, 94466, 304, 17076, 2652, 5099, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "340", "dataset": "crossner_literature", "split": "dev", "prediction": "In(O) 1966(O),(O) with(O) her(O) brother(O) Paul(B-person) Edwin(I-person) Zimmer(I-person),(O) she(O) helped(O) found(O) and(O) name(O) the(O) Society(B-organization) for(I-organization) Creative(I-organization) Anachronism(I-organization) and(O) was(O) involved(O) in(O) developing(O) several(O) local(O) groups(O),(O) some(O) in(O) New(B-location) York(I-location) after(O) her(O) move(O) to(O) Staten(B-location) Island(I-location).(O)", "instance": {"id": "340", "words": ["In", "1966", ",", "with", "her", "brother", "Paul", "Edwin", "Zimmer", ",", "she", "helped", "found", "and", "name", "the", "Society", "for", "Creative", "Anachronism", "and", "was", "involved", "in", "developing", "several", "local", "groups", ",", "some", "in", "New", "York", "after", "her", "move", "to", "Staten", "Island", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-writer", "I-writer", "I-writer", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "O", "O", "O", "O", "B-location", "I-location", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: writer, magazine, book, event, country, person, award, organization, location, literary genre, poem and O.\nSentence: In 1966 , with her brother Paul Edwin Zimmer , she helped found and name the Society for Creative Anachronism and was involved in developing several local groups , some in New York after her move to Staten Island .", "prompt_labels": "In(O) 1966(O) ,(O) with(O) her(O) brother(O) Paul(B-writer) Edwin(I-writer) Zimmer(I-writer) ,(O) she(O) helped(O) found(O) and(O) name(O) the(O) Society(B-organization) for(I-organization) Creative(I-organization) Anachronism(I-organization) and(O) was(O) involved(O) in(O) developing(O) several(O) local(O) groups(O) ,(O) some(O) in(O) New(B-location) York(I-location) after(O) her(O) move(O) to(O) Staten(B-location) Island(I-location) .(O)"}, "label_list": ["writer", "magazine", "book", "event", "country", "person", "award", "organization", "location", "literary genre", "poem"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7061, 11, 14756, 11, 2363, 11, 1567, 11, 3224, 11, 1732, 11, 10292, 11, 7471, 11, 3813, 11, 32465, 17779, 11, 33894, 323, 507, 627, 85664, 25, 763, 220, 5162, 21, 1174, 449, 1077, 10868, 7043, 76249, 41507, 1174, 1364, 9087, 1766, 323, 836, 279, 13581, 369, 25248, 1556, 613, 2298, 2191, 323, 574, 6532, 304, 11469, 3892, 2254, 5315, 1174, 1063, 304, 1561, 4356, 1306, 1077, 3351, 311, 96406, 10951, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2154", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movies(O) star(O) rose(B-actor) mcgowan(I-actor) and(O) are(O) from(O) the(O) 1980(B-year) s(I-year)", "instance": {"id": "2154", "words": ["what", "movies", "star", "rose", "mcgowan", "and", "are", "from", "the", "1980", "s"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O", "O", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, average ratings, actor, title, song, trailer, genre, plot, rating, review, director, year and O.\nSentence: what movies star rose mcgowan and are from the 1980 s", "prompt_labels": "what(O) movies(O) star(O) rose(B-actor) mcgowan(I-actor) and(O) are(O) from(O) the(O) 1980(B-year) s(I-year)"}, "label_list": ["character", "average ratings", "actor", "title", "song", "trailer", "genre", "plot", "rating", "review", "director", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 5578, 18594, 11, 12360, 11, 2316, 11, 5609, 11, 19809, 11, 17779, 11, 7234, 11, 10959, 11, 3477, 11, 7690, 11, 1060, 323, 507, 627, 85664, 25, 1148, 9698, 6917, 16392, 19777, 37286, 276, 323, 527, 505, 279, 220, 3753, 15, 274, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "99", "dataset": "mit-movie", "split": "dev", "prediction": "find(O) a(O) john(B-director) malcovich(I-director) thriller(B-genre)", "instance": {"id": "99", "words": ["find", "a", "john", "malcovich", "thriller"], "labels": ["O", "O", "B-actor", "I-actor", "B-genre"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, rating, review, actor, plot, director, year, genre, song, trailer, average ratings, character and O.\nSentence: find a john malcovich thriller", "prompt_labels": "find(O) a(O) john(B-actor) malcovich(I-actor) thriller(B-genre)"}, "label_list": ["title", "rating", "review", "actor", "plot", "director", "year", "genre", "song", "trailer", "average ratings", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 10959, 11, 3477, 11, 12360, 11, 7234, 11, 7690, 11, 1060, 11, 17779, 11, 5609, 11, 19809, 11, 5578, 18594, 11, 3752, 323, 507, 627, 85664, 25, 1505, 264, 40742, 8811, 66, 51214, 54461, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "685", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) would(O) like(O) a(O) list(O) of(O) restaurants(O) that(O) are(O) smoke(B-Amenity) free(I-Amenity) near(B-Location) my(I-Location) house(I-Location)", "instance": {"id": "685", "words": ["i", "would", "like", "a", "list", "of", "restaurants", "that", "are", "smoke", "free", "near", "my", "house"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-Amenity", "I-Amenity", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Rating, Hours, Price, Location, Amenity, Dish, Restaurant Name and O.\nSentence: i would like a list of restaurants that are smoke free near my house", "prompt_labels": "i(O) would(O) like(O) a(O) list(O) of(O) restaurants(O) that(O) are(O) smoke(B-Amenity) free(I-Amenity) near(B-Location) my(I-Location) house(I-Location)"}, "label_list": ["Cuisine", "Rating", "Hours", "Price", "Location", "Amenity", "Dish", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 19767, 11, 30192, 11, 8650, 11, 10067, 11, 3383, 56685, 11, 49268, 11, 26568, 4076, 323, 507, 627, 85664, 25, 602, 1053, 1093, 264, 1160, 315, 15926, 430, 527, 16603, 1949, 3221, 856, 3838, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "497", "dataset": "crossner_politics", "split": "dev", "prediction": "The(O) film(O) was(O) featured(O) at(O) various(O) international(O) film(O) festivals(O),(O) including(O) :(O) the(O) Deauville(B-event) Film(I-event) Festival(I-event),(O) France(B-country) ;(O) the(O) Donostia-San(B-event) Sebasti\u00e1n(I-event) International(I-event) Film(I-event) Festival(I-event),(O) Spain(B-country) ;(O) the(O) Edinburgh(B-event) International(I-event) Film(I-event) Festival(I-event),(O) Scotland(B-country) ;(O) the(O) Helsinki(B-event) International(I-event) Film(I-event) Festival(I-event),(O) Finland(B-country) ;(O) the(O) Reykjavik(B-event) Film(I-event) Festival(I-event),(O) Iceland(B-country) ;(O) and(O) others(O).(O)", "instance": {"id": "497", "words": ["The", "film", "was", "featured", "at", "various", "international", "film", "festivals", ",", "including", ":", "the", "Deauville", "Film", "Festival", ",", "France", ";", "the", "Donostia-San", "Sebasti\u00e1n", "International", "Film", "Festival", ",", "Spain", ";", "the", "Edinburgh", "International", "Film", "Festival", ",", "Scotland", ";", "the", "Helsinki", "International", "Film", "Festival", ",", "Finland", ";", "the", "Reykjavik", "Film", "Festival", ",", "Iceland", ";", "and", "others", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "O", "B-country", "O", "O", "B-event", "I-event", "I-event", "I-event", "I-event", "O", "B-country", "O", "O", "B-event", "I-event", "I-event", "I-event", "O", "B-country", "O", "O", "B-event", "I-event", "I-event", "I-event", "O", "B-country", "O", "O", "B-event", "I-event", "I-event", "O", "B-country", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, politician, event, political party, location, election, country, person and O.\nSentence: The film was featured at various international film festivals , including : the Deauville Film Festival , France ; the Donostia-San Sebasti\u00e1n International Film Festival , Spain ; the Edinburgh International Film Festival , Scotland ; the Helsinki International Film Festival , Finland ; the Reykjavik Film Festival , Iceland ; and others .", "prompt_labels": "The(O) film(O) was(O) featured(O) at(O) various(O) international(O) film(O) festivals(O) ,(O) including(O) :(O) the(O) Deauville(B-event) Film(I-event) Festival(I-event) ,(O) France(B-country) ;(O) the(O) Donostia-San(B-event) Sebasti\u00e1n(I-event) International(I-event) Film(I-event) Festival(I-event) ,(O) Spain(B-country) ;(O) the(O) Edinburgh(B-event) International(I-event) Film(I-event) Festival(I-event) ,(O) Scotland(B-country) ;(O) the(O) Helsinki(B-event) International(I-event) Film(I-event) Festival(I-event) ,(O) Finland(B-country) ;(O) the(O) Reykjavik(B-event) Film(I-event) Festival(I-event) ,(O) Iceland(B-country) ;(O) and(O) others(O) .(O)"}, "label_list": ["organization", "politician", "event", "political party", "location", "election", "country", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 37038, 11, 1567, 11, 5054, 4717, 11, 3813, 11, 6355, 11, 3224, 11, 1732, 323, 507, 627, 85664, 25, 578, 4632, 574, 15109, 520, 5370, 6625, 4632, 45517, 1174, 2737, 551, 279, 1611, 2933, 8078, 17042, 17772, 1174, 9822, 2652, 279, 4418, 537, 689, 6354, 276, 94813, 72, 11644, 7327, 17042, 17772, 1174, 18157, 2652, 279, 41406, 7327, 17042, 17772, 1174, 19627, 2652, 279, 77434, 7327, 17042, 17772, 1174, 37355, 2652, 279, 49312, 74, 62559, 1609, 17042, 17772, 1174, 39496, 2652, 323, 3885, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "364", "dataset": "crossner_politics", "split": "dev", "prediction": "It(O) continued(O) to(O) return(O) only(O) a(O) single(O) MP(O) from(O) Scottish(O) constituencies(O) at(O) the(O) 2001(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) 2005(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) 2010(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) 2015(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) general(O) elections(O),(O) before(O) winning(O) 13(O) seats(O) in(O) 2017(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election).(O)", "instance": {"id": "364", "words": ["It", "continued", "to", "return", "only", "a", "single", "MP", "from", "Scottish", "constituencies", "at", "the", "2001", "United", "Kingdom", "general", "election", ",", "2005", "United", "Kingdom", "general", "election", ",", "2010", "United", "Kingdom", "general", "election", "and", "2015", "United", "Kingdom", "general", "election", "general", "elections", ",", "before", "winning", "13", "seats", "in", "2017", "United", "Kingdom", "general", "election", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, country, location, organization, political party, election, person, event and O.\nSentence: It continued to return only a single MP from Scottish constituencies at the 2001 United Kingdom general election , 2005 United Kingdom general election , 2010 United Kingdom general election and 2015 United Kingdom general election general elections , before winning 13 seats in 2017 United Kingdom general election .", "prompt_labels": "It(O) continued(O) to(O) return(O) only(O) a(O) single(O) MP(O) from(O) Scottish(O) constituencies(O) at(O) the(O) 2001(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) 2005(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) 2010(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) 2015(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) general(O) elections(O) ,(O) before(O) winning(O) 13(O) seats(O) in(O) 2017(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)"}, "label_list": ["politician", "country", "location", "organization", "political party", "election", "person", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 37038, 11, 3224, 11, 3813, 11, 7471, 11, 5054, 4717, 11, 6355, 11, 1732, 11, 1567, 323, 507, 627, 85664, 25, 1102, 8738, 311, 471, 1193, 264, 3254, 9599, 505, 27188, 31605, 6072, 520, 279, 220, 1049, 16, 3723, 15422, 4689, 6355, 1174, 220, 1049, 20, 3723, 15422, 4689, 6355, 1174, 220, 679, 15, 3723, 15422, 4689, 6355, 323, 220, 679, 20, 3723, 15422, 4689, 6355, 4689, 16374, 1174, 1603, 11230, 220, 1032, 16712, 304, 220, 679, 22, 3723, 15422, 4689, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1484", "dataset": "mit-restaurant", "split": "dev", "prediction": "which(O) local(B-Location) restaurant(O) serves(O) only(B-Cuisine) seafood(I-Cuisine)", "instance": {"id": "1484", "words": ["which", "local", "restaurant", "serves", "only", "seafood"], "labels": ["O", "B-Location", "O", "O", "B-Amenity", "B-Cuisine"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Restaurant Name, Amenity, Location, Cuisine, Hours, Rating, Dish and O.\nSentence: which local restaurant serves only seafood", "prompt_labels": "which(O) local(B-Location) restaurant(O) serves(O) only(B-Amenity) seafood(B-Cuisine)"}, "label_list": ["Price", "Restaurant Name", "Amenity", "Location", "Cuisine", "Hours", "Rating", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 26568, 4076, 11, 3383, 56685, 11, 10067, 11, 81961, 11, 30192, 11, 19767, 11, 49268, 323, 507, 627, 85664, 25, 902, 2254, 10960, 17482, 1193, 53405, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1981", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) matt(B-actor) damons(I-actor) highest(B-average ratings) rated(I-average ratings) movie(O)", "instance": {"id": "1981", "words": ["what", "is", "matt", "damons", "highest", "rated", "movie"], "labels": ["O", "O", "B-actor", "I-actor", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, genre, review, average ratings, plot, title, trailer, director, rating, year, song, character and O.\nSentence: what is matt damons highest rated movie", "prompt_labels": "what(O) is(O) matt(B-actor) damons(I-actor) highest(O) rated(O) movie(O)"}, "label_list": ["actor", "genre", "review", "average ratings", "plot", "title", "trailer", "director", "rating", "year", "song", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 17779, 11, 3477, 11, 5578, 18594, 11, 7234, 11, 2316, 11, 19809, 11, 7690, 11, 10959, 11, 1060, 11, 5609, 11, 3752, 323, 507, 627, 85664, 25, 1148, 374, 27537, 3824, 2439, 8592, 22359, 5818, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "250", "dataset": "crossner_science", "split": "dev", "prediction": "Another(O) copolymer(O) hydrogel(O) lens(O),(O) called(O) Polymacon(O),(O) is(O) a(O) copolymer(O) of(O) hydroxyethyl(B-chemical compound) methacrylate(I-chemical compound) and(O) Ethylene(B-chemical compound) glycol(I-chemical compound) dimethacrylate(I-chemical compound).(O)", "instance": {"id": "250", "words": ["Another", "copolymer", "hydrogel", "lens", ",", "called", "Polymacon", ",", "is", "a", "copolymer", "of", "hydroxyethyl", "methacrylate", "and", "Ethylene", "glycol", "dimethacrylate", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-chemical compound", "O", "O", "O", "O", "O", "B-chemical compound", "I-chemical compound", "O", "B-chemical compound", "I-chemical compound", "I-chemical compound", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: discipline, chemical element, scientist, theory, person, award, event, university, country, enzyme, academic journal, chemical compound, protein, location, organization, astronomical object and O.\nSentence: Another copolymer hydrogel lens , called Polymacon , is a copolymer of hydroxyethyl methacrylate and Ethylene glycol dimethacrylate .", "prompt_labels": "Another(O) copolymer(O) hydrogel(O) lens(O) ,(O) called(O) Polymacon(B-chemical compound) ,(O) is(O) a(O) copolymer(O) of(O) hydroxyethyl(B-chemical compound) methacrylate(I-chemical compound) and(O) Ethylene(B-chemical compound) glycol(I-chemical compound) dimethacrylate(I-chemical compound) .(O)"}, "label_list": ["discipline", "chemical element", "scientist", "theory", "person", "award", "event", "university", "country", "enzyme", "academic journal", "chemical compound", "protein", "location", "organization", "astronomical object"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26434, 11, 11742, 2449, 11, 28568, 11, 10334, 11, 1732, 11, 10292, 11, 1567, 11, 12374, 11, 3224, 11, 49242, 11, 14584, 8486, 11, 11742, 24549, 11, 13128, 11, 3813, 11, 7471, 11, 87283, 1665, 323, 507, 627, 85664, 25, 13596, 6293, 5849, 1195, 17055, 29952, 18848, 1174, 2663, 3735, 1631, 23184, 1174, 374, 264, 6293, 5849, 1195, 315, 17055, 4223, 42972, 21747, 582, 894, 5185, 323, 14693, 64651, 37807, 2119, 5213, 774, 582, 894, 5185, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "291", "dataset": "crossner_music", "split": "dev", "prediction": "Phoenix(B-musical artist) is(O) a(O) member(O) of(O) In(B-album) Defense(I-album) of(I-album) Animals(I-album) and(O) People(B-album) for(I-album) the(I-album) Ethical(I-album) Treatment(I-album) of(I-album) Animals(I-album) and(O) has(O) campaigned(O) for(O) both(O).(O)", "instance": {"id": "291", "words": ["Phoenix", "is", "a", "member", "of", "In", "Defense", "of", "Animals", "and", "People", "for", "the", "Ethical", "Treatment", "of", "Animals", "and", "has", "campaigned", "for", "both", "."], "labels": ["B-band", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, musical instrument, person, country, location, musical artist, band, event, organization, album, award, song and O.\nSentence: Phoenix is a member of In Defense of Animals and People for the Ethical Treatment of Animals and has campaigned for both .", "prompt_labels": "Phoenix(B-band) is(O) a(O) member(O) of(O) In(B-organization) Defense(I-organization) of(I-organization) Animals(I-organization) and(O) People(B-organization) for(I-organization) the(I-organization) Ethical(I-organization) Treatment(I-organization) of(I-organization) Animals(I-organization) and(O) has(O) campaigned(O) for(O) both(O) .(O)"}, "label_list": ["music genre", "musical instrument", "person", "country", "location", "musical artist", "band", "event", "organization", "album", "award", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 4731, 17779, 11, 18273, 14473, 11, 1732, 11, 3224, 11, 3813, 11, 18273, 10255, 11, 7200, 11, 1567, 11, 7471, 11, 8176, 11, 10292, 11, 5609, 323, 507, 627, 85664, 25, 23503, 374, 264, 4562, 315, 763, 16777, 315, 47966, 323, 9029, 369, 279, 14693, 950, 31969, 315, 47966, 323, 706, 87296, 369, 2225, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "23", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) directed(O) the(O) film(O) pulp(B-title) fiction(I-title) that(O) starred(O) john(B-actor) travolta(I-actor)", "instance": {"id": "23", "words": ["who", "directed", "the", "film", "pulp", "fiction", "that", "starred", "john", "travolta"], "labels": ["O", "B-director", "O", "O", "B-title", "I-title", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, actor, average ratings, review, year, director, genre, rating, title, character, trailer, song and O.\nSentence: who directed the film pulp fiction that starred john travolta", "prompt_labels": "who(O) directed(B-director) the(O) film(O) pulp(B-title) fiction(I-title) that(O) starred(O) john(B-actor) travolta(I-actor)"}, "label_list": ["plot", "actor", "average ratings", "review", "year", "director", "genre", "rating", "title", "character", "trailer", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 12360, 11, 5578, 18594, 11, 3477, 11, 1060, 11, 7690, 11, 17779, 11, 10959, 11, 2316, 11, 3752, 11, 19809, 11, 5609, 323, 507, 627, 85664, 25, 889, 15910, 279, 4632, 64188, 17422, 430, 59335, 40742, 10346, 60954, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "100", "dataset": "crossner_politics", "split": "dev", "prediction": "ALP(B-political party) =(O) Australian(B-political party) Labor(I-political party) Party(I-political party),(O) L(O) +(O) NP(O) =(O) grouping(O) of(O) Liberal(B-political party) Party(I-political party) of(I-political party) Australia(I-political party) /(O) National(B-political party) Party(I-political party) of(I-political party) Australia(I-political party) /(O) Liberal(B-political party) National(I-political party) Party(I-political party) of(I-political party) Queensland(I-political party) /(O) Country(B-political party) Liberal(I-political party) Party(I-political party) Coalition(O) parties(O) ((O) and(O) predecessors(O) )(O),(O) Oth(O) =(O) other(O) parties(O) and(O) independents(O).(O)", "instance": {"id": "100", "words": ["ALP", "=", "Australian", "Labor", "Party", ",", "L", "+", "NP", "=", "grouping", "of", "Liberal", "Party", "of", "Australia", "/", "National", "Party", "of", "Australia", "/", "Liberal", "National", "Party", "of", "Queensland", "/", "Country", "Liberal", "Party", "Coalition", "parties", "(", "and", "predecessors", ")", ",", "Oth", "=", "other", "parties", "and", "independents", "."], "labels": ["B-political party", "O", "B-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "B-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, politician, organization, location, political party, event, person, election and O.\nSentence: ALP = Australian Labor Party , L + NP = grouping of Liberal Party of Australia / National Party of Australia / Liberal National Party of Queensland / Country Liberal Party Coalition parties ( and predecessors ) , Oth = other parties and independents .", "prompt_labels": "ALP(B-political party) =(O) Australian(B-political party) Labor(I-political party) Party(I-political party) ,(O) L(O) +(O) NP(O) =(O) grouping(O) of(O) Liberal(B-political party) Party(I-political party) of(I-political party) Australia(I-political party) /(O) National(B-political party) Party(I-political party) of(I-political party) Australia(I-political party) /(O) Liberal(B-political party) National(I-political party) Party(I-political party) of(I-political party) Queensland(I-political party) /(O) Country(B-political party) Liberal(I-political party) Party(I-political party) Coalition(O) parties(O) ((O) and(O) predecessors(O) )(O) ,(O) Oth(O) =(O) other(O) parties(O) and(O) independents(O) .(O)"}, "label_list": ["country", "politician", "organization", "location", "political party", "event", "person", "election"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 37038, 11, 7471, 11, 3813, 11, 5054, 4717, 11, 1567, 11, 1732, 11, 6355, 323, 507, 627, 85664, 25, 8927, 47, 284, 13673, 15277, 8722, 1174, 445, 489, 44340, 284, 50284, 315, 31158, 8722, 315, 8494, 611, 5165, 8722, 315, 8494, 611, 31158, 5165, 8722, 315, 41306, 611, 14438, 31158, 8722, 36892, 9875, 320, 323, 62540, 883, 1174, 507, 339, 284, 1023, 9875, 323, 97022, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1060", "dataset": "mit-movie", "split": "dev", "prediction": "a(O) mediocre(B-average ratings) movie(O) with(O) a(O) computer(B-plot) plot(O) with(O) a(O) pg(B-rating) 13(I-rating) rating(O)", "instance": {"id": "1060", "words": ["a", "mediocre", "movie", "with", "a", "computer", "plot", "with", "a", "pg", "13", "rating"], "labels": ["O", "B-average ratings", "O", "O", "O", "B-plot", "O", "O", "O", "B-rating", "I-rating", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, actor, song, year, plot, average ratings, title, trailer, review, genre, character, director and O.\nSentence: a mediocre movie with a computer plot with a pg 13 rating", "prompt_labels": "a(O) mediocre(B-average ratings) movie(O) with(O) a(O) computer(B-plot) plot(O) with(O) a(O) pg(B-rating) 13(I-rating) rating(O)"}, "label_list": ["rating", "actor", "song", "year", "plot", "average ratings", "title", "trailer", "review", "genre", "character", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 12360, 11, 5609, 11, 1060, 11, 7234, 11, 5578, 18594, 11, 2316, 11, 19809, 11, 3477, 11, 17779, 11, 3752, 11, 7690, 323, 507, 627, 85664, 25, 264, 68480, 5818, 449, 264, 6500, 7234, 449, 264, 17953, 220, 1032, 10959, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "57", "dataset": "crossner_science", "split": "dev", "prediction": "He(O) also(O) included(O) perturbations(O) due(O) to(O) the(O) other(O) planets(O) ((O) principally(O) Jupiter(B-astronomical object) and(O) Venus(B-astronomical object) )(O) and(O) also(O) accounted(O) for(O) the(O) more(O) difficult(O) problem(O) of(O) the(O) non-spherical(O) nature(O) of(O) the(O) Earth(B-astronomical object) and(O) Moon(B-astronomical object).(O)", "instance": {"id": "57", "words": ["He", "also", "included", "perturbations", "due", "to", "the", "other", "planets", "(", "principally", "Jupiter", "and", "Venus", ")", "and", "also", "accounted", "for", "the", "more", "difficult", "problem", "of", "the", "non-spherical", "nature", "of", "the", "Earth", "and", "Moon", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-astronomical object", "O", "B-astronomical object", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-astronomical object", "O", "B-astronomical object", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: discipline, location, scientist, academic journal, event, university, chemical compound, chemical element, award, enzyme, theory, protein, country, organization, astronomical object, person and O.\nSentence: He also included perturbations due to the other planets ( principally Jupiter and Venus ) and also accounted for the more difficult problem of the non-spherical nature of the Earth and Moon .", "prompt_labels": "He(O) also(O) included(O) perturbations(O) due(O) to(O) the(O) other(O) planets(O) ((O) principally(O) Jupiter(B-astronomical object) and(O) Venus(B-astronomical object) )(O) and(O) also(O) accounted(O) for(O) the(O) more(O) difficult(O) problem(O) of(O) the(O) non-spherical(O) nature(O) of(O) the(O) Earth(B-astronomical object) and(O) Moon(B-astronomical object) .(O)"}, "label_list": ["discipline", "location", "scientist", "academic journal", "event", "university", "chemical compound", "chemical element", "award", "enzyme", "theory", "protein", "country", "organization", "astronomical object", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26434, 11, 3813, 11, 28568, 11, 14584, 8486, 11, 1567, 11, 12374, 11, 11742, 24549, 11, 11742, 2449, 11, 10292, 11, 49242, 11, 10334, 11, 13128, 11, 3224, 11, 7471, 11, 87283, 1665, 11, 1732, 323, 507, 627, 85664, 25, 1283, 1101, 5343, 18713, 9225, 811, 4245, 311, 279, 1023, 33975, 320, 92381, 50789, 323, 50076, 883, 323, 1101, 41853, 369, 279, 810, 5107, 3575, 315, 279, 2536, 1355, 45845, 7138, 315, 279, 9420, 323, 17781, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "510", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) leonardo(B-actor) dicaprio(I-actor) star(O) in(O) any(O) movies(O) based(O) on(O) a(O) play(B-genre) by(I-genre) shakespeare(I-genre)", "instance": {"id": "510", "words": ["did", "leonardo", "dicaprio", "star", "in", "any", "movies", "based", "on", "a", "play", "by", "shakespeare"], "labels": ["O", "B-actor", "I-actor", "O", "O", "O", "O", "B-plot", "I-plot", "I-plot", "I-plot", "I-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, genre, character, year, trailer, average ratings, review, title, actor, plot, director, song and O.\nSentence: did leonardo dicaprio star in any movies based on a play by shakespeare", "prompt_labels": "did(O) leonardo(B-actor) dicaprio(I-actor) star(O) in(O) any(O) movies(O) based(B-plot) on(I-plot) a(I-plot) play(I-plot) by(I-plot) shakespeare(I-plot)"}, "label_list": ["rating", "genre", "character", "year", "trailer", "average ratings", "review", "title", "actor", "plot", "director", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 17779, 11, 3752, 11, 1060, 11, 19809, 11, 5578, 18594, 11, 3477, 11, 2316, 11, 12360, 11, 7234, 11, 7690, 11, 5609, 323, 507, 627, 85664, 25, 1550, 514, 263, 21106, 21945, 391, 10599, 6917, 304, 904, 9698, 3196, 389, 264, 1514, 555, 559, 37971, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "124", "dataset": "mit-restaurant", "split": "dev", "prediction": "can(O) i(O) get(O) gluten(B-Amenity) free(I-Amenity) pizza(B-Dish) within(B-Location) 10(I-Location) miles(I-Location) of(I-Location) here(I-Location)", "instance": {"id": "124", "words": ["can", "i", "get", "gluten", "free", "pizza", "within", "10", "miles", "of", "here"], "labels": ["O", "O", "O", "B-Dish", "I-Dish", "I-Dish", "B-Location", "I-Location", "I-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Price, Restaurant Name, Cuisine, Dish, Location, Hours, Rating and O.\nSentence: can i get gluten free pizza within 10 miles of here", "prompt_labels": "can(O) i(O) get(O) gluten(B-Dish) free(I-Dish) pizza(I-Dish) within(B-Location) 10(I-Location) miles(I-Location) of(I-Location) here(I-Location)"}, "label_list": ["Amenity", "Price", "Restaurant Name", "Cuisine", "Dish", "Location", "Hours", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 8650, 11, 26568, 4076, 11, 81961, 11, 49268, 11, 10067, 11, 30192, 11, 19767, 323, 507, 627, 85664, 25, 649, 602, 636, 38455, 1949, 23317, 2949, 220, 605, 8931, 315, 1618, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "193", "dataset": "crossner_literature", "split": "dev", "prediction": "In(O) view(O) of(O) the(O) success(O) of(O) her(O) novels(B-literary genre),(O) particularly(O) Jane(B-book) Eyre(I-book),(O) Bront\u00eb(B-writer) was(O) persuaded(O) by(O) her(O) publisher(O) to(O) make(O) occasional(O) visits(O) to(O) London(B-location),(O) where(O) she(O) revealed(O) her(O) TRUE(O) identity(O) and(O) began(O) to(O) move(O) in(O) more(O) exalted(O) social(O) circles(O),(O) becoming(O) friends(O) with(O) Harriet(B-writer) Martineau(I-writer) and(O) Elizabeth(B-writer) Gaskell(I-writer),(O) and(O) acquainted(O) with(O) William(B-writer) Makepeace(I-writer) Thackeray(I-writer) and(O) G.H.(B-writer) Lewes(I-writer).(O)", "instance": {"id": "193", "words": ["In", "view", "of", "the", "success", "of", "her", "novels", ",", "particularly", "Jane", "Eyre", ",", "Bront\u00eb", "was", "persuaded", "by", "her", "publisher", "to", "make", "occasional", "visits", "to", "London", ",", "where", "she", "revealed", "her", "TRUE", "identity", "and", "began", "to", "move", "in", "more", "exalted", "social", "circles", ",", "becoming", "friends", "with", "Harriet", "Martineau", "and", "Elizabeth", "Gaskell", ",", "and", "acquainted", "with", "William", "Makepeace", "Thackeray", "and", "G.H.", "Lewes", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-literary genre", "O", "O", "B-book", "I-book", "O", "B-writer", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "O", "O", "O", "B-writer", "I-writer", "I-writer", "O", "B-writer", "I-writer", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, poem, event, country, book, writer, organization, literary genre, location, award, magazine and O.\nSentence: In view of the success of her novels , particularly Jane Eyre , Bront\u00eb was persuaded by her publisher to make occasional visits to London , where she revealed her TRUE identity and began to move in more exalted social circles , becoming friends with Harriet Martineau and Elizabeth Gaskell , and acquainted with William Makepeace Thackeray and G.H. Lewes .", "prompt_labels": "In(O) view(O) of(O) the(O) success(O) of(O) her(O) novels(B-literary genre) ,(O) particularly(O) Jane(B-book) Eyre(I-book) ,(O) Bront\u00eb(B-writer) was(O) persuaded(O) by(O) her(O) publisher(O) to(O) make(O) occasional(O) visits(O) to(O) London(B-location) ,(O) where(O) she(O) revealed(O) her(O) TRUE(O) identity(O) and(O) began(O) to(O) move(O) in(O) more(O) exalted(O) social(O) circles(O) ,(O) becoming(O) friends(O) with(O) Harriet(B-writer) Martineau(I-writer) and(O) Elizabeth(B-writer) Gaskell(I-writer) ,(O) and(O) acquainted(O) with(O) William(B-writer) Makepeace(I-writer) Thackeray(I-writer) and(O) G.H.(B-writer) Lewes(I-writer) .(O)"}, "label_list": ["person", "poem", "event", "country", "book", "writer", "organization", "literary genre", "location", "award", "magazine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 33894, 11, 1567, 11, 3224, 11, 2363, 11, 7061, 11, 7471, 11, 32465, 17779, 11, 3813, 11, 10292, 11, 14756, 323, 507, 627, 85664, 25, 763, 1684, 315, 279, 2450, 315, 1077, 32963, 1174, 8104, 22195, 44511, 265, 1174, 3320, 546, 12456, 574, 65101, 555, 1077, 21959, 311, 1304, 28961, 21728, 311, 7295, 1174, 1405, 1364, 10675, 1077, 8378, 9764, 323, 6137, 311, 3351, 304, 810, 506, 62334, 3674, 26432, 1174, 10671, 4885, 449, 5340, 65670, 8290, 483, 2933, 323, 21393, 480, 43858, 1174, 323, 73734, 449, 12656, 7557, 55225, 666, 9881, 352, 323, 480, 3924, 13, 17638, 288, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "12", "dataset": "mit-restaurant", "split": "dev", "prediction": "any(O) restaurants(O) open(B-Hours) right(I-Hours) now(I-Hours)", "instance": {"id": "12", "words": ["any", "restaurants", "open", "right", "now"], "labels": ["O", "O", "B-Hours", "I-Hours", "I-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Location, Dish, Rating, Amenity, Cuisine, Restaurant Name, Price and O.\nSentence: any restaurants open right now", "prompt_labels": "any(O) restaurants(O) open(B-Hours) right(I-Hours) now(I-Hours)"}, "label_list": ["Hours", "Location", "Dish", "Rating", "Amenity", "Cuisine", "Restaurant Name", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 10067, 11, 49268, 11, 19767, 11, 3383, 56685, 11, 81961, 11, 26568, 4076, 11, 8650, 323, 507, 627, 85664, 25, 904, 15926, 1825, 1314, 1457, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1417", "dataset": "mit-movie", "split": "dev", "prediction": "in(O) the(O) last(B-year) six(I-year) years(I-year) has(O) there(O) been(O) a(O) film(O) about(O) artists(B-plot) with(O) alexandre(B-actor) rockwell(I-actor) in(O) it(O)", "instance": {"id": "1417", "words": ["in", "the", "last", "six", "years", "has", "there", "been", "a", "film", "about", "artists", "with", "alexandre", "rockwell", "in", "it"], "labels": ["O", "O", "B-year", "I-year", "I-year", "O", "O", "O", "O", "O", "O", "B-plot", "O", "B-director", "I-director", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, actor, plot, trailer, director, rating, genre, character, song, title, average ratings, review and O.\nSentence: in the last six years has there been a film about artists with alexandre rockwell in it", "prompt_labels": "in(O) the(O) last(B-year) six(I-year) years(I-year) has(O) there(O) been(O) a(O) film(O) about(O) artists(B-plot) with(O) alexandre(B-director) rockwell(I-director) in(O) it(O)"}, "label_list": ["year", "actor", "plot", "trailer", "director", "rating", "genre", "character", "song", "title", "average ratings", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 12360, 11, 7234, 11, 19809, 11, 7690, 11, 10959, 11, 17779, 11, 3752, 11, 5609, 11, 2316, 11, 5578, 18594, 11, 3477, 323, 507, 627, 85664, 25, 304, 279, 1566, 4848, 1667, 706, 1070, 1027, 264, 4632, 922, 13820, 449, 57578, 80281, 7091, 9336, 304, 433, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "455", "dataset": "mit-movie", "split": "dev", "prediction": "whats(O) the(O) movie(O) with(O) the(O) trailer(B-trailer) that(O) has(O) a(O) teenage(B-plot) girl(I-plot) flashing(I-plot) a(I-plot) crowd(I-plot)", "instance": {"id": "455", "words": ["whats", "the", "movie", "with", "the", "trailer", "that", "has", "a", "teenage", "girl", "flashing", "a", "crowd"], "labels": ["O", "O", "O", "O", "O", "B-trailer", "O", "O", "O", "B-plot", "I-plot", "I-plot", "I-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, average ratings, character, title, actor, review, year, genre, plot, trailer, song, rating and O.\nSentence: whats the movie with the trailer that has a teenage girl flashing a crowd", "prompt_labels": "whats(O) the(O) movie(O) with(O) the(O) trailer(B-trailer) that(O) has(O) a(O) teenage(B-plot) girl(I-plot) flashing(I-plot) a(I-plot) crowd(I-plot)"}, "label_list": ["director", "average ratings", "character", "title", "actor", "review", "year", "genre", "plot", "trailer", "song", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 5578, 18594, 11, 3752, 11, 2316, 11, 12360, 11, 3477, 11, 1060, 11, 17779, 11, 7234, 11, 19809, 11, 5609, 11, 10959, 323, 507, 627, 85664, 25, 41209, 279, 5818, 449, 279, 19809, 430, 706, 264, 34268, 3828, 50857, 264, 13734, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "893", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) police(B-genre) film(O) had(O) a(O) main(O) character(O) called(O) popeye(B-character) doyle(I-character)", "instance": {"id": "893", "words": ["what", "police", "film", "had", "a", "main", "character", "called", "popeye", "doyle"], "labels": ["O", "B-genre", "O", "O", "O", "O", "O", "O", "B-character", "I-character"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, trailer, average ratings, song, actor, review, year, plot, title, director, rating, character and O.\nSentence: what police film had a main character called popeye doyle", "prompt_labels": "what(O) police(B-genre) film(O) had(O) a(O) main(O) character(O) called(O) popeye(B-character) doyle(I-character)"}, "label_list": ["genre", "trailer", "average ratings", "song", "actor", "review", "year", "plot", "title", "director", "rating", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 19809, 11, 5578, 18594, 11, 5609, 11, 12360, 11, 3477, 11, 1060, 11, 7234, 11, 2316, 11, 7690, 11, 10959, 11, 3752, 323, 507, 627, 85664, 25, 1148, 4379, 4632, 1047, 264, 1925, 3752, 2663, 64372, 9188, 656, 982, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "462", "dataset": "crossner_politics", "split": "dev", "prediction": "The(O) audiobook(O) version(O) features(O) Jim(B-actor) Parsons(I-actor),(O) Jesse(B-actor) Tyler(I-actor) Ferguson(I-actor),(O) Jeff(B-actor) Garlin(I-actor),(O) Ellie(B-actor) Kemper(I-actor),(O) John(B-actor) Lithgow(I-actor),(O) Jack(B-actor) McBrayer(I-actor),(O) and(O) RuPaul(B-actor).(O)", "instance": {"id": "462", "words": ["The", "audiobook", "version", "features", "Jim", "Parsons", ",", "Jesse", "Tyler", "Ferguson", ",", "Jeff", "Garlin", ",", "Ellie", "Kemper", ",", "John", "Lithgow", ",", "Jack", "McBrayer", ",", "and", "RuPaul", "."], "labels": ["O", "O", "O", "O", "B-person", "I-person", "O", "B-person", "I-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "O", "B-person", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, politician, person, political party, country, event, election, location and O.\nSentence: The audiobook version features Jim Parsons , Jesse Tyler Ferguson , Jeff Garlin , Ellie Kemper , John Lithgow , Jack McBrayer , and RuPaul .", "prompt_labels": "The(O) audiobook(O) version(O) features(O) Jim(B-person) Parsons(I-person) ,(O) Jesse(B-person) Tyler(I-person) Ferguson(I-person) ,(O) Jeff(B-person) Garlin(I-person) ,(O) Ellie(B-person) Kemper(I-person) ,(O) John(B-person) Lithgow(I-person) ,(O) Jack(B-person) McBrayer(I-person) ,(O) and(O) RuPaul(B-person) .(O)"}, "label_list": ["organization", "politician", "person", "political party", "country", "event", "election", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 37038, 11, 1732, 11, 5054, 4717, 11, 3224, 11, 1567, 11, 6355, 11, 3813, 323, 507, 627, 85664, 25, 578, 47468, 74428, 2373, 4519, 11641, 78344, 1174, 40271, 32320, 38476, 1174, 12149, 12471, 3817, 1174, 89361, 67066, 716, 1174, 3842, 41678, 37286, 1174, 7762, 4584, 6971, 1155, 1174, 323, 29014, 26368, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1459", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) is(O) there(O) a(O) great(B-Rating) steak(B-Dish) near(B-Location) here(I-Location) that(O) has(O) a(O) buffet(B-Amenity)", "instance": {"id": "1459", "words": ["where", "is", "there", "a", "great", "steak", "near", "here", "that", "has", "a", "buffet"], "labels": ["O", "O", "O", "O", "B-Rating", "B-Dish", "B-Location", "I-Location", "O", "O", "O", "B-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Cuisine, Restaurant Name, Dish, Location, Price, Rating, Hours and O.\nSentence: where is there a great steak near here that has a buffet", "prompt_labels": "where(O) is(O) there(O) a(O) great(B-Rating) steak(B-Dish) near(B-Location) here(I-Location) that(O) has(O) a(O) buffet(B-Amenity)"}, "label_list": ["Amenity", "Cuisine", "Restaurant Name", "Dish", "Location", "Price", "Rating", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 81961, 11, 26568, 4076, 11, 49268, 11, 10067, 11, 8650, 11, 19767, 11, 30192, 323, 507, 627, 85664, 25, 1405, 374, 1070, 264, 2294, 50059, 3221, 1618, 430, 706, 264, 61886, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "354", "dataset": "mit-restaurant", "split": "dev", "prediction": "find(O) italian(B-Cuisine) restaurants(O) in(O) atlanta(B-Location) ga(I-Location)", "instance": {"id": "354", "words": ["find", "italian", "restaurants", "in", "atlanta", "ga"], "labels": ["O", "B-Cuisine", "O", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Amenity, Dish, Price, Location, Cuisine, Rating, Restaurant Name and O.\nSentence: find italian restaurants in atlanta ga", "prompt_labels": "find(O) italian(B-Cuisine) restaurants(O) in(O) atlanta(B-Location) ga(I-Location)"}, "label_list": ["Hours", "Amenity", "Dish", "Price", "Location", "Cuisine", "Rating", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 3383, 56685, 11, 49268, 11, 8650, 11, 10067, 11, 81961, 11, 19767, 11, 26568, 4076, 323, 507, 627, 85664, 25, 1505, 29048, 15926, 304, 71554, 8424, 13819, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "438", "dataset": "crossner_science", "split": "dev", "prediction": "She(O) won(O) the(O) silver(O) medal(O) at(O) the(O) 2018(B-event) European(I-event) Championships(I-event).(O)", "instance": {"id": "438", "words": ["She", "won", "the", "silver", "medal", "at", "the", "2018", "European", "Championships", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: academic journal, protein, location, event, scientist, discipline, chemical element, theory, person, chemical compound, organization, country, astronomical object, award, enzyme, university and O.\nSentence: She won the silver medal at the 2018 European Championships .", "prompt_labels": "She(O) won(O) the(O) silver(O) medal(O) at(O) the(O) 2018(B-event) European(I-event) Championships(I-event) .(O)"}, "label_list": ["academic journal", "protein", "location", "event", "scientist", "discipline", "chemical element", "theory", "person", "chemical compound", "organization", "country", "astronomical object", "award", "enzyme", "university"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 14584, 8486, 11, 13128, 11, 3813, 11, 1567, 11, 28568, 11, 26434, 11, 11742, 2449, 11, 10334, 11, 1732, 11, 11742, 24549, 11, 7471, 11, 3224, 11, 87283, 1665, 11, 10292, 11, 49242, 11, 12374, 323, 507, 627, 85664, 25, 3005, 2834, 279, 15310, 37712, 520, 279, 220, 679, 23, 7665, 48854, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "729", "dataset": "mit-movie", "split": "dev", "prediction": "are(O) there(O) any(O) movies(O) based(O) on(O) british(B-plot) versions(I-plot)", "instance": {"id": "729", "words": ["are", "there", "any", "movies", "based", "on", "british", "versions"], "labels": ["O", "O", "O", "B-plot", "I-plot", "I-plot", "I-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, trailer, review, plot, genre, average ratings, year, actor, character, rating, director, song and O.\nSentence: are there any movies based on british versions", "prompt_labels": "are(O) there(O) any(O) movies(B-plot) based(I-plot) on(I-plot) british(I-plot) versions(I-plot)"}, "label_list": ["title", "trailer", "review", "plot", "genre", "average ratings", "year", "actor", "character", "rating", "director", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 19809, 11, 3477, 11, 7234, 11, 17779, 11, 5578, 18594, 11, 1060, 11, 12360, 11, 3752, 11, 10959, 11, 7690, 11, 5609, 323, 507, 627, 85664, 25, 527, 1070, 904, 9698, 3196, 389, 95027, 11028, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "9", "dataset": "crossner_music", "split": "dev", "prediction": "Ernest(B-musical artist) Jennings(I-musical artist) Ford(I-musical artist) ((O) February(O) 13(O),(O) 1919(O) -(O) October(O) 17(O),(O) 1991(O) )(O),(O) known(O) professionally(O) as(O) Tennessee(B-musical artist) Ernie(I-musical artist) Ford(I-musical artist),(O) was(O) an(O) American(O) singer(O) and(O) television(O) host(O) who(O) enjoyed(O) success(O) in(O) the(O) Country(B-music genre) music(I-music genre),(O) Pop(B-music genre) music(I-music genre),(O) and(O) Gospel(B-music genre) music(I-music genre) musical(O) genres(O).(O)", "instance": {"id": "9", "words": ["Ernest", "Jennings", "Ford", "(", "February", "13", ",", "1919", "-", "October", "17", ",", "1991", ")", ",", "known", "professionally", "as", "Tennessee", "Ernie", "Ford", ",", "was", "an", "American", "singer", "and", "television", "host", "who", "enjoyed", "success", "in", "the", "Country", "music", ",", "Pop", "music", ",", "and", "Gospel", "music", "musical", "genres", "."], "labels": ["B-musical artist", "I-musical artist", "I-musical artist", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-musical artist", "I-musical artist", "I-musical artist", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-music genre", "I-music genre", "O", "B-music genre", "I-music genre", "O", "O", "B-music genre", "I-music genre", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, location, organization, country, album, song, person, music genre, musical artist, event, award, musical instrument and O.\nSentence: Ernest Jennings Ford ( February 13 , 1919 - October 17 , 1991 ) , known professionally as Tennessee Ernie Ford , was an American singer and television host who enjoyed success in the Country music , Pop music , and Gospel music musical genres .", "prompt_labels": "Ernest(B-musical artist) Jennings(I-musical artist) Ford(I-musical artist) ((O) February(O) 13(O) ,(O) 1919(O) -(O) October(O) 17(O) ,(O) 1991(O) )(O) ,(O) known(O) professionally(O) as(O) Tennessee(B-musical artist) Ernie(I-musical artist) Ford(I-musical artist) ,(O) was(O) an(O) American(O) singer(O) and(O) television(O) host(O) who(O) enjoyed(O) success(O) in(O) the(O) Country(B-music genre) music(I-music genre) ,(O) Pop(B-music genre) music(I-music genre) ,(O) and(O) Gospel(B-music genre) music(I-music genre) musical(O) genres(O) .(O)"}, "label_list": ["band", "location", "organization", "country", "album", "song", "person", "music genre", "musical artist", "event", "award", "musical instrument"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7200, 11, 3813, 11, 7471, 11, 3224, 11, 8176, 11, 5609, 11, 1732, 11, 4731, 17779, 11, 18273, 10255, 11, 1567, 11, 10292, 11, 18273, 14473, 323, 507, 627, 85664, 25, 62023, 71290, 14337, 320, 7552, 220, 1032, 1174, 220, 7529, 24, 482, 6664, 220, 1114, 1174, 220, 2550, 16, 883, 1174, 3967, 46029, 439, 24097, 9939, 11044, 14337, 1174, 574, 459, 3778, 23597, 323, 12707, 3552, 889, 14333, 2450, 304, 279, 14438, 4731, 1174, 10466, 4731, 1174, 323, 44468, 4731, 18273, 36744, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "920", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) anywhere(O) thats(O) open(B-Hours) past(I-Hours) 1(I-Hours) am(I-Hours) with(O) exceptional(B-Price) prices(O)", "instance": {"id": "920", "words": ["is", "there", "anywhere", "thats", "open", "past", "1", "am", "with", "exceptional", "prices"], "labels": ["O", "O", "O", "O", "B-Hours", "I-Hours", "I-Hours", "I-Hours", "O", "B-Price", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Hours, Amenity, Cuisine, Price, Dish, Rating, Location and O.\nSentence: is there anywhere thats open past 1 am with exceptional prices", "prompt_labels": "is(O) there(O) anywhere(O) thats(O) open(B-Hours) past(I-Hours) 1(I-Hours) am(I-Hours) with(O) exceptional(B-Price) prices(O)"}, "label_list": ["Restaurant Name", "Hours", "Amenity", "Cuisine", "Price", "Dish", "Rating", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 30192, 11, 3383, 56685, 11, 81961, 11, 8650, 11, 49268, 11, 19767, 11, 10067, 323, 507, 627, 85664, 25, 374, 1070, 12660, 41136, 1825, 3347, 220, 16, 1097, 449, 25363, 7729, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "562", "dataset": "mit-movie", "split": "dev", "prediction": "get(O) a(O) yul(B-actor) brenner(I-actor) action(B-genre) flick(O)", "instance": {"id": "562", "words": ["get", "a", "yul", "brenner", "action", "flick"], "labels": ["O", "O", "B-actor", "I-actor", "B-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, actor, director, rating, review, title, song, genre, year, plot, trailer, average ratings and O.\nSentence: get a yul brenner action flick", "prompt_labels": "get(O) a(O) yul(B-actor) brenner(I-actor) action(B-genre) flick(O)"}, "label_list": ["character", "actor", "director", "rating", "review", "title", "song", "genre", "year", "plot", "trailer", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 12360, 11, 7690, 11, 10959, 11, 3477, 11, 2316, 11, 5609, 11, 17779, 11, 1060, 11, 7234, 11, 19809, 11, 5578, 18594, 323, 507, 627, 85664, 25, 636, 264, 379, 360, 293, 1466, 1215, 1957, 29447, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "116", "dataset": "crossner_ai", "split": "dev", "prediction": "LSTM(B-algorithm) was(O) proposed(O) in(O) 1997(O) by(O) Sepp(B-researcher) Hochreiter(I-researcher) and(O) J\u00fcrgen(B-researcher) Schmidhuber(I-researcher).(O)", "instance": {"id": "116", "words": ["LSTM", "was", "proposed", "in", "1997", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "."], "labels": ["B-algorithm", "O", "O", "O", "O", "O", "B-researcher", "I-researcher", "O", "B-researcher", "I-researcher", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, location, country, metric, conference, programming language, person, field, algorithm, researcher, product, organization, task and O.\nSentence: LSTM was proposed in 1997 by Sepp Hochreiter and J\u00fcrgen Schmidhuber .", "prompt_labels": "LSTM(B-algorithm) was(O) proposed(O) in(O) 1997(O) by(O) Sepp(B-researcher) Hochreiter(I-researcher) and(O) J\u00fcrgen(B-researcher) Schmidhuber(I-researcher) .(O)"}, "label_list": ["university", "location", "country", "metric", "conference", "programming language", "person", "field", "algorithm", "researcher", "product", "organization", "task"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12374, 11, 3813, 11, 3224, 11, 18767, 11, 10017, 11, 15840, 4221, 11, 1732, 11, 2115, 11, 12384, 11, 32185, 11, 2027, 11, 7471, 11, 3465, 323, 507, 627, 85664, 25, 86571, 574, 11223, 304, 220, 2550, 22, 555, 1369, 604, 68875, 265, 2058, 323, 622, 2448, 2026, 268, 5124, 16497, 27780, 261, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "630", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) want(O) a(O) taco(O) from(O) a(O) taco(B-Cuisine) truck(I-Cuisine)", "instance": {"id": "630", "words": ["i", "want", "a", "taco", "from", "a", "taco", "truck"], "labels": ["O", "O", "O", "B-Dish", "O", "O", "B-Cuisine", "I-Cuisine"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Price, Location, Hours, Restaurant Name, Dish, Cuisine, Rating and O.\nSentence: i want a taco from a taco truck", "prompt_labels": "i(O) want(O) a(O) taco(B-Dish) from(O) a(O) taco(B-Cuisine) truck(I-Cuisine)"}, "label_list": ["Amenity", "Price", "Location", "Hours", "Restaurant Name", "Dish", "Cuisine", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 8650, 11, 10067, 11, 30192, 11, 26568, 4076, 11, 49268, 11, 81961, 11, 19767, 323, 507, 627, 85664, 25, 602, 1390, 264, 91941, 505, 264, 91941, 11092, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1847", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) ok(B-average ratings) crime(B-genre) movie(O) was(O) directed(O) by(O) taylor(B-director) hackford(I-director)", "instance": {"id": "1847", "words": ["what", "ok", "crime", "movie", "was", "directed", "by", "taylor", "hackford"], "labels": ["O", "B-average ratings", "B-genre", "O", "O", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, rating, plot, title, review, average ratings, song, character, trailer, actor, director, year and O.\nSentence: what ok crime movie was directed by taylor hackford", "prompt_labels": "what(O) ok(B-average ratings) crime(B-genre) movie(O) was(O) directed(O) by(O) taylor(B-director) hackford(I-director)"}, "label_list": ["genre", "rating", "plot", "title", "review", "average ratings", "song", "character", "trailer", "actor", "director", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 10959, 11, 7234, 11, 2316, 11, 3477, 11, 5578, 18594, 11, 5609, 11, 3752, 11, 19809, 11, 12360, 11, 7690, 11, 1060, 323, 507, 627, 85664, 25, 1148, 5509, 9977, 5818, 574, 15910, 555, 259, 14350, 17524, 8350, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2032", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) a(O) really(B-average ratings) good(I-average ratings) r(B-rating) rated(O) sci(B-genre) fi(I-genre) movie(O)", "instance": {"id": "2032", "words": ["what", "is", "a", "really", "good", "r", "rated", "sci", "fi", "movie"], "labels": ["O", "O", "O", "B-average ratings", "I-average ratings", "B-rating", "O", "B-genre", "I-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, plot, year, review, director, genre, rating, song, average ratings, trailer, actor, title and O.\nSentence: what is a really good r rated sci fi movie", "prompt_labels": "what(O) is(O) a(O) really(B-average ratings) good(I-average ratings) r(B-rating) rated(O) sci(B-genre) fi(I-genre) movie(O)"}, "label_list": ["character", "plot", "year", "review", "director", "genre", "rating", "song", "average ratings", "trailer", "actor", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 7234, 11, 1060, 11, 3477, 11, 7690, 11, 17779, 11, 10959, 11, 5609, 11, 5578, 18594, 11, 19809, 11, 12360, 11, 2316, 323, 507, 627, 85664, 25, 1148, 374, 264, 2216, 1695, 436, 22359, 39074, 9314, 5818, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "995", "dataset": "mit-restaurant", "split": "dev", "prediction": "make(O) a(O) reservation(O) tonight(O) for(O) four(O) at(O) billies(B-Restaurant Name) steakhouse(I-Restaurant Name)", "instance": {"id": "995", "words": ["make", "a", "reservation", "tonight", "for", "four", "at", "billies", "steakhouse"], "labels": ["O", "O", "B-Amenity", "B-Hours", "B-Amenity", "I-Amenity", "O", "B-Restaurant Name", "I-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Location, Amenity, Price, Rating, Cuisine, Hours, Dish and O.\nSentence: make a reservation tonight for four at billies steakhouse", "prompt_labels": "make(O) a(O) reservation(B-Amenity) tonight(B-Hours) for(B-Amenity) four(I-Amenity) at(O) billies(B-Restaurant Name) steakhouse(I-Restaurant Name)"}, "label_list": ["Restaurant Name", "Location", "Amenity", "Price", "Rating", "Cuisine", "Hours", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 10067, 11, 3383, 56685, 11, 8650, 11, 19767, 11, 81961, 11, 30192, 11, 49268, 323, 507, 627, 85664, 25, 1304, 264, 28767, 18396, 369, 3116, 520, 4121, 552, 50059, 7830, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "48", "dataset": "crossner_literature", "split": "dev", "prediction": "He(O) spent(O) most(O) of(O) the(O) war(O) flying(O) between(O) the(O) U.S.(B-country) and(O) India(B-country),(O) via(O) the(O) Azores(O) and(O) North(B-location) Africa(I-location) or(O) South(B-location) America(I-location),(O) Nigeria(B-country),(O) and(O) Central(B-country) Africa(I-country).(O)", "instance": {"id": "48", "words": ["He", "spent", "most", "of", "the", "war", "flying", "between", "the", "U.S.", "and", "India", ",", "via", "the", "Azores", "and", "North", "Africa", "or", "South", "America", ",", "Nigeria", ",", "and", "Central", "Africa", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-country", "O", "B-country", "O", "O", "O", "B-location", "O", "B-location", "I-location", "O", "B-location", "I-location", "O", "B-country", "O", "O", "B-location", "I-location", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, award, poem, location, magazine, book, writer, country, person, event, organization and O.\nSentence: He spent most of the war flying between the U.S. and India , via the Azores and North Africa or South America , Nigeria , and Central Africa .", "prompt_labels": "He(O) spent(O) most(O) of(O) the(O) war(O) flying(O) between(O) the(O) U.S.(B-country) and(O) India(B-country) ,(O) via(O) the(O) Azores(B-location) and(O) North(B-location) Africa(I-location) or(O) South(B-location) America(I-location) ,(O) Nigeria(B-country) ,(O) and(O) Central(B-location) Africa(I-location) .(O)"}, "label_list": ["literary genre", "award", "poem", "location", "magazine", "book", "writer", "country", "person", "event", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 32465, 17779, 11, 10292, 11, 33894, 11, 3813, 11, 14756, 11, 2363, 11, 7061, 11, 3224, 11, 1732, 11, 1567, 11, 7471, 323, 507, 627, 85664, 25, 1283, 7543, 1455, 315, 279, 4208, 16706, 1990, 279, 549, 815, 13, 323, 6890, 1174, 4669, 279, 15757, 4692, 323, 4892, 10384, 477, 4987, 5270, 1174, 29258, 1174, 323, 10913, 10384, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "85", "dataset": "crossner_politics", "split": "dev", "prediction": "She(O) was(O) a(O) candidate(O) in(O) the(O) 1984(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election),(O) 1992(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ((O) 339(O) votes(O) )(O),(O) 1996(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election),(O) and(O) 2004(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election).(O)", "instance": {"id": "85", "words": ["She", "was", "a", "candidate", "in", "the", "1984", "United", "States", "presidential", "election", ",", "1992", "United", "States", "presidential", "election", "(", "339", "votes", ")", ",", "1996", "United", "States", "presidential", "election", ",", "and", "2004", "United", "States", "presidential", "election", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, person, country, politician, organization, event, political party, election and O.\nSentence: She was a candidate in the 1984 United States presidential election , 1992 United States presidential election ( 339 votes ) , 1996 United States presidential election , and 2004 United States presidential election .", "prompt_labels": "She(O) was(O) a(O) candidate(O) in(O) the(O) 1984(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ,(O) 1992(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ((O) 339(O) votes(O) )(O) ,(O) 1996(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ,(O) and(O) 2004(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) .(O)"}, "label_list": ["location", "person", "country", "politician", "organization", "event", "political party", "election"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 1732, 11, 3224, 11, 37038, 11, 7471, 11, 1567, 11, 5054, 4717, 11, 6355, 323, 507, 627, 85664, 25, 3005, 574, 264, 9322, 304, 279, 220, 3753, 19, 3723, 4273, 13621, 6355, 1174, 220, 2550, 17, 3723, 4273, 13621, 6355, 320, 220, 17887, 12973, 883, 1174, 220, 2550, 21, 3723, 4273, 13621, 6355, 1174, 323, 220, 1049, 19, 3723, 4273, 13621, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "343", "dataset": "crossner_science", "split": "dev", "prediction": "Ethylmercury(B-chemical compound) is(O) a(O) breakdown(O) product(O) of(O) the(O) antibacteriological(O) agent(O) ethylmercurithiosalicylate(B-chemical compound),(O) which(O) has(O) been(O) used(O) as(O) a(O) topical(O) antiseptic(O) and(O) a(O) vaccine(O) preservative(O) ((O) further(O) discussed(O) under(O) Thiomersal(B-chemical compound) below(O) )(O).(O)", "instance": {"id": "343", "words": ["Ethylmercury", "is", "a", "breakdown", "product", "of", "the", "antibacteriological", "agent", "ethylmercurithiosalicylate", ",", "which", "has", "been", "used", "as", "a", "topical", "antiseptic", "and", "a", "vaccine", "preservative", "(", "further", "discussed", "under", "Thiomersal", "below", ")", "."], "labels": ["B-chemical compound", "O", "O", "O", "O", "O", "O", "O", "O", "B-chemical compound", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-chemical compound", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, discipline, theory, enzyme, event, organization, academic journal, astronomical object, scientist, person, chemical compound, chemical element, location, university, protein, award and O.\nSentence: Ethylmercury is a breakdown product of the antibacteriological agent ethylmercurithiosalicylate , which has been used as a topical antiseptic and a vaccine preservative ( further discussed under Thiomersal below ) .", "prompt_labels": "Ethylmercury(B-chemical compound) is(O) a(O) breakdown(O) product(O) of(O) the(O) antibacteriological(O) agent(O) ethylmercurithiosalicylate(B-chemical compound) ,(O) which(O) has(O) been(O) used(O) as(O) a(O) topical(O) antiseptic(O) and(O) a(O) vaccine(O) preservative(O) ((O) further(O) discussed(O) under(O) Thiomersal(B-chemical compound) below(O) )(O) .(O)"}, "label_list": ["country", "discipline", "theory", "enzyme", "event", "organization", "academic journal", "astronomical object", "scientist", "person", "chemical compound", "chemical element", "location", "university", "protein", "award"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 26434, 11, 10334, 11, 49242, 11, 1567, 11, 7471, 11, 14584, 8486, 11, 87283, 1665, 11, 28568, 11, 1732, 11, 11742, 24549, 11, 11742, 2449, 11, 3813, 11, 12374, 11, 13128, 11, 10292, 323, 507, 627, 85664, 25, 14693, 4010, 1195, 26533, 374, 264, 31085, 2027, 315, 279, 21196, 2540, 41314, 8479, 8537, 4010, 1195, 2407, 411, 3614, 278, 2912, 5185, 1174, 902, 706, 1027, 1511, 439, 264, 66376, 3276, 1082, 27330, 323, 264, 25474, 1685, 54268, 320, 4726, 14407, 1234, 666, 34695, 388, 278, 3770, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "574", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) need(O) a(O) family(B-Amenity) friendly(I-Amenity) place(O) to(O) eat(O) tonight(B-Hours)", "instance": {"id": "574", "words": ["i", "need", "a", "family", "friendly", "place", "to", "eat", "tonight"], "labels": ["O", "O", "O", "B-Amenity", "I-Amenity", "O", "O", "O", "B-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Dish, Restaurant Name, Price, Rating, Amenity, Cuisine, Hours and O.\nSentence: i need a family friendly place to eat tonight", "prompt_labels": "i(O) need(O) a(O) family(B-Amenity) friendly(I-Amenity) place(O) to(O) eat(O) tonight(B-Hours)"}, "label_list": ["Location", "Dish", "Restaurant Name", "Price", "Rating", "Amenity", "Cuisine", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 49268, 11, 26568, 4076, 11, 8650, 11, 19767, 11, 3383, 56685, 11, 81961, 11, 30192, 323, 507, 627, 85664, 25, 602, 1205, 264, 3070, 11919, 2035, 311, 8343, 18396, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1896", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) are(O) some(O) r(B-rating) rated(O) western(B-genre) movies(O) that(O) received(O) ten(B-average ratings) stars(I-average ratings)", "instance": {"id": "1896", "words": ["what", "are", "some", "r", "rated", "western", "movies", "that", "received", "ten", "stars"], "labels": ["O", "O", "O", "B-rating", "O", "B-genre", "O", "O", "O", "B-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, character, director, actor, year, song, plot, trailer, title, review, rating, genre and O.\nSentence: what are some r rated western movies that received ten stars", "prompt_labels": "what(O) are(O) some(O) r(B-rating) rated(O) western(B-genre) movies(O) that(O) received(O) ten(B-average ratings) stars(I-average ratings)"}, "label_list": ["average ratings", "character", "director", "actor", "year", "song", "plot", "trailer", "title", "review", "rating", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 3752, 11, 7690, 11, 12360, 11, 1060, 11, 5609, 11, 7234, 11, 19809, 11, 2316, 11, 3477, 11, 10959, 11, 17779, 323, 507, 627, 85664, 25, 1148, 527, 1063, 436, 22359, 19001, 9698, 430, 4036, 5899, 9958, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "382", "dataset": "crossner_literature", "split": "dev", "prediction": "In(O) a(O) 2006(O) interview(O) with(O) Tatler(B-magazine) magazine(O),(O) Rowling(B-writer) noted(O) that(O),(O) like(O) Graham(B-writer) Greene(I-writer),(O) my(O) faith(O) is(O) sometimes(O) about(O) if(O) my(O) faith(O) will(O) return(O).(O)", "instance": {"id": "382", "words": ["In", "a", "2006", "interview", "with", "Tatler", "magazine", ",", "Rowling", "noted", "that", ",", "like", "Graham", "Greene", ",", "my", "faith", "is", "sometimes", "about", "if", "my", "faith", "will", "return", "."], "labels": ["O", "O", "O", "O", "O", "B-magazine", "I-magazine", "O", "B-writer", "O", "O", "O", "O", "B-writer", "I-writer", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, event, writer, location, literary genre, poem, organization, person, book, award, country and O.\nSentence: In a 2006 interview with Tatler magazine , Rowling noted that , like Graham Greene , my faith is sometimes about if my faith will return .", "prompt_labels": "In(O) a(O) 2006(O) interview(O) with(O) Tatler(B-magazine) magazine(I-magazine) ,(O) Rowling(B-writer) noted(O) that(O) ,(O) like(O) Graham(B-writer) Greene(I-writer) ,(O) my(O) faith(O) is(O) sometimes(O) about(O) if(O) my(O) faith(O) will(O) return(O) .(O)"}, "label_list": ["magazine", "event", "writer", "location", "literary genre", "poem", "organization", "person", "book", "award", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 14756, 11, 1567, 11, 7061, 11, 3813, 11, 32465, 17779, 11, 33894, 11, 7471, 11, 1732, 11, 2363, 11, 10292, 11, 3224, 323, 507, 627, 85664, 25, 763, 264, 220, 1049, 21, 7274, 449, 63567, 1565, 14756, 1174, 96607, 10555, 430, 1174, 1093, 26181, 59174, 1174, 856, 10082, 374, 7170, 922, 422, 856, 10082, 690, 471, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "280", "dataset": "crossner_music", "split": "dev", "prediction": "Larner(B-musical artist) had(O) previously(O) played(O) koto(O) with(O) John(B-musical artist) Fahey(I-musical artist),(O) Jim(B-musical artist) O(I-musical artist) 'Rourke(I-musical artist),(O) and(O) members(O) of(O) indie(B-music genre) rock(I-music genre) groups(O) including(O) Camper(B-band) Van(I-band) Beethoven(I-band),(O) Deerhoof(B-band),(O) Jackie(B-band) O(I-band) Motherfucker(I-band),(O) and(O) Mr.(B-band) Bungle(I-band).(O)", "instance": {"id": "280", "words": ["Larner", "had", "previously", "played", "koto", "with", "John", "Fahey", ",", "Jim", "O", "'Rourke", ",", "and", "members", "of", "indie", "rock", "groups", "including", "Camper", "Van", "Beethoven", ",", "Deerhoof", ",", "Jackie", "O", "Motherfucker", ",", "and", "Mr.", "Bungle", "."], "labels": ["B-musical artist", "O", "O", "O", "B-musical instrument", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "I-musical artist", "O", "O", "O", "O", "O", "B-music genre", "O", "O", "B-band", "I-band", "I-band", "O", "B-band", "O", "B-band", "I-band", "I-band", "O", "O", "B-band", "I-band", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, location, album, song, band, event, award, musical artist, person, musical instrument, music genre, country and O.\nSentence: Larner had previously played koto with John Fahey , Jim O 'Rourke , and members of indie rock groups including Camper Van Beethoven , Deerhoof , Jackie O Motherfucker , and Mr. Bungle .", "prompt_labels": "Larner(B-musical artist) had(O) previously(O) played(O) koto(B-musical instrument) with(O) John(B-musical artist) Fahey(I-musical artist) ,(O) Jim(B-musical artist) O(I-musical artist) 'Rourke(I-musical artist) ,(O) and(O) members(O) of(O) indie(O) rock(B-music genre) groups(O) including(O) Camper(B-band) Van(I-band) Beethoven(I-band) ,(O) Deerhoof(B-band) ,(O) Jackie(B-band) O(I-band) Motherfucker(I-band) ,(O) and(O) Mr.(B-band) Bungle(I-band) .(O)"}, "label_list": ["organization", "location", "album", "song", "band", "event", "award", "musical artist", "person", "musical instrument", "music genre", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 3813, 11, 8176, 11, 5609, 11, 7200, 11, 1567, 11, 10292, 11, 18273, 10255, 11, 1732, 11, 18273, 14473, 11, 4731, 17779, 11, 3224, 323, 507, 627, 85664, 25, 32404, 1215, 1047, 8767, 6476, 597, 2117, 449, 3842, 18145, 36661, 1174, 11641, 507, 364, 49, 85534, 1174, 323, 3697, 315, 44578, 7091, 5315, 2737, 8215, 716, 13000, 2893, 93622, 1174, 64191, 6292, 1073, 1174, 51965, 507, 21720, 69, 25369, 1174, 323, 4491, 13, 426, 29747, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1438", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) is(O) the(O) nearest(B-Location) place(I-Location) i(O) can(O) get(O) a(O) smoothie(B-Dish)", "instance": {"id": "1438", "words": ["where", "is", "the", "nearest", "place", "i", "can", "get", "a", "smoothie"], "labels": ["O", "O", "O", "B-Location", "O", "O", "O", "O", "O", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Location, Cuisine, Restaurant Name, Dish, Amenity, Rating, Hours and O.\nSentence: where is the nearest place i can get a smoothie", "prompt_labels": "where(O) is(O) the(O) nearest(B-Location) place(O) i(O) can(O) get(O) a(O) smoothie(B-Dish)"}, "label_list": ["Price", "Location", "Cuisine", "Restaurant Name", "Dish", "Amenity", "Rating", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 10067, 11, 81961, 11, 26568, 4076, 11, 49268, 11, 3383, 56685, 11, 19767, 11, 30192, 323, 507, 627, 85664, 25, 1405, 374, 279, 24379, 2035, 602, 649, 636, 264, 11113, 648, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1472", "dataset": "mit-restaurant", "split": "dev", "prediction": "wheres(O) the(O) italian(B-Cuisine) restaurant(O) downtown(B-Location) thats(O) open(B-Hours) until(I-Hours) midnight(I-Hours)", "instance": {"id": "1472", "words": ["wheres", "the", "italian", "restaurant", "downtown", "thats", "open", "until", "midnight"], "labels": ["O", "O", "B-Cuisine", "O", "B-Location", "O", "B-Hours", "I-Hours", "I-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Cuisine, Location, Amenity, Rating, Dish, Price, Restaurant Name and O.\nSentence: wheres the italian restaurant downtown thats open until midnight", "prompt_labels": "wheres(O) the(O) italian(B-Cuisine) restaurant(O) downtown(B-Location) thats(O) open(B-Hours) until(I-Hours) midnight(I-Hours)"}, "label_list": ["Hours", "Cuisine", "Location", "Amenity", "Rating", "Dish", "Price", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 81961, 11, 10067, 11, 3383, 56685, 11, 19767, 11, 49268, 11, 8650, 11, 26568, 4076, 323, 507, 627, 85664, 25, 421, 13213, 279, 29048, 10960, 19441, 41136, 1825, 3156, 33433, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "251", "dataset": "crossner_ai", "split": "dev", "prediction": "Roger(B-researcher) Schank(I-researcher),(O) 1969(O),(O) A(O) conceptual(O) dependency(O) parser(O) for(O) natural(B-field) language(I-field) Proceedings(O) of(O) the(O) 1969(B-conference) on(I-conference) Computational(I-conference) linguistics(I-conference),(O) S\u00e5ng-S\u00e4by(B-location),(O) Sweden(B-country),(O) pages(O) 1-3(O) This(O) model(O),(O) partially(O) influenced(O) by(O) the(O) work(O) of(O) Sydney(B-researcher) Lamb(I-researcher),(O) was(O) extensively(O) used(O) by(O) Schank(B-researcher)'s(O) students(O) at(O) Yale(B-university) University(I-university),(O) such(O) as(O) Robert(B-researcher) Wilensky(I-researcher),(O) Wendy(B-researcher) Lehnert(I-researcher),(O) and(O) Janet(B-researcher) Kolodner(I-researcher).(O)", "instance": {"id": "251", "words": ["Roger", "Schank", ",", "1969", ",", "A", "conceptual", "dependency", "parser", "for", "natural", "language", "Proceedings", "of", "the", "1969", "on", "Computational", "linguistics", ",", "S\u00e5ng-S\u00e4by", ",", "Sweden", ",", "pages", "1-3", "This", "model", ",", "partially", "influenced", "by", "the", "work", "of", "Sydney", "Lamb", ",", "was", "extensively", "used", "by", "Schank", "'s", "students", "at", "Yale", "University", ",", "such", "as", "Robert", "Wilensky", ",", "Wendy", "Lehnert", ",", "and", "Janet", "Kolodner", "."], "labels": ["B-researcher", "I-researcher", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-conference", "I-conference", "I-conference", "I-conference", "I-conference", "I-conference", "I-conference", "O", "B-location", "O", "B-country", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-researcher", "I-researcher", "O", "O", "O", "O", "O", "B-researcher", "O", "O", "O", "B-university", "I-university", "O", "O", "O", "B-researcher", "I-researcher", "O", "B-researcher", "I-researcher", "O", "O", "B-researcher", "I-researcher", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, conference, researcher, product, location, field, algorithm, country, metric, person, organization, programming language, task and O.\nSentence: Roger Schank , 1969 , A conceptual dependency parser for natural language Proceedings of the 1969 on Computational linguistics , S\u00e5ng-S\u00e4by , Sweden , pages 1-3 This model , partially influenced by the work of Sydney Lamb , was extensively used by Schank 's students at Yale University , such as Robert Wilensky , Wendy Lehnert , and Janet Kolodner .", "prompt_labels": "Roger(B-researcher) Schank(I-researcher) ,(O) 1969(O) ,(O) A(O) conceptual(O) dependency(O) parser(O) for(O) natural(O) language(O) Proceedings(B-conference) of(I-conference) the(I-conference) 1969(I-conference) on(I-conference) Computational(I-conference) linguistics(I-conference) ,(O) S\u00e5ng-S\u00e4by(B-location) ,(O) Sweden(B-country) ,(O) pages(O) 1-3(O) This(O) model(O) ,(O) partially(O) influenced(O) by(O) the(O) work(O) of(O) Sydney(B-researcher) Lamb(I-researcher) ,(O) was(O) extensively(O) used(O) by(O) Schank(B-researcher) 's(O) students(O) at(O) Yale(B-university) University(I-university) ,(O) such(O) as(O) Robert(B-researcher) Wilensky(I-researcher) ,(O) Wendy(B-researcher) Lehnert(I-researcher) ,(O) and(O) Janet(B-researcher) Kolodner(I-researcher) .(O)"}, "label_list": ["university", "conference", "researcher", "product", "location", "field", "algorithm", "country", "metric", "person", "organization", "programming language", "task"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12374, 11, 10017, 11, 32185, 11, 2027, 11, 3813, 11, 2115, 11, 12384, 11, 3224, 11, 18767, 11, 1732, 11, 7471, 11, 15840, 4221, 11, 3465, 323, 507, 627, 85664, 25, 29607, 5124, 1201, 1174, 220, 5162, 24, 1174, 362, 44901, 24999, 6871, 369, 5933, 4221, 55227, 315, 279, 220, 5162, 24, 389, 93028, 39603, 5706, 1174, 328, 3870, 983, 6354, 2357, 1729, 1174, 24067, 1174, 6959, 220, 16, 12, 18, 1115, 1646, 1174, 26310, 28160, 555, 279, 990, 315, 21972, 32402, 1174, 574, 42817, 1511, 555, 5124, 1201, 364, 82, 4236, 520, 44552, 3907, 1174, 1778, 439, 8563, 10785, 729, 8050, 1174, 55676, 2009, 25105, 531, 1174, 323, 54765, 46615, 347, 1215, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "331", "dataset": "mit-restaurant", "split": "dev", "prediction": "feel(O) like(O) having(O) a(O) heart(B-Dish) attack(I-Dish) heart(I-Dish) attack(I-Dish) grill(I-Dish)", "instance": {"id": "331", "words": ["feel", "like", "having", "a", "heart", "attack", "heart", "attack", "grill"], "labels": ["O", "O", "O", "O", "O", "O", "B-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Amenity, Dish, Rating, Location, Price, Hours, Restaurant Name and O.\nSentence: feel like having a heart attack heart attack grill", "prompt_labels": "feel(O) like(O) having(O) a(O) heart(O) attack(O) heart(B-Restaurant Name) attack(I-Restaurant Name) grill(I-Restaurant Name)"}, "label_list": ["Cuisine", "Amenity", "Dish", "Rating", "Location", "Price", "Hours", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 3383, 56685, 11, 49268, 11, 19767, 11, 10067, 11, 8650, 11, 30192, 11, 26568, 4076, 323, 507, 627, 85664, 25, 2733, 1093, 3515, 264, 4851, 3440, 4851, 3440, 40158, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "361", "dataset": "crossner_music", "split": "dev", "prediction": "Featuring(O) West(B-music genre) Coast(I-music genre) hip(I-music genre) hop(I-music genre),(O) G-funk(B-music genre) and(O) horrorcore(B-music genre) musical(O) styles(O),(O) the(O) majority(O) of(O) The(B-album) Slim(I-album) Shady(I-album) LP(I-album) nowiki(O) /(O) '(O) s(O) lyrical(O) content(O) is(O) written(O) from(O) the(O) perspective(O) of(O) Eminem(B-musical artist)'s(O) alter(O) ego(O) Slim(O) Shady(O),(O) whom(O) he(O) created(O) on(O) the(O) Slim(O) Shady(O) EP(O) ((O) 1997(O) )(O).(O)", "instance": {"id": "361", "words": ["Featuring", "West", "Coast", "hip", "hop", ",", "G-funk", "and", "horrorcore", "musical", "styles", ",", "the", "majority", "of", "The", "Slim", "Shady", "LP", "nowiki", "/", "'", "s", "lyrical", "content", "is", "written", "from", "the", "perspective", "of", "Eminem", "'s", "alter", "ego", "Slim", "Shady", ",", "whom", "he", "created", "on", "the", "Slim", "Shady", "EP", "(", "1997", ")", "."], "labels": ["O", "B-music genre", "I-music genre", "I-music genre", "I-music genre", "O", "B-music genre", "O", "B-music genre", "O", "O", "O", "O", "O", "O", "B-album", "I-album", "I-album", "I-album", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-musical artist", "O", "O", "O", "B-musical artist", "I-musical artist", "O", "O", "O", "O", "O", "O", "B-album", "I-album", "I-album", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, album, award, musical instrument, organization, country, location, song, person, musical artist, event, band and O.\nSentence: Featuring West Coast hip hop , G-funk and horrorcore musical styles , the majority of The Slim Shady LP nowiki / ' s lyrical content is written from the perspective of Eminem 's alter ego Slim Shady , whom he created on the Slim Shady EP ( 1997 ) .", "prompt_labels": "Featuring(O) West(B-music genre) Coast(I-music genre) hip(I-music genre) hop(I-music genre) ,(O) G-funk(B-music genre) and(O) horrorcore(B-music genre) musical(O) styles(O) ,(O) the(O) majority(O) of(O) The(B-album) Slim(I-album) Shady(I-album) LP(I-album) nowiki(O) /(O) '(O) s(O) lyrical(O) content(O) is(O) written(O) from(O) the(O) perspective(O) of(O) Eminem(B-musical artist) 's(O) alter(O) ego(O) Slim(B-musical artist) Shady(I-musical artist) ,(O) whom(O) he(O) created(O) on(O) the(O) Slim(B-album) Shady(I-album) EP(I-album) ((O) 1997(O) )(O) .(O)"}, "label_list": ["music genre", "album", "award", "musical instrument", "organization", "country", "location", "song", "person", "musical artist", "event", "band"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 4731, 17779, 11, 8176, 11, 10292, 11, 18273, 14473, 11, 7471, 11, 3224, 11, 3813, 11, 5609, 11, 1732, 11, 18273, 10255, 11, 1567, 11, 7200, 323, 507, 627, 85664, 25, 52331, 4410, 16377, 18638, 7598, 1174, 480, 2269, 3200, 323, 22169, 2202, 18273, 9404, 1174, 279, 8857, 315, 578, 45491, 1443, 7759, 17540, 1457, 7723, 611, 364, 274, 86337, 950, 2262, 374, 5439, 505, 279, 13356, 315, 81500, 336, 364, 82, 11857, 37374, 45491, 1443, 7759, 1174, 8884, 568, 3549, 389, 279, 45491, 1443, 7759, 19613, 320, 220, 2550, 22, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "357", "dataset": "crossner_music", "split": "dev", "prediction": "Buckingham(B-musical artist)'s(O) Go(B-song) Your(I-song) Own(I-song) Way(I-song) was(O) the(O) lead(O) single(O),(O) soaring(O) into(O) the(O) US(B-country) Top(O) Ten(O) ;(O) also(O) on(O) the(O) album(O) were(O) Buckingham(B-song)'s(I-song) Second(I-song) Hand(I-song) News(I-song) and(O) Never(B-song) Going(I-song) Back(I-song) Again(I-song).(O)", "instance": {"id": "357", "words": ["Buckingham", "'s", "Go", "Your", "Own", "Way", "was", "the", "lead", "single", ",", "soaring", "into", "the", "US", "Top", "Ten", ";", "also", "on", "the", "album", "were", "Buckingham", "'s", "Second", "Hand", "News", "and", "Never", "Going", "Back", "Again", "."], "labels": ["B-musical artist", "O", "B-song", "I-song", "I-song", "I-song", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-musical artist", "O", "B-song", "I-song", "I-song", "O", "B-song", "I-song", "I-song", "I-song", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, music genre, location, award, musical artist, song, country, musical instrument, band, album, person, organization and O.\nSentence: Buckingham 's Go Your Own Way was the lead single , soaring into the US Top Ten ; also on the album were Buckingham 's Second Hand News and Never Going Back Again .", "prompt_labels": "Buckingham(B-musical artist) 's(O) Go(B-song) Your(I-song) Own(I-song) Way(I-song) was(O) the(O) lead(O) single(O) ,(O) soaring(O) into(O) the(O) US(O) Top(O) Ten(O) ;(O) also(O) on(O) the(O) album(O) were(O) Buckingham(B-musical artist) 's(O) Second(B-song) Hand(I-song) News(I-song) and(O) Never(B-song) Going(I-song) Back(I-song) Again(I-song) .(O)"}, "label_list": ["event", "music genre", "location", "award", "musical artist", "song", "country", "musical instrument", "band", "album", "person", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 4731, 17779, 11, 3813, 11, 10292, 11, 18273, 10255, 11, 5609, 11, 3224, 11, 18273, 14473, 11, 7200, 11, 8176, 11, 1732, 11, 7471, 323, 507, 627, 85664, 25, 96011, 364, 82, 6122, 4718, 21189, 12424, 574, 279, 3063, 3254, 1174, 69997, 1139, 279, 2326, 7054, 18165, 2652, 1101, 389, 279, 8176, 1051, 96011, 364, 82, 10657, 8704, 5513, 323, 15037, 35971, 6984, 14077, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1642", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) a(O) six(B-average ratings) stars(I-average ratings) and(I-average ratings) above(I-average ratings) rating(O) romantic(B-genre) comedy(I-genre) starring(O) vivien(B-actor) leigh(I-actor)", "instance": {"id": "1642", "words": ["list", "a", "six", "stars", "and", "above", "rating", "romantic", "comedy", "starring", "vivien", "leigh"], "labels": ["O", "O", "B-average ratings", "I-average ratings", "I-average ratings", "I-average ratings", "O", "B-genre", "I-genre", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, character, song, actor, average ratings, year, rating, trailer, genre, title, review, director and O.\nSentence: list a six stars and above rating romantic comedy starring vivien leigh", "prompt_labels": "list(O) a(O) six(B-average ratings) stars(I-average ratings) and(I-average ratings) above(I-average ratings) rating(O) romantic(B-genre) comedy(I-genre) starring(O) vivien(B-actor) leigh(I-actor)"}, "label_list": ["plot", "character", "song", "actor", "average ratings", "year", "rating", "trailer", "genre", "title", "review", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 3752, 11, 5609, 11, 12360, 11, 5578, 18594, 11, 1060, 11, 10959, 11, 19809, 11, 17779, 11, 2316, 11, 3477, 11, 7690, 323, 507, 627, 85664, 25, 1160, 264, 4848, 9958, 323, 3485, 10959, 24364, 23160, 40500, 18434, 3675, 514, 1108, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1106", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) do(O) you(O) know(O) about(O) restaurants(O) that(O) have(O) impressive(B-Amenity) wine(I-Amenity) lists(I-Amenity)", "instance": {"id": "1106", "words": ["what", "do", "you", "know", "about", "restaurants", "that", "have", "impressive", "wine", "lists"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-Amenity", "I-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Location, Price, Rating, Restaurant Name, Cuisine, Dish, Hours and O.\nSentence: what do you know about restaurants that have impressive wine lists", "prompt_labels": "what(O) do(O) you(O) know(O) about(O) restaurants(O) that(O) have(O) impressive(B-Amenity) wine(I-Amenity) lists(I-Amenity)"}, "label_list": ["Amenity", "Location", "Price", "Rating", "Restaurant Name", "Cuisine", "Dish", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 10067, 11, 8650, 11, 19767, 11, 26568, 4076, 11, 81961, 11, 49268, 11, 30192, 323, 507, 627, 85664, 25, 1148, 656, 499, 1440, 922, 15926, 430, 617, 16358, 13378, 11725, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1258", "dataset": "mit-movie", "split": "dev", "prediction": "has(O) charlton(B-actor) heston(I-actor) ever(O) been(O) a(O) voice(O) in(O) an(O) animated(B-genre) movie(O)", "instance": {"id": "1258", "words": ["has", "charlton", "heston", "ever", "been", "a", "voice", "in", "an", "animated", "movie"], "labels": ["O", "B-actor", "I-actor", "O", "O", "O", "O", "O", "O", "B-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, trailer, title, year, plot, genre, song, actor, rating, character, director, average ratings and O.\nSentence: has charlton heston ever been a voice in an animated movie", "prompt_labels": "has(O) charlton(B-actor) heston(I-actor) ever(O) been(O) a(O) voice(O) in(O) an(O) animated(B-genre) movie(O)"}, "label_list": ["review", "trailer", "title", "year", "plot", "genre", "song", "actor", "rating", "character", "director", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 19809, 11, 2316, 11, 1060, 11, 7234, 11, 17779, 11, 5609, 11, 12360, 11, 10959, 11, 3752, 11, 7690, 11, 5578, 18594, 323, 507, 627, 85664, 25, 706, 1181, 75, 783, 305, 478, 263, 3596, 1027, 264, 7899, 304, 459, 11625, 5818, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "384", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) was(O) the(O) cast(O) of(O) terminator(B-title)", "instance": {"id": "384", "words": ["who", "was", "the", "cast", "of", "terminator"], "labels": ["O", "O", "O", "B-actor", "O", "B-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, review, average ratings, plot, title, rating, director, character, trailer, song, actor, year and O.\nSentence: who was the cast of terminator", "prompt_labels": "who(O) was(O) the(O) cast(B-actor) of(O) terminator(B-title)"}, "label_list": ["genre", "review", "average ratings", "plot", "title", "rating", "director", "character", "trailer", "song", "actor", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 3477, 11, 5578, 18594, 11, 7234, 11, 2316, 11, 10959, 11, 7690, 11, 3752, 11, 19809, 11, 5609, 11, 12360, 11, 1060, 323, 507, 627, 85664, 25, 889, 574, 279, 6445, 315, 81125, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "116", "dataset": "crossner_science", "split": "dev", "prediction": "Knowles(B-person) collaborated(O) with(O) several(O) studio(O) personalities(O),(O) including(O) Jack(B-person) Splash(I-person),(O) Shea(B-person) Taylor(I-person),(O) Mr.(B-person) Familiar(I-person),(O) Lamont(B-person) Dozier(I-person),(O) production(O) teams(O) Soulshock(B-person) &(I-person) Karlin(I-person) and(O) Bama(B-person) Boyz(I-person),(O) as(O) well(O) as(O) singers(O) and(O) rappers(O) Pharrell(B-person) Williams(I-person),(O) Bilal(B-person),(O) Q-Tip(B-person) and(O) Lil(B-person) Wayne(I-person) respectively(O).(O)", "instance": {"id": "116", "words": ["Knowles", "collaborated", "with", "several", "studio", "personalities", ",", "including", "Jack", "Splash", ",", "Shea", "Taylor", ",", "Mr.", "Familiar", ",", "Lamont", "Dozier", ",", "production", "teams", "Soulshock", "&", "Karlin", "and", "Bama", "Boyz", ",", "as", "well", "as", "singers", "and", "rappers", "Pharrell", "Williams", ",", "Bilal", ",", "Q-Tip", "and", "Lil", "Wayne", "respectively", "."], "labels": ["B-person", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "B-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "B-person", "O", "B-person", "O", "B-person", "I-person", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, person, country, chemical compound, astronomical object, enzyme, event, chemical element, scientist, academic journal, theory, discipline, protein, location, organization, university and O.\nSentence: Knowles collaborated with several studio personalities , including Jack Splash , Shea Taylor , Mr. Familiar , Lamont Dozier , production teams Soulshock & Karlin and Bama Boyz , as well as singers and rappers Pharrell Williams , Bilal , Q-Tip and Lil Wayne respectively .", "prompt_labels": "Knowles(B-person) collaborated(O) with(O) several(O) studio(O) personalities(O) ,(O) including(O) Jack(B-person) Splash(I-person) ,(O) Shea(B-person) Taylor(I-person) ,(O) Mr.(B-person) Familiar(I-person) ,(O) Lamont(B-person) Dozier(I-person) ,(O) production(O) teams(O) Soulshock(B-organization) &(I-organization) Karlin(I-organization) and(O) Bama(B-organization) Boyz(I-organization) ,(O) as(O) well(O) as(O) singers(O) and(O) rappers(O) Pharrell(B-person) Williams(I-person) ,(O) Bilal(B-person) ,(O) Q-Tip(B-person) and(O) Lil(B-person) Wayne(I-person) respectively(O) .(O)"}, "label_list": ["award", "person", "country", "chemical compound", "astronomical object", "enzyme", "event", "chemical element", "scientist", "academic journal", "theory", "discipline", "protein", "location", "organization", "university"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10292, 11, 1732, 11, 3224, 11, 11742, 24549, 11, 87283, 1665, 11, 49242, 11, 1567, 11, 11742, 2449, 11, 28568, 11, 14584, 8486, 11, 10334, 11, 26434, 11, 13128, 11, 3813, 11, 7471, 11, 12374, 323, 507, 627, 85664, 25, 14521, 645, 78174, 449, 3892, 14356, 44908, 1174, 2737, 7762, 46542, 1174, 86068, 16844, 1174, 4491, 13, 34701, 9730, 1174, 33794, 546, 3234, 39068, 1174, 5788, 7411, 30242, 939, 1197, 612, 13528, 3817, 323, 426, 3105, 16576, 89, 1174, 439, 1664, 439, 68141, 323, 436, 28921, 88671, 16684, 13926, 1174, 39158, 278, 1174, 1229, 9469, 575, 323, 41578, 28640, 15947, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "265", "dataset": "crossner_ai", "split": "dev", "prediction": "They(O) ended(O) up(O) awarding(O) eleven(O) PR2s(O) to(O) different(O) institutions(O),(O) including(O) University(B-university) of(I-university) Freiburg(I-university),(O) Bosch(B-organization),(O) Georgia(B-university) Tech(I-university),(O) KU(B-university) Leuven(I-university),(O) MIT(B-university),(O) Stanford(B-university),(O) Technical(B-university) University(I-university) of(I-university) Munich(I-university),(O) UC(B-university) Berkeley(I-university),(O) U(B-university) Penn(I-university),(O) USC(B-university),(O) and(O) University(B-university) of(I-university) Tokyo(I-university).(O)", "instance": {"id": "265", "words": ["They", "ended", "up", "awarding", "eleven", "PR2s", "to", "different", "institutions", ",", "including", "University", "of", "Freiburg", ",", "Bosch", ",", "Georgia", "Tech", ",", "KU", "Leuven", ",", "MIT", ",", "Stanford", ",", "Technical", "University", "of", "Munich", ",", "UC", "Berkeley", ",", "U", "Penn", ",", "USC", ",", "and", "University", "of", "Tokyo", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-university", "I-university", "I-university", "O", "B-university", "O", "B-university", "I-university", "O", "B-university", "I-university", "O", "B-university", "O", "B-university", "O", "B-university", "I-university", "I-university", "I-university", "O", "B-university", "I-university", "O", "B-university", "I-university", "O", "B-university", "O", "O", "B-university", "I-university", "I-university", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, programming language, product, country, task, organization, field, university, metric, conference, location, researcher, algorithm and O.\nSentence: They ended up awarding eleven PR2s to different institutions , including University of Freiburg , Bosch , Georgia Tech , KU Leuven , MIT , Stanford , Technical University of Munich , UC Berkeley , U Penn , USC , and University of Tokyo .", "prompt_labels": "They(O) ended(O) up(O) awarding(O) eleven(O) PR2s(O) to(O) different(O) institutions(O) ,(O) including(O) University(B-university) of(I-university) Freiburg(I-university) ,(O) Bosch(B-university) ,(O) Georgia(B-university) Tech(I-university) ,(O) KU(B-university) Leuven(I-university) ,(O) MIT(B-university) ,(O) Stanford(B-university) ,(O) Technical(B-university) University(I-university) of(I-university) Munich(I-university) ,(O) UC(B-university) Berkeley(I-university) ,(O) U(B-university) Penn(I-university) ,(O) USC(B-university) ,(O) and(O) University(B-university) of(I-university) Tokyo(I-university) .(O)"}, "label_list": ["person", "programming language", "product", "country", "task", "organization", "field", "university", "metric", "conference", "location", "researcher", "algorithm"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 15840, 4221, 11, 2027, 11, 3224, 11, 3465, 11, 7471, 11, 2115, 11, 12374, 11, 18767, 11, 10017, 11, 3813, 11, 32185, 11, 12384, 323, 507, 627, 85664, 25, 2435, 9670, 709, 10292, 287, 45314, 8743, 17, 82, 311, 2204, 14673, 1174, 2737, 3907, 315, 7730, 581, 5673, 1174, 72325, 1174, 16272, 17829, 1174, 735, 52, 2009, 84, 1055, 1174, 15210, 1174, 31788, 1174, 27766, 3907, 315, 47304, 1174, 31613, 33108, 1174, 549, 13813, 1174, 44379, 1174, 323, 3907, 315, 27286, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "52", "dataset": "crossner_politics", "split": "dev", "prediction": "Adams(B-politician) previously(O) held(O) the(O) seat(O) from(O) 1983(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) to(O) 1992(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) when(O) he(O) lost(O) it(O) to(O) Joe(B-politician) Hendron(I-politician) of(O) the(O) Social(B-political party) Democratic(I-political party) and(I-political party) Labour(I-political party) Party(I-political party) but(O) regained(O) it(O) in(O) 1997(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election).(O)", "instance": {"id": "52", "words": ["Adams", "previously", "held", "the", "seat", "from", "1983", "United", "Kingdom", "general", "election", "to", "1992", "United", "Kingdom", "general", "election", "when", "he", "lost", "it", "to", "Joe", "Hendron", "of", "the", "Social", "Democratic", "and", "Labour", "Party", "but", "regained", "it", "in", "1997", "United", "Kingdom", "general", "election", "."], "labels": ["B-politician", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "B-politician", "I-politician", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, location, country, election, person, event, political party, organization and O.\nSentence: Adams previously held the seat from 1983 United Kingdom general election to 1992 United Kingdom general election when he lost it to Joe Hendron of the Social Democratic and Labour Party but regained it in 1997 United Kingdom general election .", "prompt_labels": "Adams(B-politician) previously(O) held(O) the(O) seat(O) from(O) 1983(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) to(O) 1992(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) when(O) he(O) lost(O) it(O) to(O) Joe(B-politician) Hendron(I-politician) of(O) the(O) Social(B-political party) Democratic(I-political party) and(I-political party) Labour(I-political party) Party(I-political party) but(O) regained(O) it(O) in(O) 1997(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)"}, "label_list": ["politician", "location", "country", "election", "person", "event", "political party", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 37038, 11, 3813, 11, 3224, 11, 6355, 11, 1732, 11, 1567, 11, 5054, 4717, 11, 7471, 323, 507, 627, 85664, 25, 27329, 8767, 5762, 279, 10954, 505, 220, 3753, 18, 3723, 15422, 4689, 6355, 311, 220, 2550, 17, 3723, 15422, 4689, 6355, 994, 568, 5675, 433, 311, 13142, 30594, 2298, 315, 279, 9983, 11650, 323, 18993, 8722, 719, 86025, 433, 304, 220, 2550, 22, 3723, 15422, 4689, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "19", "dataset": "crossner_literature", "split": "dev", "prediction": "When(O) Davies(B-writer) retired(O) from(O) his(O) position(O) at(O) the(O) university(O),(O) his(O) seventh(O) novel(O),(O) a(O) satire(O) of(O) academic(O) life(O),(O) The(B-book) Rebel(I-book) Angels(I-book) ((O) 1981(O) )(O),(O) was(O) published(O),(O) followed(O) by(O) What(B-book)'s(I-book) Bred(I-book) in(I-book) the(I-book) Bone(I-book) ((O) 1985(O) )(O) which(O) was(O) short-listed(O) for(O) the(O) Booker(B-award) Prize(I-award) for(I-award) fiction(I-award) in(O) 1986(O).(O)", "instance": {"id": "19", "words": ["When", "Davies", "retired", "from", "his", "position", "at", "the", "university", ",", "his", "seventh", "novel", ",", "a", "satire", "of", "academic", "life", ",", "The", "Rebel", "Angels", "(", "1981", ")", ",", "was", "published", ",", "followed", "by", "What", "'s", "Bred", "in", "the", "Bone", "(", "1985", ")", "which", "was", "short-listed", "for", "the", "Booker", "Prize", "for", "fiction", "in", "1986", "."], "labels": ["O", "B-writer", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-literary genre", "O", "O", "B-literary genre", "O", "O", "O", "O", "B-book", "I-book", "I-book", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-book", "I-book", "I-book", "I-book", "I-book", "I-book", "O", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: poem, literary genre, award, organization, magazine, writer, location, book, person, event, country and O.\nSentence: When Davies retired from his position at the university , his seventh novel , a satire of academic life , The Rebel Angels ( 1981 ) , was published , followed by What 's Bred in the Bone ( 1985 ) which was short-listed for the Booker Prize for fiction in 1986 .", "prompt_labels": "When(O) Davies(B-writer) retired(O) from(O) his(O) position(O) at(O) the(O) university(O) ,(O) his(O) seventh(O) novel(B-literary genre) ,(O) a(O) satire(B-literary genre) of(O) academic(O) life(O) ,(O) The(B-book) Rebel(I-book) Angels(I-book) ((O) 1981(O) )(O) ,(O) was(O) published(O) ,(O) followed(O) by(O) What(B-book) 's(I-book) Bred(I-book) in(I-book) the(I-book) Bone(I-book) ((O) 1985(O) )(O) which(O) was(O) short-listed(O) for(O) the(O) Booker(B-award) Prize(I-award) for(I-award) fiction(I-award) in(O) 1986(O) .(O)"}, "label_list": ["poem", "literary genre", "award", "organization", "magazine", "writer", "location", "book", "person", "event", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 33894, 11, 32465, 17779, 11, 10292, 11, 7471, 11, 14756, 11, 7061, 11, 3813, 11, 2363, 11, 1732, 11, 1567, 11, 3224, 323, 507, 627, 85664, 25, 3277, 56872, 22311, 505, 813, 2361, 520, 279, 12374, 1174, 813, 31487, 11775, 1174, 264, 82495, 315, 14584, 2324, 1174, 578, 64264, 43145, 320, 220, 3753, 16, 883, 1174, 574, 4756, 1174, 8272, 555, 3639, 364, 82, 426, 1171, 304, 279, 46701, 320, 220, 3753, 20, 883, 902, 574, 2875, 9206, 291, 369, 279, 66095, 32293, 369, 17422, 304, 220, 3753, 21, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "252", "dataset": "crossner_politics", "split": "dev", "prediction": "He(O) was(O) chairman(O) of(O) the(O) Executive(O) Committee(O) of(O) the(O) Board(O) of(O) the(O) Public(B-organization) Agenda(I-organization) Foundation(I-organization) ;(O) chairman(O) of(O) the(O) Executive(O) Committee(O) of(O) the(O) Board(O) of(O) Business(B-organization) Executives(I-organization) for(I-organization) National(I-organization) Security(I-organization) ;(O) a(O) member(O) of(O) the(O) Council(B-organization) on(I-organization) Foreign(I-organization) Relations(I-organization) and(O) the(O) U.S.(B-organization) Council(I-organization) on(I-organization) Competitiveness(I-organization) ;(O) and(O) a(O) member(O) of(O) the(O) Board(O) of(O) the(O) Leadership(B-organization) Institute(I-organization) of(I-organization) the(I-organization) University(I-organization) of(I-organization) Southern(I-organization) California(I-organization).(O)", "instance": {"id": "252", "words": ["He", "was", "chairman", "of", "the", "Executive", "Committee", "of", "the", "Board", "of", "the", "Public", "Agenda", "Foundation", ";", "chairman", "of", "the", "Executive", "Committee", "of", "the", "Board", "of", "Business", "Executives", "for", "National", "Security", ";", "a", "member", "of", "the", "Council", "on", "Foreign", "Relations", "and", "the", "U.S.", "Council", "on", "Competitiveness", ";", "and", "a", "member", "of", "the", "Board", "of", "the", "Leadership", "Institute", "of", "the", "University", "of", "Southern", "California", "."], "labels": ["O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "O", "O", "B-organization", "I-organization", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, person, country, event, organization, location, politician, political party and O.\nSentence: He was chairman of the Executive Committee of the Board of the Public Agenda Foundation ; chairman of the Executive Committee of the Board of Business Executives for National Security ; a member of the Council on Foreign Relations and the U.S. Council on Competitiveness ; and a member of the Board of the Leadership Institute of the University of Southern California .", "prompt_labels": "He(O) was(O) chairman(O) of(O) the(O) Executive(B-organization) Committee(I-organization) of(O) the(O) Board(O) of(O) the(O) Public(B-organization) Agenda(I-organization) Foundation(I-organization) ;(O) chairman(O) of(O) the(O) Executive(B-organization) Committee(I-organization) of(O) the(O) Board(O) of(O) Business(B-organization) Executives(I-organization) for(I-organization) National(I-organization) Security(I-organization) ;(O) a(O) member(O) of(O) the(O) Council(B-organization) on(I-organization) Foreign(I-organization) Relations(I-organization) and(O) the(O) U.S.(B-organization) Council(I-organization) on(I-organization) Competitiveness(I-organization) ;(O) and(O) a(O) member(O) of(O) the(O) Board(O) of(O) the(O) Leadership(O) Institute(O) of(O) the(O) University(B-organization) of(I-organization) Southern(I-organization) California(I-organization) .(O)"}, "label_list": ["election", "person", "country", "event", "organization", "location", "politician", "political party"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 6355, 11, 1732, 11, 3224, 11, 1567, 11, 7471, 11, 3813, 11, 37038, 11, 5054, 4717, 323, 507, 627, 85664, 25, 1283, 574, 21892, 315, 279, 18362, 10554, 315, 279, 8925, 315, 279, 3142, 58662, 5114, 2652, 21892, 315, 279, 18362, 10554, 315, 279, 8925, 315, 8184, 10502, 332, 1924, 369, 5165, 8398, 2652, 264, 4562, 315, 279, 9251, 389, 19620, 32467, 323, 279, 549, 815, 13, 9251, 389, 26517, 275, 13071, 2652, 323, 264, 4562, 315, 279, 8925, 315, 279, 37263, 10181, 315, 279, 3907, 315, 16642, 7188, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "5", "dataset": "crossner_literature", "split": "dev", "prediction": "The(O) poor(O) conditions(O) of(O) the(O) hospital(O) in(O) Lambar\u00e9n\u00e9(B-location) were(O) also(O) famously(O) criticized(O) by(O) Nigerian(O) professor(O) and(O) novelist(O) Chinua(B-writer) Achebe(I-writer) in(O) his(O) essay(O) on(O) Joseph(B-writer) Conrad(I-writer) '(O) s(O) novel(O) Heart(B-book) of(I-book) Darkness(I-book) :(O) In(O) a(O) comment(O) which(O) has(O) often(O) been(O) quoted(O) Schweitzer(O) says(O) :(O) '(O) The(O) African(O) is(O) indeed(O) my(O) brother(O) but(O) my(O) junior(O) brother(O).(O)", "instance": {"id": "5", "words": ["The", "poor", "conditions", "of", "the", "hospital", "in", "Lambar\u00e9n\u00e9", "were", "also", "famously", "criticized", "by", "Nigerian", "professor", "and", "novelist", "Chinua", "Achebe", "in", "his", "essay", "on", "Joseph", "Conrad", "'", "s", "novel", "Heart", "of", "Darkness", ":", "In", "a", "comment", "which", "has", "often", "been", "quoted", "Schweitzer", "says", ":", "'", "The", "African", "is", "indeed", "my", "brother", "but", "my", "junior", "brother", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-location", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-writer", "I-writer", "O", "O", "O", "O", "B-person", "I-person", "O", "O", "B-literary genre", "B-book", "I-book", "I-book", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-writer", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: book, award, writer, literary genre, magazine, organization, location, event, poem, country, person and O.\nSentence: The poor conditions of the hospital in Lambar\u00e9n\u00e9 were also famously criticized by Nigerian professor and novelist Chinua Achebe in his essay on Joseph Conrad ' s novel Heart of Darkness : In a comment which has often been quoted Schweitzer says : ' The African is indeed my brother but my junior brother .", "prompt_labels": "The(O) poor(O) conditions(O) of(O) the(O) hospital(O) in(O) Lambar\u00e9n\u00e9(B-location) were(O) also(O) famously(O) criticized(O) by(O) Nigerian(O) professor(O) and(O) novelist(O) Chinua(B-writer) Achebe(I-writer) in(O) his(O) essay(O) on(O) Joseph(B-person) Conrad(I-person) '(O) s(O) novel(B-literary genre) Heart(B-book) of(I-book) Darkness(I-book) :(O) In(O) a(O) comment(O) which(O) has(O) often(O) been(O) quoted(O) Schweitzer(B-writer) says(O) :(O) '(O) The(O) African(O) is(O) indeed(O) my(O) brother(O) but(O) my(O) junior(O) brother(O) .(O)"}, "label_list": ["book", "award", "writer", "literary genre", "magazine", "organization", "location", "event", "poem", "country", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2363, 11, 10292, 11, 7061, 11, 32465, 17779, 11, 14756, 11, 7471, 11, 3813, 11, 1567, 11, 33894, 11, 3224, 11, 1732, 323, 507, 627, 85664, 25, 578, 8009, 4787, 315, 279, 8952, 304, 33794, 2308, 32453, 1051, 1101, 51287, 32614, 555, 55433, 14561, 323, 81747, 49335, 4381, 362, 1557, 1395, 304, 813, 9071, 389, 15466, 77089, 364, 274, 11775, 18449, 315, 54796, 551, 763, 264, 4068, 902, 706, 3629, 1027, 24116, 56834, 21114, 2795, 551, 364, 578, 11904, 374, 13118, 856, 10868, 719, 856, 27144, 10868, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2327", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) starred(O) in(O) the(O) movie(O) the(B-title) willies(I-title)", "instance": {"id": "2327", "words": ["who", "starred", "in", "the", "movie", "the", "willies"], "labels": ["O", "O", "O", "O", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, year, rating, character, genre, director, title, song, review, actor, average ratings, plot and O.\nSentence: who starred in the movie the willies", "prompt_labels": "who(O) starred(O) in(O) the(O) movie(O) the(B-title) willies(I-title)"}, "label_list": ["trailer", "year", "rating", "character", "genre", "director", "title", "song", "review", "actor", "average ratings", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 1060, 11, 10959, 11, 3752, 11, 17779, 11, 7690, 11, 2316, 11, 5609, 11, 3477, 11, 12360, 11, 5578, 18594, 11, 7234, 323, 507, 627, 85664, 25, 889, 59335, 304, 279, 5818, 279, 690, 552, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "825", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) a(O) korean(B-Cuisine) restaurant(O) that(O) is(O) smoker(B-Amenity) friendly(I-Amenity)", "instance": {"id": "825", "words": ["is", "there", "a", "korean", "restaurant", "that", "is", "smoker", "friendly"], "labels": ["O", "O", "O", "B-Cuisine", "O", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Amenity, Rating, Hours, Cuisine, Restaurant Name, Dish, Location and O.\nSentence: is there a korean restaurant that is smoker friendly", "prompt_labels": "is(O) there(O) a(O) korean(B-Cuisine) restaurant(O) that(O) is(O) smoker(B-Amenity) friendly(I-Amenity)"}, "label_list": ["Price", "Amenity", "Rating", "Hours", "Cuisine", "Restaurant Name", "Dish", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 3383, 56685, 11, 19767, 11, 30192, 11, 81961, 11, 26568, 4076, 11, 49268, 11, 10067, 323, 507, 627, 85664, 25, 374, 1070, 264, 597, 46295, 10960, 430, 374, 78320, 11919, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "889", "dataset": "mit-movie", "split": "dev", "prediction": "find(O) movies(O) from(O) the(O) 1990s(B-year) with(O) strong(B-plot) female(I-plot) leads(I-plot)", "instance": {"id": "889", "words": ["find", "movies", "from", "the", "1990s", "with", "strong", "female", "leads"], "labels": ["O", "O", "O", "O", "B-year", "O", "B-plot", "I-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, actor, director, trailer, year, plot, character, genre, song, title, rating, review and O.\nSentence: find movies from the 1990s with strong female leads", "prompt_labels": "find(O) movies(O) from(O) the(O) 1990s(B-year) with(O) strong(B-plot) female(I-plot) leads(I-plot)"}, "label_list": ["average ratings", "actor", "director", "trailer", "year", "plot", "character", "genre", "song", "title", "rating", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 12360, 11, 7690, 11, 19809, 11, 1060, 11, 7234, 11, 3752, 11, 17779, 11, 5609, 11, 2316, 11, 10959, 11, 3477, 323, 507, 627, 85664, 25, 1505, 9698, 505, 279, 220, 2550, 15, 82, 449, 3831, 8954, 11767, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1828", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) 1990(B-year) horror(B-genre) movie(O) about(O) demons(B-plot) was(O) directed(O) by(O) philip(B-director) adrian(I-director) booth(I-director)", "instance": {"id": "1828", "words": ["what", "1990", "horror", "movie", "about", "demons", "was", "directed", "by", "philip", "adrian", "booth"], "labels": ["O", "B-year", "B-genre", "O", "O", "B-plot", "O", "O", "O", "B-director", "I-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, year, character, director, actor, review, rating, song, trailer, title, average ratings, plot and O.\nSentence: what 1990 horror movie about demons was directed by philip adrian booth", "prompt_labels": "what(O) 1990(B-year) horror(B-genre) movie(O) about(O) demons(B-plot) was(O) directed(O) by(O) philip(B-director) adrian(I-director) booth(I-director)"}, "label_list": ["genre", "year", "character", "director", "actor", "review", "rating", "song", "trailer", "title", "average ratings", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 1060, 11, 3752, 11, 7690, 11, 12360, 11, 3477, 11, 10959, 11, 5609, 11, 19809, 11, 2316, 11, 5578, 18594, 11, 7234, 323, 507, 627, 85664, 25, 1148, 220, 2550, 15, 22169, 5818, 922, 45075, 574, 15910, 555, 10891, 575, 1008, 7414, 36506, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "601", "dataset": "mit-movie", "split": "dev", "prediction": "name(O) the(O) movie(O) in(O) which(O) clint(B-song) eastwood(I-song) sings(O)", "instance": {"id": "601", "words": ["name", "the", "movie", "in", "which", "clint", "eastwood", "sings"], "labels": ["O", "O", "O", "O", "O", "B-actor", "I-actor", "B-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, actor, year, trailer, title, review, director, character, rating, song, genre, plot and O.\nSentence: name the movie in which clint eastwood sings", "prompt_labels": "name(O) the(O) movie(O) in(O) which(O) clint(B-actor) eastwood(I-actor) sings(B-plot)"}, "label_list": ["average ratings", "actor", "year", "trailer", "title", "review", "director", "character", "rating", "song", "genre", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 12360, 11, 1060, 11, 19809, 11, 2316, 11, 3477, 11, 7690, 11, 3752, 11, 10959, 11, 5609, 11, 17779, 11, 7234, 323, 507, 627, 85664, 25, 836, 279, 5818, 304, 902, 1206, 396, 11226, 6798, 68341, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "458", "dataset": "crossner_politics", "split": "dev", "prediction": "Presented(O) as(O) Loudbox(O),(O) a(O) cable(O) news(O) program(O) hosted(O) by(O) Rachel(B-person) Maddow(I-person) ((O) Atamanuik(O) )(O) and(O) Chris(B-politician) Matthews(I-politician) ((O) Adomian(O) )(O) with(O) panelists(O) Donna(B-politician) Brazile(I-politician) ((O) Nicole(B-person) Byer(I-person) )(O),(O) Jeb(B-politician) Bush(I-politician) ((O) Daniel(B-politician) Van(I-politician) Kirk(I-politician) )(O),(O) and(O) Ben(B-politician) Carson(I-politician) ((O) Jerry(B-politician) Minor(I-politician) )(O),(O) the(O) pundits(O) ignore(O) an(O) impending(O) cataclysmic(O) asteroid(O) strike(O) in(O) favor(O) of(O) political(O) optics(O) while(O) throwing(O) to(O) interviews(O) and(O) field(O) pieces(O) with(O) Trump(B-politician) and(O) Bernie(B-politician).(O)", "instance": {"id": "458", "words": ["Presented", "as", "Loudbox", ",", "a", "cable", "news", "program", "hosted", "by", "Rachel", "Maddow", "(", "Atamanuik", ")", "and", "Chris", "Matthews", "(", "Adomian", ")", "with", "panelists", "Donna", "Brazile", "(", "Nicole", "Byer", ")", ",", "Jeb", "Bush", "(", "Daniel", "Van", "Kirk", ")", ",", "and", "Ben", "Carson", "(", "Jerry", "Minor", ")", ",", "the", "pundits", "ignore", "an", "impending", "cataclysmic", "asteroid", "strike", "in", "favor", "of", "political", "optics", "while", "throwing", "to", "interviews", "and", "field", "pieces", "with", "Trump", "and", "Bernie", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "B-person", "O", "O", "B-person", "I-person", "O", "B-person", "O", "O", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "O", "B-person", "I-person", "O", "B-person", "I-person", "I-person", "O", "O", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-politician", "O", "B-politician", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, election, country, event, politician, location, person, organization and O.\nSentence: Presented as Loudbox , a cable news program hosted by Rachel Maddow ( Atamanuik ) and Chris Matthews ( Adomian ) with panelists Donna Brazile ( Nicole Byer ) , Jeb Bush ( Daniel Van Kirk ) , and Ben Carson ( Jerry Minor ) , the pundits ignore an impending cataclysmic asteroid strike in favor of political optics while throwing to interviews and field pieces with Trump and Bernie .", "prompt_labels": "Presented(O) as(O) Loudbox(O) ,(O) a(O) cable(O) news(O) program(O) hosted(O) by(O) Rachel(B-person) Maddow(I-person) ((O) Atamanuik(B-person) )(O) and(O) Chris(B-person) Matthews(I-person) ((O) Adomian(B-person) )(O) with(O) panelists(O) Donna(B-person) Brazile(I-person) ((O) Nicole(B-person) Byer(I-person) )(O) ,(O) Jeb(B-person) Bush(I-person) ((O) Daniel(B-person) Van(I-person) Kirk(I-person) )(O) ,(O) and(O) Ben(B-person) Carson(I-person) ((O) Jerry(B-person) Minor(I-person) )(O) ,(O) the(O) pundits(O) ignore(O) an(O) impending(O) cataclysmic(O) asteroid(O) strike(O) in(O) favor(O) of(O) political(O) optics(O) while(O) throwing(O) to(O) interviews(O) and(O) field(O) pieces(O) with(O) Trump(B-politician) and(O) Bernie(B-politician) .(O)"}, "label_list": ["political party", "election", "country", "event", "politician", "location", "person", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5054, 4717, 11, 6355, 11, 3224, 11, 1567, 11, 37038, 11, 3813, 11, 1732, 11, 7471, 323, 507, 627, 85664, 25, 88121, 439, 80648, 2054, 1174, 264, 14994, 3754, 2068, 21685, 555, 32532, 44637, 363, 320, 2468, 13005, 84, 1609, 883, 323, 11517, 51784, 320, 2467, 316, 1122, 883, 449, 7090, 1705, 47863, 73411, 458, 320, 45130, 3296, 261, 883, 1174, 71196, 14409, 320, 15469, 13000, 32446, 883, 1174, 323, 7505, 41276, 320, 29808, 30893, 883, 1174, 279, 79306, 10240, 459, 63561, 31179, 85245, 3647, 292, 55479, 13471, 304, 4799, 315, 5054, 70985, 1418, 21939, 311, 19905, 323, 2115, 9863, 449, 3420, 323, 30324, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2408", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movie(O) did(O) the(O) song(O) come(B-song) what(I-song) may(I-song) play(O) in(O)", "instance": {"id": "2408", "words": ["what", "movie", "did", "the", "song", "come", "what", "may", "play", "in"], "labels": ["O", "O", "O", "O", "O", "B-song", "I-song", "I-song", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, year, actor, director, plot, average ratings, title, trailer, song, review, genre, rating and O.\nSentence: what movie did the song come what may play in", "prompt_labels": "what(O) movie(O) did(O) the(O) song(O) come(B-song) what(I-song) may(I-song) play(O) in(O)"}, "label_list": ["character", "year", "actor", "director", "plot", "average ratings", "title", "trailer", "song", "review", "genre", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 1060, 11, 12360, 11, 7690, 11, 7234, 11, 5578, 18594, 11, 2316, 11, 19809, 11, 5609, 11, 3477, 11, 17779, 11, 10959, 323, 507, 627, 85664, 25, 1148, 5818, 1550, 279, 5609, 2586, 1148, 1253, 1514, 304, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1492", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) there(O) a(O) good(B-average ratings) rated(O) r(B-rating) military(B-genre) movie(O) about(O) camp(B-plot)", "instance": {"id": "1492", "words": ["is", "there", "a", "good", "rated", "r", "military", "movie", "about", "camp"], "labels": ["O", "O", "O", "O", "O", "B-rating", "B-genre", "O", "O", "B-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, plot, trailer, actor, title, review, director, average ratings, year, character, song, rating and O.\nSentence: is there a good rated r military movie about camp", "prompt_labels": "is(O) there(O) a(O) good(O) rated(O) r(B-rating) military(B-genre) movie(O) about(O) camp(B-plot)"}, "label_list": ["genre", "plot", "trailer", "actor", "title", "review", "director", "average ratings", "year", "character", "song", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 7234, 11, 19809, 11, 12360, 11, 2316, 11, 3477, 11, 7690, 11, 5578, 18594, 11, 1060, 11, 3752, 11, 5609, 11, 10959, 323, 507, 627, 85664, 25, 374, 1070, 264, 1695, 22359, 436, 6411, 5818, 922, 3190, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "342", "dataset": "crossner_music", "split": "dev", "prediction": "During(O) the(O) '(O) 90s(O),(O) Southern(B-location) California(I-location) Chicano(B-band) artists(I-band),(O) such(O) as(O) Kid(B-musical artist) Frost(I-musical artist),(O) A.L.T.(B-band),(O) A(B-band) Lighter(I-band) Shade(I-band) of(I-band) Brown(I-band),(O) B-Real(B-musical artist),(O) Psycho(B-band) Realm(I-band),(O) Gunter(B-band),(O) Delinquent(B-band) Habits(I-band) and(O) Jonny(B-musical artist) Z(I-musical artist) received(O) mainstream(O) success(O).(O)", "instance": {"id": "342", "words": ["During", "the", "'", "90s", ",", "Southern", "California", "Chicano", "artists", ",", "such", "as", "Kid", "Frost", ",", "A.L.T.", ",", "A", "Lighter", "Shade", "of", "Brown", ",", "B-Real", ",", "Psycho", "Realm", ",", "Gunter", ",", "Delinquent", "Habits", "and", "Jonny", "Z", "received", "mainstream", "success", "."], "labels": ["O", "O", "O", "O", "O", "B-location", "I-location", "O", "O", "O", "O", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "O", "B-band", "I-band", "I-band", "I-band", "I-band", "O", "B-musical artist", "O", "B-band", "I-band", "O", "B-musical artist", "O", "B-band", "I-band", "O", "B-musical artist", "I-musical artist", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, country, location, musical instrument, award, song, person, album, organization, music genre, musical artist, event and O.\nSentence: During the ' 90s , Southern California Chicano artists , such as Kid Frost , A.L.T. , A Lighter Shade of Brown , B-Real , Psycho Realm , Gunter , Delinquent Habits and Jonny Z received mainstream success .", "prompt_labels": "During(O) the(O) '(O) 90s(O) ,(O) Southern(B-location) California(I-location) Chicano(O) artists(O) ,(O) such(O) as(O) Kid(B-musical artist) Frost(I-musical artist) ,(O) A.L.T.(B-musical artist) ,(O) A(B-band) Lighter(I-band) Shade(I-band) of(I-band) Brown(I-band) ,(O) B-Real(B-musical artist) ,(O) Psycho(B-band) Realm(I-band) ,(O) Gunter(B-musical artist) ,(O) Delinquent(B-band) Habits(I-band) and(O) Jonny(B-musical artist) Z(I-musical artist) received(O) mainstream(O) success(O) .(O)"}, "label_list": ["band", "country", "location", "musical instrument", "award", "song", "person", "album", "organization", "music genre", "musical artist", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7200, 11, 3224, 11, 3813, 11, 18273, 14473, 11, 10292, 11, 5609, 11, 1732, 11, 8176, 11, 7471, 11, 4731, 17779, 11, 18273, 10255, 11, 1567, 323, 507, 627, 85664, 25, 12220, 279, 364, 220, 1954, 82, 1174, 16642, 7188, 71820, 5770, 13820, 1174, 1778, 439, 32666, 42320, 1174, 362, 1236, 844, 13, 1174, 362, 8828, 261, 80918, 315, 10690, 1174, 426, 12, 13058, 1174, 70276, 42206, 1174, 22450, 466, 1174, 7462, 258, 17187, 29976, 1220, 323, 12565, 3919, 1901, 4036, 21391, 2450, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "376", "dataset": "crossner_science", "split": "dev", "prediction": "In(O) 2007(O),(O) he(O) received(O) the(O) British(B-award) Neuroscience(I-award) Association(I-award) Award(I-award) for(I-award) Outstanding(I-award) Contribution(I-award) to(I-award) British(I-award) Neuroscience(I-award) and(O) in(O) 2008(O) he(O) received(O) the(O) Federation(B-award) of(I-award) European(I-award) Neuroscience(I-award) Societies(I-award) European(I-award) Journal(I-award) of(I-award) Neuroscience(I-award).(O)", "instance": {"id": "376", "words": ["In", "2007", ",", "he", "received", "the", "British", "Neuroscience", "Association", "Award", "for", "Outstanding", "Contribution", "to", "British", "Neuroscience", "and", "in", "2008", "he", "received", "the", "Federation", "of", "European", "Neuroscience", "Societies", "European", "Journal", "of", "Neuroscience", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "B-academic journal", "I-academic journal", "I-academic journal", "I-academic journal", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, academic journal, event, protein, theory, chemical element, scientist, chemical compound, person, location, award, organization, country, discipline, astronomical object, enzyme and O.\nSentence: In 2007 , he received the British Neuroscience Association Award for Outstanding Contribution to British Neuroscience and in 2008 he received the Federation of European Neuroscience Societies European Journal of Neuroscience .", "prompt_labels": "In(O) 2007(O) ,(O) he(O) received(O) the(O) British(B-award) Neuroscience(I-award) Association(I-award) Award(I-award) for(I-award) Outstanding(I-award) Contribution(I-award) to(I-award) British(I-award) Neuroscience(I-award) and(O) in(O) 2008(O) he(O) received(O) the(O) Federation(B-organization) of(I-organization) European(I-organization) Neuroscience(I-organization) Societies(I-organization) European(B-academic journal) Journal(I-academic journal) of(I-academic journal) Neuroscience(I-academic journal) .(O)"}, "label_list": ["university", "academic journal", "event", "protein", "theory", "chemical element", "scientist", "chemical compound", "person", "location", "award", "organization", "country", "discipline", "astronomical object", "enzyme"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12374, 11, 14584, 8486, 11, 1567, 11, 13128, 11, 10334, 11, 11742, 2449, 11, 28568, 11, 11742, 24549, 11, 1732, 11, 3813, 11, 10292, 11, 7471, 11, 3224, 11, 26434, 11, 87283, 1665, 11, 49242, 323, 507, 627, 85664, 25, 763, 220, 1049, 22, 1174, 568, 4036, 279, 8013, 85879, 10229, 17768, 369, 76441, 94628, 311, 8013, 85879, 323, 304, 220, 1049, 23, 568, 4036, 279, 28331, 315, 7665, 85879, 42509, 26640, 7665, 10139, 315, 85879, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1161", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) kosher(B-Cuisine) restaurants(O) still(O) have(O) smoking(B-Amenity) sections(I-Amenity)", "instance": {"id": "1161", "words": ["what", "kosher", "restaurants", "still", "have", "smoking", "sections"], "labels": ["O", "B-Cuisine", "O", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Dish, Price, Hours, Cuisine, Restaurant Name, Location, Amenity and O.\nSentence: what kosher restaurants still have smoking sections", "prompt_labels": "what(O) kosher(B-Cuisine) restaurants(O) still(O) have(O) smoking(B-Amenity) sections(I-Amenity)"}, "label_list": ["Rating", "Dish", "Price", "Hours", "Cuisine", "Restaurant Name", "Location", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 49268, 11, 8650, 11, 30192, 11, 81961, 11, 26568, 4076, 11, 10067, 11, 3383, 56685, 323, 507, 627, 85664, 25, 1148, 98740, 15926, 2103, 617, 20149, 14491, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "204", "dataset": "crossner_ai", "split": "dev", "prediction": "Sepp(B-researcher) Hochreiter(I-researcher),(O) Y.(B-researcher) Bengio(I-researcher),(O) P.(B-researcher) Frasconi(I-researcher),(O) and(O) J\u00fcrgen(B-researcher) Schmidhuber(I-researcher).(O)", "instance": {"id": "204", "words": ["Sepp", "Hochreiter", ",", "Y.", "Bengio", ",", "P.", "Frasconi", ",", "and", "J\u00fcrgen", "Schmidhuber", "."], "labels": ["B-researcher", "I-researcher", "O", "B-researcher", "I-researcher", "O", "B-researcher", "I-researcher", "O", "O", "B-researcher", "I-researcher", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, conference, organization, person, field, metric, university, algorithm, country, location, researcher, product, task and O.\nSentence: Sepp Hochreiter , Y. Bengio , P. Frasconi , and J\u00fcrgen Schmidhuber .", "prompt_labels": "Sepp(B-researcher) Hochreiter(I-researcher) ,(O) Y.(B-researcher) Bengio(I-researcher) ,(O) P.(B-researcher) Frasconi(I-researcher) ,(O) and(O) J\u00fcrgen(B-researcher) Schmidhuber(I-researcher) .(O)"}, "label_list": ["programming language", "conference", "organization", "person", "field", "metric", "university", "algorithm", "country", "location", "researcher", "product", "task"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 15840, 4221, 11, 10017, 11, 7471, 11, 1732, 11, 2115, 11, 18767, 11, 12374, 11, 12384, 11, 3224, 11, 3813, 11, 32185, 11, 2027, 11, 3465, 323, 507, 627, 85664, 25, 1369, 604, 68875, 265, 2058, 1174, 816, 13, 26316, 822, 1174, 393, 13, 2939, 300, 86310, 1174, 323, 622, 2448, 2026, 268, 5124, 16497, 27780, 261, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "347", "dataset": "crossner_literature", "split": "dev", "prediction": "In(O) The(B-book) Birds(I-book),(O) Melanie(B-person) Daniels(I-person),(O) a(O) young(O) socialite(O),(O) meets(O) lawyer(O) Mitch(B-writer) Brenner(I-writer) ((O) Rod(B-writer) Taylor(I-writer) )(O) in(O) a(O) bird(O) shop(O) ;(O) Jessica(B-person) Tandy(I-person) plays(O) his(O) possessive(O) mother(O).(O)", "instance": {"id": "347", "words": ["In", "The", "Birds", ",", "Melanie", "Daniels", ",", "a", "young", "socialite", ",", "meets", "lawyer", "Mitch", "Brenner", "(", "Rod", "Taylor", ")", "in", "a", "bird", "shop", ";", "Jessica", "Tandy", "plays", "his", "possessive", "mother", "."], "labels": ["O", "B-book", "I-book", "O", "B-person", "I-person", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, award, location, book, poem, person, organization, literary genre, writer, magazine, country and O.\nSentence: In The Birds , Melanie Daniels , a young socialite , meets lawyer Mitch Brenner ( Rod Taylor ) in a bird shop ; Jessica Tandy plays his possessive mother .", "prompt_labels": "In(O) The(B-book) Birds(I-book) ,(O) Melanie(B-person) Daniels(I-person) ,(O) a(O) young(O) socialite(O) ,(O) meets(O) lawyer(O) Mitch(B-person) Brenner(I-person) ((O) Rod(B-person) Taylor(I-person) )(O) in(O) a(O) bird(O) shop(O) ;(O) Jessica(B-person) Tandy(I-person) plays(O) his(O) possessive(O) mother(O) .(O)"}, "label_list": ["event", "award", "location", "book", "poem", "person", "organization", "literary genre", "writer", "magazine", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 10292, 11, 3813, 11, 2363, 11, 33894, 11, 1732, 11, 7471, 11, 32465, 17779, 11, 7061, 11, 14756, 11, 3224, 323, 507, 627, 85664, 25, 763, 578, 57628, 1174, 85350, 50635, 1174, 264, 3995, 3674, 635, 1174, 20628, 15779, 23406, 44808, 1215, 320, 13611, 16844, 883, 304, 264, 12224, 8221, 2652, 33467, 350, 13634, 11335, 813, 15575, 535, 6691, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "176", "dataset": "crossner_music", "split": "dev", "prediction": "Besides(O) fronting(O) his(O) own(O) band(O) and(O) rap(B-music genre) projects(I-music genre),(O) Ice-T(B-musical artist) has(O) also(O) collaborated(O) with(O) other(O) hard(B-music genre) rock(I-music genre) and(O) metal(B-music genre) bands(O),(O) such(O) as(O) Icepick(B-band),(O) Mot\u00f6rhead(B-band),(O) Slayer(B-band),(O) Pro-Pain(B-band),(O) and(O) Six(B-band) Feet(I-band) Under(I-band).(O)", "instance": {"id": "176", "words": ["Besides", "fronting", "his", "own", "band", "and", "rap", "projects", ",", "Ice-T", "has", "also", "collaborated", "with", "other", "hard", "rock", "and", "metal", "bands", ",", "such", "as", "Icepick", ",", "Mot\u00f6rhead", ",", "Slayer", ",", "Pro-Pain", ",", "and", "Six", "Feet", "Under", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-music genre", "O", "O", "B-musical artist", "O", "O", "O", "O", "O", "B-music genre", "I-music genre", "O", "B-music genre", "O", "O", "O", "O", "B-band", "O", "B-band", "O", "B-band", "O", "B-band", "O", "O", "B-band", "I-band", "I-band", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, event, music genre, location, song, musical artist, organization, award, band, musical instrument, country, album and O.\nSentence: Besides fronting his own band and rap projects , Ice-T has also collaborated with other hard rock and metal bands , such as Icepick , Mot\u00f6rhead , Slayer , Pro-Pain , and Six Feet Under .", "prompt_labels": "Besides(O) fronting(O) his(O) own(O) band(O) and(O) rap(B-music genre) projects(O) ,(O) Ice-T(B-musical artist) has(O) also(O) collaborated(O) with(O) other(O) hard(B-music genre) rock(I-music genre) and(O) metal(B-music genre) bands(O) ,(O) such(O) as(O) Icepick(B-band) ,(O) Mot\u00f6rhead(B-band) ,(O) Slayer(B-band) ,(O) Pro-Pain(B-band) ,(O) and(O) Six(B-band) Feet(I-band) Under(I-band) .(O)"}, "label_list": ["person", "event", "music genre", "location", "song", "musical artist", "organization", "award", "band", "musical instrument", "country", "album"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 1567, 11, 4731, 17779, 11, 3813, 11, 5609, 11, 18273, 10255, 11, 7471, 11, 10292, 11, 7200, 11, 18273, 14473, 11, 3224, 11, 8176, 323, 507, 627, 85664, 25, 31909, 4156, 287, 813, 1866, 7200, 323, 7477, 7224, 1174, 20534, 9469, 706, 1101, 78174, 449, 1023, 2653, 7091, 323, 9501, 21562, 1174, 1778, 439, 20534, 30345, 1174, 19514, 9603, 2025, 1174, 75723, 1174, 1322, 9483, 467, 1174, 323, 19198, 62289, 9636, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1508", "dataset": "mit-restaurant", "split": "dev", "prediction": "who(O) has(O) the(O) best(B-Rating) selection(O) of(O) micro(B-Dish) brew(I-Dish) and(O) imported(B-Dish) beers(I-Dish)", "instance": {"id": "1508", "words": ["who", "has", "the", "best", "selection", "of", "micro", "brew", "and", "imported", "beers"], "labels": ["O", "O", "O", "B-Rating", "I-Rating", "O", "B-Dish", "I-Dish", "O", "B-Dish", "I-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Amenity, Dish, Restaurant Name, Cuisine, Price, Hours, Location and O.\nSentence: who has the best selection of micro brew and imported beers", "prompt_labels": "who(O) has(O) the(O) best(B-Rating) selection(I-Rating) of(O) micro(B-Dish) brew(I-Dish) and(O) imported(B-Dish) beers(I-Dish)"}, "label_list": ["Rating", "Amenity", "Dish", "Restaurant Name", "Cuisine", "Price", "Hours", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 3383, 56685, 11, 49268, 11, 26568, 4076, 11, 81961, 11, 8650, 11, 30192, 11, 10067, 323, 507, 627, 85664, 25, 889, 706, 279, 1888, 6727, 315, 8162, 17109, 323, 25973, 38066, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "310", "dataset": "crossner_music", "split": "dev", "prediction": "Sangeet(B-organization) Natak(I-organization) Akademi(I-organization) is(O) the(O) national(O) level(O) academy(O) for(O) performing(O) arts(O) set(O) up(O) by(O) the(O) Government(O) of(O) India(O) in(O) 1952(O),(O) which(O) bestows(O) Sangeet(B-award) Natak(I-award) Akademi(I-award) Award(I-award) as(O) the(O) highest(O) official(O) Indian(O) goernment(O)'s(O) recognition(O) given(O) to(O) practicing(O) artists(O),(O) Sattriya(B-organization) Centre(I-organization),(O) Kathak(B-organization) Kendra(I-organization) ((O) National(B-organization) Institute(I-organization) of(I-organization) Kathak(I-organization) Dance(I-organization) )(O) at(O) New(B-location) Delhi(I-location),(O) Centre(B-organization) for(I-organization) Kutiyattam(I-organization) at(O) Thiruvananthapuram(B-location),(O) Chhau(B-organization) Centre(I-organization) at(O) Baripada(B-location) in(O) Jamshedpur(B-location),(O) and(O) the(O) Northeast(B-organization) Centre(I-organization).(O)", "instance": {"id": "310", "words": ["Sangeet", "Natak", "Akademi", "is", "the", "national", "level", "academy", "for", "performing", "arts", "set", "up", "by", "the", "Government", "of", "India", "in", "1952", ",", "which", "bestows", "Sangeet", "Natak", "Akademi", "Award", "as", "the", "highest", "official", "Indian", "goernment", "'s", "recognition", "given", "to", "practicing", "artists", ",", "Sattriya", "Centre", ",", "Kathak", "Kendra", "(", "National", "Institute", "of", "Kathak", "Dance", ")", "at", "New", "Delhi", ",", "Centre", "for", "Kutiyattam", "at", "Thiruvananthapuram", ",", "Chhau", "Centre", "at", "Baripada", "in", "Jamshedpur", ",", "and", "the", "Northeast", "Centre", "."], "labels": ["B-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-country", "O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "B-organization", "I-organization", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-location", "I-location", "O", "B-organization", "I-organization", "I-organization", "O", "B-location", "O", "B-organization", "I-organization", "O", "B-location", "O", "B-location", "O", "O", "O", "B-organization", "I-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, musical artist, organization, award, country, person, location, event, music genre, band, musical instrument, song and O.\nSentence: Sangeet Natak Akademi is the national level academy for performing arts set up by the Government of India in 1952 , which bestows Sangeet Natak Akademi Award as the highest official Indian goernment 's recognition given to practicing artists , Sattriya Centre , Kathak Kendra ( National Institute of Kathak Dance ) at New Delhi , Centre for Kutiyattam at Thiruvananthapuram , Chhau Centre at Baripada in Jamshedpur , and the Northeast Centre .", "prompt_labels": "Sangeet(B-organization) Natak(I-organization) Akademi(I-organization) is(O) the(O) national(O) level(O) academy(O) for(O) performing(O) arts(O) set(O) up(O) by(O) the(O) Government(O) of(O) India(B-country) in(O) 1952(O) ,(O) which(O) bestows(O) Sangeet(B-award) Natak(I-award) Akademi(I-award) Award(I-award) as(O) the(O) highest(O) official(O) Indian(O) goernment(O) 's(O) recognition(O) given(O) to(O) practicing(O) artists(O) ,(O) Sattriya(B-organization) Centre(I-organization) ,(O) Kathak(B-organization) Kendra(I-organization) ((O) National(B-organization) Institute(I-organization) of(I-organization) Kathak(I-organization) Dance(I-organization) )(O) at(O) New(B-location) Delhi(I-location) ,(O) Centre(B-organization) for(I-organization) Kutiyattam(I-organization) at(O) Thiruvananthapuram(B-location) ,(O) Chhau(B-organization) Centre(I-organization) at(O) Baripada(B-location) in(O) Jamshedpur(B-location) ,(O) and(O) the(O) Northeast(B-organization) Centre(I-organization) .(O)"}, "label_list": ["album", "musical artist", "organization", "award", "country", "person", "location", "event", "music genre", "band", "musical instrument", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8176, 11, 18273, 10255, 11, 7471, 11, 10292, 11, 3224, 11, 1732, 11, 3813, 11, 1567, 11, 4731, 17779, 11, 7200, 11, 18273, 14473, 11, 5609, 323, 507, 627, 85664, 25, 328, 853, 295, 452, 69828, 16762, 329, 22530, 374, 279, 5426, 2237, 44445, 369, 16785, 19071, 743, 709, 555, 279, 10423, 315, 6890, 304, 220, 6280, 17, 1174, 902, 1888, 4336, 328, 853, 295, 452, 69828, 16762, 329, 22530, 17768, 439, 279, 8592, 4033, 7904, 733, 944, 479, 364, 82, 18324, 2728, 311, 36666, 13820, 1174, 328, 3064, 80574, 14821, 1174, 33995, 587, 39217, 969, 320, 5165, 10181, 315, 33995, 587, 30704, 883, 520, 1561, 22767, 1174, 14821, 369, 97007, 16618, 1617, 309, 520, 666, 404, 12328, 29718, 339, 100140, 309, 1174, 921, 71, 2933, 14821, 520, 4821, 575, 2649, 304, 20614, 70561, 26047, 1174, 323, 279, 45680, 14821, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "721", "dataset": "mit-restaurant", "split": "dev", "prediction": "im(O) hungry(O) find(O) me(O) a(O) restaurant(O) with(O) large(B-Amenity) portions(I-Amenity)", "instance": {"id": "721", "words": ["im", "hungry", "find", "me", "a", "restaurant", "with", "large", "portions"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Price, Cuisine, Location, Restaurant Name, Amenity, Rating, Hours and O.\nSentence: im hungry find me a restaurant with large portions", "prompt_labels": "im(O) hungry(O) find(O) me(O) a(O) restaurant(O) with(O) large(B-Amenity) portions(I-Amenity)"}, "label_list": ["Dish", "Price", "Cuisine", "Location", "Restaurant Name", "Amenity", "Rating", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 8650, 11, 81961, 11, 10067, 11, 26568, 4076, 11, 3383, 56685, 11, 19767, 11, 30192, 323, 507, 627, 85664, 25, 737, 30056, 1505, 757, 264, 10960, 449, 3544, 19885, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "326", "dataset": "crossner_politics", "split": "dev", "prediction": "He(O) was(O) elected(O) as(O) a(O) Fianna(B-political party) F\u00e1il(I-political party) Teachta(O) D\u00e1la(O) ((O) TD(O) )(O) for(O) the(O) constituency(O) of(O) Dublin(B-location) North-West(I-location) at(O) the(O) 1997(B-election) Irish(I-election) general(I-election) election(I-election),(O) defeating(O) the(O) sitting(O) Fine(B-political party) Gael(I-political party) TD(O) Mary(B-politician) Flaherty(I-politician) to(O) win(O) a(O) second(O) seat(O) for(O) the(O) Fianna(B-political party) F\u00e1il(I-political party) in(O) the(O) 4-seater(O) constituency(O).(O)", "instance": {"id": "326", "words": ["He", "was", "elected", "as", "a", "Fianna", "F\u00e1il", "Teachta", "D\u00e1la", "(", "TD", ")", "for", "the", "constituency", "of", "Dublin", "North-West", "at", "the", "1997", "Irish", "general", "election", ",", "defeating", "the", "sitting", "Fine", "Gael", "TD", "Mary", "Flaherty", "to", "win", "a", "second", "seat", "for", "the", "Fianna", "F\u00e1il", "in", "the", "4-seater", "constituency", "."], "labels": ["O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "B-political party", "O", "O", "O", "O", "O", "B-location", "I-location", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "B-politician", "I-politician", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, organization, event, political party, country, politician, person, election and O.\nSentence: He was elected as a Fianna F\u00e1il Teachta D\u00e1la ( TD ) for the constituency of Dublin North-West at the 1997 Irish general election , defeating the sitting Fine Gael TD Mary Flaherty to win a second seat for the Fianna F\u00e1il in the 4-seater constituency .", "prompt_labels": "He(O) was(O) elected(O) as(O) a(O) Fianna(B-political party) F\u00e1il(I-political party) Teachta(I-political party) D\u00e1la(I-political party) ((O) TD(B-political party) )(O) for(O) the(O) constituency(O) of(O) Dublin(B-location) North-West(I-location) at(O) the(O) 1997(B-election) Irish(I-election) general(I-election) election(I-election) ,(O) defeating(O) the(O) sitting(O) Fine(B-political party) Gael(I-political party) TD(I-political party) Mary(B-politician) Flaherty(I-politician) to(O) win(O) a(O) second(O) seat(O) for(O) the(O) Fianna(B-political party) F\u00e1il(I-political party) in(O) the(O) 4-seater(O) constituency(O) .(O)"}, "label_list": ["location", "organization", "event", "political party", "country", "politician", "person", "election"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 7471, 11, 1567, 11, 5054, 4717, 11, 3224, 11, 37038, 11, 1732, 11, 6355, 323, 507, 627, 85664, 25, 1283, 574, 16689, 439, 264, 40971, 12930, 435, 1995, 321, 70377, 2629, 423, 119756, 320, 28816, 883, 369, 279, 65739, 315, 33977, 4892, 61861, 520, 279, 220, 2550, 22, 18088, 4689, 6355, 1174, 54216, 279, 11961, 31253, 89738, 28816, 10455, 3061, 1494, 1368, 311, 3243, 264, 2132, 10954, 369, 279, 40971, 12930, 435, 1995, 321, 304, 279, 220, 19, 7962, 977, 65739, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "6", "dataset": "crossner_literature", "split": "dev", "prediction": "His(O) main(O) work(O) was(O) the(O) libretto(O) for(O) The(B-book) Veiled(I-book) Prophet(I-book),(O) a(O) Romantic(B-literary genre) Opera(I-literary genre) in(O) 3(O) acts(O) composed(O) by(O) Charles(B-writer) Villiers(I-writer) Stanford(I-writer),(O) adapted(O) from(O) the(O) homonymous(O) ballad(O) in(O) Thomas(B-writer) Moore(I-writer) oriental(B-literary genre) romance(I-literary genre) Lalla-Rookh(B-poem),(O) published(O) 1890(O).(O)", "instance": {"id": "6", "words": ["His", "main", "work", "was", "the", "libretto", "for", "The", "Veiled", "Prophet", ",", "a", "Romantic", "Opera", "in", "3", "acts", "composed", "by", "Charles", "Villiers", "Stanford", ",", "adapted", "from", "the", "homonymous", "ballad", "in", "Thomas", "Moore", "oriental", "romance", "Lalla-Rookh", ",", "published", "1890", "."], "labels": ["O", "O", "O", "O", "O", "B-literary genre", "O", "O", "O", "O", "O", "O", "B-literary genre", "I-literary genre", "O", "O", "O", "O", "O", "B-person", "I-person", "I-person", "O", "O", "O", "O", "O", "O", "O", "B-writer", "I-writer", "O", "O", "B-poem", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: book, magazine, award, writer, organization, event, person, poem, country, location, literary genre and O.\nSentence: His main work was the libretto for The Veiled Prophet , a Romantic Opera in 3 acts composed by Charles Villiers Stanford , adapted from the homonymous ballad in Thomas Moore oriental romance Lalla-Rookh , published 1890 .", "prompt_labels": "His(O) main(O) work(O) was(O) the(O) libretto(B-literary genre) for(O) The(O) Veiled(O) Prophet(O) ,(O) a(O) Romantic(B-literary genre) Opera(I-literary genre) in(O) 3(O) acts(O) composed(O) by(O) Charles(B-person) Villiers(I-person) Stanford(I-person) ,(O) adapted(O) from(O) the(O) homonymous(O) ballad(O) in(O) Thomas(B-writer) Moore(I-writer) oriental(O) romance(O) Lalla-Rookh(B-poem) ,(O) published(O) 1890(O) .(O)"}, "label_list": ["book", "magazine", "award", "writer", "organization", "event", "person", "poem", "country", "location", "literary genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2363, 11, 14756, 11, 10292, 11, 7061, 11, 7471, 11, 1567, 11, 1732, 11, 33894, 11, 3224, 11, 3813, 11, 32465, 17779, 323, 507, 627, 85664, 25, 5414, 1925, 990, 574, 279, 3127, 2171, 998, 369, 578, 23404, 2230, 37728, 1174, 264, 76830, 39679, 304, 220, 18, 14385, 24306, 555, 15274, 16959, 4918, 31788, 1174, 30464, 505, 279, 5105, 9956, 5041, 329, 304, 11355, 20832, 11744, 278, 30363, 445, 21575, 11151, 1982, 71, 1174, 4756, 220, 9378, 15, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "279", "dataset": "crossner_science", "split": "dev", "prediction": "Triple(O) conjunctions(O) between(O) the(O) inferior(O) planets(O) Mercury(B-astronomical object) and(O) Venus(B-astronomical object) and(O) the(O) superior(O) planets(O) Jupiter(B-astronomical object),(O) Saturn(B-astronomical object),(O) Uranus(B-astronomical object),(O) Neptune(B-astronomical object),(O) dwarf(O) planet(O) Pluto(B-astronomical object) or(O) with(O) star(O) s(O) take(O) place(O) when(O) these(O) objects(O) are(O) at(O) the(O) same(O) time(O) in(O) conjunction(O) to(O) Sun(B-astronomical object) while(O) Mercury(B-astronomical object) or(O) Venus(B-astronomical object) are(O) at(O) inferior(O) conjunction(O).(O)", "instance": {"id": "279", "words": ["Triple", "conjunctions", "between", "the", "inferior", "planets", "Mercury", "and", "Venus", "and", "the", "superior", "planets", "Jupiter", ",", "Saturn", ",", "Uranus", ",", "Neptune", ",", "dwarf", "planet", "Pluto", "or", "with", "star", "s", "take", "place", "when", "these", "objects", "are", "at", "the", "same", "time", "in", "conjunction", "to", "Sun", "while", "Mercury", "or", "Venus", "are", "at", "inferior", "conjunction", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-astronomical object", "O", "B-astronomical object", "O", "O", "O", "O", "B-astronomical object", "O", "B-astronomical object", "O", "B-astronomical object", "O", "B-astronomical object", "O", "O", "O", "B-astronomical object", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-astronomical object", "O", "B-astronomical object", "O", "B-astronomical object", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: protein, chemical compound, discipline, person, organization, chemical element, scientist, theory, enzyme, academic journal, event, location, astronomical object, country, university, award and O.\nSentence: Triple conjunctions between the inferior planets Mercury and Venus and the superior planets Jupiter , Saturn , Uranus , Neptune , dwarf planet Pluto or with star s take place when these objects are at the same time in conjunction to Sun while Mercury or Venus are at inferior conjunction .", "prompt_labels": "Triple(O) conjunctions(O) between(O) the(O) inferior(O) planets(O) Mercury(B-astronomical object) and(O) Venus(B-astronomical object) and(O) the(O) superior(O) planets(O) Jupiter(B-astronomical object) ,(O) Saturn(B-astronomical object) ,(O) Uranus(B-astronomical object) ,(O) Neptune(B-astronomical object) ,(O) dwarf(O) planet(O) Pluto(B-astronomical object) or(O) with(O) star(O) s(O) take(O) place(O) when(O) these(O) objects(O) are(O) at(O) the(O) same(O) time(O) in(O) conjunction(O) to(O) Sun(B-astronomical object) while(O) Mercury(B-astronomical object) or(O) Venus(B-astronomical object) are(O) at(O) inferior(O) conjunction(O) .(O)"}, "label_list": ["protein", "chemical compound", "discipline", "person", "organization", "chemical element", "scientist", "theory", "enzyme", "academic journal", "event", "location", "astronomical object", "country", "university", "award"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 13128, 11, 11742, 24549, 11, 26434, 11, 1732, 11, 7471, 11, 11742, 2449, 11, 28568, 11, 10334, 11, 49242, 11, 14584, 8486, 11, 1567, 11, 3813, 11, 87283, 1665, 11, 3224, 11, 12374, 11, 10292, 323, 507, 627, 85664, 25, 37749, 32546, 82, 1990, 279, 38279, 33975, 44662, 323, 50076, 323, 279, 16757, 33975, 50789, 1174, 50253, 1174, 80770, 355, 1174, 80724, 1174, 50561, 11841, 78681, 477, 449, 6917, 274, 1935, 2035, 994, 1521, 6302, 527, 520, 279, 1890, 892, 304, 32546, 311, 8219, 1418, 44662, 477, 50076, 527, 520, 38279, 32546, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "274", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) the(B-title) half(I-title) baked(I-title) cover(I-title)", "instance": {"id": "274", "words": ["show", "me", "the", "half", "baked", "cover"], "labels": ["O", "O", "O", "B-title", "I-title", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, actor, rating, average ratings, director, song, plot, genre, character, trailer, title, review and O.\nSentence: show me the half baked cover", "prompt_labels": "show(O) me(O) the(O) half(B-title) baked(I-title) cover(O)"}, "label_list": ["year", "actor", "rating", "average ratings", "director", "song", "plot", "genre", "character", "trailer", "title", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 12360, 11, 10959, 11, 5578, 18594, 11, 7690, 11, 5609, 11, 7234, 11, 17779, 11, 3752, 11, 19809, 11, 2316, 11, 3477, 323, 507, 627, 85664, 25, 1501, 757, 279, 4376, 41778, 3504, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "173", "dataset": "crossner_politics", "split": "dev", "prediction": "Palestinian(O) groups(O) that(O) have(O) been(O) involved(O) in(O) politically(O) motivated(O) violence(O) include(O) the(O) Palestinian(B-political party) Liberation(I-political party) Organization(I-political party) ((O) PLO(B-political party) )(O),(O) Fatah(B-political party),(O) the(O) Popular(B-political party) Front(I-political party) for(I-political party) the(I-political party) Liberation(I-political party) of(I-political party) Palestine(I-political party) ((O) PFLP(B-political party) )(O),(O) the(O) Popular(B-political party) Front(I-political party) for(I-political party) the(I-political party) Liberation(I-political party) of(I-political party) Palestine(I-political party) -(O) General(O) Command(O) ((O) PFLP-GC(B-political party) )(O),(O) the(O) Democratic(B-political party) Front(I-political party) for(I-political party) the(I-political party) Liberation(I-political party) of(I-political party) Palestine(I-political party),(O) the(O) Abu(B-political party) Nidal(I-political party) Organization(I-political party),(O) the(O) Palestinian(B-political party) Islamic(I-political party) Jihad(I-political party),(O) and(O) Hamas(B-political party).(O)", "instance": {"id": "173", "words": ["Palestinian", "groups", "that", "have", "been", "involved", "in", "politically", "motivated", "violence", "include", "the", "Palestinian", "Liberation", "Organization", "(", "PLO", ")", ",", "Fatah", ",", "the", "Popular", "Front", "for", "the", "Liberation", "of", "Palestine", "(", "PFLP", ")", ",", "the", "Popular", "Front", "for", "the", "Liberation", "of", "Palestine", "-", "General", "Command", "(", "PFLP-GC", ")", ",", "the", "Democratic", "Front", "for", "the", "Liberation", "of", "Palestine", ",", "the", "Abu", "Nidal", "Organization", ",", "the", "Palestinian", "Islamic", "Jihad", ",", "and", "Hamas", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "B-organization", "O", "O", "B-political party", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "B-political party", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "B-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, political party, election, location, event, politician, country, organization and O.\nSentence: Palestinian groups that have been involved in politically motivated violence include the Palestinian Liberation Organization ( PLO ) , Fatah , the Popular Front for the Liberation of Palestine ( PFLP ) , the Popular Front for the Liberation of Palestine - General Command ( PFLP-GC ) , the Democratic Front for the Liberation of Palestine , the Abu Nidal Organization , the Palestinian Islamic Jihad , and Hamas .", "prompt_labels": "Palestinian(O) groups(O) that(O) have(O) been(O) involved(O) in(O) politically(O) motivated(O) violence(O) include(O) the(O) Palestinian(B-organization) Liberation(I-organization) Organization(I-organization) ((O) PLO(B-organization) )(O) ,(O) Fatah(B-political party) ,(O) the(O) Popular(B-political party) Front(I-political party) for(I-political party) the(I-political party) Liberation(I-political party) of(I-political party) Palestine(I-political party) ((O) PFLP(B-political party) )(O) ,(O) the(O) Popular(B-organization) Front(I-organization) for(I-organization) the(I-organization) Liberation(I-organization) of(I-organization) Palestine(I-organization) -(I-organization) General(I-organization) Command(I-organization) ((O) PFLP-GC(B-organization) )(O) ,(O) the(O) Democratic(B-political party) Front(I-political party) for(I-political party) the(I-political party) Liberation(I-political party) of(I-political party) Palestine(I-political party) ,(O) the(O) Abu(B-organization) Nidal(I-organization) Organization(I-organization) ,(O) the(O) Palestinian(B-organization) Islamic(I-organization) Jihad(I-organization) ,(O) and(O) Hamas(B-organization) .(O)"}, "label_list": ["person", "political party", "election", "location", "event", "politician", "country", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 5054, 4717, 11, 6355, 11, 3813, 11, 1567, 11, 37038, 11, 3224, 11, 7471, 323, 507, 627, 85664, 25, 22596, 5315, 430, 617, 1027, 6532, 304, 31205, 27762, 9349, 2997, 279, 22596, 72984, 21021, 320, 393, 1623, 883, 1174, 435, 460, 71, 1174, 279, 32495, 15248, 369, 279, 72984, 315, 42034, 320, 393, 6254, 47, 883, 1174, 279, 32495, 15248, 369, 279, 72984, 315, 42034, 482, 3331, 7498, 320, 393, 6254, 47, 12279, 34, 883, 1174, 279, 11650, 15248, 369, 279, 72984, 315, 42034, 1174, 279, 31229, 452, 26966, 21021, 1174, 279, 22596, 15558, 91239, 1174, 323, 41741, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "968", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) a(O) horror(B-genre) movie(O) from(O) the(O) 1950s(B-year)", "instance": {"id": "968", "words": ["show", "me", "a", "horror", "movie", "from", "the", "1950s"], "labels": ["O", "O", "O", "B-genre", "O", "O", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, song, character, year, genre, plot, trailer, average ratings, director, rating, title, review and O.\nSentence: show me a horror movie from the 1950s", "prompt_labels": "show(O) me(O) a(O) horror(B-genre) movie(O) from(O) the(O) 1950s(B-year)"}, "label_list": ["actor", "song", "character", "year", "genre", "plot", "trailer", "average ratings", "director", "rating", "title", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 5609, 11, 3752, 11, 1060, 11, 17779, 11, 7234, 11, 19809, 11, 5578, 18594, 11, 7690, 11, 10959, 11, 2316, 11, 3477, 323, 507, 627, 85664, 25, 1501, 757, 264, 22169, 5818, 505, 279, 220, 6280, 15, 82, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1036", "dataset": "mit-movie", "split": "dev", "prediction": "find(O) a(O) review(O) for(O) the(B-title) blue(I-title) bird(I-title)", "instance": {"id": "1036", "words": ["find", "a", "review", "for", "the", "blue", "bird"], "labels": ["B-average ratings", "I-average ratings", "I-average ratings", "I-average ratings", "I-average ratings", "I-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, character, plot, director, average ratings, year, rating, genre, trailer, title, song, review and O.\nSentence: find a review for the blue bird", "prompt_labels": "find(B-average ratings) a(I-average ratings) review(I-average ratings) for(I-average ratings) the(I-average ratings) blue(I-average ratings) bird(I-average ratings)"}, "label_list": ["actor", "character", "plot", "director", "average ratings", "year", "rating", "genre", "trailer", "title", "song", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 3752, 11, 7234, 11, 7690, 11, 5578, 18594, 11, 1060, 11, 10959, 11, 17779, 11, 19809, 11, 2316, 11, 5609, 11, 3477, 323, 507, 627, 85664, 25, 1505, 264, 3477, 369, 279, 6437, 12224, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "170", "dataset": "mit-restaurant", "split": "dev", "prediction": "can(O) you(O) find(O) me(O) some(O) take(B-Amenity) out(I-Amenity) ribs(B-Dish)", "instance": {"id": "170", "words": ["can", "you", "find", "me", "some", "take", "out", "ribs"], "labels": ["O", "O", "O", "O", "O", "B-Amenity", "I-Amenity", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Price, Rating, Dish, Location, Amenity, Hours, Restaurant Name and O.\nSentence: can you find me some take out ribs", "prompt_labels": "can(O) you(O) find(O) me(O) some(O) take(B-Amenity) out(I-Amenity) ribs(B-Dish)"}, "label_list": ["Cuisine", "Price", "Rating", "Dish", "Location", "Amenity", "Hours", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 8650, 11, 19767, 11, 49268, 11, 10067, 11, 3383, 56685, 11, 30192, 11, 26568, 4076, 323, 507, 627, 85664, 25, 649, 499, 1505, 757, 1063, 1935, 704, 56249, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "180", "dataset": "crossner_ai", "split": "dev", "prediction": "Along(O) with(O) Geoffrey(B-researcher) Hinton(I-researcher) and(O) Yann(B-researcher) LeCun(I-researcher),(O) Bengio(B-researcher) is(O) considered(O) by(O) Cade(B-researcher) Metz(I-researcher) as(O) one(O) of(O) the(O) three(O) people(O) most(O) responsible(O) for(O) the(O) advancement(O) of(O) deep(B-field) learning(I-field) during(O) the(O) 1990s(O) and(O) 2000s(O).(O)", "instance": {"id": "180", "words": ["Along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Bengio", "is", "considered", "by", "Cade", "Metz", "as", "one", "of", "the", "three", "people", "most", "responsible", "for", "the", "advancement", "of", "deep", "learning", "during", "the", "1990s", "and", "2000s", "."], "labels": ["O", "O", "B-researcher", "I-researcher", "O", "B-researcher", "I-researcher", "O", "B-researcher", "O", "O", "O", "B-researcher", "I-researcher", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-field", "I-field", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, algorithm, conference, organization, programming language, university, person, researcher, metric, task, product, country, location and O.\nSentence: Along with Geoffrey Hinton and Yann LeCun , Bengio is considered by Cade Metz as one of the three people most responsible for the advancement of deep learning during the 1990s and 2000s .", "prompt_labels": "Along(O) with(O) Geoffrey(B-researcher) Hinton(I-researcher) and(O) Yann(B-researcher) LeCun(I-researcher) ,(O) Bengio(B-researcher) is(O) considered(O) by(O) Cade(B-researcher) Metz(I-researcher) as(O) one(O) of(O) the(O) three(O) people(O) most(O) responsible(O) for(O) the(O) advancement(O) of(O) deep(B-field) learning(I-field) during(O) the(O) 1990s(O) and(O) 2000s(O) .(O)"}, "label_list": ["field", "algorithm", "conference", "organization", "programming language", "university", "person", "researcher", "metric", "task", "product", "country", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2115, 11, 12384, 11, 10017, 11, 7471, 11, 15840, 4221, 11, 12374, 11, 1732, 11, 32185, 11, 18767, 11, 3465, 11, 2027, 11, 3224, 11, 3813, 323, 507, 627, 85664, 25, 32944, 449, 89239, 473, 7454, 323, 816, 1036, 2009, 34, 359, 1174, 26316, 822, 374, 6646, 555, 356, 1037, 6344, 89, 439, 832, 315, 279, 2380, 1274, 1455, 8647, 369, 279, 50925, 315, 5655, 6975, 2391, 279, 220, 2550, 15, 82, 323, 220, 1049, 15, 82, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1680", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) crime(B-genre) movies(O) from(O) the(O) 2000(B-year) s(I-year) that(O) were(O) rated(O) nc(B-rating) 17(I-rating)", "instance": {"id": "1680", "words": ["list", "crime", "movies", "from", "the", "2000", "s", "that", "were", "rated", "nc", "17"], "labels": ["O", "B-genre", "O", "O", "O", "B-year", "I-year", "O", "O", "O", "B-rating", "I-rating"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, character, plot, year, title, actor, genre, average ratings, song, director, rating, review and O.\nSentence: list crime movies from the 2000 s that were rated nc 17", "prompt_labels": "list(O) crime(B-genre) movies(O) from(O) the(O) 2000(B-year) s(I-year) that(O) were(O) rated(O) nc(B-rating) 17(I-rating)"}, "label_list": ["trailer", "character", "plot", "year", "title", "actor", "genre", "average ratings", "song", "director", "rating", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 3752, 11, 7234, 11, 1060, 11, 2316, 11, 12360, 11, 17779, 11, 5578, 18594, 11, 5609, 11, 7690, 11, 10959, 11, 3477, 323, 507, 627, 85664, 25, 1160, 9977, 9698, 505, 279, 220, 1049, 15, 274, 430, 1051, 22359, 26183, 220, 1114, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1241", "dataset": "mit-restaurant", "split": "dev", "prediction": "whats(O) the(O) nearest(B-Location) pizza(B-Cuisine) place(O) that(O) serves(O) anchovies(B-Dish)", "instance": {"id": "1241", "words": ["whats", "the", "nearest", "pizza", "place", "that", "serves", "anchovies"], "labels": ["O", "O", "B-Location", "B-Cuisine", "O", "O", "O", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Restaurant Name, Location, Dish, Price, Hours, Cuisine, Rating and O.\nSentence: whats the nearest pizza place that serves anchovies", "prompt_labels": "whats(O) the(O) nearest(B-Location) pizza(B-Cuisine) place(O) that(O) serves(O) anchovies(B-Dish)"}, "label_list": ["Amenity", "Restaurant Name", "Location", "Dish", "Price", "Hours", "Cuisine", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 26568, 4076, 11, 10067, 11, 49268, 11, 8650, 11, 30192, 11, 81961, 11, 19767, 323, 507, 627, 85664, 25, 41209, 279, 24379, 23317, 2035, 430, 17482, 34330, 12831, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "478", "dataset": "crossner_politics", "split": "dev", "prediction": "He(O) spent(O) some(O) time(O) working(O) abroad(O),(O) notably(O) in(O) a(O) field(O) hospital(O) from(O) 1951(O) to(O) 1952(O) during(O) the(O) Korean(B-event) War(I-event),(O) as(O) leader(O) of(O) the(O) Norwegian(O) sanitary(O) company(O) stationed(O) in(O) Suez(B-location) from(O) 1956(O) to(O) 1957(O) after(O) the(O) Suez(B-event) Crisis(I-event),(O) and(O) as(O) sanitary(O) leader(O) for(O) United(B-organization) Nations(I-organization) Operation(I-organization) in(I-organization) the(I-organization) Congo(I-organization) ((O) intervening(O) in(O) the(O) Congo(B-event) Crisis(I-event),(O) State(B-location) of(I-location) Katanga(I-location) )(O) in(O) 1961(O).(O)", "instance": {"id": "478", "words": ["He", "spent", "some", "time", "working", "abroad", ",", "notably", "in", "a", "field", "hospital", "from", "1951", "to", "1952", "during", "the", "Korean", "War", ",", "as", "leader", "of", "the", "Norwegian", "sanitary", "company", "stationed", "in", "Suez", "from", "1956", "to", "1957", "after", "the", "Suez", "Crisis", ",", "and", "as", "sanitary", "leader", "for", "United", "Nations", "Operation", "in", "the", "Congo", "(", "intervening", "in", "the", "Congo", "Crisis", ",", "State", "of", "Katanga", ")", "in", "1961", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "I-event", "I-event", "I-event", "O", "O", "O", "O", "B-event", "I-event", "O", "B-country", "I-country", "I-country", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, location, person, political party, election, politician, country, organization and O.\nSentence: He spent some time working abroad , notably in a field hospital from 1951 to 1952 during the Korean War , as leader of the Norwegian sanitary company stationed in Suez from 1956 to 1957 after the Suez Crisis , and as sanitary leader for United Nations Operation in the Congo ( intervening in the Congo Crisis , State of Katanga ) in 1961 .", "prompt_labels": "He(O) spent(O) some(O) time(O) working(O) abroad(O) ,(O) notably(O) in(O) a(O) field(O) hospital(O) from(O) 1951(O) to(O) 1952(O) during(O) the(O) Korean(B-event) War(I-event) ,(O) as(O) leader(O) of(O) the(O) Norwegian(O) sanitary(O) company(O) stationed(O) in(O) Suez(B-location) from(O) 1956(O) to(O) 1957(O) after(O) the(O) Suez(B-event) Crisis(I-event) ,(O) and(O) as(O) sanitary(O) leader(O) for(O) United(B-event) Nations(I-event) Operation(I-event) in(I-event) the(I-event) Congo(I-event) ((O) intervening(O) in(O) the(O) Congo(B-event) Crisis(I-event) ,(O) State(B-country) of(I-country) Katanga(I-country) )(O) in(O) 1961(O) .(O)"}, "label_list": ["event", "location", "person", "political party", "election", "politician", "country", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 3813, 11, 1732, 11, 5054, 4717, 11, 6355, 11, 37038, 11, 3224, 11, 7471, 323, 507, 627, 85664, 25, 1283, 7543, 1063, 892, 3318, 22917, 1174, 35146, 304, 264, 2115, 8952, 505, 220, 6280, 16, 311, 220, 6280, 17, 2391, 279, 16526, 5111, 1174, 439, 7808, 315, 279, 45721, 95629, 2883, 63620, 304, 328, 28700, 505, 220, 6280, 21, 311, 220, 6280, 22, 1306, 279, 328, 28700, 46250, 1174, 323, 439, 95629, 7808, 369, 3723, 19687, 17145, 304, 279, 54932, 320, 89501, 304, 279, 54932, 46250, 1174, 3314, 315, 17816, 19934, 883, 304, 220, 5162, 16, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1710", "dataset": "mit-movie", "split": "dev", "prediction": "looking(O) for(O) an(O) ok(B-average ratings) terrorist(B-plot) film(O) to(O) watch(O)", "instance": {"id": "1710", "words": ["looking", "for", "an", "ok", "terrorist", "film", "to", "watch"], "labels": ["O", "O", "O", "B-average ratings", "B-plot", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, review, actor, year, plot, director, character, song, trailer, title, genre, rating and O.\nSentence: looking for an ok terrorist film to watch", "prompt_labels": "looking(O) for(O) an(O) ok(B-average ratings) terrorist(B-plot) film(O) to(O) watch(O)"}, "label_list": ["average ratings", "review", "actor", "year", "plot", "director", "character", "song", "trailer", "title", "genre", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 3477, 11, 12360, 11, 1060, 11, 7234, 11, 7690, 11, 3752, 11, 5609, 11, 19809, 11, 2316, 11, 17779, 11, 10959, 323, 507, 627, 85664, 25, 3411, 369, 459, 5509, 20320, 4632, 311, 3821, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "868", "dataset": "mit-movie", "split": "dev", "prediction": "find(O) the(O) movie(O) with(O) sean(B-actor) connery(I-actor) as(O) an(O) fbi(B-character) agent(I-character)", "instance": {"id": "868", "words": ["find", "the", "movie", "with", "sean", "connery", "as", "an", "fbi", "agent"], "labels": ["O", "O", "O", "O", "B-actor", "I-actor", "O", "O", "B-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, genre, average ratings, song, plot, director, trailer, year, title, actor, rating, character and O.\nSentence: find the movie with sean connery as an fbi agent", "prompt_labels": "find(O) the(O) movie(O) with(O) sean(B-actor) connery(I-actor) as(O) an(O) fbi(B-plot) agent(I-plot)"}, "label_list": ["review", "genre", "average ratings", "song", "plot", "director", "trailer", "year", "title", "actor", "rating", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 17779, 11, 5578, 18594, 11, 5609, 11, 7234, 11, 7690, 11, 19809, 11, 1060, 11, 2316, 11, 12360, 11, 10959, 11, 3752, 323, 507, 627, 85664, 25, 1505, 279, 5818, 449, 85522, 4635, 727, 439, 459, 282, 8385, 8479, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "378", "dataset": "crossner_science", "split": "dev", "prediction": "The(O) town(O) was(O) frequented(O) by(O) notable(O) Old(B-event) West(I-event) personalities(O),(O) including(O) Dave(B-person) Rudabaugh(I-person),(O) Billy(B-person) the(I-person) Kid(I-person),(O) Pat(B-person) Garrett(I-person),(O) and(O) Shotgun(B-person) John(I-person) Collins(I-person).(O)", "instance": {"id": "378", "words": ["The", "town", "was", "frequented", "by", "notable", "Old", "West", "personalities", ",", "including", "Dave", "Rudabaugh", ",", "Billy", "the", "Kid", ",", "Pat", "Garrett", ",", "and", "Shotgun", "John", "Collins", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "B-person", "I-person", "I-person", "O", "B-person", "I-person", "O", "O", "B-person", "I-person", "I-person", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: academic journal, person, chemical element, location, astronomical object, theory, enzyme, award, scientist, protein, university, organization, event, discipline, chemical compound, country and O.\nSentence: The town was frequented by notable Old West personalities , including Dave Rudabaugh , Billy the Kid , Pat Garrett , and Shotgun John Collins .", "prompt_labels": "The(O) town(O) was(O) frequented(O) by(O) notable(O) Old(O) West(O) personalities(O) ,(O) including(O) Dave(B-person) Rudabaugh(I-person) ,(O) Billy(B-person) the(I-person) Kid(I-person) ,(O) Pat(B-person) Garrett(I-person) ,(O) and(O) Shotgun(B-person) John(I-person) Collins(I-person) .(O)"}, "label_list": ["academic journal", "person", "chemical element", "location", "astronomical object", "theory", "enzyme", "award", "scientist", "protein", "university", "organization", "event", "discipline", "chemical compound", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 14584, 8486, 11, 1732, 11, 11742, 2449, 11, 3813, 11, 87283, 1665, 11, 10334, 11, 49242, 11, 10292, 11, 28568, 11, 13128, 11, 12374, 11, 7471, 11, 1567, 11, 26434, 11, 11742, 24549, 11, 3224, 323, 507, 627, 85664, 25, 578, 6424, 574, 6297, 16243, 555, 28289, 10846, 4410, 44908, 1174, 2737, 20851, 48538, 12273, 7595, 1174, 33919, 279, 32666, 1174, 7281, 58716, 1174, 323, 98207, 3842, 29770, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "276", "dataset": "crossner_science", "split": "dev", "prediction": "Writers(O) Terry(B-scientist) Nation(I-scientist) and(O) Dennis(B-scientist) Spooner(I-scientist),(O) Director(O) Douglas(B-director) Camfield(I-director),(O) Producer(O) John(B-director) Wiles(I-director).(O)", "instance": {"id": "276", "words": ["Writers", "Terry", "Nation", "and", "Dennis", "Spooner", ",", "Director", "Douglas", "Camfield", ",", "Producer", "John", "Wiles", "."], "labels": ["O", "B-person", "I-person", "O", "B-person", "I-person", "O", "O", "B-person", "I-person", "O", "O", "B-person", "I-person", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, person, theory, chemical element, chemical compound, academic journal, discipline, country, enzyme, organization, award, location, protein, event, university, astronomical object and O.\nSentence: Writers Terry Nation and Dennis Spooner , Director Douglas Camfield , Producer John Wiles .", "prompt_labels": "Writers(O) Terry(B-person) Nation(I-person) and(O) Dennis(B-person) Spooner(I-person) ,(O) Director(O) Douglas(B-person) Camfield(I-person) ,(O) Producer(O) John(B-person) Wiles(I-person) .(O)"}, "label_list": ["scientist", "person", "theory", "chemical element", "chemical compound", "academic journal", "discipline", "country", "enzyme", "organization", "award", "location", "protein", "event", "university", "astronomical object"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 28568, 11, 1732, 11, 10334, 11, 11742, 2449, 11, 11742, 24549, 11, 14584, 8486, 11, 26434, 11, 3224, 11, 49242, 11, 7471, 11, 10292, 11, 3813, 11, 13128, 11, 1567, 11, 12374, 11, 87283, 1665, 323, 507, 627, 85664, 25, 59798, 32618, 17671, 323, 35727, 94613, 261, 1174, 10783, 31164, 8215, 2630, 1174, 44459, 3842, 468, 3742, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "791", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) the(O) treat(B-actor) williams(I-actor) appear(O) in(O) a(O) film(O)", "instance": {"id": "791", "words": ["did", "the", "treat", "williams", "appear", "in", "a", "film"], "labels": ["O", "O", "B-actor", "I-actor", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, rating, average ratings, title, review, trailer, song, genre, character, director, actor, plot and O.\nSentence: did the treat williams appear in a film", "prompt_labels": "did(O) the(O) treat(B-actor) williams(I-actor) appear(O) in(O) a(O) film(O)"}, "label_list": ["year", "rating", "average ratings", "title", "review", "trailer", "song", "genre", "character", "director", "actor", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 10959, 11, 5578, 18594, 11, 2316, 11, 3477, 11, 19809, 11, 5609, 11, 17779, 11, 3752, 11, 7690, 11, 12360, 11, 7234, 323, 507, 627, 85664, 25, 1550, 279, 4322, 690, 12663, 5101, 304, 264, 4632, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2343", "dataset": "mit-movie", "split": "dev", "prediction": "would(O) you(O) be(O) able(O) to(O) show(O) me(O) where(O) i(O) can(O) find(O) a(O) drama(B-genre) starring(O) keri(B-actor) russell(I-actor)", "instance": {"id": "2343", "words": ["would", "you", "be", "able", "to", "show", "me", "where", "i", "can", "find", "a", "drama", "starring", "keri", "russell"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-genre", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, trailer, genre, average ratings, title, song, plot, review, rating, year, character, actor and O.\nSentence: would you be able to show me where i can find a drama starring keri russell", "prompt_labels": "would(O) you(O) be(O) able(O) to(O) show(O) me(O) where(O) i(O) can(O) find(O) a(O) drama(B-genre) starring(O) keri(B-actor) russell(I-actor)"}, "label_list": ["director", "trailer", "genre", "average ratings", "title", "song", "plot", "review", "rating", "year", "character", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 19809, 11, 17779, 11, 5578, 18594, 11, 2316, 11, 5609, 11, 7234, 11, 3477, 11, 10959, 11, 1060, 11, 3752, 11, 12360, 323, 507, 627, 85664, 25, 1053, 499, 387, 3025, 311, 1501, 757, 1405, 602, 649, 1505, 264, 20156, 40500, 597, 31803, 64663, 616, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "41", "dataset": "crossner_ai", "split": "dev", "prediction": "A(O) Java(B-programming language) implementation(O) using(O) zero(B-metric) based(I-metric) array(I-metric) indexes(I-metric) along(O) with(O) a(O) convenience(O) method(O) for(O) printing(O) the(O) solved(O) order(O) of(O) operations(O) :(O)", "instance": {"id": "41", "words": ["A", "Java", "implementation", "using", "zero", "based", "array", "indexes", "along", "with", "a", "convenience", "method", "for", "printing", "the", "solved", "order", "of", "operations", ":"], "labels": ["O", "B-programming language", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, researcher, metric, algorithm, programming language, person, country, field, product, task, conference, organization, location and O.\nSentence: A Java implementation using zero based array indexes along with a convenience method for printing the solved order of operations :", "prompt_labels": "A(O) Java(B-programming language) implementation(O) using(O) zero(O) based(O) array(O) indexes(O) along(O) with(O) a(O) convenience(O) method(O) for(O) printing(O) the(O) solved(O) order(O) of(O) operations(O) :(O)"}, "label_list": ["university", "researcher", "metric", "algorithm", "programming language", "person", "country", "field", "product", "task", "conference", "organization", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12374, 11, 32185, 11, 18767, 11, 12384, 11, 15840, 4221, 11, 1732, 11, 3224, 11, 2115, 11, 2027, 11, 3465, 11, 10017, 11, 7471, 11, 3813, 323, 507, 627, 85664, 25, 362, 8102, 8292, 1701, 7315, 3196, 1358, 25998, 3235, 449, 264, 19679, 1749, 369, 18991, 279, 29056, 2015, 315, 7677, 551, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "152", "dataset": "crossner_music", "split": "dev", "prediction": "The(O) Academy(B-organization) sought(O) to(O) promote(O) country(B-music genre) /(O) western(O) music(O) in(O) the(O) western(O) states(O) ;(O) this(O) was(O) in(O) contrast(O) to(O) the(O) Country(B-organization) Music(I-organization) Association(I-organization),(O) based(O) in(O) Nashville(B-location),(O) Tennessee(B-location) ((O) then(O) the(O) center(O) of(O) the(O) pop-oriented(O) Nashville(B-song) sound(I-song) )(O).(O)", "instance": {"id": "152", "words": ["The", "Academy", "sought", "to", "promote", "country", "/", "western", "music", "in", "the", "western", "states", ";", "this", "was", "in", "contrast", "to", "the", "Country", "Music", "Association", ",", "based", "in", "Nashville", ",", "Tennessee", "(", "then", "the", "center", "of", "the", "pop-oriented", "Nashville", "sound", ")", "."], "labels": ["O", "O", "O", "O", "O", "B-music genre", "I-music genre", "I-music genre", "I-music genre", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "O", "B-location", "O", "B-location", "O", "O", "O", "O", "O", "O", "O", "B-music genre", "I-music genre", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, country, band, album, event, music genre, musical instrument, organization, location, person, musical artist, song and O.\nSentence: The Academy sought to promote country / western music in the western states ; this was in contrast to the Country Music Association , based in Nashville , Tennessee ( then the center of the pop-oriented Nashville sound ) .", "prompt_labels": "The(O) Academy(O) sought(O) to(O) promote(O) country(B-music genre) /(I-music genre) western(I-music genre) music(I-music genre) in(O) the(O) western(O) states(O) ;(O) this(O) was(O) in(O) contrast(O) to(O) the(O) Country(B-organization) Music(I-organization) Association(I-organization) ,(O) based(O) in(O) Nashville(B-location) ,(O) Tennessee(B-location) ((O) then(O) the(O) center(O) of(O) the(O) pop-oriented(O) Nashville(B-music genre) sound(I-music genre) )(O) .(O)"}, "label_list": ["award", "country", "band", "album", "event", "music genre", "musical instrument", "organization", "location", "person", "musical artist", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10292, 11, 3224, 11, 7200, 11, 8176, 11, 1567, 11, 4731, 17779, 11, 18273, 14473, 11, 7471, 11, 3813, 11, 1732, 11, 18273, 10255, 11, 5609, 323, 507, 627, 85664, 25, 578, 16192, 16495, 311, 12192, 3224, 611, 19001, 4731, 304, 279, 19001, 5415, 2652, 420, 574, 304, 13168, 311, 279, 14438, 10948, 10229, 1174, 3196, 304, 37640, 1174, 24097, 320, 1243, 279, 4219, 315, 279, 2477, 36185, 37640, 5222, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1786", "dataset": "mit-movie", "split": "dev", "prediction": "wanted(O) to(O) know(O) is(O) there(O) a(O) rated(O) r(B-rating) movie(O) set(O) in(O) war(B-genre) made(O) in(O) 2010(B-year) that(O) has(O) the(O) actor(O) yasmine(B-actor) bleeth(I-actor) in(O) it(O)", "instance": {"id": "1786", "words": ["wanted", "to", "know", "is", "there", "a", "rated", "r", "movie", "set", "in", "war", "made", "in", "2010", "that", "has", "the", "actor", "yasmine", "bleeth", "in", "it"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-rating", "O", "O", "O", "B-genre", "O", "O", "B-year", "O", "O", "O", "O", "B-actor", "I-actor", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, year, average ratings, character, trailer, director, actor, plot, rating, song, genre, review and O.\nSentence: wanted to know is there a rated r movie set in war made in 2010 that has the actor yasmine bleeth in it", "prompt_labels": "wanted(O) to(O) know(O) is(O) there(O) a(O) rated(O) r(B-rating) movie(O) set(O) in(O) war(B-genre) made(O) in(O) 2010(B-year) that(O) has(O) the(O) actor(O) yasmine(B-actor) bleeth(I-actor) in(O) it(O)"}, "label_list": ["title", "year", "average ratings", "character", "trailer", "director", "actor", "plot", "rating", "song", "genre", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 1060, 11, 5578, 18594, 11, 3752, 11, 19809, 11, 7690, 11, 12360, 11, 7234, 11, 10959, 11, 5609, 11, 17779, 11, 3477, 323, 507, 627, 85664, 25, 4934, 311, 1440, 374, 1070, 264, 22359, 436, 5818, 743, 304, 4208, 1903, 304, 220, 679, 15, 430, 706, 279, 12360, 379, 39964, 12704, 774, 304, 433, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "41", "dataset": "mit-restaurant", "split": "dev", "prediction": "are(O) there(O) any(O) four(B-Rating) star(I-Rating) restaurants(O) in(B-Location) this(I-Location) town(I-Location)", "instance": {"id": "41", "words": ["are", "there", "any", "four", "star", "restaurants", "in", "this", "town"], "labels": ["O", "O", "O", "B-Rating", "I-Rating", "O", "O", "O", "B-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Price, Amenity, Rating, Cuisine, Dish, Hours, Restaurant Name and O.\nSentence: are there any four star restaurants in this town", "prompt_labels": "are(O) there(O) any(O) four(B-Rating) star(I-Rating) restaurants(O) in(O) this(O) town(B-Location)"}, "label_list": ["Location", "Price", "Amenity", "Rating", "Cuisine", "Dish", "Hours", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 8650, 11, 3383, 56685, 11, 19767, 11, 81961, 11, 49268, 11, 30192, 11, 26568, 4076, 323, 507, 627, 85664, 25, 527, 1070, 904, 3116, 6917, 15926, 304, 420, 6424, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1632", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) a(O) police(B-genre) film(O)", "instance": {"id": "1632", "words": ["list", "a", "police", "film"], "labels": ["O", "O", "B-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, director, title, genre, plot, trailer, review, rating, average ratings, actor, character, year and O.\nSentence: list a police film", "prompt_labels": "list(O) a(O) police(B-genre) film(O)"}, "label_list": ["song", "director", "title", "genre", "plot", "trailer", "review", "rating", "average ratings", "actor", "character", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 7690, 11, 2316, 11, 17779, 11, 7234, 11, 19809, 11, 3477, 11, 10959, 11, 5578, 18594, 11, 12360, 11, 3752, 11, 1060, 323, 507, 627, 85664, 25, 1160, 264, 4379, 4632, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "48", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) movies(O) about(O) horse(B-plot) racing(I-plot)", "instance": {"id": "48", "words": ["show", "me", "movies", "about", "horse", "racing"], "labels": ["O", "O", "O", "O", "B-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, trailer, average ratings, title, year, plot, genre, review, director, actor, character, rating and O.\nSentence: show me movies about horse racing", "prompt_labels": "show(O) me(O) movies(O) about(O) horse(B-plot) racing(I-plot)"}, "label_list": ["song", "trailer", "average ratings", "title", "year", "plot", "genre", "review", "director", "actor", "character", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 19809, 11, 5578, 18594, 11, 2316, 11, 1060, 11, 7234, 11, 17779, 11, 3477, 11, 7690, 11, 12360, 11, 3752, 11, 10959, 323, 507, 627, 85664, 25, 1501, 757, 9698, 922, 15580, 22019, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "936", "dataset": "mit-restaurant", "split": "dev", "prediction": "king(B-Restaurant Name) fung(I-Restaurant Name) garden(I-Restaurant Name) two(B-Amenity) with(I-Amenity) parking(I-Amenity)", "instance": {"id": "936", "words": ["king", "fung", "garden", "two", "with", "parking"], "labels": ["B-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name", "O", "B-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Restaurant Name, Amenity, Hours, Price, Dish, Cuisine, Rating and O.\nSentence: king fung garden two with parking", "prompt_labels": "king(B-Restaurant Name) fung(I-Restaurant Name) garden(I-Restaurant Name) two(I-Restaurant Name) with(O) parking(B-Amenity)"}, "label_list": ["Location", "Restaurant Name", "Amenity", "Hours", "Price", "Dish", "Cuisine", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 26568, 4076, 11, 3383, 56685, 11, 30192, 11, 8650, 11, 49268, 11, 81961, 11, 19767, 323, 507, 627, 85664, 25, 11734, 34698, 13863, 1403, 449, 13217, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2166", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) pollution(B-plot) mockumentary(B-genre) in(O) the(O) last(B-year) ten(I-year) years(I-year) was(O) directed(O) by(O) stephan(B-director) elliott(I-director) and(O) rated(O) pg(B-rating) 13(I-rating)", "instance": {"id": "2166", "words": ["what", "pollution", "mockumentary", "in", "the", "last", "ten", "years", "was", "directed", "by", "stephan", "elliott", "and", "rated", "pg", "13"], "labels": ["O", "B-plot", "B-genre", "O", "O", "B-year", "I-year", "I-year", "O", "O", "O", "B-director", "I-director", "O", "O", "B-rating", "I-rating"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, character, title, director, song, rating, trailer, year, genre, average ratings, actor, plot and O.\nSentence: what pollution mockumentary in the last ten years was directed by stephan elliott and rated pg 13", "prompt_labels": "what(O) pollution(B-plot) mockumentary(B-genre) in(O) the(O) last(B-year) ten(I-year) years(I-year) was(O) directed(O) by(O) stephan(B-director) elliott(I-director) and(O) rated(O) pg(B-rating) 13(I-rating)"}, "label_list": ["review", "character", "title", "director", "song", "rating", "trailer", "year", "genre", "average ratings", "actor", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 3752, 11, 2316, 11, 7690, 11, 5609, 11, 10959, 11, 19809, 11, 1060, 11, 17779, 11, 5578, 18594, 11, 12360, 11, 7234, 323, 507, 627, 85664, 25, 1148, 25793, 8018, 1143, 661, 304, 279, 1566, 5899, 1667, 574, 15910, 555, 3094, 10118, 220, 21148, 1751, 323, 22359, 17953, 220, 1032, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "540", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) am(O) diabetic(O) and(O) need(O) to(O) know(O) if(O) there(O) are(O) any(O) health(B-Cuisine) stores(O) in(B-Location) the(I-Location) area(I-Location)", "instance": {"id": "540", "words": ["i", "am", "diabetic", "and", "need", "to", "know", "if", "there", "are", "any", "health", "stores", "in", "the", "area"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-Cuisine", "O", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Price, Rating, Location, Hours, Dish, Cuisine, Amenity and O.\nSentence: i am diabetic and need to know if there are any health stores in the area", "prompt_labels": "i(O) am(O) diabetic(O) and(O) need(O) to(O) know(O) if(O) there(O) are(O) any(O) health(B-Cuisine) stores(O) in(B-Location) the(I-Location) area(I-Location)"}, "label_list": ["Restaurant Name", "Price", "Rating", "Location", "Hours", "Dish", "Cuisine", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 8650, 11, 19767, 11, 10067, 11, 30192, 11, 49268, 11, 81961, 11, 3383, 56685, 323, 507, 627, 85664, 25, 602, 1097, 71975, 323, 1205, 311, 1440, 422, 1070, 527, 904, 2890, 10756, 304, 279, 3158, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "154", "dataset": "crossner_music", "split": "dev", "prediction": "In(O) recognition(O) of(O) her(O) film(O) career(O),(O) she(O) received(O) BAFTA(B-award)'s(I-award) Lifetime(I-award) Achievement(I-award) Award(I-award),(O) the(O) Golden(B-award) Globe(I-award) Cecil(I-award) B.(I-award) DeMille(I-award) Award(I-award),(O) the(O) Screen(B-award) Actors(I-award) Guild(I-award) Life(I-award) Achievement(I-award) Award(I-award),(O) and(O) the(O) Special(O) Tony(B-award) Award(I-award).(O)", "instance": {"id": "154", "words": ["In", "recognition", "of", "her", "film", "career", ",", "she", "received", "BAFTA", "'s", "Lifetime", "Achievement", "Award", ",", "the", "Golden", "Globe", "Cecil", "B.", "DeMille", "Award", ",", "the", "Screen", "Actors", "Guild", "Life", "Achievement", "Award", ",", "and", "the", "Special", "Tony", "Award", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O", "O", "O", "B-award", "I-award", "I-award", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, band, award, song, country, music genre, album, person, organization, musical instrument, event, location and O.\nSentence: In recognition of her film career , she received BAFTA 's Lifetime Achievement Award , the Golden Globe Cecil B. DeMille Award , the Screen Actors Guild Life Achievement Award , and the Special Tony Award .", "prompt_labels": "In(O) recognition(O) of(O) her(O) film(O) career(O) ,(O) she(O) received(O) BAFTA(B-award) 's(I-award) Lifetime(I-award) Achievement(I-award) Award(I-award) ,(O) the(O) Golden(B-award) Globe(I-award) Cecil(I-award) B.(I-award) DeMille(I-award) Award(I-award) ,(O) the(O) Screen(B-award) Actors(I-award) Guild(I-award) Life(I-award) Achievement(I-award) Award(I-award) ,(O) and(O) the(O) Special(B-award) Tony(I-award) Award(I-award) .(O)"}, "label_list": ["musical artist", "band", "award", "song", "country", "music genre", "album", "person", "organization", "musical instrument", "event", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18273, 10255, 11, 7200, 11, 10292, 11, 5609, 11, 3224, 11, 4731, 17779, 11, 8176, 11, 1732, 11, 7471, 11, 18273, 14473, 11, 1567, 11, 3813, 323, 507, 627, 85664, 25, 763, 18324, 315, 1077, 4632, 7076, 1174, 1364, 4036, 34589, 59512, 364, 82, 65452, 66695, 17768, 1174, 279, 18288, 41910, 90227, 426, 13, 1611, 44, 4618, 17768, 1174, 279, 14275, 82461, 33592, 9601, 66695, 17768, 1174, 323, 279, 9984, 19036, 17768, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "160", "dataset": "crossner_science", "split": "dev", "prediction": "Models(O) of(O) heat(O) retention(O) and(O) heating(O) via(O) radioactive(O) decay(O) in(O) smaller(O) icy(O) Solar(O) System(O) bodies(O) suggest(O) that(O) Rhea(B-astronomical object),(O) Titania(B-astronomical object),(O) Oberon(B-astronomical object),(O) Triton(B-astronomical object),(O) Pluto(B-astronomical object),(O) Eris(B-astronomical object),(O) 90377(B-astronomical object) Sedna(I-astronomical object),(O) and(O) 90482(B-astronomical object) Orcus(I-astronomical object) may(O) have(O) oceans(O) underneath(O) solid(O) icy(O) crusts(O) approximately(O) 100(O) km(O) thick(O).(O)", "instance": {"id": "160", "words": ["Models", "of", "heat", "retention", "and", "heating", "via", "radioactive", "decay", "in", "smaller", "icy", "Solar", "System", "bodies", "suggest", "that", "Rhea", ",", "Titania", ",", "Oberon", ",", "Triton", ",", "Pluto", ",", "Eris", ",", "90377", "Sedna", ",", "and", "90482", "Orcus", "may", "have", "oceans", "underneath", "solid", "icy", "crusts", "approximately", "100", "km", "thick", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-astronomical object", "O", "B-astronomical object", "O", "B-astronomical object", "O", "B-astronomical object", "O", "B-astronomical object", "O", "B-astronomical object", "O", "B-astronomical object", "I-astronomical object", "O", "O", "B-astronomical object", "I-astronomical object", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical element, university, chemical compound, scientist, theory, astronomical object, enzyme, country, person, location, protein, organization, event, award, discipline, academic journal and O.\nSentence: Models of heat retention and heating via radioactive decay in smaller icy Solar System bodies suggest that Rhea , Titania , Oberon , Triton , Pluto , Eris , 90377 Sedna , and 90482 Orcus may have oceans underneath solid icy crusts approximately 100 km thick .", "prompt_labels": "Models(O) of(O) heat(O) retention(O) and(O) heating(O) via(O) radioactive(O) decay(O) in(O) smaller(O) icy(O) Solar(O) System(O) bodies(O) suggest(O) that(O) Rhea(B-astronomical object) ,(O) Titania(B-astronomical object) ,(O) Oberon(B-astronomical object) ,(O) Triton(B-astronomical object) ,(O) Pluto(B-astronomical object) ,(O) Eris(B-astronomical object) ,(O) 90377(B-astronomical object) Sedna(I-astronomical object) ,(O) and(O) 90482(B-astronomical object) Orcus(I-astronomical object) may(O) have(O) oceans(O) underneath(O) solid(O) icy(O) crusts(O) approximately(O) 100(O) km(O) thick(O) .(O)"}, "label_list": ["chemical element", "university", "chemical compound", "scientist", "theory", "astronomical object", "enzyme", "country", "person", "location", "protein", "organization", "event", "award", "discipline", "academic journal"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 11742, 2449, 11, 12374, 11, 11742, 24549, 11, 28568, 11, 10334, 11, 87283, 1665, 11, 49242, 11, 3224, 11, 1732, 11, 3813, 11, 13128, 11, 7471, 11, 1567, 11, 10292, 11, 26434, 11, 14584, 8486, 323, 507, 627, 85664, 25, 27972, 315, 8798, 38231, 323, 24494, 4669, 59862, 31815, 304, 9333, 67004, 25450, 744, 13162, 4284, 430, 432, 41033, 1174, 24977, 9345, 1174, 52245, 263, 1174, 85283, 263, 1174, 78681, 1174, 469, 6091, 1174, 220, 23305, 2813, 36378, 3458, 1174, 323, 220, 22777, 6086, 57686, 355, 1253, 617, 54280, 30456, 6573, 67004, 40712, 82, 13489, 220, 1041, 13437, 12314, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "212", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) directed(O) beaty(B-title) and(I-title) the(I-title) beast(I-title)", "instance": {"id": "212", "words": ["who", "directed", "beaty", "and", "the", "beast"], "labels": ["O", "O", "B-title", "I-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, title, rating, review, actor, director, year, trailer, average ratings, plot, genre, song and O.\nSentence: who directed beaty and the beast", "prompt_labels": "who(O) directed(O) beaty(B-title) and(I-title) the(I-title) beast(I-title)"}, "label_list": ["character", "title", "rating", "review", "actor", "director", "year", "trailer", "average ratings", "plot", "genre", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 2316, 11, 10959, 11, 3477, 11, 12360, 11, 7690, 11, 1060, 11, 19809, 11, 5578, 18594, 11, 7234, 11, 17779, 11, 5609, 323, 507, 627, 85664, 25, 889, 15910, 9567, 88, 323, 279, 32236, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "947", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) film(O) had(O) the(O) song(O) the(B-song) power(I-song) of(I-song) love(I-song)", "instance": {"id": "947", "words": ["what", "film", "had", "the", "song", "the", "power", "of", "love"], "labels": ["O", "O", "O", "O", "O", "B-song", "I-song", "I-song", "I-song"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, director, plot, song, average ratings, trailer, title, character, review, genre, year, actor and O.\nSentence: what film had the song the power of love", "prompt_labels": "what(O) film(O) had(O) the(O) song(O) the(B-song) power(I-song) of(I-song) love(I-song)"}, "label_list": ["rating", "director", "plot", "song", "average ratings", "trailer", "title", "character", "review", "genre", "year", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 7690, 11, 7234, 11, 5609, 11, 5578, 18594, 11, 19809, 11, 2316, 11, 3752, 11, 3477, 11, 17779, 11, 1060, 11, 12360, 323, 507, 627, 85664, 25, 1148, 4632, 1047, 279, 5609, 279, 2410, 315, 3021, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "23", "dataset": "crossner_science", "split": "dev", "prediction": "Other(O) notable(O) German(O) scientists(O),(O) who(O) worked(O) on(O) the(O) Soviet(B-country) atomic(I-country) bomb(I-country) project(O) and(O) joined(O) Rexer(O) at(O) the(O) Technische(B-university) Hochschule(I-university) Dresden(I-university) were(O) Heinz(B-scientist) Pose(I-scientist) and(O) two(O) other(O) physicists(O),(O) Werner(B-scientist) Hartmann(I-scientist) and(O) Heinz(B-scientist) Barwich(I-scientist),(O) who(O) had(O) been(O) at(O) Gustav(B-organization) Hertz(I-organization)'s(I-organization) Institute(I-organization) G(I-organization),(O) in(O) Agudseri(B-location) ((O) Agudzery(B-location) )(O).(O)", "instance": {"id": "23", "words": ["Other", "notable", "German", "scientists", ",", "who", "worked", "on", "the", "Soviet", "atomic", "bomb", "project", "and", "joined", "Rexer", "at", "the", "Technische", "Hochschule", "Dresden", "were", "Heinz", "Pose", "and", "two", "other", "physicists", ",", "Werner", "Hartmann", "and", "Heinz", "Barwich", ",", "who", "had", "been", "at", "Gustav", "Hertz", "'s", "Institute", "G", ",", "in", "Agudseri", "(", "Agudzery", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-scientist", "O", "O", "B-university", "I-university", "I-university", "O", "B-scientist", "I-scientist", "O", "O", "O", "O", "O", "B-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-location", "O", "B-location", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: astronomical object, country, university, discipline, academic journal, protein, person, enzyme, organization, scientist, chemical compound, location, event, theory, award, chemical element and O.\nSentence: Other notable German scientists , who worked on the Soviet atomic bomb project and joined Rexer at the Technische Hochschule Dresden were Heinz Pose and two other physicists , Werner Hartmann and Heinz Barwich , who had been at Gustav Hertz 's Institute G , in Agudseri ( Agudzery ) .", "prompt_labels": "Other(O) notable(O) German(O) scientists(O) ,(O) who(O) worked(O) on(O) the(O) Soviet(O) atomic(O) bomb(O) project(O) and(O) joined(O) Rexer(B-scientist) at(O) the(O) Technische(B-university) Hochschule(I-university) Dresden(I-university) were(O) Heinz(B-scientist) Pose(I-scientist) and(O) two(O) other(O) physicists(O) ,(O) Werner(B-scientist) Hartmann(I-scientist) and(O) Heinz(B-scientist) Barwich(I-scientist) ,(O) who(O) had(O) been(O) at(O) Gustav(B-organization) Hertz(I-organization) 's(I-organization) Institute(I-organization) G(I-organization) ,(O) in(O) Agudseri(B-location) ((O) Agudzery(B-location) )(O) .(O)"}, "label_list": ["astronomical object", "country", "university", "discipline", "academic journal", "protein", "person", "enzyme", "organization", "scientist", "chemical compound", "location", "event", "theory", "award", "chemical element"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 87283, 1665, 11, 3224, 11, 12374, 11, 26434, 11, 14584, 8486, 11, 13128, 11, 1732, 11, 49242, 11, 7471, 11, 28568, 11, 11742, 24549, 11, 3813, 11, 1567, 11, 10334, 11, 10292, 11, 11742, 2449, 323, 507, 627, 85664, 25, 7089, 28289, 6063, 14248, 1174, 889, 6575, 389, 279, 19953, 25524, 13054, 2447, 323, 11096, 42907, 261, 520, 279, 7146, 10782, 68875, 21740, 1130, 86545, 1051, 1283, 41622, 51473, 323, 1403, 1023, 98417, 1174, 80835, 23750, 18022, 323, 1283, 41622, 4821, 17316, 1174, 889, 1047, 1027, 520, 49720, 402, 473, 59037, 364, 82, 10181, 480, 1174, 304, 4701, 664, 805, 72, 320, 4701, 664, 89, 727, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "14", "dataset": "crossner_music", "split": "dev", "prediction": "Phoenix(O) has(O) long(O) been(O) a(O) social(O) activist(O),(O) lending(O) his(O) support(O) to(O) a(O) number(O) of(O) charities(O) and(O) humanitarian(O) organizations(O),(O) such(O) as(O) Amnesty(B-organization) International(I-organization),(O) The(B-organization) Art(I-organization) of(I-organization) Elysium(I-organization),(O) HEART(B-organization),(O) and(O) the(O) Peace(B-organization) Alliance(I-organization) ((O) which(O) campaigns(O) for(O) a(O) United(B-country) States(I-country) Department(I-country) of(I-country) Peace(I-country) )(O).(O)", "instance": {"id": "14", "words": ["Phoenix", "has", "long", "been", "a", "social", "activist", ",", "lending", "his", "support", "to", "a", "number", "of", "charities", "and", "humanitarian", "organizations", ",", "such", "as", "Amnesty", "International", ",", "The", "Art", "of", "Elysium", ",", "HEART", ",", "and", "the", "Peace", "Alliance", "(", "which", "campaigns", "for", "a", "United", "States", "Department", "of", "Peace", ")", "."], "labels": ["B-band", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "O", "O", "O", "B-organization", "I-organization", "O", "O", "O", "O", "O", "B-country", "I-country", "B-organization", "I-organization", "I-organization", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, song, person, country, band, music genre, musical artist, organization, album, award, location, event and O.\nSentence: Phoenix has long been a social activist , lending his support to a number of charities and humanitarian organizations , such as Amnesty International , The Art of Elysium , HEART , and the Peace Alliance ( which campaigns for a United States Department of Peace ) .", "prompt_labels": "Phoenix(B-band) has(O) long(O) been(O) a(O) social(O) activist(O) ,(O) lending(O) his(O) support(O) to(O) a(O) number(O) of(O) charities(O) and(O) humanitarian(O) organizations(O) ,(O) such(O) as(O) Amnesty(B-organization) International(I-organization) ,(O) The(B-organization) Art(I-organization) of(I-organization) Elysium(I-organization) ,(O) HEART(B-organization) ,(O) and(O) the(O) Peace(B-organization) Alliance(I-organization) ((O) which(O) campaigns(O) for(O) a(O) United(B-country) States(I-country) Department(B-organization) of(I-organization) Peace(I-organization) )(O) .(O)"}, "label_list": ["musical instrument", "song", "person", "country", "band", "music genre", "musical artist", "organization", "album", "award", "location", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18273, 14473, 11, 5609, 11, 1732, 11, 3224, 11, 7200, 11, 4731, 17779, 11, 18273, 10255, 11, 7471, 11, 8176, 11, 10292, 11, 3813, 11, 1567, 323, 507, 627, 85664, 25, 23503, 706, 1317, 1027, 264, 3674, 28941, 1174, 40651, 813, 1862, 311, 264, 1396, 315, 51371, 323, 38748, 11351, 1174, 1778, 439, 78796, 7327, 1174, 578, 5277, 315, 469, 61492, 2411, 1174, 11947, 3065, 1174, 323, 279, 26888, 23590, 320, 902, 21343, 369, 264, 3723, 4273, 6011, 315, 26888, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "101", "dataset": "crossner_music", "split": "dev", "prediction": "The(O) film(O) received(O) several(O) Golden(B-award) Globe(I-award) Awards(I-award) and(O) Academy(B-award) Awards(I-award) nominations(O),(O) and(O) earned(O) Kidman(B-musical artist) a(O) fourth(O) Screen(B-award) Actors(I-award) Guild(I-award) Award(I-award) nomination(O),(O) as(O) part(O) of(O) the(O) Screen(B-award) Actors(I-award) Award(I-award) for(I-award) Outstanding(I-award) Performance(I-award) by(I-award) a(I-award) Cast(I-award) in(I-award) a(I-award) Motion(I-award) Picture(I-award).(O)", "instance": {"id": "101", "words": ["The", "film", "received", "several", "Golden", "Globe", "Awards", "and", "Academy", "Awards", "nominations", ",", "and", "earned", "Kidman", "a", "fourth", "Screen", "Actors", "Guild", "Award", "nomination", ",", "as", "part", "of", "the", "Screen", "Actors", "Guild", "Award", "for", "Outstanding", "Performance", "by", "a", "Cast", "in", "a", "Motion", "Picture", "."], "labels": ["O", "O", "O", "O", "B-award", "I-award", "I-award", "O", "B-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, event, song, album, person, musical artist, country, award, music genre, organization, musical instrument, band and O.\nSentence: The film received several Golden Globe Awards and Academy Awards nominations , and earned Kidman a fourth Screen Actors Guild Award nomination , as part of the Screen Actors Guild Award for Outstanding Performance by a Cast in a Motion Picture .", "prompt_labels": "The(O) film(O) received(O) several(O) Golden(B-award) Globe(I-award) Awards(I-award) and(O) Academy(B-award) Awards(I-award) nominations(O) ,(O) and(O) earned(O) Kidman(O) a(O) fourth(O) Screen(B-award) Actors(I-award) Guild(I-award) Award(I-award) nomination(O) ,(O) as(O) part(O) of(O) the(O) Screen(B-award) Actors(I-award) Guild(I-award) Award(I-award) for(I-award) Outstanding(I-award) Performance(I-award) by(I-award) a(I-award) Cast(I-award) in(I-award) a(I-award) Motion(I-award) Picture(I-award) .(O)"}, "label_list": ["location", "event", "song", "album", "person", "musical artist", "country", "award", "music genre", "organization", "musical instrument", "band"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 1567, 11, 5609, 11, 8176, 11, 1732, 11, 18273, 10255, 11, 3224, 11, 10292, 11, 4731, 17779, 11, 7471, 11, 18273, 14473, 11, 7200, 323, 507, 627, 85664, 25, 578, 4632, 4036, 3892, 18288, 41910, 23488, 323, 16192, 23488, 60698, 1174, 323, 15662, 32666, 1543, 264, 11999, 14275, 82461, 33592, 17768, 29804, 1174, 439, 961, 315, 279, 14275, 82461, 33592, 17768, 369, 76441, 21304, 555, 264, 11514, 304, 264, 27660, 25586, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1485", "dataset": "mit-restaurant", "split": "dev", "prediction": "which(O) nearby(B-Location) restaurant(O) serves(O) the(O) best(B-Rating) steak(B-Dish)", "instance": {"id": "1485", "words": ["which", "nearby", "restaurant", "serves", "the", "best", "steak"], "labels": ["O", "B-Location", "O", "O", "O", "B-Rating", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Cuisine, Price, Hours, Rating, Dish, Location, Amenity and O.\nSentence: which nearby restaurant serves the best steak", "prompt_labels": "which(O) nearby(B-Location) restaurant(O) serves(O) the(O) best(B-Rating) steak(B-Dish)"}, "label_list": ["Restaurant Name", "Cuisine", "Price", "Hours", "Rating", "Dish", "Location", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 81961, 11, 8650, 11, 30192, 11, 19767, 11, 49268, 11, 10067, 11, 3383, 56685, 323, 507, 627, 85664, 25, 902, 14373, 10960, 17482, 279, 1888, 50059, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "459", "dataset": "mit-movie", "split": "dev", "prediction": "name(O) a(O) movie(O) where(O) beer(B-plot) is(O) important(O) to(O) the(O) plot(O)", "instance": {"id": "459", "words": ["name", "a", "movie", "where", "beer", "is", "important", "to", "the", "plot"], "labels": ["O", "O", "O", "O", "B-plot", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, title, review, director, plot, year, song, average ratings, character, actor, trailer, rating and O.\nSentence: name a movie where beer is important to the plot", "prompt_labels": "name(O) a(O) movie(O) where(O) beer(B-plot) is(O) important(O) to(O) the(O) plot(O)"}, "label_list": ["genre", "title", "review", "director", "plot", "year", "song", "average ratings", "character", "actor", "trailer", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 2316, 11, 3477, 11, 7690, 11, 7234, 11, 1060, 11, 5609, 11, 5578, 18594, 11, 3752, 11, 12360, 11, 19809, 11, 10959, 323, 507, 627, 85664, 25, 836, 264, 5818, 1405, 13179, 374, 3062, 311, 279, 7234, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "966", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) a(O) james(B-character) bond(I-character) movie(O) that(O) starred(O) timothy(B-director) dalton(I-director)", "instance": {"id": "966", "words": ["show", "me", "a", "james", "bond", "movie", "that", "starred", "timothy", "dalton"], "labels": ["O", "O", "O", "B-character", "I-character", "O", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, song, actor, genre, average ratings, trailer, year, review, director, rating, character, title and O.\nSentence: show me a james bond movie that starred timothy dalton", "prompt_labels": "show(O) me(O) a(O) james(B-character) bond(I-character) movie(O) that(O) starred(O) timothy(B-actor) dalton(I-actor)"}, "label_list": ["plot", "song", "actor", "genre", "average ratings", "trailer", "year", "review", "director", "rating", "character", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 5609, 11, 12360, 11, 17779, 11, 5578, 18594, 11, 19809, 11, 1060, 11, 3477, 11, 7690, 11, 10959, 11, 3752, 11, 2316, 323, 507, 627, 85664, 25, 1501, 757, 264, 86046, 11049, 5818, 430, 59335, 6935, 29671, 25769, 783, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "353", "dataset": "mit-restaurant", "split": "dev", "prediction": "find(O) an(O) italian(B-Cuisine) resturant(O) that(O) serves(O) family(B-Amenity) style(I-Amenity)", "instance": {"id": "353", "words": ["find", "an", "italian", "resturant", "that", "serves", "family", "style"], "labels": ["O", "O", "B-Cuisine", "O", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Dish, Rating, Restaurant Name, Location, Cuisine, Price, Amenity and O.\nSentence: find an italian resturant that serves family style", "prompt_labels": "find(O) an(O) italian(B-Cuisine) resturant(O) that(O) serves(O) family(B-Amenity) style(I-Amenity)"}, "label_list": ["Hours", "Dish", "Rating", "Restaurant Name", "Location", "Cuisine", "Price", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 49268, 11, 19767, 11, 26568, 4076, 11, 10067, 11, 81961, 11, 8650, 11, 3383, 56685, 323, 507, 627, 85664, 25, 1505, 459, 29048, 2800, 324, 519, 430, 17482, 3070, 1742, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "269", "dataset": "crossner_politics", "split": "dev", "prediction": "He(O) was(O) a(O) member(O) of(O) the(O) National(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization),(O) the(O) American(B-organization) Academy(I-organization) of(I-organization) Arts(I-organization) and(I-organization) Sciences(I-organization),(O) the(O) American(B-organization) Philosophical(I-organization) Society(I-organization),(O) the(O) Sociological(B-organization) Research(I-organization) Association(I-organization) and(O) the(O) Ordre(B-organization) des(I-organization) Palmes(I-organization) Academiques(I-organization).(O)", "instance": {"id": "269", "words": ["He", "was", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Philosophical", "Society", ",", "the", "Sociological", "Research", "Association", "and", "the", "Ordre", "des", "Palmes", "Academiques", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, country, event, election, location, person, organization, political party and O.\nSentence: He was a member of the National Academy of Sciences , the American Academy of Arts and Sciences , the American Philosophical Society , the Sociological Research Association and the Ordre des Palmes Academiques .", "prompt_labels": "He(O) was(O) a(O) member(O) of(O) the(O) National(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) ,(O) the(O) American(B-organization) Academy(I-organization) of(I-organization) Arts(I-organization) and(I-organization) Sciences(I-organization) ,(O) the(O) American(B-organization) Philosophical(I-organization) Society(I-organization) ,(O) the(O) Sociological(B-organization) Research(I-organization) Association(I-organization) and(O) the(O) Ordre(B-organization) des(I-organization) Palmes(I-organization) Academiques(I-organization) .(O)"}, "label_list": ["politician", "country", "event", "election", "location", "person", "organization", "political party"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 37038, 11, 3224, 11, 1567, 11, 6355, 11, 3813, 11, 1732, 11, 7471, 11, 5054, 4717, 323, 507, 627, 85664, 25, 1283, 574, 264, 4562, 315, 279, 5165, 16192, 315, 23199, 1174, 279, 3778, 16192, 315, 17979, 323, 23199, 1174, 279, 3778, 38356, 950, 13581, 1174, 279, 42509, 5848, 8483, 10229, 323, 279, 31137, 265, 951, 33578, 288, 123600, 8467, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2234", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) watchable(B-average ratings) rated(O) g(B-rating) animation(B-genre) did(O) richard(B-director) robinson(I-director) direct(O) last(B-year) year(I-year)", "instance": {"id": "2234", "words": ["what", "watchable", "rated", "g", "animation", "did", "richard", "robinson", "direct", "last", "year"], "labels": ["O", "B-average ratings", "O", "B-rating", "B-genre", "O", "B-director", "I-director", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, character, plot, title, song, genre, director, actor, trailer, rating, review, year and O.\nSentence: what watchable rated g animation did richard robinson direct last year", "prompt_labels": "what(O) watchable(B-average ratings) rated(O) g(B-rating) animation(B-genre) did(O) richard(B-director) robinson(I-director) direct(O) last(B-year) year(I-year)"}, "label_list": ["average ratings", "character", "plot", "title", "song", "genre", "director", "actor", "trailer", "rating", "review", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 3752, 11, 7234, 11, 2316, 11, 5609, 11, 17779, 11, 7690, 11, 12360, 11, 19809, 11, 10959, 11, 3477, 11, 1060, 323, 507, 627, 85664, 25, 1148, 3821, 481, 22359, 342, 10571, 1550, 9257, 569, 99685, 942, 2167, 1566, 1060, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "141", "dataset": "crossner_ai", "split": "dev", "prediction": "OMR(B-product) is(O) generally(O) distinguished(O) from(O) optical(B-product) character(I-product) recognition(I-product) ((O) OCR(B-product) )(O) by(O) the(O) fact(O) that(O) a(O) complicated(O) pattern(O) recognition(O) engine(O) is(O) not(O) required(O).(O)", "instance": {"id": "141", "words": ["OMR", "is", "generally", "distinguished", "from", "optical", "character", "recognition", "(", "OCR", ")", "by", "the", "fact", "that", "a", "complicated", "pattern", "recognition", "engine", "is", "not", "required", "."], "labels": ["B-task", "O", "O", "O", "O", "B-task", "I-task", "I-task", "O", "B-task", "O", "O", "O", "O", "O", "O", "O", "B-field", "I-field", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, field, organization, task, algorithm, metric, person, product, programming language, conference, researcher, university, location and O.\nSentence: OMR is generally distinguished from optical character recognition ( OCR ) by the fact that a complicated pattern recognition engine is not required .", "prompt_labels": "OMR(B-task) is(O) generally(O) distinguished(O) from(O) optical(B-task) character(I-task) recognition(I-task) ((O) OCR(B-task) )(O) by(O) the(O) fact(O) that(O) a(O) complicated(O) pattern(B-field) recognition(I-field) engine(O) is(O) not(O) required(O) .(O)"}, "label_list": ["country", "field", "organization", "task", "algorithm", "metric", "person", "product", "programming language", "conference", "researcher", "university", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 2115, 11, 7471, 11, 3465, 11, 12384, 11, 18767, 11, 1732, 11, 2027, 11, 15840, 4221, 11, 10017, 11, 32185, 11, 12374, 11, 3813, 323, 507, 627, 85664, 25, 507, 18953, 374, 8965, 39575, 505, 29393, 3752, 18324, 320, 81677, 883, 555, 279, 2144, 430, 264, 17395, 5497, 18324, 4817, 374, 539, 2631, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "57", "dataset": "crossner_ai", "split": "dev", "prediction": "Apertium(B-product) is(O) a(O) shallow-transfer(B-algorithm) machine(I-algorithm) translation(I-algorithm) system(I-algorithm),(O) which(O) uses(O) finite(O) state(O) transducer(O) s(O) for(O) all(O) of(O) its(O) lexical(O) transformations(O),(O) and(O) hidden(B-algorithm) Markov(I-algorithm) model(I-algorithm) s(O) for(O) part-of-speech(B-task) tagging(I-task) or(O) word(O) category(O) disambiguation(O).(O)", "instance": {"id": "57", "words": ["Apertium", "is", "a", "shallow-transfer", "machine", "translation", "system", ",", "which", "uses", "finite", "state", "transducer", "s", "for", "all", "of", "its", "lexical", "transformations", ",", "and", "hidden", "Markov", "model", "s", "for", "part-of-speech", "tagging", "or", "word", "category", "disambiguation", "."], "labels": ["B-product", "O", "O", "B-product", "I-product", "I-product", "I-product", "O", "O", "O", "B-algorithm", "I-algorithm", "I-algorithm", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-algorithm", "I-algorithm", "I-algorithm", "O", "O", "B-task", "I-task", "O", "B-task", "I-task", "I-task", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, location, person, organization, algorithm, task, country, conference, field, university, researcher, product, metric and O.\nSentence: Apertium is a shallow-transfer machine translation system , which uses finite state transducer s for all of its lexical transformations , and hidden Markov model s for part-of-speech tagging or word category disambiguation .", "prompt_labels": "Apertium(B-product) is(O) a(O) shallow-transfer(B-product) machine(I-product) translation(I-product) system(I-product) ,(O) which(O) uses(O) finite(B-algorithm) state(I-algorithm) transducer(I-algorithm) s(O) for(O) all(O) of(O) its(O) lexical(O) transformations(O) ,(O) and(O) hidden(B-algorithm) Markov(I-algorithm) model(I-algorithm) s(O) for(O) part-of-speech(B-task) tagging(I-task) or(O) word(B-task) category(I-task) disambiguation(I-task) .(O)"}, "label_list": ["programming language", "location", "person", "organization", "algorithm", "task", "country", "conference", "field", "university", "researcher", "product", "metric"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 15840, 4221, 11, 3813, 11, 1732, 11, 7471, 11, 12384, 11, 3465, 11, 3224, 11, 10017, 11, 2115, 11, 12374, 11, 32185, 11, 2027, 11, 18767, 323, 507, 627, 85664, 25, 5345, 531, 2411, 374, 264, 26682, 93791, 5780, 14807, 1887, 1174, 902, 5829, 35326, 1614, 1380, 30038, 274, 369, 682, 315, 1202, 78686, 54070, 1174, 323, 8340, 4488, 869, 1646, 274, 369, 961, 8838, 1355, 40686, 79253, 477, 3492, 5699, 834, 3042, 343, 4090, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "882", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) a(O) wah(B-Restaurant Name) sang(I-Restaurant Name) restaurant(O) with(O) a(O) great(B-Amenity) beer(I-Amenity) list(I-Amenity)", "instance": {"id": "882", "words": ["is", "there", "a", "wah", "sang", "restaurant", "with", "a", "great", "beer", "list"], "labels": ["O", "O", "O", "B-Restaurant Name", "I-Restaurant Name", "O", "O", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Location, Amenity, Price, Rating, Dish, Cuisine, Hours and O.\nSentence: is there a wah sang restaurant with a great beer list", "prompt_labels": "is(O) there(O) a(O) wah(B-Restaurant Name) sang(I-Restaurant Name) restaurant(O) with(O) a(O) great(O) beer(B-Amenity) list(I-Amenity)"}, "label_list": ["Restaurant Name", "Location", "Amenity", "Price", "Rating", "Dish", "Cuisine", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 10067, 11, 3383, 56685, 11, 8650, 11, 19767, 11, 49268, 11, 81961, 11, 30192, 323, 507, 627, 85664, 25, 374, 1070, 264, 86327, 29340, 10960, 449, 264, 2294, 13179, 1160, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "794", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) the(O) twirl(B-Restaurant Name) pasta(I-Restaurant Name) in(O) north(B-Location) end(I-Location) a(O) good(B-Rating) place(O) for(O) a(O) business(B-Amenity) lunch(B-Hours)", "instance": {"id": "794", "words": ["is", "the", "twirl", "pasta", "in", "north", "end", "a", "good", "place", "for", "a", "business", "lunch"], "labels": ["O", "O", "B-Restaurant Name", "I-Restaurant Name", "O", "B-Location", "I-Location", "O", "O", "O", "O", "O", "B-Amenity", "B-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Dish, Location, Restaurant Name, Hours, Rating, Cuisine, Amenity and O.\nSentence: is the twirl pasta in north end a good place for a business lunch", "prompt_labels": "is(O) the(O) twirl(B-Restaurant Name) pasta(I-Restaurant Name) in(O) north(B-Location) end(I-Location) a(O) good(O) place(O) for(O) a(O) business(B-Amenity) lunch(B-Hours)"}, "label_list": ["Price", "Dish", "Location", "Restaurant Name", "Hours", "Rating", "Cuisine", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 49268, 11, 10067, 11, 26568, 4076, 11, 30192, 11, 19767, 11, 81961, 11, 3383, 56685, 323, 507, 627, 85664, 25, 374, 279, 4483, 2881, 37547, 304, 10411, 842, 264, 1695, 2035, 369, 264, 2626, 16163, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "27", "dataset": "crossner_music", "split": "dev", "prediction": "Under(O) the(O) current(O) voting(O) system(O),(O) in(O) place(O) since(O) 2016(O),(O) the(O) highest-scoring(O) winner(O) is(O) Salvador(B-musical artist) Sobral(I-musical artist) of(O) Portugal(B-country) who(O) won(O) the(O) Eurovision(B-event) Song(I-event) Contest(I-event) 2017(I-event) in(O) Kiev(B-location),(O) Ukraine(B-country),(O) with(O) 758(O) points(O) ;(O) under(O) the(O) previous(O) system(O),(O) the(O) highest-scoring(O) winner(O) was(O) Alexander(B-musical artist) Rybak(I-musical artist) of(O) Norway(B-country) with(O) 387(O) points(O) in(O) Eurovision(B-event) Song(I-event) Contest(I-event) 2009(I-event).(O)", "instance": {"id": "27", "words": ["Under", "the", "current", "voting", "system", ",", "in", "place", "since", "2016", ",", "the", "highest-scoring", "winner", "is", "Salvador", "Sobral", "of", "Portugal", "who", "won", "the", "Eurovision", "Song", "Contest", "2017", "in", "Kiev", ",", "Ukraine", ",", "with", "758", "points", ";", "under", "the", "previous", "system", ",", "the", "highest-scoring", "winner", "was", "Alexander", "Rybak", "of", "Norway", "with", "387", "points", "in", "Eurovision", "Song", "Contest", "2009", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-musical artist", "I-musical artist", "O", "B-country", "O", "O", "O", "B-event", "I-event", "I-event", "I-event", "O", "B-location", "O", "B-country", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-musical artist", "I-musical artist", "O", "B-country", "O", "O", "O", "O", "B-event", "I-event", "I-event", "I-event", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, music genre, song, country, organization, award, event, musical artist, person, album, musical instrument, band and O.\nSentence: Under the current voting system , in place since 2016 , the highest-scoring winner is Salvador Sobral of Portugal who won the Eurovision Song Contest 2017 in Kiev , Ukraine , with 758 points ; under the previous system , the highest-scoring winner was Alexander Rybak of Norway with 387 points in Eurovision Song Contest 2009 .", "prompt_labels": "Under(O) the(O) current(O) voting(O) system(O) ,(O) in(O) place(O) since(O) 2016(O) ,(O) the(O) highest-scoring(O) winner(O) is(O) Salvador(B-musical artist) Sobral(I-musical artist) of(O) Portugal(B-country) who(O) won(O) the(O) Eurovision(B-event) Song(I-event) Contest(I-event) 2017(I-event) in(O) Kiev(B-location) ,(O) Ukraine(B-country) ,(O) with(O) 758(O) points(O) ;(O) under(O) the(O) previous(O) system(O) ,(O) the(O) highest-scoring(O) winner(O) was(O) Alexander(B-musical artist) Rybak(I-musical artist) of(O) Norway(B-country) with(O) 387(O) points(O) in(O) Eurovision(B-event) Song(I-event) Contest(I-event) 2009(I-event) .(O)"}, "label_list": ["location", "music genre", "song", "country", "organization", "award", "event", "musical artist", "person", "album", "musical instrument", "band"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 4731, 17779, 11, 5609, 11, 3224, 11, 7471, 11, 10292, 11, 1567, 11, 18273, 10255, 11, 1732, 11, 8176, 11, 18273, 14473, 11, 7200, 323, 507, 627, 85664, 25, 9636, 279, 1510, 16043, 1887, 1174, 304, 2035, 2533, 220, 679, 21, 1174, 279, 8592, 31419, 5620, 13946, 374, 49459, 67537, 3545, 315, 34411, 889, 2834, 279, 20026, 13311, 19508, 47633, 220, 679, 22, 304, 62725, 1174, 19278, 1174, 449, 220, 25302, 3585, 2652, 1234, 279, 3766, 1887, 1174, 279, 8592, 31419, 5620, 13946, 574, 20643, 26775, 70922, 315, 32603, 449, 220, 20062, 3585, 304, 20026, 13311, 19508, 47633, 220, 1049, 24, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "855", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) a(O) pg(B-rating) 13(I-rating) movie(O) about(O) aliens(B-plot)", "instance": {"id": "855", "words": ["show", "me", "a", "pg", "13", "movie", "about", "aliens"], "labels": ["O", "O", "O", "B-rating", "I-rating", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, year, trailer, rating, song, character, actor, plot, review, genre, average ratings, director and O.\nSentence: show me a pg 13 movie about aliens", "prompt_labels": "show(O) me(O) a(O) pg(B-rating) 13(I-rating) movie(O) about(O) aliens(O)"}, "label_list": ["title", "year", "trailer", "rating", "song", "character", "actor", "plot", "review", "genre", "average ratings", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 1060, 11, 19809, 11, 10959, 11, 5609, 11, 3752, 11, 12360, 11, 7234, 11, 3477, 11, 17779, 11, 5578, 18594, 11, 7690, 323, 507, 627, 85664, 25, 1501, 757, 264, 17953, 220, 1032, 5818, 922, 37219, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2310", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) directed(O) the(O) r(B-rating) rated(O) bette(B-actor) davis(I-actor) film(O) that(O) came(O) out(O) in(O) 1960(B-year)", "instance": {"id": "2310", "words": ["who", "directed", "the", "r", "rated", "bette", "davis", "film", "that", "came", "out", "in", "1960"], "labels": ["O", "O", "O", "B-rating", "O", "B-actor", "I-actor", "O", "O", "O", "O", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, review, trailer, plot, genre, title, character, average ratings, year, rating, song, director and O.\nSentence: who directed the r rated bette davis film that came out in 1960", "prompt_labels": "who(O) directed(O) the(O) r(B-rating) rated(O) bette(B-actor) davis(I-actor) film(O) that(O) came(O) out(O) in(O) 1960(B-year)"}, "label_list": ["actor", "review", "trailer", "plot", "genre", "title", "character", "average ratings", "year", "rating", "song", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 3477, 11, 19809, 11, 7234, 11, 17779, 11, 2316, 11, 3752, 11, 5578, 18594, 11, 1060, 11, 10959, 11, 5609, 11, 7690, 323, 507, 627, 85664, 25, 889, 15910, 279, 436, 22359, 1297, 668, 294, 23156, 4632, 430, 3782, 704, 304, 220, 5162, 15, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "162", "dataset": "crossner_music", "split": "dev", "prediction": "Rebana(B-musical instrument) is(O) a(O) Malay(O) tambourine(O) that(O) is(O) used(O) in(O) Islamic(O) devotional(O) music(O) in(O) Southeast(B-location) Asia(I-location),(O) particularly(O) in(O) Indonesia(B-country),(O) Malaysia(B-country),(O) Brunei(B-country),(O) and(O) Singapore(B-country).(O)", "instance": {"id": "162", "words": ["Rebana", "is", "a", "Malay", "tambourine", "that", "is", "used", "in", "Islamic", "devotional", "music", "in", "Southeast", "Asia", ",", "particularly", "in", "Indonesia", ",", "Malaysia", ",", "Brunei", ",", "and", "Singapore", "."], "labels": ["B-musical instrument", "O", "O", "B-musical instrument", "I-musical instrument", "O", "O", "O", "O", "B-music genre", "I-music genre", "I-music genre", "O", "B-location", "B-location", "O", "O", "O", "B-country", "O", "B-country", "O", "B-country", "O", "O", "B-country", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, country, event, album, musical artist, award, location, song, person, band, organization, music genre and O.\nSentence: Rebana is a Malay tambourine that is used in Islamic devotional music in Southeast Asia , particularly in Indonesia , Malaysia , Brunei , and Singapore .", "prompt_labels": "Rebana(B-musical instrument) is(O) a(O) Malay(B-musical instrument) tambourine(I-musical instrument) that(O) is(O) used(O) in(O) Islamic(B-music genre) devotional(I-music genre) music(I-music genre) in(O) Southeast(B-location) Asia(B-location) ,(O) particularly(O) in(O) Indonesia(B-country) ,(O) Malaysia(B-country) ,(O) Brunei(B-country) ,(O) and(O) Singapore(B-country) .(O)"}, "label_list": ["musical instrument", "country", "event", "album", "musical artist", "award", "location", "song", "person", "band", "organization", "music genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18273, 14473, 11, 3224, 11, 1567, 11, 8176, 11, 18273, 10255, 11, 10292, 11, 3813, 11, 5609, 11, 1732, 11, 7200, 11, 7471, 11, 4731, 17779, 323, 507, 627, 85664, 25, 52743, 3444, 374, 264, 80240, 17834, 414, 483, 430, 374, 1511, 304, 15558, 3567, 41964, 4731, 304, 36664, 13936, 1174, 8104, 304, 24922, 1174, 28796, 1174, 3320, 96323, 1174, 323, 21181, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1150", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) john(B-director) huston(I-director) direct(O) a(O) mystery(B-genre) film(O)", "instance": {"id": "1150", "words": ["did", "john", "huston", "direct", "a", "mystery", "film"], "labels": ["O", "B-director", "I-director", "O", "O", "B-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, song, genre, rating, year, plot, trailer, character, director, actor, average ratings, title and O.\nSentence: did john huston direct a mystery film", "prompt_labels": "did(O) john(B-director) huston(I-director) direct(O) a(O) mystery(B-genre) film(O)"}, "label_list": ["review", "song", "genre", "rating", "year", "plot", "trailer", "character", "director", "actor", "average ratings", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 5609, 11, 17779, 11, 10959, 11, 1060, 11, 7234, 11, 19809, 11, 3752, 11, 7690, 11, 12360, 11, 5578, 18594, 11, 2316, 323, 507, 627, 85664, 25, 1550, 40742, 59750, 263, 2167, 264, 23347, 4632, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "47", "dataset": "crossner_music", "split": "dev", "prediction": "One(O) of(O) the(O) main(O) differences(O) between(O) American(O) and(O) European(O) pop(B-music genre) is(O) that(O) Europop(B-music genre) is(O) generally(O) more(O) Dance(B-music genre) music(I-music genre) and(O) Trance(B-music genre) music(I-music genre) oriented(O).(O)", "instance": {"id": "47", "words": ["One", "of", "the", "main", "differences", "between", "American", "and", "European", "pop", "is", "that", "Europop", "is", "generally", "more", "Dance", "music", "and", "Trance", "music", "oriented", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-music genre", "O", "O", "B-music genre", "O", "O", "O", "B-music genre", "I-music genre", "O", "B-music genre", "I-music genre", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, location, song, organization, event, person, music genre, musical artist, musical instrument, country, band, award and O.\nSentence: One of the main differences between American and European pop is that Europop is generally more Dance music and Trance music oriented .", "prompt_labels": "One(O) of(O) the(O) main(O) differences(O) between(O) American(O) and(O) European(O) pop(B-music genre) is(O) that(O) Europop(B-music genre) is(O) generally(O) more(O) Dance(B-music genre) music(I-music genre) and(O) Trance(B-music genre) music(I-music genre) oriented(O) .(O)"}, "label_list": ["album", "location", "song", "organization", "event", "person", "music genre", "musical artist", "musical instrument", "country", "band", "award"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8176, 11, 3813, 11, 5609, 11, 7471, 11, 1567, 11, 1732, 11, 4731, 17779, 11, 18273, 10255, 11, 18273, 14473, 11, 3224, 11, 7200, 11, 10292, 323, 507, 627, 85664, 25, 3861, 315, 279, 1925, 12062, 1990, 3778, 323, 7665, 2477, 374, 430, 68115, 454, 374, 8965, 810, 30704, 4731, 323, 1183, 685, 4731, 42208, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "251", "dataset": "crossner_literature", "split": "dev", "prediction": "137(O) was(O) a(O) German(O) -(O) Netherlands(O) canon(O) regular(O) of(O) the(O) late(O) medieval(O) period(O) and(O) the(O) author(O) of(O) The(B-book) Imitation(I-book) of(I-book) Christ(I-book),(O) one(O) of(O) the(O) most(O) popular(O) and(O) best(O) known(O) Christian(O) devotional(O) books(O).(O)", "instance": {"id": "251", "words": ["137", "was", "a", "German", "-", "Netherlands", "canon", "regular", "of", "the", "late", "medieval", "period", "and", "the", "author", "of", "The", "Imitation", "of", "Christ", ",", "one", "of", "the", "most", "popular", "and", "best", "known", "Christian", "devotional", "books", "."], "labels": ["B-book", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-book", "I-book", "I-book", "I-book", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, person, poem, award, writer, event, literary genre, organization, book, location, magazine and O.\nSentence: 137 was a German - Netherlands canon regular of the late medieval period and the author of The Imitation of Christ , one of the most popular and best known Christian devotional books .", "prompt_labels": "137(B-book) was(O) a(O) German(O) -(O) Netherlands(O) canon(O) regular(O) of(O) the(O) late(O) medieval(O) period(O) and(O) the(O) author(O) of(O) The(B-book) Imitation(I-book) of(I-book) Christ(I-book) ,(O) one(O) of(O) the(O) most(O) popular(O) and(O) best(O) known(O) Christian(O) devotional(O) books(O) .(O)"}, "label_list": ["country", "person", "poem", "award", "writer", "event", "literary genre", "organization", "book", "location", "magazine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 1732, 11, 33894, 11, 10292, 11, 7061, 11, 1567, 11, 32465, 17779, 11, 7471, 11, 2363, 11, 3813, 11, 14756, 323, 507, 627, 85664, 25, 220, 10148, 574, 264, 6063, 482, 26746, 44916, 5912, 315, 279, 3389, 42108, 4261, 323, 279, 3229, 315, 578, 358, 1800, 367, 315, 3771, 1174, 832, 315, 279, 1455, 5526, 323, 1888, 3967, 9052, 3567, 41964, 6603, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "75", "dataset": "crossner_politics", "split": "dev", "prediction": "She(O) was(O) elected(O) to(O) the(O) Ontario(B-location) legislature(I-location) in(O) the(O) 1995(B-election) Ontario(I-election) general(I-election) election(I-election),(O) defeating(O) Ontario(B-political party) Liberal(I-political party) Party(I-political party) Joe(B-politician) Dickson(I-politician) and(O) incumbent(O) Ontario(B-political party) New(I-political party) Democratic(I-political party) Party(I-political party) Jim(B-politician) Wiseman(I-politician) by(O) a(O) significant(O) margin(O) in(O) the(O) riding(O) of(O) Durham(B-location) West(I-location),(O) east(B-location) of(I-location) Toronto(I-location).(O)", "instance": {"id": "75", "words": ["She", "was", "elected", "to", "the", "Ontario", "legislature", "in", "the", "1995", "Ontario", "general", "election", ",", "defeating", "Ontario", "Liberal", "Party", "Joe", "Dickson", "and", "incumbent", "Ontario", "New", "Democratic", "Party", "Jim", "Wiseman", "by", "a", "significant", "margin", "in", "the", "riding", "of", "Durham", "West", ",", "east", "of", "Toronto", "."], "labels": ["O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "B-political party", "I-political party", "I-political party", "B-politician", "I-politician", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "B-politician", "I-politician", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "O", "O", "O", "B-location", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, election, organization, political party, location, country, person, politician and O.\nSentence: She was elected to the Ontario legislature in the 1995 Ontario general election , defeating Ontario Liberal Party Joe Dickson and incumbent Ontario New Democratic Party Jim Wiseman by a significant margin in the riding of Durham West , east of Toronto .", "prompt_labels": "She(O) was(O) elected(O) to(O) the(O) Ontario(B-organization) legislature(I-organization) in(O) the(O) 1995(B-election) Ontario(I-election) general(I-election) election(I-election) ,(O) defeating(O) Ontario(B-political party) Liberal(I-political party) Party(I-political party) Joe(B-politician) Dickson(I-politician) and(O) incumbent(O) Ontario(B-political party) New(I-political party) Democratic(I-political party) Party(I-political party) Jim(B-politician) Wiseman(I-politician) by(O) a(O) significant(O) margin(O) in(O) the(O) riding(O) of(O) Durham(B-location) West(I-location) ,(O) east(O) of(O) Toronto(B-location) .(O)"}, "label_list": ["event", "election", "organization", "political party", "location", "country", "person", "politician"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 6355, 11, 7471, 11, 5054, 4717, 11, 3813, 11, 3224, 11, 1732, 11, 37038, 323, 507, 627, 85664, 25, 3005, 574, 16689, 311, 279, 21193, 39856, 304, 279, 220, 2550, 20, 21193, 4689, 6355, 1174, 54216, 21193, 31158, 8722, 13142, 23373, 942, 323, 51382, 21193, 1561, 11650, 8722, 11641, 16208, 16357, 555, 264, 5199, 4850, 304, 279, 20427, 315, 58814, 4410, 1174, 11226, 315, 14974, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1158", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) robert(B-director) zemeckis(I-director) ever(O) direct(O) a(O) fantasy(B-genre) movie(O)", "instance": {"id": "1158", "words": ["did", "robert", "zemeckis", "ever", "direct", "a", "fantasy", "movie"], "labels": ["O", "B-director", "I-director", "O", "O", "O", "B-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, rating, character, actor, average ratings, title, trailer, review, plot, year, director, genre and O.\nSentence: did robert zemeckis ever direct a fantasy movie", "prompt_labels": "did(O) robert(B-director) zemeckis(I-director) ever(O) direct(O) a(O) fantasy(B-genre) movie(O)"}, "label_list": ["song", "rating", "character", "actor", "average ratings", "title", "trailer", "review", "plot", "year", "director", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 10959, 11, 3752, 11, 12360, 11, 5578, 18594, 11, 2316, 11, 19809, 11, 3477, 11, 7234, 11, 1060, 11, 7690, 11, 17779, 323, 507, 627, 85664, 25, 1550, 89993, 1167, 3981, 377, 285, 3596, 2167, 264, 18884, 5818, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1888", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) are(O) some(O) ok(B-average ratings) r(B-rating) biographys(B-genre) that(O) came(O) out(O) in(O) the(O) 1970(B-year) s(I-year)", "instance": {"id": "1888", "words": ["what", "are", "some", "ok", "r", "biographys", "that", "came", "out", "in", "the", "1970", "s"], "labels": ["O", "O", "O", "B-average ratings", "B-rating", "B-genre", "O", "O", "O", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, title, trailer, plot, year, character, average ratings, actor, song, rating, review, genre and O.\nSentence: what are some ok r biographys that came out in the 1970 s", "prompt_labels": "what(O) are(O) some(O) ok(B-average ratings) r(B-rating) biographys(B-genre) that(O) came(O) out(O) in(O) the(O) 1970(B-year) s(I-year)"}, "label_list": ["director", "title", "trailer", "plot", "year", "character", "average ratings", "actor", "song", "rating", "review", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 2316, 11, 19809, 11, 7234, 11, 1060, 11, 3752, 11, 5578, 18594, 11, 12360, 11, 5609, 11, 10959, 11, 3477, 11, 17779, 323, 507, 627, 85664, 25, 1148, 527, 1063, 5509, 436, 6160, 3257, 1065, 430, 3782, 704, 304, 279, 220, 4468, 15, 274, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "170", "dataset": "crossner_music", "split": "dev", "prediction": "Some(O) of(O) the(O) early(O) stars(O) on(O) the(O) Opry(B-location) were(O) Uncle(B-musical artist) Dave(I-musical artist) Macon(I-musical artist),(O) Roy(B-musical artist) Acuff(I-musical artist) and(O) African(O) American(O) harmonica(O) player(O) DeFord(B-musical artist) Bailey(I-musical artist).(O)", "instance": {"id": "170", "words": ["Some", "of", "the", "early", "stars", "on", "the", "Opry", "were", "Uncle", "Dave", "Macon", ",", "Roy", "Acuff", "and", "African", "American", "harmonica", "player", "DeFord", "Bailey", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-location", "O", "B-musical artist", "I-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "O", "O", "B-musical instrument", "O", "B-musical artist", "I-musical artist", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, musical instrument, musical artist, music genre, country, event, person, organization, album, band, award, song and O.\nSentence: Some of the early stars on the Opry were Uncle Dave Macon , Roy Acuff and African American harmonica player DeFord Bailey .", "prompt_labels": "Some(O) of(O) the(O) early(O) stars(O) on(O) the(O) Opry(B-location) were(O) Uncle(B-musical artist) Dave(I-musical artist) Macon(I-musical artist) ,(O) Roy(B-musical artist) Acuff(I-musical artist) and(O) African(O) American(O) harmonica(B-musical instrument) player(O) DeFord(B-musical artist) Bailey(I-musical artist) .(O)"}, "label_list": ["location", "musical instrument", "musical artist", "music genre", "country", "event", "person", "organization", "album", "band", "award", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 18273, 14473, 11, 18273, 10255, 11, 4731, 17779, 11, 3224, 11, 1567, 11, 1732, 11, 7471, 11, 8176, 11, 7200, 11, 10292, 11, 5609, 323, 507, 627, 85664, 25, 4427, 315, 279, 4216, 9958, 389, 279, 78618, 88, 1051, 51521, 20851, 11583, 444, 1174, 11284, 6515, 1386, 323, 11904, 3778, 18249, 3074, 2851, 1611, 59663, 43314, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "12", "dataset": "crossner_science", "split": "dev", "prediction": "The(O) traditional(O) precursor(O) is(O) N-Nitroso-N-methylurea(B-chemical compound),(O) but(O) this(O) compound(O) is(O) itself(O) somewhat(O) unstable(O),(O) and(O) nowadays(O) compounds(O) such(O) as(O) Methylnitronitrosoguanidine(B-chemical compound) ((O) MNNG(B-chemical compound) )(O) and(O) Diazald(B-chemical compound) ((O) Diazald(B-chemical compound) )(O) are(O) preferred(O).(O)", "instance": {"id": "12", "words": ["The", "traditional", "precursor", "is", "N-Nitroso-N-methylurea", ",", "but", "this", "compound", "is", "itself", "somewhat", "unstable", ",", "and", "nowadays", "compounds", "such", "as", "Methylnitronitrosoguanidine", "(", "MNNG", ")", "and", "Diazald", "(", "Diazald", ")", "are", "preferred", "."], "labels": ["O", "O", "O", "O", "B-chemical compound", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-chemical compound", "O", "B-chemical compound", "O", "O", "B-chemical compound", "O", "B-chemical compound", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: enzyme, theory, astronomical object, academic journal, organization, person, event, chemical compound, country, scientist, university, location, chemical element, protein, award, discipline and O.\nSentence: The traditional precursor is N-Nitroso-N-methylurea , but this compound is itself somewhat unstable , and nowadays compounds such as Methylnitronitrosoguanidine ( MNNG ) and Diazald ( Diazald ) are preferred .", "prompt_labels": "The(O) traditional(O) precursor(O) is(O) N-Nitroso-N-methylurea(B-chemical compound) ,(O) but(O) this(O) compound(O) is(O) itself(O) somewhat(O) unstable(O) ,(O) and(O) nowadays(O) compounds(O) such(O) as(O) Methylnitronitrosoguanidine(B-chemical compound) ((O) MNNG(B-chemical compound) )(O) and(O) Diazald(B-chemical compound) ((O) Diazald(B-chemical compound) )(O) are(O) preferred(O) .(O)"}, "label_list": ["enzyme", "theory", "astronomical object", "academic journal", "organization", "person", "event", "chemical compound", "country", "scientist", "university", "location", "chemical element", "protein", "award", "discipline"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49242, 11, 10334, 11, 87283, 1665, 11, 14584, 8486, 11, 7471, 11, 1732, 11, 1567, 11, 11742, 24549, 11, 3224, 11, 28568, 11, 12374, 11, 3813, 11, 11742, 2449, 11, 13128, 11, 10292, 11, 26434, 323, 507, 627, 85664, 25, 578, 8776, 71261, 374, 452, 11500, 275, 299, 708, 11500, 1474, 42972, 554, 64, 1174, 719, 420, 24549, 374, 5196, 14738, 45311, 1174, 323, 46877, 32246, 1778, 439, 57175, 88, 2312, 275, 2298, 275, 3714, 540, 10602, 91073, 320, 36095, 6269, 883, 323, 58131, 4852, 320, 58131, 4852, 883, 527, 15236, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1489", "dataset": "mit-restaurant", "split": "dev", "prediction": "which(O) restaurant(O) can(O) i(O) get(O) to(O) within(B-Location) 5(I-Location) minutes(I-Location) which(O) serves(O) healthy(B-Amenity) portions(I-Amenity)", "instance": {"id": "1489", "words": ["which", "restaurant", "can", "i", "get", "to", "within", "5", "minutes", "which", "serves", "healthy", "portions"], "labels": ["O", "O", "O", "O", "O", "O", "B-Location", "I-Location", "I-Location", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Dish, Price, Amenity, Hours, Cuisine, Rating, Restaurant Name and O.\nSentence: which restaurant can i get to within 5 minutes which serves healthy portions", "prompt_labels": "which(O) restaurant(O) can(O) i(O) get(O) to(O) within(B-Location) 5(I-Location) minutes(I-Location) which(O) serves(O) healthy(B-Amenity) portions(I-Amenity)"}, "label_list": ["Location", "Dish", "Price", "Amenity", "Hours", "Cuisine", "Rating", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 49268, 11, 8650, 11, 3383, 56685, 11, 30192, 11, 81961, 11, 19767, 11, 26568, 4076, 323, 507, 627, 85664, 25, 902, 10960, 649, 602, 636, 311, 2949, 220, 20, 4520, 902, 17482, 9498, 19885, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1102", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) are(O) the(O) spiciest(O) local(B-Rating) favourites(I-Rating) served(O) at(O) cappys(B-Restaurant Name) pizza(I-Restaurant Name) and(I-Restaurant Name) subs(I-Restaurant Name)", "instance": {"id": "1102", "words": ["what", "are", "the", "spiciest", "local", "favourites", "served", "at", "cappys", "pizza", "and", "subs"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Location, Restaurant Name, Rating, Amenity, Hours, Dish, Cuisine and O.\nSentence: what are the spiciest local favourites served at cappys pizza and subs", "prompt_labels": "what(O) are(O) the(O) spiciest(O) local(O) favourites(O) served(O) at(O) cappys(B-Restaurant Name) pizza(I-Restaurant Name) and(I-Restaurant Name) subs(I-Restaurant Name)"}, "label_list": ["Price", "Location", "Restaurant Name", "Rating", "Amenity", "Hours", "Dish", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 10067, 11, 26568, 4076, 11, 19767, 11, 3383, 56685, 11, 30192, 11, 49268, 11, 81961, 323, 507, 627, 85664, 25, 1148, 527, 279, 993, 3457, 478, 2254, 58034, 10434, 520, 272, 680, 1065, 23317, 323, 5258, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "121", "dataset": "crossner_science", "split": "dev", "prediction": "This(O) subcategory(O) includes(O) Pluto(B-astronomical object),(O) Haumea(B-astronomical object),(O) Makemake(B-astronomical object) and(O) Eris(B-astronomical object).(O)", "instance": {"id": "121", "words": ["This", "subcategory", "includes", "Pluto", ",", "Haumea", ",", "Makemake", "and", "Eris", "."], "labels": ["O", "O", "O", "B-astronomical object", "O", "B-astronomical object", "O", "B-astronomical object", "O", "B-astronomical object", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, scientist, discipline, chemical compound, chemical element, country, location, academic journal, event, astronomical object, theory, organization, enzyme, protein, university, person and O.\nSentence: This subcategory includes Pluto , Haumea , Makemake and Eris .", "prompt_labels": "This(O) subcategory(O) includes(O) Pluto(B-astronomical object) ,(O) Haumea(B-astronomical object) ,(O) Makemake(B-astronomical object) and(O) Eris(B-astronomical object) .(O)"}, "label_list": ["award", "scientist", "discipline", "chemical compound", "chemical element", "country", "location", "academic journal", "event", "astronomical object", "theory", "organization", "enzyme", "protein", "university", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10292, 11, 28568, 11, 26434, 11, 11742, 24549, 11, 11742, 2449, 11, 3224, 11, 3813, 11, 14584, 8486, 11, 1567, 11, 87283, 1665, 11, 10334, 11, 7471, 11, 49242, 11, 13128, 11, 12374, 11, 1732, 323, 507, 627, 85664, 25, 1115, 1207, 5588, 5764, 78681, 1174, 14433, 3972, 64, 1174, 40424, 336, 731, 323, 469, 6091, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "263", "dataset": "crossner_science", "split": "dev", "prediction": "These(O) can(O) be(O) further(O) subdivided(O) into(O) the(O) gas(O) giant(O) s(O) ((O) Jupiter(B-astronomical object) and(O) Saturn(B-astronomical object) )(O) and(O) the(O) ice(O) giant(O) s(O) ((O) Uranus(B-astronomical object) and(O) Neptune(B-astronomical object) )(O) that(O) have(O) large(O) icy(O) cores(O).(O)", "instance": {"id": "263", "words": ["These", "can", "be", "further", "subdivided", "into", "the", "gas", "giant", "s", "(", "Jupiter", "and", "Saturn", ")", "and", "the", "ice", "giant", "s", "(", "Uranus", "and", "Neptune", ")", "that", "have", "large", "icy", "cores", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-astronomical object", "O", "B-astronomical object", "O", "O", "O", "O", "O", "O", "O", "B-astronomical object", "O", "B-astronomical object", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: astronomical object, organization, chemical element, country, university, scientist, chemical compound, location, enzyme, event, award, academic journal, person, theory, protein, discipline and O.\nSentence: These can be further subdivided into the gas giant s ( Jupiter and Saturn ) and the ice giant s ( Uranus and Neptune ) that have large icy cores .", "prompt_labels": "These(O) can(O) be(O) further(O) subdivided(O) into(O) the(O) gas(O) giant(O) s(O) ((O) Jupiter(B-astronomical object) and(O) Saturn(B-astronomical object) )(O) and(O) the(O) ice(O) giant(O) s(O) ((O) Uranus(B-astronomical object) and(O) Neptune(B-astronomical object) )(O) that(O) have(O) large(O) icy(O) cores(O) .(O)"}, "label_list": ["astronomical object", "organization", "chemical element", "country", "university", "scientist", "chemical compound", "location", "enzyme", "event", "award", "academic journal", "person", "theory", "protein", "discipline"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 87283, 1665, 11, 7471, 11, 11742, 2449, 11, 3224, 11, 12374, 11, 28568, 11, 11742, 24549, 11, 3813, 11, 49242, 11, 1567, 11, 10292, 11, 14584, 8486, 11, 1732, 11, 10334, 11, 13128, 11, 26434, 323, 507, 627, 85664, 25, 4314, 649, 387, 4726, 67609, 4591, 1139, 279, 6962, 14880, 274, 320, 50789, 323, 50253, 883, 323, 279, 10054, 14880, 274, 320, 80770, 355, 323, 80724, 883, 430, 617, 3544, 67004, 36804, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "56", "dataset": "crossner_literature", "split": "dev", "prediction": "Snyder(B-writer)'s(O) interest(O) in(O) things(O) Chinese(O) and(O) Japanese(O) stemmed(O) from(O) his(O) early(O) reading(O) of(O) Pound(B-writer)'s(O) writings(O).(O) and(O) his(O) long(O) poem(B-literary genre) Mountains(B-book) and(I-book) Rivers(I-book) Without(I-book) End(I-book) ((O) 1965-1996(O) )(O) reflects(O) his(O) reading(O) of(O) The(B-book) Cantos(I-book) in(O) many(O) of(O) the(O) formal(O) devices(O) used(O).(O)", "instance": {"id": "56", "words": ["Snyder", "'s", "interest", "in", "things", "Chinese", "and", "Japanese", "stemmed", "from", "his", "early", "reading", "of", "Pound", "'s", "writings.", "and", "his", "long", "poem", "Mountains", "and", "Rivers", "Without", "End", "(", "1965-1996", ")", "reflects", "his", "reading", "of", "The", "Cantos", "in", "many", "of", "the", "formal", "devices", "used", "."], "labels": ["B-writer", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-writer", "O", "O", "O", "O", "B-literary genre", "I-literary genre", "B-poem", "I-poem", "I-poem", "I-poem", "I-poem", "O", "O", "O", "O", "O", "O", "O", "B-poem", "I-poem", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, country, literary genre, book, organization, person, location, writer, award, magazine, poem and O.\nSentence: Snyder 's interest in things Chinese and Japanese stemmed from his early reading of Pound 's writings. and his long poem Mountains and Rivers Without End ( 1965-1996 ) reflects his reading of The Cantos in many of the formal devices used .", "prompt_labels": "Snyder(B-writer) 's(O) interest(O) in(O) things(O) Chinese(O) and(O) Japanese(O) stemmed(O) from(O) his(O) early(O) reading(O) of(O) Pound(B-writer) 's(O) writings.(O) and(O) his(O) long(B-literary genre) poem(I-literary genre) Mountains(B-poem) and(I-poem) Rivers(I-poem) Without(I-poem) End(I-poem) ((O) 1965-1996(O) )(O) reflects(O) his(O) reading(O) of(O) The(B-poem) Cantos(I-poem) in(O) many(O) of(O) the(O) formal(O) devices(O) used(O) .(O)"}, "label_list": ["event", "country", "literary genre", "book", "organization", "person", "location", "writer", "award", "magazine", "poem"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 3224, 11, 32465, 17779, 11, 2363, 11, 7471, 11, 1732, 11, 3813, 11, 7061, 11, 10292, 11, 14756, 11, 33894, 323, 507, 627, 85664, 25, 54231, 364, 82, 2802, 304, 2574, 8620, 323, 11002, 99618, 505, 813, 4216, 5403, 315, 79352, 364, 82, 43422, 13, 323, 813, 1317, 33894, 41114, 323, 36739, 17586, 4060, 320, 220, 5162, 20, 12, 2550, 21, 883, 27053, 813, 5403, 315, 578, 42931, 437, 304, 1690, 315, 279, 16287, 7766, 1511, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "491", "dataset": "crossner_politics", "split": "dev", "prediction": "According(O) to(O) a(O) press(O) release(O) issued(O) by(O) Mohammed(B-politician) Ali(I-politician) Jinnah(I-politician),(O) the(O) Convenor(O) of(O) the(O) Conference(O),(O) the(O) first(O) copy(O) of(O) manifesto(O) of(O) the(O) Social(B-event) Justice(I-event) Conference(I-event) was(O) issued(O) by(O) E.(B-politician) Aboobacker(I-politician),(O) the(O) National(O) President(O) Social(B-political party) Democratic(I-political party) Party(I-political party) of(I-political party) India(I-political party) and(O) the(O) theme(O) of(O) the(O) Social(B-event) Justice(I-event) Conference(I-event) was(O) delivered(O) by(O) Popular(B-political party) Front(I-political party) of(I-political party) India(I-political party) Chairman(O),(O) E.M(B-politician) Abdul(I-politician) Rahiman(I-politician).(O)", "instance": {"id": "491", "words": ["According", "to", "a", "press", "release", "issued", "by", "Mohammed", "Ali", "Jinnah", ",", "the", "Convenor", "of", "the", "Conference", ",", "the", "first", "copy", "of", "manifesto", "of", "the", "Social", "Justice", "Conference", "was", "issued", "by", "E.", "Aboobacker", ",", "the", "National", "President", "Social", "Democratic", "Party", "of", "India", "and", "the", "theme", "of", "the", "Social", "Justice", "Conference", "was", "delivered", "by", "Popular", "Front", "of", "India", "Chairman", ",", "E.M", "Abdul", "Rahiman", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-politician", "I-politician", "I-politician", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "O", "O", "O", "B-politician", "I-politician", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "B-person", "I-person", "I-person", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, politician, organization, election, location, event, political party, person and O.\nSentence: According to a press release issued by Mohammed Ali Jinnah , the Convenor of the Conference , the first copy of manifesto of the Social Justice Conference was issued by E. Aboobacker , the National President Social Democratic Party of India and the theme of the Social Justice Conference was delivered by Popular Front of India Chairman , E.M Abdul Rahiman .", "prompt_labels": "According(O) to(O) a(O) press(O) release(O) issued(O) by(O) Mohammed(B-politician) Ali(I-politician) Jinnah(I-politician) ,(O) the(O) Convenor(O) of(O) the(O) Conference(O) ,(O) the(O) first(O) copy(O) of(O) manifesto(O) of(O) the(O) Social(B-event) Justice(I-event) Conference(I-event) was(O) issued(O) by(O) E.(B-politician) Aboobacker(I-politician) ,(O) the(O) National(O) President(O) Social(B-political party) Democratic(I-political party) Party(I-political party) of(I-political party) India(I-political party) and(O) the(O) theme(O) of(O) the(O) Social(B-event) Justice(I-event) Conference(I-event) was(O) delivered(O) by(O) Popular(B-organization) Front(I-organization) of(I-organization) India(I-organization) Chairman(O) ,(O) E.M(B-person) Abdul(I-person) Rahiman(I-person) .(O)"}, "label_list": ["country", "politician", "organization", "election", "location", "event", "political party", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 37038, 11, 7471, 11, 6355, 11, 3813, 11, 1567, 11, 5054, 4717, 11, 1732, 323, 507, 627, 85664, 25, 10771, 311, 264, 3577, 4984, 11136, 555, 46392, 14925, 622, 6258, 1494, 1174, 279, 1221, 1055, 269, 315, 279, 15217, 1174, 279, 1176, 3048, 315, 75703, 315, 279, 9983, 12007, 15217, 574, 11136, 555, 469, 13, 362, 754, 677, 9881, 1174, 279, 5165, 4900, 9983, 11650, 8722, 315, 6890, 323, 279, 7057, 315, 279, 9983, 12007, 15217, 574, 12886, 555, 32495, 15248, 315, 6890, 27390, 1174, 469, 1345, 52698, 33348, 40310, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "347", "dataset": "mit-restaurant", "split": "dev", "prediction": "find(O) a(O) place(O) with(O) live(B-Amenity) music(I-Amenity) and(O) happy(B-Amenity) hour(I-Amenity) specials(I-Amenity)", "instance": {"id": "347", "words": ["find", "a", "place", "with", "live", "music", "and", "happy", "hour", "specials"], "labels": ["O", "O", "O", "O", "B-Amenity", "I-Amenity", "O", "B-Amenity", "I-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Hours, Price, Restaurant Name, Location, Cuisine, Amenity, Dish and O.\nSentence: find a place with live music and happy hour specials", "prompt_labels": "find(O) a(O) place(O) with(O) live(B-Amenity) music(I-Amenity) and(O) happy(B-Amenity) hour(I-Amenity) specials(I-Amenity)"}, "label_list": ["Rating", "Hours", "Price", "Restaurant Name", "Location", "Cuisine", "Amenity", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 30192, 11, 8650, 11, 26568, 4076, 11, 10067, 11, 81961, 11, 3383, 56685, 11, 49268, 323, 507, 627, 85664, 25, 1505, 264, 2035, 449, 3974, 4731, 323, 6380, 6596, 60874, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "153", "dataset": "mit-restaurant", "split": "dev", "prediction": "can(O) you(O) find(O) me(O) a(O) fredas(B-Restaurant Name) thats(O) not(B-Amenity) too(I-Amenity) busy(I-Amenity)", "instance": {"id": "153", "words": ["can", "you", "find", "me", "a", "fredas", "thats", "not", "too", "busy"], "labels": ["O", "O", "O", "O", "O", "B-Restaurant Name", "O", "B-Amenity", "I-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Hours, Rating, Location, Restaurant Name, Dish, Price, Amenity and O.\nSentence: can you find me a fredas thats not too busy", "prompt_labels": "can(O) you(O) find(O) me(O) a(O) fredas(B-Restaurant Name) thats(O) not(B-Amenity) too(I-Amenity) busy(I-Amenity)"}, "label_list": ["Cuisine", "Hours", "Rating", "Location", "Restaurant Name", "Dish", "Price", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 30192, 11, 19767, 11, 10067, 11, 26568, 4076, 11, 49268, 11, 8650, 11, 3383, 56685, 323, 507, 627, 85664, 25, 649, 499, 1505, 757, 264, 98226, 300, 41136, 539, 2288, 13326, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2264", "dataset": "mit-movie", "split": "dev", "prediction": "when(O) did(O) war(B-title) gods(I-title) of(I-title) the(I-title) deep(I-title) come(O) out(O)", "instance": {"id": "2264", "words": ["when", "did", "war", "gods", "of", "the", "deep", "come", "out"], "labels": ["O", "O", "B-title", "I-title", "I-title", "I-title", "I-title", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, song, director, rating, title, year, review, plot, average ratings, genre, actor, character and O.\nSentence: when did war gods of the deep come out", "prompt_labels": "when(O) did(O) war(B-title) gods(I-title) of(I-title) the(I-title) deep(I-title) come(O) out(O)"}, "label_list": ["trailer", "song", "director", "rating", "title", "year", "review", "plot", "average ratings", "genre", "actor", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 5609, 11, 7690, 11, 10959, 11, 2316, 11, 1060, 11, 3477, 11, 7234, 11, 5578, 18594, 11, 17779, 11, 12360, 11, 3752, 323, 507, 627, 85664, 25, 994, 1550, 4208, 29913, 315, 279, 5655, 2586, 704, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "120", "dataset": "crossner_science", "split": "dev", "prediction": "GSK-3(B-protein) has(O) been(O) implicated(O) in(O) bipolar(B-event) disorder(I-event),(O) as(O) bipolar(O) medications(O) lithium(B-chemical compound) and(O) valproate(B-chemical compound) have(O) been(O) shown(O) to(O) increase(O) its(O) phosphorylation(O),(O) thereby(O) inhibiting(O) it(O).(O)", "instance": {"id": "120", "words": ["GSK-3", "has", "been", "implicated", "in", "bipolar", "disorder", ",", "as", "bipolar", "medications", "lithium", "and", "valproate", "have", "been", "shown", "to", "increase", "its", "phosphorylation", ",", "thereby", "inhibiting", "it", "."], "labels": ["B-protein", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-chemical element", "O", "B-chemical compound", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, person, country, chemical compound, enzyme, theory, organization, university, protein, event, academic journal, award, discipline, astronomical object, location, chemical element and O.\nSentence: GSK-3 has been implicated in bipolar disorder , as bipolar medications lithium and valproate have been shown to increase its phosphorylation , thereby inhibiting it .", "prompt_labels": "GSK-3(B-protein) has(O) been(O) implicated(O) in(O) bipolar(O) disorder(O) ,(O) as(O) bipolar(O) medications(O) lithium(B-chemical element) and(O) valproate(B-chemical compound) have(O) been(O) shown(O) to(O) increase(O) its(O) phosphorylation(O) ,(O) thereby(O) inhibiting(O) it(O) .(O)"}, "label_list": ["scientist", "person", "country", "chemical compound", "enzyme", "theory", "organization", "university", "protein", "event", "academic journal", "award", "discipline", "astronomical object", "location", "chemical element"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 28568, 11, 1732, 11, 3224, 11, 11742, 24549, 11, 49242, 11, 10334, 11, 7471, 11, 12374, 11, 13128, 11, 1567, 11, 14584, 8486, 11, 10292, 11, 26434, 11, 87283, 1665, 11, 3813, 11, 11742, 2449, 323, 507, 627, 85664, 25, 480, 16074, 12, 18, 706, 1027, 69702, 304, 65919, 19823, 1174, 439, 65919, 31010, 57907, 323, 1062, 782, 349, 617, 1027, 6982, 311, 5376, 1202, 95089, 2354, 1174, 28592, 20747, 5977, 433, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1001", "dataset": "mit-restaurant", "split": "dev", "prediction": "mexican(B-Cuisine) restaurant(O) nearby(B-Location)", "instance": {"id": "1001", "words": ["mexican", "restaurant", "nearby"], "labels": ["B-Cuisine", "O", "B-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Rating, Price, Hours, Dish, Cuisine, Restaurant Name, Amenity and O.\nSentence: mexican restaurant nearby", "prompt_labels": "mexican(B-Cuisine) restaurant(O) nearby(B-Location)"}, "label_list": ["Location", "Rating", "Price", "Hours", "Dish", "Cuisine", "Restaurant Name", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 19767, 11, 8650, 11, 30192, 11, 49268, 11, 81961, 11, 26568, 4076, 11, 3383, 56685, 323, 507, 627, 85664, 25, 38049, 7210, 10960, 14373, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "318", "dataset": "mit-restaurant", "split": "dev", "prediction": "does(O) the(O) kyotoyo(B-Restaurant Name) japanese(I-Restaurant Name) restaurant(I-Restaurant Name) in(B-Location) the(I-Location) theater(I-Location) district(I-Location) deliver(B-Amenity)", "instance": {"id": "318", "words": ["does", "the", "kyotoyo", "japanese", "restaurant", "in", "the", "theater", "district", "deliver"], "labels": ["O", "O", "B-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name", "O", "O", "B-Location", "I-Location", "B-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Location, Dish, Restaurant Name, Hours, Rating, Amenity, Price and O.\nSentence: does the kyotoyo japanese restaurant in the theater district deliver", "prompt_labels": "does(O) the(O) kyotoyo(B-Restaurant Name) japanese(I-Restaurant Name) restaurant(I-Restaurant Name) in(O) the(O) theater(B-Location) district(I-Location) deliver(B-Amenity)"}, "label_list": ["Cuisine", "Location", "Dish", "Restaurant Name", "Hours", "Rating", "Amenity", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 10067, 11, 49268, 11, 26568, 4076, 11, 30192, 11, 19767, 11, 3383, 56685, 11, 8650, 323, 507, 627, 85664, 25, 1587, 279, 56053, 2117, 16417, 54048, 10960, 304, 279, 27803, 9474, 6493, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "343", "dataset": "mit-movie", "split": "dev", "prediction": "best(B-average ratings) crome(B-title) movie(O) from(O) almodovar(B-director)", "instance": {"id": "343", "words": ["best", "crome", "movie", "from", "almodovar"], "labels": ["B-review", "O", "O", "O", "B-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, genre, trailer, rating, plot, character, actor, review, director, song, title, average ratings and O.\nSentence: best crome movie from almodovar", "prompt_labels": "best(B-review) crome(O) movie(O) from(O) almodovar(B-director)"}, "label_list": ["year", "genre", "trailer", "rating", "plot", "character", "actor", "review", "director", "song", "title", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 17779, 11, 19809, 11, 10959, 11, 7234, 11, 3752, 11, 12360, 11, 3477, 11, 7690, 11, 5609, 11, 2316, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1888, 272, 6786, 5818, 505, 453, 2658, 869, 277, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "548", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) year(B-year) did(O) goodfellas(B-title) release(O)", "instance": {"id": "548", "words": ["what", "year", "did", "goodfellas", "release"], "labels": ["O", "O", "O", "B-title", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, trailer, genre, title, character, rating, year, average ratings, plot, director, review, song and O.\nSentence: what year did goodfellas release", "prompt_labels": "what(O) year(O) did(O) goodfellas(B-title) release(O)"}, "label_list": ["actor", "trailer", "genre", "title", "character", "rating", "year", "average ratings", "plot", "director", "review", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 19809, 11, 17779, 11, 2316, 11, 3752, 11, 10959, 11, 1060, 11, 5578, 18594, 11, 7234, 11, 7690, 11, 3477, 11, 5609, 323, 507, 627, 85664, 25, 1148, 1060, 1550, 1695, 67643, 300, 4984, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "614", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) smell(O) bread(B-Dish) take(O) me(O) there(O)", "instance": {"id": "614", "words": ["i", "smell", "bread", "take", "me", "there"], "labels": ["O", "O", "B-Dish", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Hours, Cuisine, Price, Dish, Location, Restaurant Name, Rating and O.\nSentence: i smell bread take me there", "prompt_labels": "i(O) smell(O) bread(B-Dish) take(O) me(O) there(O)"}, "label_list": ["Amenity", "Hours", "Cuisine", "Price", "Dish", "Location", "Restaurant Name", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 30192, 11, 81961, 11, 8650, 11, 49268, 11, 10067, 11, 26568, 4076, 11, 19767, 323, 507, 627, 85664, 25, 602, 22843, 16385, 1935, 757, 1070, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "34", "dataset": "crossner_ai", "split": "dev", "prediction": "The(O) research(O) activities(O) include(O) an(O) annual(O) research(O) conference(O),(O) the(O) RuleML(B-conference) Symposium(I-conference),(O) also(O) known(O) as(O) RuleML(B-conference) for(O) short(O).(O)", "instance": {"id": "34", "words": ["The", "research", "activities", "include", "an", "annual", "research", "conference", ",", "the", "RuleML", "Symposium", ",", "also", "known", "as", "RuleML", "for", "short", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-conference", "I-conference", "O", "O", "O", "O", "B-conference", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, programming language, field, metric, university, organization, conference, task, algorithm, person, product, researcher, country and O.\nSentence: The research activities include an annual research conference , the RuleML Symposium , also known as RuleML for short .", "prompt_labels": "The(O) research(O) activities(O) include(O) an(O) annual(O) research(O) conference(O) ,(O) the(O) RuleML(B-conference) Symposium(I-conference) ,(O) also(O) known(O) as(O) RuleML(B-conference) for(O) short(O) .(O)"}, "label_list": ["location", "programming language", "field", "metric", "university", "organization", "conference", "task", "algorithm", "person", "product", "researcher", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 15840, 4221, 11, 2115, 11, 18767, 11, 12374, 11, 7471, 11, 10017, 11, 3465, 11, 12384, 11, 1732, 11, 2027, 11, 32185, 11, 3224, 323, 507, 627, 85664, 25, 578, 3495, 7640, 2997, 459, 9974, 3495, 10017, 1174, 279, 18592, 2735, 74938, 1174, 1101, 3967, 439, 18592, 2735, 369, 2875, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2388", "dataset": "mit-movie", "split": "dev", "prediction": "whats(O) a(O) documentary(B-genre) about(O) youth(B-plot) identity(I-plot)", "instance": {"id": "2388", "words": ["whats", "a", "documentary", "about", "youth", "identity"], "labels": ["O", "O", "B-genre", "O", "B-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, director, genre, actor, character, rating, trailer, review, year, average ratings, title, song and O.\nSentence: whats a documentary about youth identity", "prompt_labels": "whats(O) a(O) documentary(B-genre) about(O) youth(B-plot) identity(I-plot)"}, "label_list": ["plot", "director", "genre", "actor", "character", "rating", "trailer", "review", "year", "average ratings", "title", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 7690, 11, 17779, 11, 12360, 11, 3752, 11, 10959, 11, 19809, 11, 3477, 11, 1060, 11, 5578, 18594, 11, 2316, 11, 5609, 323, 507, 627, 85664, 25, 41209, 264, 25999, 922, 12822, 9764, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "109", "dataset": "crossner_ai", "split": "dev", "prediction": "We(O) make(O) as(O) well(O) as(O) possible(O) precise(O) by(O) measuring(O) the(O) mean(B-metric) squared(I-metric) error(I-metric) between(O) mathy(B-product) /(O) math(B-product) and(O) math(B-product) \\(O) hat(O) {(O) f(O) }(O) ((O) x(O) ;(O) D(O) )(O) /(O) math(O) :(O) we(O) want(O) math(O) ((O) y(O) -(O) \\(O) hat(O) {(O) f(O) }(O) ((O) x(O) ;(O) D(O) )(O) ^(O) 2(O) /(O) math(O) to(O) be(O) minimal(O),(O) both(O) for(O) mathx(B-product) _(O) 1(O),(O) \\(O) dots(O),(O) x(O) _(O) n(O) /(O) math(O) and(O) for(O) points(O) outside(O) of(O) our(O) sample(O).(O)", "instance": {"id": "109", "words": ["We", "make", "as", "well", "as", "possible", "precise", "by", "measuring", "the", "mean", "squared", "error", "between", "mathy", "/", "math", "and", "math", "\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", "/", "math", ":", "we", "want", "math", "(", "y", "-", "\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", ")", "^", "2", "/", "math", "to", "be", "minimal", ",", "both", "for", "mathx", "_", "1", ",", "\\", "dots", ",", "x", "_", "n", "/", "math", "and", "for", "points", "outside", "of", "our", "sample", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-metric", "I-metric", "I-metric", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, organization, location, programming language, conference, metric, product, field, person, task, algorithm, country, researcher and O.\nSentence: We make as well as possible precise by measuring the mean squared error between mathy / math and math \\ hat { f } ( x ; D ) / math : we want math ( y - \\ hat { f } ( x ; D ) ) ^ 2 / math to be minimal , both for mathx _ 1 , \\ dots , x _ n / math and for points outside of our sample .", "prompt_labels": "We(O) make(O) as(O) well(O) as(O) possible(O) precise(O) by(O) measuring(O) the(O) mean(B-metric) squared(I-metric) error(I-metric) between(O) mathy(O) /(O) math(O) and(O) math(O) \\(O) hat(O) {(O) f(O) }(O) ((O) x(O) ;(O) D(O) )(O) /(O) math(O) :(O) we(O) want(O) math(O) ((O) y(O) -(O) \\(O) hat(O) {(O) f(O) }(O) ((O) x(O) ;(O) D(O) )(O) )(O) ^(O) 2(O) /(O) math(O) to(O) be(O) minimal(O) ,(O) both(O) for(O) mathx(O) _(O) 1(O) ,(O) \\(O) dots(O) ,(O) x(O) _(O) n(O) /(O) math(O) and(O) for(O) points(O) outside(O) of(O) our(O) sample(O) .(O)"}, "label_list": ["university", "organization", "location", "programming language", "conference", "metric", "product", "field", "person", "task", "algorithm", "country", "researcher"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12374, 11, 7471, 11, 3813, 11, 15840, 4221, 11, 10017, 11, 18767, 11, 2027, 11, 2115, 11, 1732, 11, 3465, 11, 12384, 11, 3224, 11, 32185, 323, 507, 627, 85664, 25, 1226, 1304, 439, 1664, 439, 3284, 24473, 555, 30090, 279, 3152, 53363, 1493, 1990, 7033, 88, 611, 7033, 323, 7033, 1144, 9072, 314, 282, 335, 320, 865, 2652, 423, 883, 611, 7033, 551, 584, 1390, 7033, 320, 379, 482, 1144, 9072, 314, 282, 335, 320, 865, 2652, 423, 883, 883, 6440, 220, 17, 611, 7033, 311, 387, 17832, 1174, 2225, 369, 7033, 87, 721, 220, 16, 1174, 1144, 32094, 1174, 865, 721, 308, 611, 7033, 323, 369, 3585, 4994, 315, 1057, 6205, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "263", "dataset": "crossner_politics", "split": "dev", "prediction": "Osborne(B-politician) was(O) a(O) free(O) silver(O) supporters(O) and(O) during(O) the(O) 1896(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election),(O) 1900(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election),(O) and(O) 1908(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) he(O) supported(O) William(B-politician) Jennings(I-politician) Bryan(I-politician).(O)", "instance": {"id": "263", "words": ["Osborne", "was", "a", "free", "silver", "supporters", "and", "during", "the", "1896", "United", "States", "presidential", "election", ",", "1900", "United", "States", "presidential", "election", ",", "and", "1908", "United", "States", "presidential", "election", "he", "supported", "William", "Jennings", "Bryan", "."], "labels": ["B-person", "O", "O", "B-event", "I-event", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-politician", "I-politician", "I-politician", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, political party, location, person, event, organization, election, country and O.\nSentence: Osborne was a free silver supporters and during the 1896 United States presidential election , 1900 United States presidential election , and 1908 United States presidential election he supported William Jennings Bryan .", "prompt_labels": "Osborne(B-person) was(O) a(O) free(B-event) silver(I-event) supporters(O) and(O) during(O) the(O) 1896(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ,(O) 1900(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ,(O) and(O) 1908(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) he(O) supported(O) William(B-politician) Jennings(I-politician) Bryan(I-politician) .(O)"}, "label_list": ["politician", "political party", "location", "person", "event", "organization", "election", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 37038, 11, 5054, 4717, 11, 3813, 11, 1732, 11, 1567, 11, 7471, 11, 6355, 11, 3224, 323, 507, 627, 85664, 25, 71229, 574, 264, 1949, 15310, 15879, 323, 2391, 279, 220, 9378, 21, 3723, 4273, 13621, 6355, 1174, 220, 7028, 15, 3723, 4273, 13621, 6355, 1174, 323, 220, 7028, 23, 3723, 4273, 13621, 6355, 568, 7396, 12656, 71290, 37453, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2281", "dataset": "mit-movie", "split": "dev", "prediction": "where(O) could(O) i(O) find(O) the(O) movie(O) prey(B-title) for(I-title) rock(I-title) and(I-title) roll(I-title)", "instance": {"id": "2281", "words": ["where", "could", "i", "find", "the", "movie", "prey", "for", "rock", "and", "roll"], "labels": ["O", "O", "O", "O", "O", "O", "B-title", "I-title", "I-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, genre, rating, average ratings, director, title, plot, actor, song, trailer, year, character and O.\nSentence: where could i find the movie prey for rock and roll", "prompt_labels": "where(O) could(O) i(O) find(O) the(O) movie(O) prey(B-title) for(I-title) rock(I-title) and(I-title) roll(I-title)"}, "label_list": ["review", "genre", "rating", "average ratings", "director", "title", "plot", "actor", "song", "trailer", "year", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 17779, 11, 10959, 11, 5578, 18594, 11, 7690, 11, 2316, 11, 7234, 11, 12360, 11, 5609, 11, 19809, 11, 1060, 11, 3752, 323, 507, 627, 85664, 25, 1405, 1436, 602, 1505, 279, 5818, 37693, 369, 7091, 323, 6638, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "760", "dataset": "mit-movie", "split": "dev", "prediction": "have(O) any(O) movies(O) been(O) made(O) about(O) robot(B-title) ninjas(I-title)", "instance": {"id": "760", "words": ["have", "any", "movies", "been", "made", "about", "robot", "ninjas"], "labels": ["O", "O", "O", "O", "O", "O", "B-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, genre, song, character, trailer, rating, plot, year, title, review, actor, average ratings and O.\nSentence: have any movies been made about robot ninjas", "prompt_labels": "have(O) any(O) movies(O) been(O) made(O) about(O) robot(B-plot) ninjas(I-plot)"}, "label_list": ["director", "genre", "song", "character", "trailer", "rating", "plot", "year", "title", "review", "actor", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 17779, 11, 5609, 11, 3752, 11, 19809, 11, 10959, 11, 7234, 11, 1060, 11, 2316, 11, 3477, 11, 12360, 11, 5578, 18594, 323, 507, 627, 85664, 25, 617, 904, 9698, 1027, 1903, 922, 12585, 20120, 30826, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1110", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) is(O) a(O) family(B-Amenity) friendly(I-Amenity) restaurant(O) in(B-Location) dorche(I-Location) that(O) serves(O) vietnamese(B-Cuisine) food(O)", "instance": {"id": "1110", "words": ["what", "is", "a", "family", "friendly", "restaurant", "in", "dorche", "that", "serves", "vietnamese", "food"], "labels": ["O", "O", "O", "B-Amenity", "I-Amenity", "O", "O", "B-Location", "O", "O", "B-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Location, Cuisine, Rating, Restaurant Name, Dish, Price, Amenity and O.\nSentence: what is a family friendly restaurant in dorche that serves vietnamese food", "prompt_labels": "what(O) is(O) a(O) family(B-Amenity) friendly(I-Amenity) restaurant(O) in(O) dorche(B-Location) that(O) serves(O) vietnamese(B-Cuisine) food(O)"}, "label_list": ["Hours", "Location", "Cuisine", "Rating", "Restaurant Name", "Dish", "Price", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 10067, 11, 81961, 11, 19767, 11, 26568, 4076, 11, 49268, 11, 8650, 11, 3383, 56685, 323, 507, 627, 85664, 25, 1148, 374, 264, 3070, 11919, 10960, 304, 53403, 1557, 430, 17482, 85459, 44519, 3691, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "317", "dataset": "crossner_politics", "split": "dev", "prediction": "Lieberthal(B-politician) has(O) consulted(O) widely(O) on(O) Chinese(O) and(O) Asian(O) affairs(O) and(O) has(O) advised(O),(O) among(O) others(O),(O) the(O) U.S.(B-country) Departments(O) of(O) State(O),(O) Defense(O) and(O) Commerce(O),(O) the(O) World(B-organization) Bank(I-organization),(O) the(O) Kettering(B-organization) Foundation(I-organization),(O) the(O) Aspen(B-organization) Institute(I-organization),(O) the(O) United(B-organization) Nations(I-organization) Association(I-organization) and(O) corporations(O) in(O) the(O) private(O) sector(O).(O)", "instance": {"id": "317", "words": ["Lieberthal", "has", "consulted", "widely", "on", "Chinese", "and", "Asian", "affairs", "and", "has", "advised", ",", "among", "others", ",", "the", "U.S.", "Departments", "of", "State", ",", "Defense", "and", "Commerce", ",", "the", "World", "Bank", ",", "the", "Kettering", "Foundation", ",", "the", "Aspen", "Institute", ",", "the", "United", "Nations", "Association", "and", "corporations", "in", "the", "private", "sector", "."], "labels": ["B-politician", "O", "O", "O", "O", "O", "O", "B-location", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "O", "O", "B-organization", "I-organization", "O", "O", "B-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, country, politician, election, person, political party, location, organization and O.\nSentence: Lieberthal has consulted widely on Chinese and Asian affairs and has advised , among others , the U.S. Departments of State , Defense and Commerce , the World Bank , the Kettering Foundation , the Aspen Institute , the United Nations Association and corporations in the private sector .", "prompt_labels": "Lieberthal(B-politician) has(O) consulted(O) widely(O) on(O) Chinese(O) and(O) Asian(B-location) affairs(O) and(O) has(O) advised(O) ,(O) among(O) others(O) ,(O) the(O) U.S.(B-organization) Departments(I-organization) of(I-organization) State(I-organization) ,(O) Defense(B-organization) and(I-organization) Commerce(I-organization) ,(O) the(O) World(B-organization) Bank(I-organization) ,(O) the(O) Kettering(B-organization) Foundation(I-organization) ,(O) the(O) Aspen(B-organization) Institute(I-organization) ,(O) the(O) United(B-organization) Nations(I-organization) Association(I-organization) and(O) corporations(O) in(O) the(O) private(O) sector(O) .(O)"}, "label_list": ["event", "country", "politician", "election", "person", "political party", "location", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 3224, 11, 37038, 11, 6355, 11, 1732, 11, 5054, 4717, 11, 3813, 11, 7471, 323, 507, 627, 85664, 25, 22213, 655, 31392, 706, 61302, 13882, 389, 8620, 323, 14875, 22747, 323, 706, 26160, 1174, 4315, 3885, 1174, 279, 549, 815, 13, 85608, 315, 3314, 1174, 16777, 323, 31480, 1174, 279, 4435, 8715, 1174, 279, 735, 22120, 287, 5114, 1174, 279, 94328, 10181, 1174, 279, 3723, 19687, 10229, 323, 25341, 304, 279, 879, 10706, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "302", "dataset": "crossner_politics", "split": "dev", "prediction": "This(O) region(O) has(O) been(O) dominated(O) by(O) the(O) Conservative(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) and(O) the(O) former(O) Reform(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) and(O) Canadian(B-political party) Alliance(I-political party) parties(O) for(O) most(O) of(O) the(O) time(O) from(O) 1993(O) to(O) 2011(O).(O)", "instance": {"id": "302", "words": ["This", "region", "has", "been", "dominated", "by", "the", "Conservative", "Party", "of", "Canada", "and", "the", "former", "Reform", "Party", "of", "Canada", "and", "Canadian", "Alliance", "parties", "for", "most", "of", "the", "time", "from", "1993", "to", "2011", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "B-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, person, political party, location, election, organization, politician, country and O.\nSentence: This region has been dominated by the Conservative Party of Canada and the former Reform Party of Canada and Canadian Alliance parties for most of the time from 1993 to 2011 .", "prompt_labels": "This(O) region(O) has(O) been(O) dominated(O) by(O) the(O) Conservative(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) and(O) the(O) former(O) Reform(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) and(O) Canadian(B-political party) Alliance(I-political party) parties(O) for(O) most(O) of(O) the(O) time(O) from(O) 1993(O) to(O) 2011(O) .(O)"}, "label_list": ["event", "person", "political party", "location", "election", "organization", "politician", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 1732, 11, 5054, 4717, 11, 3813, 11, 6355, 11, 7471, 11, 37038, 11, 3224, 323, 507, 627, 85664, 25, 1115, 5654, 706, 1027, 30801, 555, 279, 30071, 8722, 315, 7008, 323, 279, 4846, 40365, 8722, 315, 7008, 323, 12152, 23590, 9875, 369, 1455, 315, 279, 892, 505, 220, 2550, 18, 311, 220, 679, 16, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "43", "dataset": "mit-movie", "split": "dev", "prediction": "lets(O) find(O) an(O) independent(B-genre) film(O) company(O)", "instance": {"id": "43", "words": ["lets", "find", "an", "independent", "film", "company"], "labels": ["O", "O", "O", "B-genre", "I-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, review, title, average ratings, rating, genre, director, trailer, year, plot, song, actor and O.\nSentence: lets find an independent film company", "prompt_labels": "lets(O) find(O) an(O) independent(B-genre) film(I-genre) company(O)"}, "label_list": ["character", "review", "title", "average ratings", "rating", "genre", "director", "trailer", "year", "plot", "song", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 3477, 11, 2316, 11, 5578, 18594, 11, 10959, 11, 17779, 11, 7690, 11, 19809, 11, 1060, 11, 7234, 11, 5609, 11, 12360, 323, 507, 627, 85664, 25, 15714, 1505, 459, 9678, 4632, 2883, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "28", "dataset": "crossner_literature", "split": "dev", "prediction": "Sk\u00ed\u00f0ar\u00edma(B-book),(O) Bjarkar\u00edmur(B-book),(O) and(O) Lokrur(B-book) are(O) other(O) examples(O) of(O) early(O) r\u00edmur(B-literary genre).(O)", "instance": {"id": "28", "words": ["Sk\u00ed\u00f0ar\u00edma", ",", "Bjarkar\u00edmur", ",", "and", "Lokrur", "are", "other", "examples", "of", "early", "r\u00edmur", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, writer, poem, country, location, event, magazine, book, literary genre, award, organization and O.\nSentence: Sk\u00ed\u00f0ar\u00edma , Bjarkar\u00edmur , and Lokrur are other examples of early r\u00edmur .", "prompt_labels": "Sk\u00ed\u00f0ar\u00edma(O) ,(O) Bjarkar\u00edmur(O) ,(O) and(O) Lokrur(O) are(O) other(O) examples(O) of(O) early(O) r\u00edmur(O) .(O)"}, "label_list": ["person", "writer", "poem", "country", "location", "event", "magazine", "book", "literary genre", "award", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 7061, 11, 33894, 11, 3224, 11, 3813, 11, 1567, 11, 14756, 11, 2363, 11, 32465, 17779, 11, 10292, 11, 7471, 323, 507, 627, 85664, 25, 4923, 2483, 68800, 277, 2483, 1764, 1174, 69841, 847, 277, 56094, 324, 1174, 323, 58501, 81, 324, 527, 1023, 10507, 315, 4216, 436, 56094, 324, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "278", "dataset": "crossner_science", "split": "dev", "prediction": "R(O) gene(O) s(O) are(O) highly(O) polymorphic(O),(O) and(O) many(O) plants(O) produce(O) several(O) different(O) types(O) of(O) R(O) gene(O) products(O),(O) enabling(O) them(O) to(O) recognize(O) virulence(O) products(O) produced(O) by(O) many(O) different(O) pathogens(O).(O)", "instance": {"id": "278", "words": ["R", "gene", "s", "are", "highly", "polymorphic", ",", "and", "many", "plants", "produce", "several", "different", "types", "of", "R", "gene", "products", ",", "enabling", "them", "to", "recognize", "virulence", "products", "produced", "by", "many", "different", "pathogens", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, university, academic journal, enzyme, astronomical object, chemical compound, country, person, location, event, discipline, award, scientist, chemical element, protein, theory and O.\nSentence: R gene s are highly polymorphic , and many plants produce several different types of R gene products , enabling them to recognize virulence products produced by many different pathogens .", "prompt_labels": "R(O) gene(O) s(O) are(O) highly(O) polymorphic(O) ,(O) and(O) many(O) plants(O) produce(O) several(O) different(O) types(O) of(O) R(O) gene(O) products(O) ,(O) enabling(O) them(O) to(O) recognize(O) virulence(O) products(O) produced(O) by(O) many(O) different(O) pathogens(O) .(O)"}, "label_list": ["organization", "university", "academic journal", "enzyme", "astronomical object", "chemical compound", "country", "person", "location", "event", "discipline", "award", "scientist", "chemical element", "protein", "theory"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 12374, 11, 14584, 8486, 11, 49242, 11, 87283, 1665, 11, 11742, 24549, 11, 3224, 11, 1732, 11, 3813, 11, 1567, 11, 26434, 11, 10292, 11, 28568, 11, 11742, 2449, 11, 13128, 11, 10334, 323, 507, 627, 85664, 25, 432, 15207, 274, 527, 7701, 46033, 41969, 1174, 323, 1690, 11012, 8356, 3892, 2204, 4595, 315, 432, 15207, 3956, 1174, 28462, 1124, 311, 15641, 9043, 59566, 3956, 9124, 555, 1690, 2204, 78284, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1804", "dataset": "mit-movie", "split": "dev", "prediction": "was(O) pam(B-actor) grier(I-actor) in(O) an(O) r(B-rating) rated(O) movie(O) that(O) critics(O) said(O) was(O) very(B-average ratings) good(I-average ratings)", "instance": {"id": "1804", "words": ["was", "pam", "grier", "in", "an", "r", "rated", "movie", "that", "critics", "said", "was", "very", "good"], "labels": ["O", "B-actor", "I-actor", "O", "O", "B-rating", "O", "O", "O", "O", "O", "O", "B-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, plot, director, title, character, average ratings, actor, review, genre, song, rating, trailer and O.\nSentence: was pam grier in an r rated movie that critics said was very good", "prompt_labels": "was(O) pam(B-actor) grier(I-actor) in(O) an(O) r(B-rating) rated(O) movie(O) that(O) critics(O) said(O) was(O) very(B-average ratings) good(I-average ratings)"}, "label_list": ["year", "plot", "director", "title", "character", "average ratings", "actor", "review", "genre", "song", "rating", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 7234, 11, 7690, 11, 2316, 11, 3752, 11, 5578, 18594, 11, 12360, 11, 3477, 11, 17779, 11, 5609, 11, 10959, 11, 19809, 323, 507, 627, 85664, 25, 574, 42290, 342, 7401, 304, 459, 436, 22359, 5818, 430, 23531, 1071, 574, 1633, 1695, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2238", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) year(B-year) did(O) the(O) lizzie(B-title) mcguire(I-title) movie(O) come(O) out(O)", "instance": {"id": "2238", "words": ["what", "year", "did", "the", "lizzie", "mcguire", "movie", "come", "out"], "labels": ["O", "O", "O", "B-title", "I-title", "I-title", "I-title", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, character, plot, director, review, song, rating, average ratings, actor, year, genre, title and O.\nSentence: what year did the lizzie mcguire movie come out", "prompt_labels": "what(O) year(O) did(O) the(B-title) lizzie(I-title) mcguire(I-title) movie(I-title) come(O) out(O)"}, "label_list": ["trailer", "character", "plot", "director", "review", "song", "rating", "average ratings", "actor", "year", "genre", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 3752, 11, 7234, 11, 7690, 11, 3477, 11, 5609, 11, 10959, 11, 5578, 18594, 11, 12360, 11, 1060, 11, 17779, 11, 2316, 323, 507, 627, 85664, 25, 1148, 1060, 1550, 279, 326, 89087, 19777, 8890, 556, 5818, 2586, 704, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "193", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) theme(O) song(O) to(O) stand(B-title) by(I-title) me(I-title)", "instance": {"id": "193", "words": ["what", "is", "the", "theme", "song", "to", "stand", "by", "me"], "labels": ["O", "O", "O", "O", "O", "O", "B-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, rating, actor, director, year, average ratings, trailer, character, plot, review, title, song and O.\nSentence: what is the theme song to stand by me", "prompt_labels": "what(O) is(O) the(O) theme(O) song(O) to(O) stand(B-title) by(I-title) me(I-title)"}, "label_list": ["genre", "rating", "actor", "director", "year", "average ratings", "trailer", "character", "plot", "review", "title", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 10959, 11, 12360, 11, 7690, 11, 1060, 11, 5578, 18594, 11, 19809, 11, 3752, 11, 7234, 11, 3477, 11, 2316, 11, 5609, 323, 507, 627, 85664, 25, 1148, 374, 279, 7057, 5609, 311, 2559, 555, 757, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "263", "dataset": "crossner_music", "split": "dev", "prediction": "!(O) --as(O) per(O) MOS(O) :(O) BIO(O) ;(O) became(O) notable(O) as(O) Welsh(O),(O) and(O) self(O) identifies(O) as(O) Welsh(O) ;(O) 2012(O) Guardian(O) interview(O) ;(O) I(O) suppose(O) it(O)'s(O) because(O) we(O) are(O) both(O) Welsh(O) --(O) He(O) won(O) the(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Actor(I-award) in(O) 1992(O) and(O) has(O) also(O) received(O) three(O) British(B-award) Academy(I-award) Film(I-award) Awards(I-award) s(O),(O) two(O) Emmy(B-award) Award(I-award) and(O) the(O) Golden(B-award) Globe(I-award) Cecil(I-award) B.(I-award) DeMille(I-award) Award(I-award).(O)", "instance": {"id": "263", "words": ["!", "--as", "per", "MOS", ":", "BIO", ";", "became", "notable", "as", "Welsh", ",", "and", "self", "identifies", "as", "Welsh", ";", "2012", "Guardian", "interview", ";", "I", "suppose", "it", "'s", "because", "we", "are", "both", "Welsh", "--", "He", "won", "the", "Academy", "Award", "for", "Best", "Actor", "in", "1992", "and", "has", "also", "received", "three", "British", "Academy", "Film", "Awards", "s", ",", "two", "Emmy", "Award", "and", "the", "Golden", "Globe", "Cecil", "B.", "DeMille", "Award", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "O", "O", "O", "B-award", "I-award", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, organization, band, music genre, country, song, musical instrument, person, event, location, award, album and O.\nSentence: ! --as per MOS : BIO ; became notable as Welsh , and self identifies as Welsh ; 2012 Guardian interview ; I suppose it 's because we are both Welsh -- He won the Academy Award for Best Actor in 1992 and has also received three British Academy Film Awards s , two Emmy Award and the Golden Globe Cecil B. DeMille Award .", "prompt_labels": "!(O) --as(O) per(O) MOS(O) :(O) BIO(O) ;(O) became(O) notable(O) as(O) Welsh(O) ,(O) and(O) self(O) identifies(O) as(O) Welsh(O) ;(O) 2012(B-event) Guardian(I-event) interview(I-event) ;(O) I(O) suppose(O) it(O) 's(O) because(O) we(O) are(O) both(O) Welsh(O) --(O) He(O) won(O) the(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Actor(I-award) in(O) 1992(O) and(O) has(O) also(O) received(O) three(O) British(B-award) Academy(I-award) Film(I-award) Awards(I-award) s(O) ,(O) two(O) Emmy(B-award) Award(I-award) and(O) the(O) Golden(B-award) Globe(I-award) Cecil(I-award) B.(I-award) DeMille(I-award) Award(I-award) .(O)"}, "label_list": ["musical artist", "organization", "band", "music genre", "country", "song", "musical instrument", "person", "event", "location", "award", "album"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18273, 10255, 11, 7471, 11, 7200, 11, 4731, 17779, 11, 3224, 11, 5609, 11, 18273, 14473, 11, 1732, 11, 1567, 11, 3813, 11, 10292, 11, 8176, 323, 507, 627, 85664, 25, 758, 1198, 300, 824, 74174, 551, 73166, 2652, 6244, 28289, 439, 46881, 1174, 323, 659, 36611, 439, 46881, 2652, 220, 679, 17, 25460, 7274, 2652, 358, 23289, 433, 364, 82, 1606, 584, 527, 2225, 46881, 1198, 1283, 2834, 279, 16192, 17768, 369, 7252, 25749, 304, 220, 2550, 17, 323, 706, 1101, 4036, 2380, 8013, 16192, 17042, 23488, 274, 1174, 1403, 67112, 17768, 323, 279, 18288, 41910, 90227, 426, 13, 1611, 44, 4618, 17768, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "222", "dataset": "crossner_science", "split": "dev", "prediction": "Directors(O) ((O) superintendents(O) )(O) of(O) the(O) observatory(O) included(O) Stephen(B-person) Demainbray(I-person),(O) Francis(B-person) Ronalds(I-person),(O) John(B-person) Welsh(I-person),(O) Balfour(B-person) Stewart(I-person),(O) Francis(B-person) John(I-person) Welsh(I-person) Whipple(I-person),(O) Charles(B-person) Chree(I-person),(O) and(O) George(B-person) Clarke(I-person) Simpson(I-person).(O)", "instance": {"id": "222", "words": ["Directors", "(", "superintendents", ")", "of", "the", "observatory", "included", "Stephen", "Demainbray", ",", "Francis", "Ronalds", ",", "John", "Welsh", ",", "Balfour", "Stewart", ",", "Francis", "John", "Welsh", "Whipple", ",", "Charles", "Chree", ",", "and", "George", "Clarke", "Simpson", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "I-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "O", "O", "B-scientist", "I-scientist", "I-scientist", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, person, academic journal, enzyme, country, award, event, university, chemical compound, discipline, organization, location, astronomical object, protein, chemical element, theory and O.\nSentence: Directors ( superintendents ) of the observatory included Stephen Demainbray , Francis Ronalds , John Welsh , Balfour Stewart , Francis John Welsh Whipple , Charles Chree , and George Clarke Simpson .", "prompt_labels": "Directors(O) ((O) superintendents(O) )(O) of(O) the(O) observatory(O) included(O) Stephen(B-scientist) Demainbray(I-scientist) ,(O) Francis(B-scientist) Ronalds(I-scientist) ,(O) John(B-scientist) Welsh(I-scientist) ,(O) Balfour(B-scientist) Stewart(I-scientist) ,(O) Francis(B-scientist) John(I-scientist) Welsh(I-scientist) Whipple(I-scientist) ,(O) Charles(B-scientist) Chree(I-scientist) ,(O) and(O) George(B-scientist) Clarke(I-scientist) Simpson(I-scientist) .(O)"}, "label_list": ["scientist", "person", "academic journal", "enzyme", "country", "award", "event", "university", "chemical compound", "discipline", "organization", "location", "astronomical object", "protein", "chemical element", "theory"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 28568, 11, 1732, 11, 14584, 8486, 11, 49242, 11, 3224, 11, 10292, 11, 1567, 11, 12374, 11, 11742, 24549, 11, 26434, 11, 7471, 11, 3813, 11, 87283, 1665, 11, 13128, 11, 11742, 2449, 11, 10334, 323, 507, 627, 85664, 25, 46085, 320, 2307, 396, 408, 812, 883, 315, 279, 9466, 5382, 5343, 18587, 4829, 467, 1347, 352, 1174, 26184, 39748, 82, 1174, 3842, 46881, 1174, 426, 3181, 414, 29868, 1174, 26184, 3842, 46881, 1254, 52264, 1174, 15274, 921, 770, 1174, 323, 10058, 43655, 35766, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "230", "dataset": "crossner_science", "split": "dev", "prediction": "Due(O) to(O) the(O) immense(O) size(O) of(O) the(O) Jupiter(B-astronomical object) system(O) and(O) the(O) relative(O) closeness(O) of(O) the(O) Jovian(O) system(O) to(O) Earth(B-astronomical object) in(O) comparison(O) to(O) the(O) closeness(O) of(O) Pluto(B-astronomical object) to(O) Earth(B-astronomical object),(O) New(B-organization) Horizons(I-organization) sent(O) back(O) more(O) data(O) to(O) Earth(B-astronomical object) from(O) the(O) Jupiter(O) encounter(O) than(O) the(O) Pluto(O) encounter(O).(O)", "instance": {"id": "230", "words": ["Due", "to", "the", "immense", "size", "of", "the", "Jupiter", "system", "and", "the", "relative", "closeness", "of", "the", "Jovian", "system", "to", "Earth", "in", "comparison", "to", "the", "closeness", "of", "Pluto", "to", "Earth", ",", "New", "Horizons", "sent", "back", "more", "data", "to", "Earth", "from", "the", "Jupiter", "encounter", "than", "the", "Pluto", "encounter", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-astronomical object", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-astronomical object", "O", "O", "O", "O", "O", "O", "B-astronomical object", "O", "B-astronomical object", "O", "B-event", "B-event", "O", "O", "O", "O", "O", "B-astronomical object", "O", "O", "B-astronomical object", "O", "O", "O", "B-astronomical object", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, chemical element, country, university, academic journal, enzyme, location, theory, protein, discipline, event, person, chemical compound, astronomical object, award, organization and O.\nSentence: Due to the immense size of the Jupiter system and the relative closeness of the Jovian system to Earth in comparison to the closeness of Pluto to Earth , New Horizons sent back more data to Earth from the Jupiter encounter than the Pluto encounter .", "prompt_labels": "Due(O) to(O) the(O) immense(O) size(O) of(O) the(O) Jupiter(B-astronomical object) system(O) and(O) the(O) relative(O) closeness(O) of(O) the(O) Jovian(O) system(O) to(O) Earth(B-astronomical object) in(O) comparison(O) to(O) the(O) closeness(O) of(O) Pluto(B-astronomical object) to(O) Earth(B-astronomical object) ,(O) New(B-event) Horizons(B-event) sent(O) back(O) more(O) data(O) to(O) Earth(B-astronomical object) from(O) the(O) Jupiter(B-astronomical object) encounter(O) than(O) the(O) Pluto(B-astronomical object) encounter(O) .(O)"}, "label_list": ["scientist", "chemical element", "country", "university", "academic journal", "enzyme", "location", "theory", "protein", "discipline", "event", "person", "chemical compound", "astronomical object", "award", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 28568, 11, 11742, 2449, 11, 3224, 11, 12374, 11, 14584, 8486, 11, 49242, 11, 3813, 11, 10334, 11, 13128, 11, 26434, 11, 1567, 11, 1732, 11, 11742, 24549, 11, 87283, 1665, 11, 10292, 11, 7471, 323, 507, 627, 85664, 25, 24586, 311, 279, 38883, 1404, 315, 279, 50789, 1887, 323, 279, 8844, 4597, 24639, 315, 279, 622, 869, 1122, 1887, 311, 9420, 304, 12593, 311, 279, 4597, 24639, 315, 78681, 311, 9420, 1174, 1561, 15083, 64947, 3288, 1203, 810, 828, 311, 9420, 505, 279, 50789, 13123, 1109, 279, 78681, 13123, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "272", "dataset": "crossner_ai", "split": "dev", "prediction": "A(O) commercially(B-average sales) successful(I-average sales) but(O) specialized(O) computer(B-field) vision(I-field) based(O) articulated(B-task) body(I-task) pose(I-task) estimation(I-task) technique(O) is(O) optical(O) motion(O) capture(O).(O)", "instance": {"id": "272", "words": ["A", "commercially", "successful", "but", "specialized", "computer", "vision-based", "articulated", "body", "pose", "estimation", "technique", "is", "optical", "motion", "capture", "."], "labels": ["O", "O", "O", "O", "O", "B-task", "I-task", "I-task", "I-task", "I-task", "I-task", "O", "O", "B-algorithm", "I-algorithm", "I-algorithm", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, conference, programming language, country, task, researcher, metric, product, university, person, field, location, algorithm and O.\nSentence: A commercially successful but specialized computer vision-based articulated body pose estimation technique is optical motion capture .", "prompt_labels": "A(O) commercially(O) successful(O) but(O) specialized(O) computer(B-task) vision-based(I-task) articulated(I-task) body(I-task) pose(I-task) estimation(I-task) technique(O) is(O) optical(B-algorithm) motion(I-algorithm) capture(I-algorithm) .(O)"}, "label_list": ["organization", "conference", "programming language", "country", "task", "researcher", "metric", "product", "university", "person", "field", "location", "algorithm"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 10017, 11, 15840, 4221, 11, 3224, 11, 3465, 11, 32185, 11, 18767, 11, 2027, 11, 12374, 11, 1732, 11, 2115, 11, 3813, 11, 12384, 323, 507, 627, 85664, 25, 362, 54453, 6992, 719, 28175, 6500, 11376, 6108, 83280, 2547, 17477, 42304, 15105, 374, 29393, 11633, 12602, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "63", "dataset": "crossner_politics", "split": "dev", "prediction": "Farry(B-politician) was(O) elected(O) to(O) the(O) position(O) in(O) the(O) 2019(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) replacing(O) the(O) incumbent(O) Sylvia(B-politician) Hermon(I-politician),(O) who(O) had(O) held(O) the(O) position(O) since(O) being(O) elected(O) to(O) it(O) in(O) the(O) 2001(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) but(O) chose(O) not(O) to(O) contest(O) in(O) the(O) 2019(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election).(O)", "instance": {"id": "63", "words": ["Farry", "was", "elected", "to", "the", "position", "in", "the", "2019", "United", "Kingdom", "general", "election", ",", "replacing", "the", "incumbent", "Sylvia", "Hermon", ",", "who", "had", "held", "the", "position", "since", "being", "elected", "to", "it", "in", "the", "2001", "United", "Kingdom", "general", "election", ",", "but", "chose", "not", "to", "contest", "in", "the", "2019", "United", "Kingdom", "general", "election", "."], "labels": ["B-politician", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "B-politician", "I-politician", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, country, person, location, election, event, political party, organization and O.\nSentence: Farry was elected to the position in the 2019 United Kingdom general election , replacing the incumbent Sylvia Hermon , who had held the position since being elected to it in the 2001 United Kingdom general election , but chose not to contest in the 2019 United Kingdom general election .", "prompt_labels": "Farry(B-politician) was(O) elected(O) to(O) the(O) position(O) in(O) the(O) 2019(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) replacing(O) the(O) incumbent(O) Sylvia(B-politician) Hermon(I-politician) ,(O) who(O) had(O) held(O) the(O) position(O) since(O) being(O) elected(O) to(O) it(O) in(O) the(O) 2001(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) but(O) chose(O) not(O) to(O) contest(O) in(O) the(O) 2019(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)"}, "label_list": ["politician", "country", "person", "location", "election", "event", "political party", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 37038, 11, 3224, 11, 1732, 11, 3813, 11, 6355, 11, 1567, 11, 5054, 4717, 11, 7471, 323, 507, 627, 85664, 25, 435, 11687, 574, 16689, 311, 279, 2361, 304, 279, 220, 679, 24, 3723, 15422, 4689, 6355, 1174, 25935, 279, 51382, 89406, 6385, 1677, 1174, 889, 1047, 5762, 279, 2361, 2533, 1694, 16689, 311, 433, 304, 279, 220, 1049, 16, 3723, 15422, 4689, 6355, 1174, 719, 14896, 539, 311, 14130, 304, 279, 220, 679, 24, 3723, 15422, 4689, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2192", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) the(O) name(O) of(O) the(O) very(B-average ratings) popular(I-average ratings) first(B-genre) love(I-genre) movie(O) from(O) lisa(B-director) wolfinger(I-director) in(O) 2010(B-year)", "instance": {"id": "2192", "words": ["what", "the", "name", "of", "the", "very", "popular", "first", "love", "movie", "from", "lisa", "wolfinger", "in", "2010"], "labels": ["O", "O", "O", "O", "O", "B-average ratings", "I-average ratings", "B-plot", "I-plot", "O", "O", "B-director", "I-director", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, trailer, genre, director, year, review, character, actor, average ratings, rating, song, plot and O.\nSentence: what the name of the very popular first love movie from lisa wolfinger in 2010", "prompt_labels": "what(O) the(O) name(O) of(O) the(O) very(B-average ratings) popular(I-average ratings) first(B-plot) love(I-plot) movie(O) from(O) lisa(B-director) wolfinger(I-director) in(O) 2010(B-year)"}, "label_list": ["title", "trailer", "genre", "director", "year", "review", "character", "actor", "average ratings", "rating", "song", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 19809, 11, 17779, 11, 7690, 11, 1060, 11, 3477, 11, 3752, 11, 12360, 11, 5578, 18594, 11, 10959, 11, 5609, 11, 7234, 323, 507, 627, 85664, 25, 1148, 279, 836, 315, 279, 1633, 5526, 1176, 3021, 5818, 505, 326, 10994, 37642, 5248, 304, 220, 679, 15, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "105", "dataset": "crossner_literature", "split": "dev", "prediction": "In(O) 2000(B-year) Atwood(B-writer) published(O) her(O) tenth(O) novel(B-literary genre),(O) The(B-book) Blind(I-book) Assassin(I-book),(O) to(O) critical(O) acclaim(O),(O) winning(O) both(O) the(O) Booker(B-award) Prize(I-award)", "instance": {"id": "105", "words": ["In", "2000", "Atwood", "published", "her", "tenth", "novel", ",", "The", "Blind", "Assassin", ",", "to", "critical", "acclaim", ",", "winning", "both", "the", "Booker", "Prize"], "labels": ["O", "O", "B-writer", "O", "O", "O", "B-literary genre", "O", "B-book", "I-book", "I-book", "O", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, book, writer, organization, award, literary genre, person, location, magazine, poem, country and O.\nSentence: In 2000 Atwood published her tenth novel , The Blind Assassin , to critical acclaim , winning both the Booker Prize", "prompt_labels": "In(O) 2000(O) Atwood(B-writer) published(O) her(O) tenth(O) novel(B-literary genre) ,(O) The(B-book) Blind(I-book) Assassin(I-book) ,(O) to(O) critical(O) acclaim(O) ,(O) winning(O) both(O) the(O) Booker(B-award) Prize(I-award)"}, "label_list": ["event", "book", "writer", "organization", "award", "literary genre", "person", "location", "magazine", "poem", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 2363, 11, 7061, 11, 7471, 11, 10292, 11, 32465, 17779, 11, 1732, 11, 3813, 11, 14756, 11, 33894, 11, 3224, 323, 507, 627, 85664, 25, 763, 220, 1049, 15, 2468, 6798, 4756, 1077, 56766, 11775, 1174, 578, 55370, 61101, 1174, 311, 9200, 97963, 1174, 11230, 2225, 279, 66095, 32293, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1040", "dataset": "mit-restaurant", "split": "dev", "prediction": "pub(B-Cuisine)", "instance": {"id": "1040", "words": ["pub"], "labels": ["B-Cuisine"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Restaurant Name, Price, Dish, Rating, Amenity, Location, Hours and O.\nSentence: pub", "prompt_labels": "pub(B-Cuisine)"}, "label_list": ["Cuisine", "Restaurant Name", "Price", "Dish", "Rating", "Amenity", "Location", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 26568, 4076, 11, 8650, 11, 49268, 11, 19767, 11, 3383, 56685, 11, 10067, 11, 30192, 323, 507, 627, 85664, 25, 6814, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1271", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) can(O) i(O) find(O) a(O) cracker(B-Restaurant Name) barrel(I-Restaurant Name) near(B-Location) miami(I-Location)", "instance": {"id": "1271", "words": ["where", "can", "i", "find", "a", "cracker", "barrel", "near", "miami"], "labels": ["O", "O", "O", "O", "O", "B-Restaurant Name", "I-Restaurant Name", "O", "B-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Cuisine, Location, Price, Dish, Hours, Amenity, Rating and O.\nSentence: where can i find a cracker barrel near miami", "prompt_labels": "where(O) can(O) i(O) find(O) a(O) cracker(B-Restaurant Name) barrel(I-Restaurant Name) near(O) miami(B-Location)"}, "label_list": ["Restaurant Name", "Cuisine", "Location", "Price", "Dish", "Hours", "Amenity", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 81961, 11, 10067, 11, 8650, 11, 49268, 11, 30192, 11, 3383, 56685, 11, 19767, 323, 507, 627, 85664, 25, 1405, 649, 602, 1505, 264, 1589, 9881, 20929, 3221, 296, 15622, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "0", "dataset": "crossner_music", "split": "dev", "prediction": "As(O) part(O) of(O) the(O) 2010(O) leg(O) of(O) the(O) My(B-album) Christmas(I-album) Tour(I-album),(O) Bocelli(B-musical artist) gave(O) two(O) concerts(O) in(O) The(B-location) O2(I-location) Arena(I-location),(O) in(O) London(B-location),(O) and(O) the(O) Manchester(B-location) Arena(I-location),(O) in(O) Manchester(B-location),(O) and(O) a(O) concert(O) at(O) 3Arena(B-location),(O) in(O) Dublin(B-location),(O) in(O) late(O) November(O) 2010(O).(O)", "instance": {"id": "0", "words": ["As", "part", "of", "the", "2010", "leg", "of", "the", "My", "Christmas", "Tour", ",", "Bocelli", "gave", "two", "concerts", "in", "The", "O2", "Arena", ",", "in", "London", ",", "and", "the", "Manchester", "Arena", ",", "in", "Manchester", ",", "and", "a", "concert", "at", "3Arena", ",", "in", "Dublin", ",", "in", "late", "November", "2010", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "O", "B-musical artist", "O", "O", "O", "O", "B-location", "I-location", "I-location", "O", "O", "B-location", "O", "O", "O", "B-location", "I-location", "O", "O", "B-location", "O", "O", "O", "O", "O", "B-location", "O", "O", "B-location", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, band, song, location, album, musical artist, country, award, music genre, person, organization, event and O.\nSentence: As part of the 2010 leg of the My Christmas Tour , Bocelli gave two concerts in The O2 Arena , in London , and the Manchester Arena , in Manchester , and a concert at 3Arena , in Dublin , in late November 2010 .", "prompt_labels": "As(O) part(O) of(O) the(O) 2010(O) leg(O) of(O) the(O) My(B-event) Christmas(I-event) Tour(I-event) ,(O) Bocelli(B-musical artist) gave(O) two(O) concerts(O) in(O) The(B-location) O2(I-location) Arena(I-location) ,(O) in(O) London(B-location) ,(O) and(O) the(O) Manchester(B-location) Arena(I-location) ,(O) in(O) Manchester(B-location) ,(O) and(O) a(O) concert(O) at(O) 3Arena(B-location) ,(O) in(O) Dublin(B-location) ,(O) in(O) late(O) November(O) 2010(O) .(O)"}, "label_list": ["musical instrument", "band", "song", "location", "album", "musical artist", "country", "award", "music genre", "person", "organization", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18273, 14473, 11, 7200, 11, 5609, 11, 3813, 11, 8176, 11, 18273, 10255, 11, 3224, 11, 10292, 11, 4731, 17779, 11, 1732, 11, 7471, 11, 1567, 323, 507, 627, 85664, 25, 1666, 961, 315, 279, 220, 679, 15, 2531, 315, 279, 3092, 10280, 14986, 1174, 426, 511, 21148, 6688, 1403, 47679, 304, 578, 507, 17, 28145, 1174, 304, 7295, 1174, 323, 279, 19922, 28145, 1174, 304, 19922, 1174, 323, 264, 21497, 520, 220, 18, 95037, 1174, 304, 33977, 1174, 304, 3389, 6841, 220, 679, 15, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "377", "dataset": "crossner_politics", "split": "dev", "prediction": "In(O) 1977(O),(O) he(O) was(O) 1977(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election) to(O) the(O) Parliament(B-organization) of(I-organization) Norway(I-organization) from(O) Hedmark(B-location),(O) and(O) he(O) was(O) re-elected(O) in(O) 1981(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election),(O) 1985(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election) and(O) 1989(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election).(O)", "instance": {"id": "377", "words": ["In", "1977", ",", "he", "was", "1977", "Norwegian", "parliamentary", "election", "to", "the", "Parliament", "of", "Norway", "from", "Hedmark", ",", "and", "he", "was", "re-elected", "in", "1981", "Norwegian", "parliamentary", "election", ",", "1985", "Norwegian", "parliamentary", "election", "and", "1989", "Norwegian", "parliamentary", "election", "."], "labels": ["O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "B-organization", "I-organization", "I-organization", "O", "B-country", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, political party, politician, event, organization, election, location, person and O.\nSentence: In 1977 , he was 1977 Norwegian parliamentary election to the Parliament of Norway from Hedmark , and he was re-elected in 1981 Norwegian parliamentary election , 1985 Norwegian parliamentary election and 1989 Norwegian parliamentary election .", "prompt_labels": "In(O) 1977(O) ,(O) he(O) was(O) 1977(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election) to(O) the(O) Parliament(B-organization) of(I-organization) Norway(I-organization) from(O) Hedmark(B-country) ,(O) and(O) he(O) was(O) re-elected(O) in(O) 1981(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election) ,(O) 1985(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election) and(O) 1989(B-election) Norwegian(I-election) parliamentary(I-election) election(I-election) .(O)"}, "label_list": ["country", "political party", "politician", "event", "organization", "election", "location", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 5054, 4717, 11, 37038, 11, 1567, 11, 7471, 11, 6355, 11, 3813, 11, 1732, 323, 507, 627, 85664, 25, 763, 220, 4468, 22, 1174, 568, 574, 220, 4468, 22, 45721, 44250, 6355, 311, 279, 20302, 315, 32603, 505, 75263, 4075, 1174, 323, 568, 574, 312, 96805, 304, 220, 3753, 16, 45721, 44250, 6355, 1174, 220, 3753, 20, 45721, 44250, 6355, 323, 220, 3753, 24, 45721, 44250, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "46", "dataset": "crossner_science", "split": "dev", "prediction": "She(O) competed(O) in(O) the(O) 4(B-event) \u00d7(I-event) 100(I-event) metres(I-event) relay(I-event) event(O) at(O) the(O) 2015(B-event) World(I-event) Championships(I-event) in(O) Athletics(O) in(O) Beijing(B-location),(O) China(B-country).(O)", "instance": {"id": "46", "words": ["She", "competed", "in", "the", "4", "\u00d7", "100", "metres", "relay", "event", "at", "the", "2015", "World", "Championships", "in", "Athletics", "in", "Beijing", ",", "China", "."], "labels": ["O", "O", "O", "O", "B-event", "I-event", "I-event", "I-event", "I-event", "I-event", "O", "O", "B-event", "I-event", "I-event", "O", "O", "O", "B-location", "O", "B-country", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, enzyme, event, person, location, chemical compound, theory, chemical element, discipline, protein, astronomical object, university, award, country, academic journal, scientist and O.\nSentence: She competed in the 4 \u00d7 100 metres relay event at the 2015 World Championships in Athletics in Beijing , China .", "prompt_labels": "She(O) competed(O) in(O) the(O) 4(B-event) \u00d7(I-event) 100(I-event) metres(I-event) relay(I-event) event(I-event) at(O) the(O) 2015(B-event) World(I-event) Championships(I-event) in(O) Athletics(O) in(O) Beijing(B-location) ,(O) China(B-country) .(O)"}, "label_list": ["organization", "enzyme", "event", "person", "location", "chemical compound", "theory", "chemical element", "discipline", "protein", "astronomical object", "university", "award", "country", "academic journal", "scientist"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 49242, 11, 1567, 11, 1732, 11, 3813, 11, 11742, 24549, 11, 10334, 11, 11742, 2449, 11, 26434, 11, 13128, 11, 87283, 1665, 11, 12374, 11, 10292, 11, 3224, 11, 14584, 8486, 11, 28568, 323, 507, 627, 85664, 25, 3005, 67235, 304, 279, 220, 19, 25800, 220, 1041, 37356, 32951, 1567, 520, 279, 220, 679, 20, 4435, 48854, 304, 70831, 304, 27647, 1174, 5734, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1428", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) is(O) the(O) nearest(B-Location) bar(B-Amenity) with(I-Amenity) dinning(I-Amenity) located(O)", "instance": {"id": "1428", "words": ["where", "is", "the", "nearest", "bar", "with", "dinning", "located"], "labels": ["O", "O", "O", "B-Location", "B-Cuisine", "O", "B-Amenity", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Amenity, Price, Dish, Rating, Restaurant Name, Cuisine, Hours and O.\nSentence: where is the nearest bar with dinning located", "prompt_labels": "where(O) is(O) the(O) nearest(B-Location) bar(B-Cuisine) with(O) dinning(B-Amenity) located(O)"}, "label_list": ["Location", "Amenity", "Price", "Dish", "Rating", "Restaurant Name", "Cuisine", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 3383, 56685, 11, 8650, 11, 49268, 11, 19767, 11, 26568, 4076, 11, 81961, 11, 30192, 323, 507, 627, 85664, 25, 1405, 374, 279, 24379, 3703, 449, 11884, 1251, 7559, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "96", "dataset": "crossner_literature", "split": "dev", "prediction": "The(O) friends(O) joined(O) in(O) keeping(O) up(O) the(O) delusion(O) that(O) Erskine(B-writer) and(O) not(O) Scott(B-writer) was(O) the(O) author(O) of(O) the(O) portions(O) of(O) The(B-book) Bridal(I-book) of(I-book) Triermain(I-book),(O) and(O) wrote(O) a(O) preface(O) intended(O) to(O) throw(O) out(O) the(O) knowing(O) ones(O).(O)", "instance": {"id": "96", "words": ["The", "friends", "joined", "in", "keeping", "up", "the", "delusion", "that", "Erskine", "and", "not", "Scott", "was", "the", "author", "of", "the", "portions", "of", "The", "Bridal", "of", "Triermain", ",", "and", "wrote", "a", "preface", "intended", "to", "throw", "out", "the", "knowing", "ones", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "O", "O", "B-location", "O", "O", "O", "O", "O", "O", "O", "B-poem", "I-poem", "I-poem", "I-poem", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, person, poem, award, magazine, country, location, organization, writer, literary genre, book and O.\nSentence: The friends joined in keeping up the delusion that Erskine and not Scott was the author of the portions of The Bridal of Triermain , and wrote a preface intended to throw out the knowing ones .", "prompt_labels": "The(O) friends(O) joined(O) in(O) keeping(O) up(O) the(O) delusion(O) that(O) Erskine(B-location) and(O) not(O) Scott(B-location) was(O) the(O) author(O) of(O) the(O) portions(O) of(O) The(B-poem) Bridal(I-poem) of(I-poem) Triermain(I-poem) ,(O) and(O) wrote(O) a(O) preface(O) intended(O) to(O) throw(O) out(O) the(O) knowing(O) ones(O) .(O)"}, "label_list": ["event", "person", "poem", "award", "magazine", "country", "location", "organization", "writer", "literary genre", "book"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 1732, 11, 33894, 11, 10292, 11, 14756, 11, 3224, 11, 3813, 11, 7471, 11, 7061, 11, 32465, 17779, 11, 2363, 323, 507, 627, 85664, 25, 578, 4885, 11096, 304, 10494, 709, 279, 1624, 7713, 430, 9939, 4991, 483, 323, 539, 10016, 574, 279, 3229, 315, 279, 19885, 315, 578, 32437, 278, 315, 350, 7401, 3902, 1174, 323, 6267, 264, 864, 1594, 10825, 311, 2571, 704, 279, 14392, 6305, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "13", "dataset": "crossner_literature", "split": "dev", "prediction": "During(O) this(O) period(O),(O) he(O) covered(O) Timothy(B-writer) Leary(I-writer) and(O) Richard(B-writer) Alpert(I-writer) '(O) s(O) Millbrook(B-location),(O) New(B-location) York(I-location) -based(O) Castalia(B-organization) Foundation(I-organization) at(O) the(O) instigation(O) of(O) Alan(B-writer) Watts(I-writer) in(O) The(B-book) Realist(I-book),(O) cultivated(O) important(O) friendships(O) with(O) William(B-writer) S.(I-writer) Burroughs(I-writer) and(O) Allen(B-writer) Ginsberg(I-writer),(O) and(O) lectured(O) at(O) the(O) Free(B-university) University(I-university) of(I-university) New(I-university) York(I-university) on(O) '(O) Anarchist(O) and(O) Synergetic(O) Politics(O) '(O) in(O) 1965(O).(O)", "instance": {"id": "13", "words": ["During", "this", "period", ",", "he", "covered", "Timothy", "Leary", "and", "Richard", "Alpert", "'", "s", "Millbrook", ",", "New", "York", "-based", "Castalia", "Foundation", "at", "the", "instigation", "of", "Alan", "Watts", "in", "The", "Realist", ",", "cultivated", "important", "friendships", "with", "William", "S.", "Burroughs", "and", "Allen", "Ginsberg", ",", "and", "lectured", "at", "the", "Free", "University", "of", "New", "York", "on", "'", "Anarchist", "and", "Synergetic", "Politics", "'", "in", "1965", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "O", "B-location", "O", "B-location", "I-location", "O", "B-organization", "I-organization", "O", "O", "O", "O", "B-writer", "I-writer", "O", "B-magazine", "I-magazine", "O", "O", "O", "O", "O", "B-writer", "I-writer", "I-writer", "O", "B-writer", "I-writer", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, award, literary genre, poem, country, person, magazine, book, event, writer, organization and O.\nSentence: During this period , he covered Timothy Leary and Richard Alpert ' s Millbrook , New York -based Castalia Foundation at the instigation of Alan Watts in The Realist , cultivated important friendships with William S. Burroughs and Allen Ginsberg , and lectured at the Free University of New York on ' Anarchist and Synergetic Politics ' in 1965 .", "prompt_labels": "During(O) this(O) period(O) ,(O) he(O) covered(O) Timothy(B-person) Leary(I-person) and(O) Richard(B-person) Alpert(I-person) '(O) s(O) Millbrook(B-location) ,(O) New(B-location) York(I-location) -based(O) Castalia(B-organization) Foundation(I-organization) at(O) the(O) instigation(O) of(O) Alan(B-writer) Watts(I-writer) in(O) The(B-magazine) Realist(I-magazine) ,(O) cultivated(O) important(O) friendships(O) with(O) William(B-writer) S.(I-writer) Burroughs(I-writer) and(O) Allen(B-writer) Ginsberg(I-writer) ,(O) and(O) lectured(O) at(O) the(O) Free(B-organization) University(I-organization) of(I-organization) New(I-organization) York(I-organization) on(O) '(O) Anarchist(O) and(O) Synergetic(O) Politics(O) '(O) in(O) 1965(O) .(O)"}, "label_list": ["location", "award", "literary genre", "poem", "country", "person", "magazine", "book", "event", "writer", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 10292, 11, 32465, 17779, 11, 33894, 11, 3224, 11, 1732, 11, 14756, 11, 2363, 11, 1567, 11, 7061, 11, 7471, 323, 507, 627, 85664, 25, 12220, 420, 4261, 1174, 568, 9960, 45568, 2009, 661, 323, 12131, 1708, 77468, 364, 274, 8384, 43366, 1174, 1561, 4356, 482, 31039, 11514, 19379, 5114, 520, 279, 1798, 18413, 315, 26349, 59336, 304, 578, 8976, 380, 1174, 67166, 3062, 63081, 449, 12656, 328, 13, 12649, 1458, 82, 323, 20661, 86829, 7881, 1174, 323, 16920, 3149, 520, 279, 3658, 3907, 315, 1561, 4356, 389, 364, 1556, 1132, 380, 323, 5837, 1215, 36324, 35979, 364, 304, 220, 5162, 20, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "769", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) movie(O) made(O) by(O) stephen(B-director) stieldberg(I-director)", "instance": {"id": "769", "words": ["what", "is", "the", "movie", "made", "by", "stephen", "stieldberg"], "labels": ["O", "O", "O", "O", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, trailer, average ratings, director, rating, review, actor, plot, character, title, genre, year and O.\nSentence: what is the movie made by stephen stieldberg", "prompt_labels": "what(O) is(O) the(O) movie(O) made(O) by(O) stephen(B-director) stieldberg(I-director)"}, "label_list": ["song", "trailer", "average ratings", "director", "rating", "review", "actor", "plot", "character", "title", "genre", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 19809, 11, 5578, 18594, 11, 7690, 11, 10959, 11, 3477, 11, 12360, 11, 7234, 11, 3752, 11, 2316, 11, 17779, 11, 1060, 323, 507, 627, 85664, 25, 1148, 374, 279, 5818, 1903, 555, 3094, 12301, 357, 823, 7881, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "296", "dataset": "crossner_music", "split": "dev", "prediction": "In(O) addition(O) to(O) Woolfson(B-musical artist),(O) vocalists(O) Chris(B-musical artist) Rainbow(I-musical artist),(O) Lenny(B-musical artist) Zakatek(I-musical artist),(O) John(B-musical artist) Miles(I-musical artist),(O) David(B-musical artist) Paton(I-musical artist),(O) and(O) Colin(B-musical artist) Blunstone(I-musical artist) are(O) regulars(O).(O)", "instance": {"id": "296", "words": ["In", "addition", "to", "Woolfson", ",", "vocalists", "Chris", "Rainbow", ",", "Lenny", "Zakatek", ",", "John", "Miles", ",", "David", "Paton", ",", "and", "Colin", "Blunstone", "are", "regulars", "."], "labels": ["O", "O", "O", "B-musical artist", "O", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O", "O", "B-musical artist", "I-musical artist", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, event, person, album, award, location, musical instrument, band, organization, song, music genre, musical artist and O.\nSentence: In addition to Woolfson , vocalists Chris Rainbow , Lenny Zakatek , John Miles , David Paton , and Colin Blunstone are regulars .", "prompt_labels": "In(O) addition(O) to(O) Woolfson(B-musical artist) ,(O) vocalists(O) Chris(B-musical artist) Rainbow(I-musical artist) ,(O) Lenny(B-musical artist) Zakatek(I-musical artist) ,(O) John(B-musical artist) Miles(I-musical artist) ,(O) David(B-musical artist) Paton(I-musical artist) ,(O) and(O) Colin(B-musical artist) Blunstone(I-musical artist) are(O) regulars(O) .(O)"}, "label_list": ["country", "event", "person", "album", "award", "location", "musical instrument", "band", "organization", "song", "music genre", "musical artist"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 1567, 11, 1732, 11, 8176, 11, 10292, 11, 3813, 11, 18273, 14473, 11, 7200, 11, 7471, 11, 5609, 11, 4731, 17779, 11, 18273, 10255, 323, 507, 627, 85664, 25, 763, 5369, 311, 47400, 69, 942, 1174, 26480, 1705, 11517, 47745, 1174, 445, 18314, 68553, 349, 74, 1174, 3842, 36303, 1174, 6941, 7281, 263, 1174, 323, 40979, 2563, 359, 11046, 527, 5912, 82, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "98", "dataset": "crossner_literature", "split": "dev", "prediction": "The(O) title(O) page(O) of(O) the(O) collection(O) Cathay(B-book) ((O) 1915(O) )(O),(O) refers(O) to(O) the(O) poet(O) Rihaku(B-writer),(O) the(O) pronunciation(O) in(O) Japanese(O) of(O) the(O) Tang(B-country) dynasty(I-country) Chinese(O) poet(O),(O) Li(B-writer) Bai(I-writer),(O) whose(O) poems(B-literary genre) were(O) much(O) beloved(O) in(O) China(B-country) and(O) Japan(B-country) for(O) their(O) technical(O) mastery(O) and(O) much(O) translated(O) in(O) the(O) West(O) because(O) of(O) their(O) seeming(O) simplicity(O).(O)", "instance": {"id": "98", "words": ["The", "title", "page", "of", "the", "collection", "Cathay", "(", "1915", ")", ",", "refers", "to", "the", "poet", "Rihaku", ",", "the", "pronunciation", "in", "Japanese", "of", "the", "Tang", "dynasty", "Chinese", "poet", ",", "Li", "Bai", ",", "whose", "poems", "were", "much", "beloved", "in", "China", "and", "Japan", "for", "their", "technical", "mastery", "and", "much", "translated", "in", "the", "West", "because", "of", "their", "seeming", "simplicity", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-book", "O", "O", "O", "O", "O", "O", "O", "O", "B-writer", "O", "O", "O", "O", "O", "O", "O", "B-country", "I-country", "O", "O", "O", "B-writer", "I-writer", "O", "O", "B-literary genre", "O", "O", "O", "O", "B-country", "O", "B-country", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: writer, book, country, event, person, award, poem, location, organization, literary genre, magazine and O.\nSentence: The title page of the collection Cathay ( 1915 ) , refers to the poet Rihaku , the pronunciation in Japanese of the Tang dynasty Chinese poet , Li Bai , whose poems were much beloved in China and Japan for their technical mastery and much translated in the West because of their seeming simplicity .", "prompt_labels": "The(O) title(O) page(O) of(O) the(O) collection(O) Cathay(B-book) ((O) 1915(O) )(O) ,(O) refers(O) to(O) the(O) poet(O) Rihaku(B-writer) ,(O) the(O) pronunciation(O) in(O) Japanese(O) of(O) the(O) Tang(B-country) dynasty(I-country) Chinese(O) poet(O) ,(O) Li(B-writer) Bai(I-writer) ,(O) whose(O) poems(B-literary genre) were(O) much(O) beloved(O) in(O) China(B-country) and(O) Japan(B-country) for(O) their(O) technical(O) mastery(O) and(O) much(O) translated(O) in(O) the(O) West(O) because(O) of(O) their(O) seeming(O) simplicity(O) .(O)"}, "label_list": ["writer", "book", "country", "event", "person", "award", "poem", "location", "organization", "literary genre", "magazine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7061, 11, 2363, 11, 3224, 11, 1567, 11, 1732, 11, 10292, 11, 33894, 11, 3813, 11, 7471, 11, 32465, 17779, 11, 14756, 323, 507, 627, 85664, 25, 578, 2316, 2199, 315, 279, 4526, 12513, 352, 320, 220, 7529, 20, 883, 1174, 19813, 311, 279, 40360, 432, 7141, 24468, 1174, 279, 71722, 304, 11002, 315, 279, 41462, 67946, 8620, 40360, 1174, 14851, 86008, 1174, 6832, 45319, 1051, 1790, 28530, 304, 5734, 323, 6457, 369, 872, 11156, 66763, 323, 1790, 25548, 304, 279, 4410, 1606, 315, 872, 76795, 40075, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "482", "dataset": "mit-restaurant", "split": "dev", "prediction": "help(O) me(O) find(O) a(O) place(O) my(O) kids(B-Amenity) would(I-Amenity) like(I-Amenity) to(I-Amenity) eat(I-Amenity)", "instance": {"id": "482", "words": ["help", "me", "find", "a", "place", "my", "kids", "would", "like", "to", "eat"], "labels": ["O", "O", "O", "O", "O", "O", "B-Amenity", "I-Amenity", "I-Amenity", "I-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Amenity, Hours, Cuisine, Dish, Rating, Restaurant Name, Location and O.\nSentence: help me find a place my kids would like to eat", "prompt_labels": "help(O) me(O) find(O) a(O) place(O) my(O) kids(B-Amenity) would(I-Amenity) like(I-Amenity) to(I-Amenity) eat(I-Amenity)"}, "label_list": ["Price", "Amenity", "Hours", "Cuisine", "Dish", "Rating", "Restaurant Name", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 3383, 56685, 11, 30192, 11, 81961, 11, 49268, 11, 19767, 11, 26568, 4076, 11, 10067, 323, 507, 627, 85664, 25, 1520, 757, 1505, 264, 2035, 856, 6980, 1053, 1093, 311, 8343, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1741", "dataset": "mit-movie", "split": "dev", "prediction": "name(O) some(O) 1950(B-year) s(I-year) history(B-genre) movies(O)", "instance": {"id": "1741", "words": ["name", "some", "1950", "s", "history", "movies"], "labels": ["O", "O", "B-year", "I-year", "B-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, actor, character, director, average ratings, trailer, title, rating, song, review, plot, genre and O.\nSentence: name some 1950 s history movies", "prompt_labels": "name(O) some(O) 1950(B-year) s(I-year) history(B-genre) movies(O)"}, "label_list": ["year", "actor", "character", "director", "average ratings", "trailer", "title", "rating", "song", "review", "plot", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 12360, 11, 3752, 11, 7690, 11, 5578, 18594, 11, 19809, 11, 2316, 11, 10959, 11, 5609, 11, 3477, 11, 7234, 11, 17779, 323, 507, 627, 85664, 25, 836, 1063, 220, 6280, 15, 274, 3925, 9698, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "278", "dataset": "mit-restaurant", "split": "dev", "prediction": "does(O) burger(B-Restaurant Name) king(I-Restaurant Name) accept(B-Amenity) credit(I-Amenity) cards(I-Amenity)", "instance": {"id": "278", "words": ["does", "burger", "king", "accept", "credit", "cards"], "labels": ["O", "B-Restaurant Name", "I-Restaurant Name", "B-Amenity", "I-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Amenity, Price, Rating, Cuisine, Location, Dish, Restaurant Name and O.\nSentence: does burger king accept credit cards", "prompt_labels": "does(O) burger(B-Restaurant Name) king(I-Restaurant Name) accept(B-Amenity) credit(I-Amenity) cards(I-Amenity)"}, "label_list": ["Hours", "Amenity", "Price", "Rating", "Cuisine", "Location", "Dish", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 3383, 56685, 11, 8650, 11, 19767, 11, 81961, 11, 10067, 11, 49268, 11, 26568, 4076, 323, 507, 627, 85664, 25, 1587, 45723, 11734, 4287, 6807, 7563, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "144", "dataset": "mit-movie", "split": "dev", "prediction": "where(O) can(O) i(O) watch(O) a(O) preview(B-trailer) of(O) moneyball(B-title)", "instance": {"id": "144", "words": ["where", "can", "i", "watch", "a", "preview", "of", "moneyball"], "labels": ["O", "O", "O", "O", "O", "B-trailer", "O", "B-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, actor, song, review, rating, genre, character, title, plot, average ratings, year, trailer and O.\nSentence: where can i watch a preview of moneyball", "prompt_labels": "where(O) can(O) i(O) watch(O) a(O) preview(B-trailer) of(O) moneyball(B-title)"}, "label_list": ["director", "actor", "song", "review", "rating", "genre", "character", "title", "plot", "average ratings", "year", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 12360, 11, 5609, 11, 3477, 11, 10959, 11, 17779, 11, 3752, 11, 2316, 11, 7234, 11, 5578, 18594, 11, 1060, 11, 19809, 323, 507, 627, 85664, 25, 1405, 649, 602, 3821, 264, 17562, 315, 3300, 4047, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1269", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) can(O) i(O) find(O) a(O) coffee(B-Cuisine) shop(O) within(B-Location) 10(I-Location) miles(I-Location) that(O) is(O) not(B-Amenity) part(I-Amenity) of(I-Amenity) a(I-Amenity) chain(I-Amenity)", "instance": {"id": "1269", "words": ["where", "can", "i", "find", "a", "coffee", "shop", "within", "10", "miles", "that", "is", "not", "part", "of", "a", "chain"], "labels": ["O", "O", "O", "O", "O", "B-Cuisine", "O", "B-Location", "I-Location", "I-Location", "O", "O", "B-Amenity", "I-Amenity", "I-Amenity", "I-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Location, Price, Rating, Cuisine, Amenity, Hours, Restaurant Name and O.\nSentence: where can i find a coffee shop within 10 miles that is not part of a chain", "prompt_labels": "where(O) can(O) i(O) find(O) a(O) coffee(B-Cuisine) shop(O) within(B-Location) 10(I-Location) miles(I-Location) that(O) is(O) not(B-Amenity) part(I-Amenity) of(I-Amenity) a(I-Amenity) chain(I-Amenity)"}, "label_list": ["Dish", "Location", "Price", "Rating", "Cuisine", "Amenity", "Hours", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 10067, 11, 8650, 11, 19767, 11, 81961, 11, 3383, 56685, 11, 30192, 11, 26568, 4076, 323, 507, 627, 85664, 25, 1405, 649, 602, 1505, 264, 11033, 8221, 2949, 220, 605, 8931, 430, 374, 539, 961, 315, 264, 8957, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "946", "dataset": "mit-restaurant", "split": "dev", "prediction": "local(B-Location) mcdonalds(B-Restaurant Name) please(O)", "instance": {"id": "946", "words": ["local", "mcdonalds", "please"], "labels": ["B-Location", "B-Restaurant Name", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Amenity, Cuisine, Location, Hours, Dish, Price, Restaurant Name and O.\nSentence: local mcdonalds please", "prompt_labels": "local(B-Location) mcdonalds(B-Restaurant Name) please(O)"}, "label_list": ["Rating", "Amenity", "Cuisine", "Location", "Hours", "Dish", "Price", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 3383, 56685, 11, 81961, 11, 10067, 11, 30192, 11, 49268, 11, 8650, 11, 26568, 4076, 323, 507, 627, 85664, 25, 2254, 296, 4484, 80794, 82, 4587, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "915", "dataset": "mit-movie", "split": "dev", "prediction": "find(O) a(O) review(O) for(O) coach(B-title) carter(I-title)", "instance": {"id": "915", "words": ["find", "a", "review", "for", "coach", "carter"], "labels": ["O", "O", "B-average ratings", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, year, average ratings, character, review, trailer, genre, title, song, rating, plot, director and O.\nSentence: find a review for coach carter", "prompt_labels": "find(O) a(O) review(B-average ratings) for(O) coach(B-title) carter(I-title)"}, "label_list": ["actor", "year", "average ratings", "character", "review", "trailer", "genre", "title", "song", "rating", "plot", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 1060, 11, 5578, 18594, 11, 3752, 11, 3477, 11, 19809, 11, 17779, 11, 2316, 11, 5609, 11, 10959, 11, 7234, 11, 7690, 323, 507, 627, 85664, 25, 1505, 264, 3477, 369, 7395, 1841, 466, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1230", "dataset": "mit-restaurant", "split": "dev", "prediction": "whats(O) the(O) best(B-Rating) french(B-Cuisine) style(I-Cuisine) cafe(I-Cuisine) in(O) sacramento(B-Location)", "instance": {"id": "1230", "words": ["whats", "the", "best", "french", "style", "cafe", "in", "sacramento"], "labels": ["O", "O", "B-Rating", "B-Cuisine", "O", "B-Cuisine", "O", "B-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Location, Rating, Hours, Cuisine, Dish, Price, Amenity and O.\nSentence: whats the best french style cafe in sacramento", "prompt_labels": "whats(O) the(O) best(B-Rating) french(B-Cuisine) style(O) cafe(B-Cuisine) in(O) sacramento(B-Location)"}, "label_list": ["Restaurant Name", "Location", "Rating", "Hours", "Cuisine", "Dish", "Price", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 10067, 11, 19767, 11, 30192, 11, 81961, 11, 49268, 11, 8650, 11, 3383, 56685, 323, 507, 627, 85664, 25, 41209, 279, 1888, 42293, 1742, 42030, 304, 11347, 36856, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "918", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) directed(O) the(B-title) bee(I-title) movie(O)", "instance": {"id": "918", "words": ["who", "directed", "the", "bee", "movie"], "labels": ["O", "O", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, director, song, rating, actor, trailer, plot, year, title, genre, character, average ratings and O.\nSentence: who directed the bee movie", "prompt_labels": "who(O) directed(O) the(O) bee(B-title) movie(I-title)"}, "label_list": ["review", "director", "song", "rating", "actor", "trailer", "plot", "year", "title", "genre", "character", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 7690, 11, 5609, 11, 10959, 11, 12360, 11, 19809, 11, 7234, 11, 1060, 11, 2316, 11, 17779, 11, 3752, 11, 5578, 18594, 323, 507, 627, 85664, 25, 889, 15910, 279, 38328, 5818, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1367", "dataset": "mit-movie", "split": "dev", "prediction": "im(O) looking(O) for(O) a(O) short(B-genre) film(O) starring(O) jared(B-actor) leto(I-actor) that(O) was(O) liked(B-average ratings) by(I-average ratings) many(I-average ratings) rated(O) r(B-rating) and(O) made(O) in(O) the(O) past(B-year) four(I-year) decades(I-year)", "instance": {"id": "1367", "words": ["im", "looking", "for", "a", "short", "film", "starring", "jared", "leto", "that", "was", "liked", "by", "many", "rated", "r", "and", "made", "in", "the", "past", "four", "decades"], "labels": ["O", "O", "O", "O", "B-genre", "O", "O", "B-actor", "I-actor", "O", "O", "B-average ratings", "I-average ratings", "I-average ratings", "O", "B-rating", "O", "O", "O", "O", "B-year", "I-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, year, rating, character, plot, review, actor, average ratings, director, title, genre, song and O.\nSentence: im looking for a short film starring jared leto that was liked by many rated r and made in the past four decades", "prompt_labels": "im(O) looking(O) for(O) a(O) short(B-genre) film(O) starring(O) jared(B-actor) leto(I-actor) that(O) was(O) liked(B-average ratings) by(I-average ratings) many(I-average ratings) rated(O) r(B-rating) and(O) made(O) in(O) the(O) past(B-year) four(I-year) decades(I-year)"}, "label_list": ["trailer", "year", "rating", "character", "plot", "review", "actor", "average ratings", "director", "title", "genre", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 1060, 11, 10959, 11, 3752, 11, 7234, 11, 3477, 11, 12360, 11, 5578, 18594, 11, 7690, 11, 2316, 11, 17779, 11, 5609, 323, 507, 627, 85664, 25, 737, 3411, 369, 264, 2875, 4632, 40500, 503, 1636, 514, 998, 430, 574, 15262, 555, 1690, 22359, 436, 323, 1903, 304, 279, 3347, 3116, 11026, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1171", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) steven(B-director) shainberg(I-director) star(O) in(O) a(O) very(B-average ratings) popular(I-average ratings) mystery(B-genre) movie(O) that(O) was(O) rated(O) r(B-rating)", "instance": {"id": "1171", "words": ["did", "steven", "shainberg", "star", "in", "a", "very", "popular", "mystery", "movie", "that", "was", "rated", "r"], "labels": ["O", "B-director", "I-director", "O", "O", "O", "B-average ratings", "I-average ratings", "B-genre", "O", "O", "O", "O", "B-rating"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, rating, year, genre, trailer, plot, actor, average ratings, director, character, title, review and O.\nSentence: did steven shainberg star in a very popular mystery movie that was rated r", "prompt_labels": "did(O) steven(B-director) shainberg(I-director) star(O) in(O) a(O) very(B-average ratings) popular(I-average ratings) mystery(B-genre) movie(O) that(O) was(O) rated(O) r(B-rating)"}, "label_list": ["song", "rating", "year", "genre", "trailer", "plot", "actor", "average ratings", "director", "character", "title", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 10959, 11, 1060, 11, 17779, 11, 19809, 11, 7234, 11, 12360, 11, 5578, 18594, 11, 7690, 11, 3752, 11, 2316, 11, 3477, 323, 507, 627, 85664, 25, 1550, 4179, 1055, 559, 467, 7881, 6917, 304, 264, 1633, 5526, 23347, 5818, 430, 574, 22359, 436, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1251", "dataset": "mit-restaurant", "split": "dev", "prediction": "when(O) does(O) white(B-Restaurant Name) castle(I-Restaurant Name) close(B-Hours)", "instance": {"id": "1251", "words": ["when", "does", "white", "castle", "close"], "labels": ["O", "O", "B-Restaurant Name", "I-Restaurant Name", "B-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Cuisine, Restaurant Name, Hours, Amenity, Price, Rating, Location and O.\nSentence: when does white castle close", "prompt_labels": "when(O) does(O) white(B-Restaurant Name) castle(I-Restaurant Name) close(B-Location)"}, "label_list": ["Dish", "Cuisine", "Restaurant Name", "Hours", "Amenity", "Price", "Rating", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 81961, 11, 26568, 4076, 11, 30192, 11, 3383, 56685, 11, 8650, 11, 19767, 11, 10067, 323, 507, 627, 85664, 25, 994, 1587, 4251, 33684, 3345, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1352", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) can(O) i(O) go(O) to(O) get(O) a(O) sandwich(B-Dish) around(B-Location) here(I-Location)", "instance": {"id": "1352", "words": ["where", "can", "i", "go", "to", "get", "a", "sandwich", "around", "here"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-Dish", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Hours, Dish, Amenity, Restaurant Name, Price, Rating, Location and O.\nSentence: where can i go to get a sandwich around here", "prompt_labels": "where(O) can(O) i(O) go(O) to(O) get(O) a(O) sandwich(B-Dish) around(B-Location) here(I-Location)"}, "label_list": ["Cuisine", "Hours", "Dish", "Amenity", "Restaurant Name", "Price", "Rating", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 30192, 11, 49268, 11, 3383, 56685, 11, 26568, 4076, 11, 8650, 11, 19767, 11, 10067, 323, 507, 627, 85664, 25, 1405, 649, 602, 733, 311, 636, 264, 28974, 2212, 1618, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "209", "dataset": "mit-movie", "split": "dev", "prediction": "i(O) want(O) a(O) 1960s(B-plot) zombie(I-plot) flick(O)", "instance": {"id": "209", "words": ["i", "want", "a", "1960s", "zombie", "flick"], "labels": ["B-genre", "I-genre", "I-genre", "I-genre", "I-genre", "I-genre"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, title, year, rating, average ratings, song, genre, plot, character, director, trailer, actor and O.\nSentence: i want a 1960s zombie flick", "prompt_labels": "i(B-genre) want(I-genre) a(I-genre) 1960s(I-genre) zombie(I-genre) flick(I-genre)"}, "label_list": ["review", "title", "year", "rating", "average ratings", "song", "genre", "plot", "character", "director", "trailer", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 2316, 11, 1060, 11, 10959, 11, 5578, 18594, 11, 5609, 11, 17779, 11, 7234, 11, 3752, 11, 7690, 11, 19809, 11, 12360, 323, 507, 627, 85664, 25, 602, 1390, 264, 220, 5162, 15, 82, 38836, 29447, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2415", "dataset": "mit-movie", "split": "dev", "prediction": "snow(B-title) white(I-title) and(I-title) the(I-title) seven(I-title) dwarfs(I-title)", "instance": {"id": "2415", "words": ["snow", "white", "and", "the", "seven", "dwarfs"], "labels": ["B-title", "I-title", "I-title", "I-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, year, plot, rating, song, title, director, actor, average ratings, genre, trailer, character and O.\nSentence: snow white and the seven dwarfs", "prompt_labels": "snow(B-title) white(I-title) and(I-title) the(I-title) seven(I-title) dwarfs(I-title)"}, "label_list": ["review", "year", "plot", "rating", "song", "title", "director", "actor", "average ratings", "genre", "trailer", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 1060, 11, 7234, 11, 10959, 11, 5609, 11, 2316, 11, 7690, 11, 12360, 11, 5578, 18594, 11, 17779, 11, 19809, 11, 3752, 323, 507, 627, 85664, 25, 12056, 4251, 323, 279, 8254, 71143, 3933, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "468", "dataset": "crossner_politics", "split": "dev", "prediction": "The(O) on(O) June(O) 19(O),(O) 1945(O),(O) was(O) part(O) of(O) the(O) strategic(O) bombing(O) campaign(O) waged(O) by(O) the(O) United(B-country) States(I-country) against(O) military(O) and(O) civilian(O) targets(O) and(O) population(O) centers(O) during(O) the(O) Japan(B-location) home(I-location) islands(I-location) campaign(O) in(O) the(O) closing(O) stages(O) of(O) World(B-event) War(I-event) II(I-event).(O)", "instance": {"id": "468", "words": ["The", "on", "June", "19", ",", "1945", ",", "was", "part", "of", "the", "strategic", "bombing", "campaign", "waged", "by", "the", "United", "States", "against", "military", "and", "civilian", "targets", "and", "population", "centers", "during", "the", "Japan", "home", "islands", "campaign", "in", "the", "closing", "stages", "of", "World", "War", "II", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-country", "I-country", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "I-event", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, organization, event, election, person, political party, country, location and O.\nSentence: The on June 19 , 1945 , was part of the strategic bombing campaign waged by the United States against military and civilian targets and population centers during the Japan home islands campaign in the closing stages of World War II .", "prompt_labels": "The(O) on(O) June(O) 19(O) ,(O) 1945(O) ,(O) was(O) part(O) of(O) the(O) strategic(O) bombing(O) campaign(O) waged(O) by(O) the(O) United(B-country) States(I-country) against(O) military(O) and(O) civilian(O) targets(O) and(O) population(O) centers(O) during(O) the(O) Japan(B-event) home(I-event) islands(I-event) campaign(I-event) in(O) the(O) closing(O) stages(O) of(O) World(B-event) War(I-event) II(I-event) .(O)"}, "label_list": ["politician", "organization", "event", "election", "person", "political party", "country", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 37038, 11, 7471, 11, 1567, 11, 6355, 11, 1732, 11, 5054, 4717, 11, 3224, 11, 3813, 323, 507, 627, 85664, 25, 578, 389, 5651, 220, 777, 1174, 220, 6393, 20, 1174, 574, 961, 315, 279, 19092, 37431, 4901, 92500, 555, 279, 3723, 4273, 2403, 6411, 323, 30028, 11811, 323, 7187, 19169, 2391, 279, 6457, 2162, 30100, 4901, 304, 279, 15676, 18094, 315, 4435, 5111, 8105, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "365", "dataset": "crossner_literature", "split": "dev", "prediction": "In(O) 2009(O),(O) he(O) was(O) named(O) the(O) United(B-organization) Nations(I-organization) Special(I-organization) Envoy(I-organization) to(I-organization) Haiti(I-organization) and(O) after(O) the(O) 2010(B-event) Haiti(I-event) earthquake(I-event),(O) he(O) teamed(O) up(O) with(O) George(B-person) W.(I-person) Bush(I-person) to(O) form(O) the(O) Clinton(B-organization) Bush(I-organization) Haiti(I-organization) Fund(I-organization).(O)", "instance": {"id": "365", "words": ["In", "2009", ",", "he", "was", "named", "the", "United", "Nations", "Special", "Envoy", "to", "Haiti", "and", "after", "the", "2010", "Haiti", "earthquake", ",", "he", "teamed", "up", "with", "George", "W.", "Bush", "to", "form", "the", "Clinton", "Bush", "Haiti", "Fund", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "O", "O", "B-country", "O", "O", "O", "B-event", "I-event", "I-event", "O", "O", "O", "O", "O", "B-person", "I-person", "I-person", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: poem, writer, location, organization, literary genre, magazine, event, book, person, award, country and O.\nSentence: In 2009 , he was named the United Nations Special Envoy to Haiti and after the 2010 Haiti earthquake , he teamed up with George W. Bush to form the Clinton Bush Haiti Fund .", "prompt_labels": "In(O) 2009(O) ,(O) he(O) was(O) named(O) the(O) United(B-organization) Nations(I-organization) Special(O) Envoy(O) to(O) Haiti(B-country) and(O) after(O) the(O) 2010(B-event) Haiti(I-event) earthquake(I-event) ,(O) he(O) teamed(O) up(O) with(O) George(B-person) W.(I-person) Bush(I-person) to(O) form(O) the(O) Clinton(B-organization) Bush(I-organization) Haiti(I-organization) Fund(I-organization) .(O)"}, "label_list": ["poem", "writer", "location", "organization", "literary genre", "magazine", "event", "book", "person", "award", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 33894, 11, 7061, 11, 3813, 11, 7471, 11, 32465, 17779, 11, 14756, 11, 1567, 11, 2363, 11, 1732, 11, 10292, 11, 3224, 323, 507, 627, 85664, 25, 763, 220, 1049, 24, 1174, 568, 574, 7086, 279, 3723, 19687, 9984, 38139, 2303, 311, 56290, 323, 1306, 279, 220, 679, 15, 56290, 38413, 1174, 568, 61310, 709, 449, 10058, 468, 13, 14409, 311, 1376, 279, 8283, 14409, 56290, 13492, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1161", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) ron(B-director) howard(I-director) ever(O) direct(O) a(O) musical(B-genre) in(O) the(O) 1960(B-year) s(I-year)", "instance": {"id": "1161", "words": ["did", "ron", "howard", "ever", "direct", "a", "musical", "in", "the", "1960", "s"], "labels": ["O", "B-director", "I-director", "O", "O", "O", "B-genre", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, average ratings, title, rating, actor, director, character, review, song, year, plot, genre and O.\nSentence: did ron howard ever direct a musical in the 1960 s", "prompt_labels": "did(O) ron(B-director) howard(I-director) ever(O) direct(O) a(O) musical(B-genre) in(O) the(O) 1960(B-year) s(I-year)"}, "label_list": ["trailer", "average ratings", "title", "rating", "actor", "director", "character", "review", "song", "year", "plot", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 5578, 18594, 11, 2316, 11, 10959, 11, 12360, 11, 7690, 11, 3752, 11, 3477, 11, 5609, 11, 1060, 11, 7234, 11, 17779, 323, 507, 627, 85664, 25, 1550, 436, 263, 1268, 569, 3596, 2167, 264, 18273, 304, 279, 220, 5162, 15, 274, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2182", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) sci(B-genre) fi(I-genre) movie(O) did(O) carol(B-actor) burnette(I-actor) star(O) in(O) during(O) the(O) last(B-year) decade(I-year)", "instance": {"id": "2182", "words": ["what", "sci", "fi", "movie", "did", "carol", "burnette", "star", "in", "during", "the", "last", "decade"], "labels": ["O", "B-genre", "I-genre", "O", "O", "B-actor", "I-actor", "O", "O", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, director, character, year, review, rating, plot, trailer, genre, average ratings, song, title and O.\nSentence: what sci fi movie did carol burnette star in during the last decade", "prompt_labels": "what(O) sci(B-genre) fi(I-genre) movie(O) did(O) carol(B-actor) burnette(I-actor) star(O) in(O) during(O) the(O) last(B-year) decade(I-year)"}, "label_list": ["actor", "director", "character", "year", "review", "rating", "plot", "trailer", "genre", "average ratings", "song", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 7690, 11, 3752, 11, 1060, 11, 3477, 11, 10959, 11, 7234, 11, 19809, 11, 17779, 11, 5578, 18594, 11, 5609, 11, 2316, 323, 507, 627, 85664, 25, 1148, 39074, 9314, 5818, 1550, 1841, 337, 8395, 6672, 6917, 304, 2391, 279, 1566, 13515, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "628", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) there(O) a(O) color(O) slapstick(B-genre) comedy(I-genre) movie(O)", "instance": {"id": "628", "words": ["is", "there", "a", "color", "slapstick", "comedy", "movie"], "labels": ["O", "O", "O", "B-genre", "I-genre", "I-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, genre, director, review, title, plot, rating, average ratings, trailer, year, actor, character and O.\nSentence: is there a color slapstick comedy movie", "prompt_labels": "is(O) there(O) a(O) color(B-genre) slapstick(I-genre) comedy(I-genre) movie(O)"}, "label_list": ["song", "genre", "director", "review", "title", "plot", "rating", "average ratings", "trailer", "year", "actor", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 17779, 11, 7690, 11, 3477, 11, 2316, 11, 7234, 11, 10959, 11, 5578, 18594, 11, 19809, 11, 1060, 11, 12360, 11, 3752, 323, 507, 627, 85664, 25, 374, 1070, 264, 1933, 51152, 30133, 23160, 5818, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "340", "dataset": "crossner_ai", "split": "dev", "prediction": "There(O) are(O) bindings(O) in(O) Python(B-programming language),(O) Java(B-programming language) and(O) MATLAB(B-product) /(O) OCTAVE(B-product).(O)", "instance": {"id": "340", "words": ["There", "are", "bindings", "in", "Python", ",", "Java", "and", "MATLAB", "/", "OCTAVE", "."], "labels": ["O", "O", "O", "O", "B-programming language", "O", "B-programming language", "O", "B-product", "O", "B-programming language", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, person, researcher, location, country, university, algorithm, conference, metric, product, programming language, field, task and O.\nSentence: There are bindings in Python , Java and MATLAB / OCTAVE .", "prompt_labels": "There(O) are(O) bindings(O) in(O) Python(B-programming language) ,(O) Java(B-programming language) and(O) MATLAB(B-product) /(O) OCTAVE(B-programming language) .(O)"}, "label_list": ["organization", "person", "researcher", "location", "country", "university", "algorithm", "conference", "metric", "product", "programming language", "field", "task"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 1732, 11, 32185, 11, 3813, 11, 3224, 11, 12374, 11, 12384, 11, 10017, 11, 18767, 11, 2027, 11, 15840, 4221, 11, 2115, 11, 3465, 323, 507, 627, 85664, 25, 2684, 527, 36800, 304, 13325, 1174, 8102, 323, 50447, 611, 67277, 9682, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "711", "dataset": "mit-movie", "split": "dev", "prediction": "looking(O) for(O) a(O) comedy(B-genre) with(O) darryl(B-actor) hannah(I-actor) and(O) steve(B-actor) martin(I-actor)", "instance": {"id": "711", "words": ["looking", "for", "a", "comedy", "with", "darryl", "hannah", "and", "steve", "martin"], "labels": ["O", "O", "O", "B-genre", "O", "B-actor", "I-actor", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, actor, trailer, review, character, genre, year, average ratings, title, rating, song, director and O.\nSentence: looking for a comedy with darryl hannah and steve martin", "prompt_labels": "looking(O) for(O) a(O) comedy(B-genre) with(O) darryl(B-actor) hannah(I-actor) and(O) steve(B-actor) martin(I-actor)"}, "label_list": ["plot", "actor", "trailer", "review", "character", "genre", "year", "average ratings", "title", "rating", "song", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 12360, 11, 19809, 11, 3477, 11, 3752, 11, 17779, 11, 1060, 11, 5578, 18594, 11, 2316, 11, 10959, 11, 5609, 11, 7690, 323, 507, 627, 85664, 25, 3411, 369, 264, 23160, 449, 294, 11687, 75, 305, 44104, 323, 4179, 588, 96016, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "870", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) a(O) seafood(B-Cuisine) restaurant(O) around(B-Location) here(I-Location)", "instance": {"id": "870", "words": ["is", "there", "a", "seafood", "restaurant", "around", "here"], "labels": ["O", "O", "O", "B-Cuisine", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Hours, Amenity, Cuisine, Restaurant Name, Rating, Dish, Location and O.\nSentence: is there a seafood restaurant around here", "prompt_labels": "is(O) there(O) a(O) seafood(B-Cuisine) restaurant(O) around(O) here(O)"}, "label_list": ["Price", "Hours", "Amenity", "Cuisine", "Restaurant Name", "Rating", "Dish", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 30192, 11, 3383, 56685, 11, 81961, 11, 26568, 4076, 11, 19767, 11, 49268, 11, 10067, 323, 507, 627, 85664, 25, 374, 1070, 264, 53405, 10960, 2212, 1618, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "754", "dataset": "mit-movie", "split": "dev", "prediction": "tell(O) me(O) the(O) names(O) of(O) all(O) critically(B-average ratings) acclaimed(I-average ratings) horror(B-genre) films(O)", "instance": {"id": "754", "words": ["tell", "me", "the", "names", "of", "all", "critically", "acclaimed", "horror", "films"], "labels": ["O", "O", "O", "O", "O", "O", "B-average ratings", "I-average ratings", "B-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, trailer, song, director, actor, character, average ratings, title, genre, year, rating, plot and O.\nSentence: tell me the names of all critically acclaimed horror films", "prompt_labels": "tell(O) me(O) the(O) names(O) of(O) all(O) critically(B-average ratings) acclaimed(I-average ratings) horror(B-genre) films(O)"}, "label_list": ["review", "trailer", "song", "director", "actor", "character", "average ratings", "title", "genre", "year", "rating", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 19809, 11, 5609, 11, 7690, 11, 12360, 11, 3752, 11, 5578, 18594, 11, 2316, 11, 17779, 11, 1060, 11, 10959, 11, 7234, 323, 507, 627, 85664, 25, 3371, 757, 279, 5144, 315, 682, 41440, 50082, 22169, 12631, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "191", "dataset": "crossner_ai", "split": "dev", "prediction": "Apple(B-organization) Inc(I-organization) introduced(O) Face(B-product) ID(I-product) on(O) the(O) flagship(O) iPhone(B-product) X(I-product) as(O) a(O) biometric(O) authentication(O) successor(O) to(O) the(O) Touch(B-product) ID(I-product),(O) a(O) fingerprint(O) based(O) system(O).(O)", "instance": {"id": "191", "words": ["Apple", "Inc", "introduced", "Face", "ID", "on", "the", "flagship", "iPhone", "X", "as", "a", "biometric", "authentication", "successor", "to", "the", "Touch", "ID", ",", "a", "fingerprint", "based", "system", "."], "labels": ["B-organization", "I-organization", "O", "B-product", "I-product", "O", "O", "O", "B-product", "I-product", "O", "O", "O", "O", "O", "O", "O", "B-product", "I-product", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: task, country, location, field, person, researcher, organization, university, metric, conference, product, algorithm, programming language and O.\nSentence: Apple Inc introduced Face ID on the flagship iPhone X as a biometric authentication successor to the Touch ID , a fingerprint based system .", "prompt_labels": "Apple(B-organization) Inc(I-organization) introduced(O) Face(B-product) ID(I-product) on(O) the(O) flagship(O) iPhone(B-product) X(I-product) as(O) a(O) biometric(O) authentication(O) successor(O) to(O) the(O) Touch(B-product) ID(I-product) ,(O) a(O) fingerprint(O) based(O) system(O) .(O)"}, "label_list": ["task", "country", "location", "field", "person", "researcher", "organization", "university", "metric", "conference", "product", "algorithm", "programming language"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3465, 11, 3224, 11, 3813, 11, 2115, 11, 1732, 11, 32185, 11, 7471, 11, 12374, 11, 18767, 11, 10017, 11, 2027, 11, 12384, 11, 15840, 4221, 323, 507, 627, 85664, 25, 8325, 4953, 11784, 19109, 3110, 389, 279, 43772, 12443, 1630, 439, 264, 6160, 24264, 17066, 34665, 311, 279, 19898, 3110, 1174, 264, 43697, 3196, 1887, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1011", "dataset": "mit-restaurant", "split": "dev", "prediction": "need(O) a(O) four(B-Rating) star(I-Rating) restaurant(O) in(B-Amenity) a(I-Amenity) hotel(I-Amenity)", "instance": {"id": "1011", "words": ["need", "a", "four", "star", "restaurant", "in", "a", "hotel"], "labels": ["O", "O", "B-Rating", "I-Rating", "O", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Dish, Amenity, Location, Rating, Price, Restaurant Name, Hours and O.\nSentence: need a four star restaurant in a hotel", "prompt_labels": "need(O) a(O) four(B-Rating) star(I-Rating) restaurant(O) in(B-Location) a(I-Location) hotel(I-Location)"}, "label_list": ["Cuisine", "Dish", "Amenity", "Location", "Rating", "Price", "Restaurant Name", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 49268, 11, 3383, 56685, 11, 10067, 11, 19767, 11, 8650, 11, 26568, 4076, 11, 30192, 323, 507, 627, 85664, 25, 1205, 264, 3116, 6917, 10960, 304, 264, 9689, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "821", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) any(O) shirley(B-actor) temple(I-actor) movies(O) playing(O) today(O)", "instance": {"id": "821", "words": ["list", "any", "shirley", "temple", "movies", "playing", "today"], "labels": ["O", "O", "B-actor", "I-actor", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, average ratings, genre, song, review, year, rating, actor, title, director, character, trailer and O.\nSentence: list any shirley temple movies playing today", "prompt_labels": "list(O) any(O) shirley(B-actor) temple(I-actor) movies(O) playing(O) today(O)"}, "label_list": ["plot", "average ratings", "genre", "song", "review", "year", "rating", "actor", "title", "director", "character", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 5578, 18594, 11, 17779, 11, 5609, 11, 3477, 11, 1060, 11, 10959, 11, 12360, 11, 2316, 11, 7690, 11, 3752, 11, 19809, 323, 507, 627, 85664, 25, 1160, 904, 559, 404, 3258, 27850, 9698, 5737, 3432, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "975", "dataset": "mit-movie", "split": "dev", "prediction": "can(O) you(O) find(O) me(O) a(O) pg(B-rating) 13(I-rating) movie(O) about(O) a(O) bank(B-plot) robbery(I-plot)", "instance": {"id": "975", "words": ["can", "you", "find", "me", "a", "pg", "13", "movie", "about", "a", "bank", "robbery"], "labels": ["O", "O", "O", "O", "O", "B-rating", "I-rating", "O", "O", "O", "B-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, year, rating, review, average ratings, plot, character, song, director, trailer, title, actor and O.\nSentence: can you find me a pg 13 movie about a bank robbery", "prompt_labels": "can(O) you(O) find(O) me(O) a(O) pg(B-rating) 13(I-rating) movie(O) about(O) a(O) bank(B-plot) robbery(I-plot)"}, "label_list": ["genre", "year", "rating", "review", "average ratings", "plot", "character", "song", "director", "trailer", "title", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 1060, 11, 10959, 11, 3477, 11, 5578, 18594, 11, 7234, 11, 3752, 11, 5609, 11, 7690, 11, 19809, 11, 2316, 11, 12360, 323, 507, 627, 85664, 25, 649, 499, 1505, 757, 264, 17953, 220, 1032, 5818, 922, 264, 6201, 44214, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1396", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) is(O) some(O) good(B-Rating) outdoor(B-Amenity) dining(I-Amenity)", "instance": {"id": "1396", "words": ["where", "is", "some", "good", "outdoor", "dining"], "labels": ["O", "O", "O", "B-Rating", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Rating, Dish, Location, Restaurant Name, Cuisine, Hours, Price and O.\nSentence: where is some good outdoor dining", "prompt_labels": "where(O) is(O) some(O) good(B-Rating) outdoor(B-Amenity) dining(I-Amenity)"}, "label_list": ["Amenity", "Rating", "Dish", "Location", "Restaurant Name", "Cuisine", "Hours", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 19767, 11, 49268, 11, 10067, 11, 26568, 4076, 11, 81961, 11, 30192, 11, 8650, 323, 507, 627, 85664, 25, 1405, 374, 1063, 1695, 16166, 18397, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2211", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) was(O) that(O) unrated(B-rating) spaghetti(B-genre) western(I-genre) with(O) reese(B-actor) witherspoon(I-actor) that(O) had(O) a(O) five(B-average ratings) star(I-average ratings) rating(O) average(O) and(O) came(O) out(O) in(O) the(O) 2000(B-year) s(I-year)", "instance": {"id": "2211", "words": ["what", "was", "that", "unrated", "spaghetti", "western", "with", "reese", "witherspoon", "that", "had", "a", "five", "star", "rating", "average", "and", "came", "out", "in", "the", "2000", "s"], "labels": ["O", "O", "O", "B-rating", "B-genre", "I-genre", "O", "B-actor", "I-actor", "O", "O", "O", "B-average ratings", "I-average ratings", "O", "O", "O", "O", "O", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, director, average ratings, trailer, rating, year, review, song, plot, character, actor, genre and O.\nSentence: what was that unrated spaghetti western with reese witherspoon that had a five star rating average and came out in the 2000 s", "prompt_labels": "what(O) was(O) that(O) unrated(B-rating) spaghetti(B-genre) western(I-genre) with(O) reese(B-actor) witherspoon(I-actor) that(O) had(O) a(O) five(B-average ratings) star(I-average ratings) rating(O) average(O) and(O) came(O) out(O) in(O) the(O) 2000(B-year) s(I-year)"}, "label_list": ["title", "director", "average ratings", "trailer", "rating", "year", "review", "song", "plot", "character", "actor", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 7690, 11, 5578, 18594, 11, 19809, 11, 10959, 11, 1060, 11, 3477, 11, 5609, 11, 7234, 11, 3752, 11, 12360, 11, 17779, 323, 507, 627, 85664, 25, 1148, 574, 430, 41480, 660, 88010, 19001, 449, 312, 2423, 449, 388, 33076, 430, 1047, 264, 4330, 6917, 10959, 5578, 323, 3782, 704, 304, 279, 220, 1049, 15, 274, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "242", "dataset": "crossner_music", "split": "dev", "prediction": "Bedrock(B-band) Records(I-band) is(O) an(O) English(O) record(O) label(O) for(O) trance(B-music genre),(O) house(B-music genre) and(O) techno(B-music genre) started(O) by(O) Nick(B-musical artist) Muir(I-musical artist) and(O) John(B-musical artist) Digweed(I-musical artist).(O)", "instance": {"id": "242", "words": ["Bedrock", "Records", "is", "an", "English", "record", "label", "for", "trance", ",", "house", "and", "techno", "started", "by", "Nick", "Muir", "and", "John", "Digweed", "."], "labels": ["B-organization", "I-organization", "O", "O", "O", "O", "O", "O", "B-music genre", "O", "B-music genre", "O", "B-music genre", "O", "O", "B-musical artist", "I-musical artist", "O", "B-musical artist", "I-musical artist", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, location, person, musical instrument, event, song, country, musical artist, organization, award, band, album and O.\nSentence: Bedrock Records is an English record label for trance , house and techno started by Nick Muir and John Digweed .", "prompt_labels": "Bedrock(B-organization) Records(I-organization) is(O) an(O) English(O) record(O) label(O) for(O) trance(B-music genre) ,(O) house(B-music genre) and(O) techno(B-music genre) started(O) by(O) Nick(B-musical artist) Muir(I-musical artist) and(O) John(B-musical artist) Digweed(I-musical artist) .(O)"}, "label_list": ["music genre", "location", "person", "musical instrument", "event", "song", "country", "musical artist", "organization", "award", "band", "album"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 4731, 17779, 11, 3813, 11, 1732, 11, 18273, 14473, 11, 1567, 11, 5609, 11, 3224, 11, 18273, 10255, 11, 7471, 11, 10292, 11, 7200, 11, 8176, 323, 507, 627, 85664, 25, 13394, 21161, 22293, 374, 459, 6498, 3335, 2440, 369, 98531, 1174, 3838, 323, 89999, 3940, 555, 15341, 15130, 404, 323, 3842, 39069, 86427, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "92", "dataset": "mit-restaurant", "split": "dev", "prediction": "are(O) there(O) any(O) sushi(B-Cuisine) restaurants(O) near(B-Location) colonel(I-Location) bell(I-Location) drive(I-Location)", "instance": {"id": "92", "words": ["are", "there", "any", "sushi", "restaurants", "near", "colonel", "bell", "drive"], "labels": ["O", "O", "O", "B-Cuisine", "O", "B-Location", "I-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Restaurant Name, Location, Amenity, Rating, Dish, Cuisine, Price and O.\nSentence: are there any sushi restaurants near colonel bell drive", "prompt_labels": "are(O) there(O) any(O) sushi(B-Cuisine) restaurants(O) near(B-Location) colonel(I-Location) bell(I-Location) drive(I-Location)"}, "label_list": ["Hours", "Restaurant Name", "Location", "Amenity", "Rating", "Dish", "Cuisine", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 26568, 4076, 11, 10067, 11, 3383, 56685, 11, 19767, 11, 49268, 11, 81961, 11, 8650, 323, 507, 627, 85664, 25, 527, 1070, 904, 67322, 15926, 3221, 15235, 301, 29519, 6678, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "200", "dataset": "crossner_music", "split": "dev", "prediction": "Brooks(B-musical artist) and(I-musical artist) Dunn(I-musical artist) have(O) more(O) Country(B-organization) Music(I-organization) Association(I-organization) awards(O) and(O) Academy(B-organization) of(I-organization) Country(I-organization) Music(I-organization) awards(O) than(O) any(O) act(O) in(O) the(O) history(O) of(O) country(B-music genre) music(I-music genre).(O)", "instance": {"id": "200", "words": ["Brooks", "and", "Dunn", "have", "more", "Country", "Music", "Association", "awards", "and", "Academy", "of", "Country", "Music", "awards", "than", "any", "act", "in", "the", "history", "of", "country", "music", "."], "labels": ["B-band", "I-band", "I-band", "O", "O", "B-award", "I-award", "I-award", "I-award", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "B-music genre", "I-music genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, musical artist, country, person, award, album, band, location, music genre, musical instrument, organization, song and O.\nSentence: Brooks and Dunn have more Country Music Association awards and Academy of Country Music awards than any act in the history of country music .", "prompt_labels": "Brooks(B-band) and(I-band) Dunn(I-band) have(O) more(O) Country(B-award) Music(I-award) Association(I-award) awards(I-award) and(O) Academy(B-award) of(I-award) Country(I-award) Music(I-award) awards(I-award) than(O) any(O) act(O) in(O) the(O) history(O) of(O) country(B-music genre) music(I-music genre) .(O)"}, "label_list": ["event", "musical artist", "country", "person", "award", "album", "band", "location", "music genre", "musical instrument", "organization", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 18273, 10255, 11, 3224, 11, 1732, 11, 10292, 11, 8176, 11, 7200, 11, 3813, 11, 4731, 17779, 11, 18273, 14473, 11, 7471, 11, 5609, 323, 507, 627, 85664, 25, 39119, 323, 64845, 617, 810, 14438, 10948, 10229, 23146, 323, 16192, 315, 14438, 10948, 23146, 1109, 904, 1180, 304, 279, 3925, 315, 3224, 4731, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "249", "dataset": "crossner_literature", "split": "dev", "prediction": "Philip(B-writer) K.(I-writer) Dick(I-writer) '(O) s(O) novel(O),(O) The(B-book) Man(I-book) in(I-book) the(I-book) High(I-book) Castle(I-book) ((O) 1962(O) )(O),(O) is(O) an(O) alternate(O) history(O) in(O) which(O) Nazi(B-country) Germany(I-country) and(O) Imperial(O) Japan(B-country) won(O) World(B-event) War(I-event) II(I-event).(O)", "instance": {"id": "249", "words": ["Philip", "K.", "Dick", "'", "s", "novel", ",", "The", "Man", "in", "the", "High", "Castle", "(", "1962", ")", ",", "is", "an", "alternate", "history", "in", "which", "Nazi", "Germany", "and", "Imperial", "Japan", "won", "World", "War", "II", "."], "labels": ["B-writer", "I-writer", "I-writer", "O", "O", "B-literary genre", "O", "B-book", "I-book", "I-book", "I-book", "I-book", "I-book", "O", "O", "O", "O", "O", "O", "B-literary genre", "I-literary genre", "O", "O", "B-country", "I-country", "O", "B-country", "I-country", "O", "B-event", "I-event", "I-event", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: writer, person, magazine, literary genre, award, book, location, poem, country, event, organization and O.\nSentence: Philip K. Dick ' s novel , The Man in the High Castle ( 1962 ) , is an alternate history in which Nazi Germany and Imperial Japan won World War II .", "prompt_labels": "Philip(B-writer) K.(I-writer) Dick(I-writer) '(O) s(O) novel(B-literary genre) ,(O) The(B-book) Man(I-book) in(I-book) the(I-book) High(I-book) Castle(I-book) ((O) 1962(O) )(O) ,(O) is(O) an(O) alternate(B-literary genre) history(I-literary genre) in(O) which(O) Nazi(B-country) Germany(I-country) and(O) Imperial(B-country) Japan(I-country) won(O) World(B-event) War(I-event) II(I-event) .(O)"}, "label_list": ["writer", "person", "magazine", "literary genre", "award", "book", "location", "poem", "country", "event", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7061, 11, 1732, 11, 14756, 11, 32465, 17779, 11, 10292, 11, 2363, 11, 3813, 11, 33894, 11, 3224, 11, 1567, 11, 7471, 323, 507, 627, 85664, 25, 26241, 735, 13, 23373, 364, 274, 11775, 1174, 578, 2418, 304, 279, 5234, 27987, 320, 220, 5162, 17, 883, 1174, 374, 459, 25631, 3925, 304, 902, 32527, 10057, 323, 31013, 6457, 2834, 4435, 5111, 8105, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "114", "dataset": "crossner_science", "split": "dev", "prediction": "Uranus(B-astronomical object) is(O) similar(O) in(O) composition(O) to(O) Neptune(B-astronomical object),(O) and(O) both(O) have(O) bulk(O) chemical(O) compositions(O) which(O) differ(O) from(O) that(O) of(O) the(O) larger(O) gas(O) giant(O) s(O) Jupiter(B-astronomical object) and(O) Saturn(B-astronomical object).(O)", "instance": {"id": "114", "words": ["Uranus", "is", "similar", "in", "composition", "to", "Neptune", ",", "and", "both", "have", "bulk", "chemical", "compositions", "which", "differ", "from", "that", "of", "the", "larger", "gas", "giant", "s", "Jupiter", "and", "Saturn", "."], "labels": ["B-astronomical object", "O", "O", "O", "O", "O", "B-astronomical object", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-astronomical object", "O", "B-astronomical object", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, event, chemical element, discipline, enzyme, academic journal, country, theory, university, protein, astronomical object, location, award, scientist, organization, chemical compound and O.\nSentence: Uranus is similar in composition to Neptune , and both have bulk chemical compositions which differ from that of the larger gas giant s Jupiter and Saturn .", "prompt_labels": "Uranus(B-astronomical object) is(O) similar(O) in(O) composition(O) to(O) Neptune(B-astronomical object) ,(O) and(O) both(O) have(O) bulk(O) chemical(O) compositions(O) which(O) differ(O) from(O) that(O) of(O) the(O) larger(O) gas(O) giant(O) s(O) Jupiter(B-astronomical object) and(O) Saturn(B-astronomical object) .(O)"}, "label_list": ["person", "event", "chemical element", "discipline", "enzyme", "academic journal", "country", "theory", "university", "protein", "astronomical object", "location", "award", "scientist", "organization", "chemical compound"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 1567, 11, 11742, 2449, 11, 26434, 11, 49242, 11, 14584, 8486, 11, 3224, 11, 10334, 11, 12374, 11, 13128, 11, 87283, 1665, 11, 3813, 11, 10292, 11, 28568, 11, 7471, 11, 11742, 24549, 323, 507, 627, 85664, 25, 80770, 355, 374, 4528, 304, 18528, 311, 80724, 1174, 323, 2225, 617, 20155, 11742, 62644, 902, 1782, 505, 430, 315, 279, 8294, 6962, 14880, 274, 50789, 323, 50253, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1148", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) is(O) the(O) price(O) for(O) a(O) lobster(B-Dish) entree(O) at(O) martys(B-Restaurant Name) marina(I-Restaurant Name)", "instance": {"id": "1148", "words": ["what", "is", "the", "price", "for", "a", "lobster", "entree", "at", "martys", "marina"], "labels": ["O", "O", "O", "O", "O", "O", "B-Dish", "O", "O", "B-Restaurant Name", "I-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Dish, Restaurant Name, Amenity, Price, Hours, Rating, Location and O.\nSentence: what is the price for a lobster entree at martys marina", "prompt_labels": "what(O) is(O) the(O) price(O) for(O) a(O) lobster(B-Dish) entree(O) at(O) martys(B-Restaurant Name) marina(I-Restaurant Name)"}, "label_list": ["Cuisine", "Dish", "Restaurant Name", "Amenity", "Price", "Hours", "Rating", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 49268, 11, 26568, 4076, 11, 3383, 56685, 11, 8650, 11, 30192, 11, 19767, 11, 10067, 323, 507, 627, 85664, 25, 1148, 374, 279, 3430, 369, 264, 80815, 1218, 770, 520, 49295, 1065, 3678, 2259, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "390", "dataset": "crossner_science", "split": "dev", "prediction": "Pneumatic(B-discipline) chemistry(I-discipline) developed(O) in(O) the(O) eighteenth(O) century(O) with(O) the(O) work(O) of(O) scientists(O) such(O) as(O) Stephen(B-scientist) Hales(I-scientist),(O) Joseph(B-scientist) Black(I-scientist),(O) Joseph(B-scientist) Priestley(I-scientist),(O) and(O) Antoine-Laurent(B-scientist) Lavoisier(I-scientist),(O) and(O) others(O).(O)", "instance": {"id": "390", "words": ["Pneumatic", "chemistry", "developed", "in", "the", "eighteenth", "century", "with", "the", "work", "of", "scientists", "such", "as", "Stephen", "Hales", ",", "Joseph", "Black", ",", "Joseph", "Priestley", ",", "and", "Antoine-Laurent", "Lavoisier", ",", "and", "others", "."], "labels": ["B-discipline", "I-discipline", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "O", "O", "B-scientist", "I-scientist", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, event, location, discipline, enzyme, protein, award, organization, astronomical object, country, theory, chemical element, person, chemical compound, academic journal, university and O.\nSentence: Pneumatic chemistry developed in the eighteenth century with the work of scientists such as Stephen Hales , Joseph Black , Joseph Priestley , and Antoine-Laurent Lavoisier , and others .", "prompt_labels": "Pneumatic(B-discipline) chemistry(I-discipline) developed(O) in(O) the(O) eighteenth(O) century(O) with(O) the(O) work(O) of(O) scientists(O) such(O) as(O) Stephen(B-scientist) Hales(I-scientist) ,(O) Joseph(B-scientist) Black(I-scientist) ,(O) Joseph(B-scientist) Priestley(I-scientist) ,(O) and(O) Antoine-Laurent(B-scientist) Lavoisier(I-scientist) ,(O) and(O) others(O) .(O)"}, "label_list": ["scientist", "event", "location", "discipline", "enzyme", "protein", "award", "organization", "astronomical object", "country", "theory", "chemical element", "person", "chemical compound", "academic journal", "university"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 28568, 11, 1567, 11, 3813, 11, 26434, 11, 49242, 11, 13128, 11, 10292, 11, 7471, 11, 87283, 1665, 11, 3224, 11, 10334, 11, 11742, 2449, 11, 1732, 11, 11742, 24549, 11, 14584, 8486, 11, 12374, 323, 507, 627, 85664, 25, 393, 818, 33030, 30903, 8040, 304, 279, 8223, 62655, 9478, 449, 279, 990, 315, 14248, 1778, 439, 18587, 473, 3916, 1174, 15466, 5348, 1174, 15466, 50003, 3258, 1174, 323, 91254, 95016, 77065, 445, 28316, 285, 1291, 1174, 323, 3885, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1225", "dataset": "mit-movie", "split": "dev", "prediction": "do(O) you(O) think(O) youd(O) be(O) able(O) to(O) help(O) me(O) find(O) the(B-title) penguins(I-title) of(I-title) madagascar(I-title) operation(I-title) dvd(O) premier(O)", "instance": {"id": "1225", "words": ["do", "you", "think", "youd", "be", "able", "to", "help", "me", "find", "the", "penguins", "of", "madagascar", "operation", "dvd", "premier"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-title", "I-title", "I-title", "I-title", "I-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, review, character, song, rating, title, genre, trailer, average ratings, director, actor, plot and O.\nSentence: do you think youd be able to help me find the penguins of madagascar operation dvd premier", "prompt_labels": "do(O) you(O) think(O) youd(O) be(O) able(O) to(O) help(O) me(O) find(O) the(B-title) penguins(I-title) of(I-title) madagascar(I-title) operation(I-title) dvd(I-title) premier(I-title)"}, "label_list": ["year", "review", "character", "song", "rating", "title", "genre", "trailer", "average ratings", "director", "actor", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 3477, 11, 3752, 11, 5609, 11, 10959, 11, 2316, 11, 17779, 11, 19809, 11, 5578, 18594, 11, 7690, 11, 12360, 11, 7234, 323, 507, 627, 85664, 25, 656, 499, 1781, 499, 67, 387, 3025, 311, 1520, 757, 1505, 279, 281, 56458, 315, 13088, 79775, 5784, 51008, 21134, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1836", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) carroll(B-actor) oconner(I-actor) musical(B-genre) is(O) liked(B-average ratings) by(I-average ratings) many(I-average ratings)", "instance": {"id": "1836", "words": ["what", "carroll", "oconner", "musical", "is", "liked", "by", "many"], "labels": ["O", "B-actor", "I-actor", "B-genre", "O", "B-average ratings", "I-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, review, year, plot, rating, song, genre, title, director, average ratings, actor, character and O.\nSentence: what carroll oconner musical is liked by many", "prompt_labels": "what(O) carroll(B-actor) oconner(I-actor) musical(B-genre) is(O) liked(B-average ratings) by(I-average ratings) many(I-average ratings)"}, "label_list": ["trailer", "review", "year", "plot", "rating", "song", "genre", "title", "director", "average ratings", "actor", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 3477, 11, 1060, 11, 7234, 11, 10959, 11, 5609, 11, 17779, 11, 2316, 11, 7690, 11, 5578, 18594, 11, 12360, 11, 3752, 323, 507, 627, 85664, 25, 1148, 1841, 1119, 297, 444, 1215, 18273, 374, 15262, 555, 1690, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "701", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) would(O) llike(O) breakfast(B-Cuisine) foods(O)", "instance": {"id": "701", "words": ["i", "would", "llike", "breakfast", "foods"], "labels": ["O", "O", "O", "B-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Cuisine, Location, Rating, Restaurant Name, Dish, Price, Amenity and O.\nSentence: i would llike breakfast foods", "prompt_labels": "i(O) would(O) llike(O) breakfast(B-Cuisine) foods(O)"}, "label_list": ["Hours", "Cuisine", "Location", "Rating", "Restaurant Name", "Dish", "Price", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 81961, 11, 10067, 11, 19767, 11, 26568, 4076, 11, 49268, 11, 8650, 11, 3383, 56685, 323, 507, 627, 85664, 25, 602, 1053, 326, 4908, 17954, 15657, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "424", "dataset": "crossner_science", "split": "dev", "prediction": "In(O) March(O) 1737(O) Short(B-scientist) was(O) elected(O) a(O) Fellow(B-award) of(I-award) the(I-award) Royal(I-award) Society(I-award) and(O) in(O) 1758(O) became(O) a(O) foreign(O) member(O) of(O) the(O) Royal(B-organization) Swedish(I-organization) Academy(I-organization) of(I-organization) Sciences(I-organization).(O)", "instance": {"id": "424", "words": ["In", "March", "1737", "Short", "was", "elected", "a", "Fellow", "of", "the", "Royal", "Society", "and", "in", "1758", "became", "a", "foreign", "member", "of", "the", "Royal", "Swedish", "Academy", "of", "Sciences", "."], "labels": ["O", "O", "O", "B-scientist", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: protein, scientist, country, academic journal, person, award, chemical element, theory, chemical compound, university, event, location, discipline, astronomical object, organization, enzyme and O.\nSentence: In March 1737 Short was elected a Fellow of the Royal Society and in 1758 became a foreign member of the Royal Swedish Academy of Sciences .", "prompt_labels": "In(O) March(O) 1737(O) Short(B-scientist) was(O) elected(O) a(O) Fellow(B-award) of(I-award) the(I-award) Royal(I-award) Society(I-award) and(O) in(O) 1758(O) became(O) a(O) foreign(O) member(O) of(O) the(O) Royal(B-organization) Swedish(I-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) .(O)"}, "label_list": ["protein", "scientist", "country", "academic journal", "person", "award", "chemical element", "theory", "chemical compound", "university", "event", "location", "discipline", "astronomical object", "organization", "enzyme"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 13128, 11, 28568, 11, 3224, 11, 14584, 8486, 11, 1732, 11, 10292, 11, 11742, 2449, 11, 10334, 11, 11742, 24549, 11, 12374, 11, 1567, 11, 3813, 11, 26434, 11, 87283, 1665, 11, 7471, 11, 49242, 323, 507, 627, 85664, 25, 763, 5587, 220, 11908, 22, 10928, 574, 16689, 264, 37946, 315, 279, 16591, 13581, 323, 304, 220, 10005, 23, 6244, 264, 7362, 4562, 315, 279, 16591, 31209, 16192, 315, 23199, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "567", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) just(O) need(O) to(O) find(O) the(O) closest(B-Location) diner(B-Cuisine) to(O) pick(O) up(O) some(O) quick(B-Amenity) cheap(B-Price) breakfast(B-Hours)", "instance": {"id": "567", "words": ["i", "just", "need", "to", "find", "the", "closest", "diner", "to", "pick", "up", "some", "quick", "cheap", "breakfast"], "labels": ["O", "O", "O", "O", "O", "O", "B-Location", "B-Cuisine", "O", "O", "O", "O", "O", "B-Price", "B-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Price, Rating, Dish, Restaurant Name, Hours, Location, Amenity and O.\nSentence: i just need to find the closest diner to pick up some quick cheap breakfast", "prompt_labels": "i(O) just(O) need(O) to(O) find(O) the(O) closest(B-Location) diner(B-Cuisine) to(O) pick(O) up(O) some(O) quick(O) cheap(B-Price) breakfast(B-Hours)"}, "label_list": ["Cuisine", "Price", "Rating", "Dish", "Restaurant Name", "Hours", "Location", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 8650, 11, 19767, 11, 49268, 11, 26568, 4076, 11, 30192, 11, 10067, 11, 3383, 56685, 323, 507, 627, 85664, 25, 602, 1120, 1205, 311, 1505, 279, 18585, 89206, 311, 3820, 709, 1063, 4062, 12136, 17954, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2373", "dataset": "mit-movie", "split": "dev", "prediction": "name(O) a(O) sci(B-genre) fi(I-genre) about(O) a(O) human(B-plot)", "instance": {"id": "2373", "words": ["name", "a", "sci", "fi", "about", "a", "human"], "labels": ["O", "O", "B-genre", "I-genre", "O", "O", "B-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, genre, plot, title, song, year, actor, character, review, average ratings, trailer, director and O.\nSentence: name a sci fi about a human", "prompt_labels": "name(O) a(O) sci(B-genre) fi(I-genre) about(O) a(O) human(B-plot)"}, "label_list": ["rating", "genre", "plot", "title", "song", "year", "actor", "character", "review", "average ratings", "trailer", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 17779, 11, 7234, 11, 2316, 11, 5609, 11, 1060, 11, 12360, 11, 3752, 11, 3477, 11, 5578, 18594, 11, 19809, 11, 7690, 323, 507, 627, 85664, 25, 836, 264, 39074, 9314, 922, 264, 3823, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "490", "dataset": "crossner_politics", "split": "dev", "prediction": "Held(O) during(O) the(O) escalation(O) of(O) United(B-country) States(I-country) involvement(O) of(O) the(O) Vietnam(B-event) War(I-event),(O) the(O) race(O) was(O) between(O) Republican(O) candidate(O) and(O) incumbent(O) Governor(O) of(O) Oregon(O) Mark(B-politician) Hatfield(I-politician),(O) who(O) opposed(O) the(O) war(O),(O) and(O) Democratic(O) congressman(O) Robert(B-politician) B.(I-politician) Duncan(I-politician),(O) who(O) supported(O) the(O) war(O).(O)", "instance": {"id": "490", "words": ["Held", "during", "the", "escalation", "of", "United", "States", "involvement", "of", "the", "Vietnam", "War", ",", "the", "race", "was", "between", "Republican", "candidate", "and", "incumbent", "Governor", "of", "Oregon", "Mark", "Hatfield", ",", "who", "opposed", "the", "war", ",", "and", "Democratic", "congressman", "Robert", "B.", "Duncan", ",", "who", "supported", "the", "war", "."], "labels": ["O", "O", "O", "O", "O", "B-country", "I-country", "O", "O", "O", "B-event", "I-event", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "B-politician", "I-politician", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-politician", "I-politician", "I-politician", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, country, event, politician, person, organization, location, election and O.\nSentence: Held during the escalation of United States involvement of the Vietnam War , the race was between Republican candidate and incumbent Governor of Oregon Mark Hatfield , who opposed the war , and Democratic congressman Robert B. Duncan , who supported the war .", "prompt_labels": "Held(O) during(O) the(O) escalation(O) of(O) United(B-country) States(I-country) involvement(O) of(O) the(O) Vietnam(B-event) War(I-event) ,(O) the(O) race(O) was(O) between(O) Republican(O) candidate(O) and(O) incumbent(O) Governor(O) of(O) Oregon(B-location) Mark(B-politician) Hatfield(I-politician) ,(O) who(O) opposed(O) the(O) war(O) ,(O) and(O) Democratic(O) congressman(O) Robert(B-politician) B.(I-politician) Duncan(I-politician) ,(O) who(O) supported(O) the(O) war(O) .(O)"}, "label_list": ["political party", "country", "event", "politician", "person", "organization", "location", "election"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5054, 4717, 11, 3224, 11, 1567, 11, 37038, 11, 1732, 11, 7471, 11, 3813, 11, 6355, 323, 507, 627, 85664, 25, 83531, 2391, 279, 71389, 315, 3723, 4273, 22315, 315, 279, 23315, 5111, 1174, 279, 7102, 574, 1990, 9540, 9322, 323, 51382, 24245, 315, 19313, 4488, 22050, 2630, 1174, 889, 16475, 279, 4208, 1174, 323, 11650, 74588, 8563, 426, 13, 42409, 1174, 889, 7396, 279, 4208, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "802", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) movie(O) has(O) the(O) highest(B-review) viewers(O) rating(O)", "instance": {"id": "802", "words": ["what", "movie", "has", "the", "highest", "viewers", "rating"], "labels": ["O", "O", "O", "O", "B-average ratings", "I-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, song, genre, review, average ratings, character, director, rating, year, actor, title, trailer and O.\nSentence: what movie has the highest viewers rating", "prompt_labels": "what(O) movie(O) has(O) the(O) highest(B-average ratings) viewers(I-average ratings) rating(I-average ratings)"}, "label_list": ["plot", "song", "genre", "review", "average ratings", "character", "director", "rating", "year", "actor", "title", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 5609, 11, 17779, 11, 3477, 11, 5578, 18594, 11, 3752, 11, 7690, 11, 10959, 11, 1060, 11, 12360, 11, 2316, 11, 19809, 323, 507, 627, 85664, 25, 1148, 5818, 706, 279, 8592, 22511, 10959, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "216", "dataset": "crossner_politics", "split": "dev", "prediction": "Hence(O),(O) Nixon(B-politician)'s(O) five(O) appearances(O) on(O) his(O) party(O)'s(O) ticket(O) matched(O) the(O) major-party(O) American(O) standard(O) of(O) Franklin(B-politician) D.(I-politician) Roosevelt(I-politician),(O) a(O) Democrat(O) who(O) had(O) been(O) nominated(O) for(O) vice(O) president(O) once(O) ((O) in(O) 1920(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) )(O) and(O) president(O) four(O) times(O) ((O) in(O) 1932(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election),(O) 1936(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election),(O) 1940(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) and(O) 1944(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) )(O).(O)", "instance": {"id": "216", "words": ["Hence", ",", "Nixon", "'s", "five", "appearances", "on", "his", "party", "'s", "ticket", "matched", "the", "major-party", "American", "standard", "of", "Franklin", "D.", "Roosevelt", ",", "a", "Democrat", "who", "had", "been", "nominated", "for", "vice", "president", "once", "(", "in", "1920", "United", "States", "presidential", "election", ")", "and", "president", "four", "times", "(", "in", "1932", "United", "States", "presidential", "election", ",", "1936", "United", "States", "presidential", "election", ",", "1940", "United", "States", "presidential", "election", "and", "1944", "United", "States", "presidential", "election", ")", "."], "labels": ["O", "O", "B-politician", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-politician", "I-politician", "I-politician", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, event, country, politician, location, organization, political party, election and O.\nSentence: Hence , Nixon 's five appearances on his party 's ticket matched the major-party American standard of Franklin D. Roosevelt , a Democrat who had been nominated for vice president once ( in 1920 United States presidential election ) and president four times ( in 1932 United States presidential election , 1936 United States presidential election , 1940 United States presidential election and 1944 United States presidential election ) .", "prompt_labels": "Hence(O) ,(O) Nixon(B-politician) 's(O) five(O) appearances(O) on(O) his(O) party(O) 's(O) ticket(O) matched(O) the(O) major-party(O) American(O) standard(O) of(O) Franklin(B-politician) D.(I-politician) Roosevelt(I-politician) ,(O) a(O) Democrat(O) who(O) had(O) been(O) nominated(O) for(O) vice(O) president(O) once(O) ((O) in(O) 1920(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) )(O) and(O) president(O) four(O) times(O) ((O) in(O) 1932(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ,(O) 1936(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ,(O) 1940(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) and(O) 1944(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) )(O) .(O)"}, "label_list": ["person", "event", "country", "politician", "location", "organization", "political party", "election"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 1567, 11, 3224, 11, 37038, 11, 3813, 11, 7471, 11, 5054, 4717, 11, 6355, 323, 507, 627, 85664, 25, 32140, 1174, 42726, 364, 82, 4330, 27351, 389, 813, 4717, 364, 82, 11989, 18545, 279, 3682, 24993, 3778, 5410, 315, 19372, 423, 13, 47042, 1174, 264, 24846, 889, 1047, 1027, 39048, 369, 17192, 4872, 3131, 320, 304, 220, 5926, 15, 3723, 4273, 13621, 6355, 883, 323, 4872, 3116, 3115, 320, 304, 220, 7285, 17, 3723, 4273, 13621, 6355, 1174, 220, 7285, 21, 3723, 4273, 13621, 6355, 1174, 220, 6393, 15, 3723, 4273, 13621, 6355, 323, 220, 6393, 19, 3723, 4273, 13621, 6355, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "128", "dataset": "crossner_politics", "split": "dev", "prediction": "The(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) of(I-political party) Canada(I-political party) government(O) of(O) the(O) time(O),(O) headed(O) by(O) Prime(O) Minister(O) John(B-politician) Diefenbaker(I-politician),(O) did(O) not(O) accept(O) the(O) invitation(O) to(O) establish(O) a(O) new(O) Canadian(O) flag(O),(O) so(O) Pearson(B-politician) made(O) it(O) Liberal(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) policy(O) in(O) 1961(O),(O) and(O) part(O) of(O) the(O) party(O)'s(O) election(O) platform(O) in(O) the(O) 1962(B-election) Canadian(I-election) federal(I-election) election(I-election) and(O) 1963(B-election) Canadian(I-election) federal(I-election) election(I-election).(O)", "instance": {"id": "128", "words": ["The", "Progressive", "Conservative", "Party", "of", "Canada", "government", "of", "the", "time", ",", "headed", "by", "Prime", "Minister", "John", "Diefenbaker", ",", "did", "not", "accept", "the", "invitation", "to", "establish", "a", "new", "Canadian", "flag", ",", "so", "Pearson", "made", "it", "Liberal", "Party", "of", "Canada", "policy", "in", "1961", ",", "and", "part", "of", "the", "party", "'s", "election", "platform", "in", "the", "1962", "Canadian", "federal", "election", "and", "1963", "Canadian", "federal", "election", "."], "labels": ["O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-politician", "I-politician", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-politician", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, politician, country, organization, person, location, election, event and O.\nSentence: The Progressive Conservative Party of Canada government of the time , headed by Prime Minister John Diefenbaker , did not accept the invitation to establish a new Canadian flag , so Pearson made it Liberal Party of Canada policy in 1961 , and part of the party 's election platform in the 1962 Canadian federal election and 1963 Canadian federal election .", "prompt_labels": "The(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) of(I-political party) Canada(I-political party) government(O) of(O) the(O) time(O) ,(O) headed(O) by(O) Prime(O) Minister(O) John(B-politician) Diefenbaker(I-politician) ,(O) did(O) not(O) accept(O) the(O) invitation(O) to(O) establish(O) a(O) new(O) Canadian(O) flag(O) ,(O) so(O) Pearson(B-politician) made(O) it(O) Liberal(B-political party) Party(I-political party) of(I-political party) Canada(I-political party) policy(O) in(O) 1961(O) ,(O) and(O) part(O) of(O) the(O) party(O) 's(O) election(O) platform(O) in(O) the(O) 1962(B-election) Canadian(I-election) federal(I-election) election(I-election) and(O) 1963(B-election) Canadian(I-election) federal(I-election) election(I-election) .(O)"}, "label_list": ["political party", "politician", "country", "organization", "person", "location", "election", "event"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5054, 4717, 11, 37038, 11, 3224, 11, 7471, 11, 1732, 11, 3813, 11, 6355, 11, 1567, 323, 507, 627, 85664, 25, 578, 52870, 30071, 8722, 315, 7008, 3109, 315, 279, 892, 1174, 19946, 555, 12801, 9675, 3842, 423, 4843, 268, 65, 4506, 1174, 1550, 539, 4287, 279, 29788, 311, 5813, 264, 502, 12152, 5292, 1174, 779, 59642, 1903, 433, 31158, 8722, 315, 7008, 4947, 304, 220, 5162, 16, 1174, 323, 961, 315, 279, 4717, 364, 82, 6355, 5452, 304, 279, 220, 5162, 17, 12152, 6918, 6355, 323, 220, 5162, 18, 12152, 6918, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "613", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) really(O) feel(O) like(O) seafood(B-Cuisine) right(O) now(O) whats(O) close(B-Location)", "instance": {"id": "613", "words": ["i", "really", "feel", "like", "seafood", "right", "now", "whats", "close"], "labels": ["O", "O", "O", "O", "B-Cuisine", "O", "O", "O", "B-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Dish, Location, Restaurant Name, Rating, Hours, Price, Amenity and O.\nSentence: i really feel like seafood right now whats close", "prompt_labels": "i(O) really(O) feel(O) like(O) seafood(B-Cuisine) right(O) now(O) whats(O) close(B-Location)"}, "label_list": ["Cuisine", "Dish", "Location", "Restaurant Name", "Rating", "Hours", "Price", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 49268, 11, 10067, 11, 26568, 4076, 11, 19767, 11, 30192, 11, 8650, 11, 3383, 56685, 323, 507, 627, 85664, 25, 602, 2216, 2733, 1093, 53405, 1314, 1457, 41209, 3345, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "287", "dataset": "crossner_ai", "split": "dev", "prediction": "The(O) Roberts(B-algorithm) cross(I-algorithm) operator(I-algorithm) is(O) used(O) in(O) image(B-field) processing(I-field) and(O) computer(B-field) vision(I-field) for(O) edge(B-task) detection(I-task).(O)", "instance": {"id": "287", "words": ["The", "Roberts", "cross", "operator", "is", "used", "in", "image", "processing", "and", "computer", "vision", "for", "edge", "detection", "."], "labels": ["O", "B-algorithm", "I-algorithm", "I-algorithm", "O", "O", "O", "B-field", "I-field", "O", "B-field", "I-field", "O", "B-task", "I-task", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, organization, country, conference, task, product, algorithm, programming language, field, researcher, metric, university, location and O.\nSentence: The Roberts cross operator is used in image processing and computer vision for edge detection .", "prompt_labels": "The(O) Roberts(B-algorithm) cross(I-algorithm) operator(I-algorithm) is(O) used(O) in(O) image(B-field) processing(I-field) and(O) computer(B-field) vision(I-field) for(O) edge(B-task) detection(I-task) .(O)"}, "label_list": ["person", "organization", "country", "conference", "task", "product", "algorithm", "programming language", "field", "researcher", "metric", "university", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 7471, 11, 3224, 11, 10017, 11, 3465, 11, 2027, 11, 12384, 11, 15840, 4221, 11, 2115, 11, 32185, 11, 18767, 11, 12374, 11, 3813, 323, 507, 627, 85664, 25, 578, 31248, 5425, 5793, 374, 1511, 304, 2217, 8863, 323, 6500, 11376, 369, 6964, 18468, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "227", "dataset": "mit-restaurant", "split": "dev", "prediction": "diner(B-Cuisine) locations(O)", "instance": {"id": "227", "words": ["diner", "locations"], "labels": ["B-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Hours, Dish, Amenity, Rating, Price, Restaurant Name, Location and O.\nSentence: diner locations", "prompt_labels": "diner(B-Cuisine) locations(O)"}, "label_list": ["Cuisine", "Hours", "Dish", "Amenity", "Rating", "Price", "Restaurant Name", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 30192, 11, 49268, 11, 3383, 56685, 11, 19767, 11, 8650, 11, 26568, 4076, 11, 10067, 323, 507, 627, 85664, 25, 89206, 10687, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "564", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) movie(O) step(B-title) up(I-title) rated(B-average ratings)", "instance": {"id": "564", "words": ["what", "is", "the", "movie", "step", "up", "rated"], "labels": ["O", "O", "O", "O", "B-title", "I-title", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, title, average ratings, year, director, song, actor, character, genre, plot, trailer, review and O.\nSentence: what is the movie step up rated", "prompt_labels": "what(O) is(O) the(O) movie(O) step(B-title) up(I-title) rated(O)"}, "label_list": ["rating", "title", "average ratings", "year", "director", "song", "actor", "character", "genre", "plot", "trailer", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 2316, 11, 5578, 18594, 11, 1060, 11, 7690, 11, 5609, 11, 12360, 11, 3752, 11, 17779, 11, 7234, 11, 19809, 11, 3477, 323, 507, 627, 85664, 25, 1148, 374, 279, 5818, 3094, 709, 22359, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "83", "dataset": "crossner_ai", "split": "dev", "prediction": "She(O) has(O) held(O) the(O) positions(O) of(O) President(O),(O) Vice(O) President(O),(O) and(O) Secretary-Treasurer(O) of(O) the(O) Association(B-conference) for(I-conference) Computational(I-conference) Linguistics(I-conference) and(O) has(O) been(O) a(O) board(O) member(O) and(O) secretary(O) of(O) the(O) Computing(B-organization) Research(I-organization) Association(I-organization).(O)", "instance": {"id": "83", "words": ["She", "has", "held", "the", "positions", "of", "President", ",", "Vice", "President", ",", "and", "Secretary-Treasurer", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "has", "been", "a", "board", "member", "and", "secretary", "of", "the", "board", "of", "the", "Computing", "Research", "Association", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-conference", "I-conference", "I-conference", "I-conference", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, university, location, conference, algorithm, person, task, field, product, metric, organization, country, programming language and O.\nSentence: She has held the positions of President , Vice President , and Secretary-Treasurer of the Association for Computational Linguistics and has been a board member and secretary of the board of the Computing Research Association .", "prompt_labels": "She(O) has(O) held(O) the(O) positions(O) of(O) President(O) ,(O) Vice(O) President(O) ,(O) and(O) Secretary-Treasurer(O) of(O) the(O) Association(B-conference) for(I-conference) Computational(I-conference) Linguistics(I-conference) and(O) has(O) been(O) a(O) board(O) member(O) and(O) secretary(O) of(O) the(O) board(O) of(O) the(O) Computing(B-organization) Research(I-organization) Association(I-organization) .(O)"}, "label_list": ["researcher", "university", "location", "conference", "algorithm", "person", "task", "field", "product", "metric", "organization", "country", "programming language"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 32185, 11, 12374, 11, 3813, 11, 10017, 11, 12384, 11, 1732, 11, 3465, 11, 2115, 11, 2027, 11, 18767, 11, 7471, 11, 3224, 11, 15840, 4221, 323, 507, 627, 85664, 25, 3005, 706, 5762, 279, 10093, 315, 4900, 1174, 23270, 4900, 1174, 323, 12667, 9469, 51518, 7889, 315, 279, 10229, 369, 93028, 89333, 5706, 323, 706, 1027, 264, 4580, 4562, 323, 19607, 315, 279, 4580, 315, 279, 46879, 8483, 10229, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "939", "dataset": "mit-restaurant", "split": "dev", "prediction": "lets(O) go(O) get(O) a(O) taco(B-Dish)", "instance": {"id": "939", "words": ["lets", "go", "get", "a", "taco"], "labels": ["O", "O", "O", "O", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Cuisine, Price, Amenity, Rating, Hours, Dish, Location and O.\nSentence: lets go get a taco", "prompt_labels": "lets(O) go(O) get(O) a(O) taco(B-Dish)"}, "label_list": ["Restaurant Name", "Cuisine", "Price", "Amenity", "Rating", "Hours", "Dish", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 81961, 11, 8650, 11, 3383, 56685, 11, 19767, 11, 30192, 11, 49268, 11, 10067, 323, 507, 627, 85664, 25, 15714, 733, 636, 264, 91941, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2375", "dataset": "mit-movie", "split": "dev", "prediction": "name(O) a(O) teen(B-genre) movie(O) with(O) steve(B-actor) mcqueen(I-actor) that(O) was(O) received(B-average ratings) well(I-average ratings)", "instance": {"id": "2375", "words": ["name", "a", "teen", "movie", "with", "steve", "mcqueen", "that", "was", "received", "well"], "labels": ["O", "O", "B-genre", "O", "O", "B-actor", "I-actor", "O", "O", "B-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, title, review, actor, trailer, character, plot, director, genre, rating, average ratings, year and O.\nSentence: name a teen movie with steve mcqueen that was received well", "prompt_labels": "name(O) a(O) teen(B-genre) movie(O) with(O) steve(B-actor) mcqueen(I-actor) that(O) was(O) received(B-average ratings) well(I-average ratings)"}, "label_list": ["song", "title", "review", "actor", "trailer", "character", "plot", "director", "genre", "rating", "average ratings", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 2316, 11, 3477, 11, 12360, 11, 19809, 11, 3752, 11, 7234, 11, 7690, 11, 17779, 11, 10959, 11, 5578, 18594, 11, 1060, 323, 507, 627, 85664, 25, 836, 264, 9562, 5818, 449, 4179, 588, 19777, 94214, 430, 574, 4036, 1664, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1977", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) hellhounds(B-title) about(O)", "instance": {"id": "1977", "words": ["what", "is", "hellhounds", "about"], "labels": ["O", "O", "B-title", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, song, plot, rating, trailer, review, average ratings, year, title, director, genre, actor and O.\nSentence: what is hellhounds about", "prompt_labels": "what(O) is(O) hellhounds(B-title) about(O)"}, "label_list": ["character", "song", "plot", "rating", "trailer", "review", "average ratings", "year", "title", "director", "genre", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 5609, 11, 7234, 11, 10959, 11, 19809, 11, 3477, 11, 5578, 18594, 11, 1060, 11, 2316, 11, 7690, 11, 17779, 11, 12360, 323, 507, 627, 85664, 25, 1148, 374, 15123, 71, 3171, 922, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "638", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) want(O) some(O) taco(B-Restaurant Name) bell(I-Restaurant Name)", "instance": {"id": "638", "words": ["i", "want", "some", "taco", "bell"], "labels": ["O", "O", "O", "B-Restaurant Name", "I-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Restaurant Name, Location, Price, Cuisine, Amenity, Hours, Dish and O.\nSentence: i want some taco bell", "prompt_labels": "i(O) want(O) some(O) taco(B-Restaurant Name) bell(I-Restaurant Name)"}, "label_list": ["Rating", "Restaurant Name", "Location", "Price", "Cuisine", "Amenity", "Hours", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 26568, 4076, 11, 10067, 11, 8650, 11, 81961, 11, 3383, 56685, 11, 30192, 11, 49268, 323, 507, 627, 85664, 25, 602, 1390, 1063, 91941, 29519, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1539", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) there(O) a(O) spaghetti(B-genre) western(I-genre) about(O) a(O) sheriff(B-plot) with(O) an(O) average(B-average ratings) rating(O)", "instance": {"id": "1539", "words": ["is", "there", "a", "spaghetti", "western", "about", "a", "sheriff", "with", "an", "average", "rating"], "labels": ["O", "O", "O", "B-genre", "I-genre", "O", "O", "B-plot", "O", "O", "B-average ratings", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, plot, character, trailer, rating, review, director, song, genre, title, year, average ratings and O.\nSentence: is there a spaghetti western about a sheriff with an average rating", "prompt_labels": "is(O) there(O) a(O) spaghetti(B-genre) western(I-genre) about(O) a(O) sheriff(B-plot) with(O) an(O) average(B-average ratings) rating(O)"}, "label_list": ["actor", "plot", "character", "trailer", "rating", "review", "director", "song", "genre", "title", "year", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 7234, 11, 3752, 11, 19809, 11, 10959, 11, 3477, 11, 7690, 11, 5609, 11, 17779, 11, 2316, 11, 1060, 11, 5578, 18594, 323, 507, 627, 85664, 25, 374, 1070, 264, 88010, 19001, 922, 264, 40839, 449, 459, 5578, 10959, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2336", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) stars(O) in(O) world(B-title) for(I-title) ransom(I-title)", "instance": {"id": "2336", "words": ["who", "stars", "in", "world", "for", "ransom"], "labels": ["O", "O", "O", "B-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, review, year, rating, song, plot, trailer, director, average ratings, title, character, genre and O.\nSentence: who stars in world for ransom", "prompt_labels": "who(O) stars(O) in(O) world(B-title) for(I-title) ransom(I-title)"}, "label_list": ["actor", "review", "year", "rating", "song", "plot", "trailer", "director", "average ratings", "title", "character", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 3477, 11, 1060, 11, 10959, 11, 5609, 11, 7234, 11, 19809, 11, 7690, 11, 5578, 18594, 11, 2316, 11, 3752, 11, 17779, 323, 507, 627, 85664, 25, 889, 9958, 304, 1917, 369, 58686, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "356", "dataset": "mit-restaurant", "split": "dev", "prediction": "find(O) me(O) a(O) 3(B-Rating) star(I-Rating) rated(I-Rating) burger(B-Cuisine) restaurant(O) within(B-Location) 10(I-Location) miles(I-Location)", "instance": {"id": "356", "words": ["find", "me", "a", "3", "star", "rated", "burger", "restaurant", "within", "10", "miles"], "labels": ["O", "O", "O", "B-Rating", "I-Rating", "I-Rating", "B-Dish", "I-Dish", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Location, Cuisine, Restaurant Name, Amenity, Dish, Rating, Price and O.\nSentence: find me a 3 star rated burger restaurant within 10 miles", "prompt_labels": "find(O) me(O) a(O) 3(B-Rating) star(I-Rating) rated(I-Rating) burger(B-Dish) restaurant(I-Dish) within(B-Location) 10(I-Location) miles(I-Location)"}, "label_list": ["Hours", "Location", "Cuisine", "Restaurant Name", "Amenity", "Dish", "Rating", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 10067, 11, 81961, 11, 26568, 4076, 11, 3383, 56685, 11, 49268, 11, 19767, 11, 8650, 323, 507, 627, 85664, 25, 1505, 757, 264, 220, 18, 6917, 22359, 45723, 10960, 2949, 220, 605, 8931, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "571", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) need(O) a(O) cheap(B-Price) restaurant(O) for(O) brunch(B-Hours)", "instance": {"id": "571", "words": ["i", "need", "a", "cheap", "restaurant", "for", "brunch"], "labels": ["O", "O", "O", "B-Price", "O", "O", "B-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Price, Restaurant Name, Rating, Dish, Cuisine, Hours, Location and O.\nSentence: i need a cheap restaurant for brunch", "prompt_labels": "i(O) need(O) a(O) cheap(B-Price) restaurant(O) for(O) brunch(B-Hours)"}, "label_list": ["Amenity", "Price", "Restaurant Name", "Rating", "Dish", "Cuisine", "Hours", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 8650, 11, 26568, 4076, 11, 19767, 11, 49268, 11, 81961, 11, 30192, 11, 10067, 323, 507, 627, 85664, 25, 602, 1205, 264, 12136, 10960, 369, 70917, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1124", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) is(O) the(O) closest(B-Location) bar(B-Restaurant Name) near(I-Restaurant Name) heidis(I-Restaurant Name) restaurant(I-Restaurant Name)", "instance": {"id": "1124", "words": ["what", "is", "the", "closest", "bar", "near", "heidis", "restaurant"], "labels": ["O", "O", "O", "B-Location", "O", "O", "B-Restaurant Name", "I-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Price, Cuisine, Rating, Dish, Hours, Location, Restaurant Name and O.\nSentence: what is the closest bar near heidis restaurant", "prompt_labels": "what(O) is(O) the(O) closest(B-Location) bar(O) near(O) heidis(B-Restaurant Name) restaurant(I-Restaurant Name)"}, "label_list": ["Amenity", "Price", "Cuisine", "Rating", "Dish", "Hours", "Location", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 8650, 11, 81961, 11, 19767, 11, 49268, 11, 30192, 11, 10067, 11, 26568, 4076, 323, 507, 627, 85664, 25, 1148, 374, 279, 18585, 3703, 3221, 568, 85342, 10960, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1811", "dataset": "mit-movie", "split": "dev", "prediction": "was(O) there(O) a(O) highly(B-average ratings) recommended(I-average ratings) romance(B-genre) released(O) in(O) the(O) 1960(B-year) s(I-year)", "instance": {"id": "1811", "words": ["was", "there", "a", "highly", "recommended", "romance", "released", "in", "the", "1960", "s"], "labels": ["O", "O", "O", "B-average ratings", "I-average ratings", "B-genre", "O", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, director, rating, plot, song, year, genre, title, average ratings, actor, character, trailer and O.\nSentence: was there a highly recommended romance released in the 1960 s", "prompt_labels": "was(O) there(O) a(O) highly(B-average ratings) recommended(I-average ratings) romance(B-genre) released(O) in(O) the(O) 1960(B-year) s(I-year)"}, "label_list": ["review", "director", "rating", "plot", "song", "year", "genre", "title", "average ratings", "actor", "character", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 7690, 11, 10959, 11, 7234, 11, 5609, 11, 1060, 11, 17779, 11, 2316, 11, 5578, 18594, 11, 12360, 11, 3752, 11, 19809, 323, 507, 627, 85664, 25, 574, 1070, 264, 7701, 11349, 30363, 6004, 304, 279, 220, 5162, 15, 274, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1701", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) the(O) g(B-rating) rated(O) films(O) with(O) susan(B-actor) hargrove(I-actor) from(O) the(O) 1960(B-year) s(I-year)", "instance": {"id": "1701", "words": ["list", "the", "g", "rated", "films", "with", "susan", "hargrove", "from", "the", "1960", "s"], "labels": ["O", "O", "B-rating", "O", "O", "O", "B-actor", "I-actor", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, trailer, director, plot, year, title, song, actor, genre, rating, character, average ratings and O.\nSentence: list the g rated films with susan hargrove from the 1960 s", "prompt_labels": "list(O) the(O) g(B-rating) rated(O) films(O) with(O) susan(B-actor) hargrove(I-actor) from(O) the(O) 1960(B-year) s(I-year)"}, "label_list": ["review", "trailer", "director", "plot", "year", "title", "song", "actor", "genre", "rating", "character", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 19809, 11, 7690, 11, 7234, 11, 1060, 11, 2316, 11, 5609, 11, 12360, 11, 17779, 11, 10959, 11, 3752, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1160, 279, 342, 22359, 12631, 449, 4582, 276, 305, 867, 51515, 505, 279, 220, 5162, 15, 274, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1742", "dataset": "mit-movie", "split": "dev", "prediction": "name(O) the(O) 1940(B-year) s(I-year) military(B-genre) movie(O) by(O) directory(O) florian(B-director) baxmeyer(I-director) with(O) a(O) government(B-plot) assassin(I-plot) plot(O)", "instance": {"id": "1742", "words": ["name", "the", "1940", "s", "military", "movie", "by", "directory", "florian", "baxmeyer", "with", "a", "government", "assassin", "plot"], "labels": ["O", "O", "B-year", "I-year", "B-genre", "O", "O", "O", "B-director", "I-director", "O", "O", "B-plot", "I-plot", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, plot, character, title, review, average ratings, song, rating, actor, director, trailer, year and O.\nSentence: name the 1940 s military movie by directory florian baxmeyer with a government assassin plot", "prompt_labels": "name(O) the(O) 1940(B-year) s(I-year) military(B-genre) movie(O) by(O) directory(O) florian(B-director) baxmeyer(I-director) with(O) a(O) government(B-plot) assassin(I-plot) plot(O)"}, "label_list": ["genre", "plot", "character", "title", "review", "average ratings", "song", "rating", "actor", "director", "trailer", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 7234, 11, 3752, 11, 2316, 11, 3477, 11, 5578, 18594, 11, 5609, 11, 10959, 11, 12360, 11, 7690, 11, 19809, 11, 1060, 323, 507, 627, 85664, 25, 836, 279, 220, 6393, 15, 274, 6411, 5818, 555, 6352, 1344, 22865, 293, 710, 76, 35472, 449, 264, 3109, 68769, 7234, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1324", "dataset": "mit-movie", "split": "dev", "prediction": "i(O) want(O) to(O) find(O) a(O) 2010(B-year) movie(O) that(O) was(O) directed(O) by(O) alek(B-director) keshishian(I-director) with(O) the(O) plot(O) being(O) about(O) striking(B-plot) it(I-plot) rich(I-plot)", "instance": {"id": "1324", "words": ["i", "want", "to", "find", "a", "2010", "movie", "that", "was", "directed", "by", "alek", "keshishian", "with", "the", "plot", "being", "about", "striking", "it", "rich"], "labels": ["O", "O", "O", "O", "O", "B-year", "O", "O", "O", "O", "O", "B-director", "I-director", "O", "O", "O", "O", "O", "B-plot", "I-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, review, title, trailer, actor, plot, song, character, rating, genre, year, director and O.\nSentence: i want to find a 2010 movie that was directed by alek keshishian with the plot being about striking it rich", "prompt_labels": "i(O) want(O) to(O) find(O) a(O) 2010(B-year) movie(O) that(O) was(O) directed(O) by(O) alek(B-director) keshishian(I-director) with(O) the(O) plot(O) being(O) about(O) striking(B-plot) it(I-plot) rich(I-plot)"}, "label_list": ["average ratings", "review", "title", "trailer", "actor", "plot", "song", "character", "rating", "genre", "year", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 3477, 11, 2316, 11, 19809, 11, 12360, 11, 7234, 11, 5609, 11, 3752, 11, 10959, 11, 17779, 11, 1060, 11, 7690, 323, 507, 627, 85664, 25, 602, 1390, 311, 1505, 264, 220, 679, 15, 5818, 430, 574, 15910, 555, 22180, 74, 597, 4385, 819, 1122, 449, 279, 7234, 1694, 922, 21933, 433, 9257, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "234", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) horror(B-genre) movies(I-genre) have(O) snakes(B-plot)", "instance": {"id": "234", "words": ["what", "horror", "movies", "have", "snakes"], "labels": ["O", "B-genre", "O", "O", "B-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, character, actor, average ratings, genre, director, rating, song, trailer, year, plot, title and O.\nSentence: what horror movies have snakes", "prompt_labels": "what(O) horror(B-genre) movies(O) have(O) snakes(B-plot)"}, "label_list": ["review", "character", "actor", "average ratings", "genre", "director", "rating", "song", "trailer", "year", "plot", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 3752, 11, 12360, 11, 5578, 18594, 11, 17779, 11, 7690, 11, 10959, 11, 5609, 11, 19809, 11, 1060, 11, 7234, 11, 2316, 323, 507, 627, 85664, 25, 1148, 22169, 9698, 617, 57196, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1495", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) there(O) a(O) good(O) scary(B-genre) movie(O) that(O) is(O) rated(O) pg(B-rating) 13(I-rating) about(O) extrasensory(B-plot) perception(I-plot)", "instance": {"id": "1495", "words": ["is", "there", "a", "good", "scary", "movie", "that", "is", "rated", "pg", "13", "about", "extrasensory", "perception"], "labels": ["O", "O", "O", "O", "B-genre", "O", "O", "O", "O", "B-rating", "I-rating", "O", "B-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, review, genre, year, title, trailer, song, actor, average ratings, director, plot, character and O.\nSentence: is there a good scary movie that is rated pg 13 about extrasensory perception", "prompt_labels": "is(O) there(O) a(O) good(O) scary(B-genre) movie(O) that(O) is(O) rated(O) pg(B-rating) 13(I-rating) about(O) extrasensory(B-plot) perception(I-plot)"}, "label_list": ["rating", "review", "genre", "year", "title", "trailer", "song", "actor", "average ratings", "director", "plot", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 3477, 11, 17779, 11, 1060, 11, 2316, 11, 19809, 11, 5609, 11, 12360, 11, 5578, 18594, 11, 7690, 11, 7234, 11, 3752, 323, 507, 627, 85664, 25, 374, 1070, 264, 1695, 29565, 5818, 430, 374, 22359, 17953, 220, 1032, 922, 37375, 729, 683, 21063, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "703", "dataset": "mit-restaurant", "split": "dev", "prediction": "id(O) like(O) a(O) coffee(B-Cuisine) shop(O) that(O) serves(O) pie(B-Dish)", "instance": {"id": "703", "words": ["id", "like", "a", "coffee", "shop", "that", "serves", "pie"], "labels": ["O", "O", "O", "B-Cuisine", "O", "O", "O", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Amenity, Location, Hours, Restaurant Name, Dish, Cuisine, Rating and O.\nSentence: id like a coffee shop that serves pie", "prompt_labels": "id(O) like(O) a(O) coffee(B-Cuisine) shop(O) that(O) serves(O) pie(B-Dish)"}, "label_list": ["Price", "Amenity", "Location", "Hours", "Restaurant Name", "Dish", "Cuisine", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 3383, 56685, 11, 10067, 11, 30192, 11, 26568, 4076, 11, 49268, 11, 81961, 11, 19767, 323, 507, 627, 85664, 25, 887, 1093, 264, 11033, 8221, 430, 17482, 4447, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1677", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) an(O) unrated(B-rating) adventure(B-genre) from(O) the(O) past(B-year) ten(I-year) decades(I-year)", "instance": {"id": "1677", "words": ["list", "an", "unrated", "adventure", "from", "the", "past", "ten", "decades"], "labels": ["O", "O", "B-rating", "B-genre", "O", "O", "B-year", "I-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, song, actor, genre, title, trailer, year, character, average ratings, plot, review, rating and O.\nSentence: list an unrated adventure from the past ten decades", "prompt_labels": "list(O) an(O) unrated(B-rating) adventure(B-genre) from(O) the(O) past(B-year) ten(I-year) decades(I-year)"}, "label_list": ["director", "song", "actor", "genre", "title", "trailer", "year", "character", "average ratings", "plot", "review", "rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 5609, 11, 12360, 11, 17779, 11, 2316, 11, 19809, 11, 1060, 11, 3752, 11, 5578, 18594, 11, 7234, 11, 3477, 11, 10959, 323, 507, 627, 85664, 25, 1160, 459, 41480, 660, 18427, 505, 279, 3347, 5899, 11026, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "247", "dataset": "crossner_politics", "split": "dev", "prediction": "The(O) historic(O) county(O) boundaries(O) continue(O) to(O) be(O) used(O) as(O) the(O) basis(O) for(O) organisations(O) such(O) as(O) the(O) Duchy(B-organization) of(I-organization) Lancaster(I-organization),(O) Lancashire(B-organization) County(I-organization) Cricket(I-organization) Club(I-organization) and(O) Lancashire(B-organization) County(I-organization) Football(I-organization) Association(I-organization) ((O) although(O) its(O) area(O) overlaps(O) with(O) the(O) Liverpool(B-organization) County(I-organization) Football(I-organization) Association(I-organization) and(O) Manchester(B-organization) Football(I-organization) Association(I-organization) s(O),(O) both(O) of(O) which(O) predate(O) their(O) corresponding(O) metropolitan(O) counties(O) )(O).(O)", "instance": {"id": "247", "words": ["The", "historic", "county", "boundaries", "continue", "to", "be", "used", "as", "the", "basis", "for", "organisations", "such", "as", "the", "Duchy", "of", "Lancaster", ",", "Lancashire", "County", "Cricket", "Club", "and", "Lancashire", "County", "Football", "Association", "(", "although", "its", "area", "overlaps", "with", "the", "Liverpool", "County", "Football", "Association", "and", "Manchester", "Football", "Association", "s", ",", "both", "of", "which", "predate", "their", "corresponding", "metropolitan", "counties", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, organization, country, location, person, election, event, politician and O.\nSentence: The historic county boundaries continue to be used as the basis for organisations such as the Duchy of Lancaster , Lancashire County Cricket Club and Lancashire County Football Association ( although its area overlaps with the Liverpool County Football Association and Manchester Football Association s , both of which predate their corresponding metropolitan counties ) .", "prompt_labels": "The(O) historic(O) county(O) boundaries(O) continue(O) to(O) be(O) used(O) as(O) the(O) basis(O) for(O) organisations(O) such(O) as(O) the(O) Duchy(B-organization) of(I-organization) Lancaster(I-organization) ,(O) Lancashire(B-organization) County(I-organization) Cricket(I-organization) Club(I-organization) and(O) Lancashire(B-organization) County(I-organization) Football(I-organization) Association(I-organization) ((O) although(O) its(O) area(O) overlaps(O) with(O) the(O) Liverpool(B-organization) County(I-organization) Football(I-organization) Association(I-organization) and(O) Manchester(B-organization) Football(I-organization) Association(I-organization) s(O) ,(O) both(O) of(O) which(O) predate(O) their(O) corresponding(O) metropolitan(O) counties(O) )(O) .(O)"}, "label_list": ["political party", "organization", "country", "location", "person", "election", "event", "politician"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5054, 4717, 11, 7471, 11, 3224, 11, 3813, 11, 1732, 11, 6355, 11, 1567, 11, 37038, 323, 507, 627, 85664, 25, 578, 18526, 14189, 23546, 3136, 311, 387, 1511, 439, 279, 8197, 369, 29533, 1778, 439, 279, 61122, 88, 315, 66223, 1174, 39634, 97414, 6406, 59019, 10349, 323, 39634, 97414, 6406, 21424, 10229, 320, 8051, 1202, 3158, 77107, 449, 279, 25715, 6406, 21424, 10229, 323, 19922, 21424, 10229, 274, 1174, 2225, 315, 902, 864, 1045, 872, 12435, 58506, 31276, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "271", "dataset": "crossner_science", "split": "dev", "prediction": "The(O) mass(O) of(O) Thetis(B-astronomical object) has(O) been(O) calculated(O) from(O) perturbations(O) by(O) 4(O) Vesta(B-astronomical object) and(O) 11(O) Parthenope(B-astronomical object).(O)", "instance": {"id": "271", "words": ["The", "mass", "of", "Thetis", "has", "been", "calculated", "from", "perturbations", "by", "4", "Vesta", "and", "11", "Parthenope", "."], "labels": ["O", "O", "O", "B-astronomical object", "O", "O", "O", "O", "O", "O", "B-astronomical object", "I-astronomical object", "O", "B-astronomical object", "I-astronomical object", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, enzyme, award, organization, academic journal, astronomical object, theory, country, scientist, protein, chemical compound, university, chemical element, location, event, discipline and O.\nSentence: The mass of Thetis has been calculated from perturbations by 4 Vesta and 11 Parthenope .", "prompt_labels": "The(O) mass(O) of(O) Thetis(B-astronomical object) has(O) been(O) calculated(O) from(O) perturbations(O) by(O) 4(B-astronomical object) Vesta(I-astronomical object) and(O) 11(B-astronomical object) Parthenope(I-astronomical object) .(O)"}, "label_list": ["person", "enzyme", "award", "organization", "academic journal", "astronomical object", "theory", "country", "scientist", "protein", "chemical compound", "university", "chemical element", "location", "event", "discipline"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 49242, 11, 10292, 11, 7471, 11, 14584, 8486, 11, 87283, 1665, 11, 10334, 11, 3224, 11, 28568, 11, 13128, 11, 11742, 24549, 11, 12374, 11, 11742, 2449, 11, 3813, 11, 1567, 11, 26434, 323, 507, 627, 85664, 25, 578, 3148, 315, 666, 295, 285, 706, 1027, 16997, 505, 18713, 9225, 811, 555, 220, 19, 650, 30279, 323, 220, 806, 4366, 3473, 2862, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "185", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) played(O) as(O) princess(B-character) fiona(I-character) in(O) shrek(B-title)", "instance": {"id": "185", "words": ["who", "played", "as", "princess", "fiona", "in", "shrek"], "labels": ["O", "O", "O", "B-character", "I-character", "O", "B-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, song, year, rating, character, director, title, trailer, plot, average ratings, actor, genre and O.\nSentence: who played as princess fiona in shrek", "prompt_labels": "who(O) played(O) as(O) princess(B-character) fiona(I-character) in(O) shrek(B-title)"}, "label_list": ["review", "song", "year", "rating", "character", "director", "title", "trailer", "plot", "average ratings", "actor", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 5609, 11, 1060, 11, 10959, 11, 3752, 11, 7690, 11, 2316, 11, 19809, 11, 7234, 11, 5578, 18594, 11, 12360, 11, 17779, 323, 507, 627, 85664, 25, 889, 6476, 439, 40688, 282, 42790, 304, 559, 42961, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "393", "dataset": "crossner_science", "split": "dev", "prediction": "The(O) RCS(B-university) and(O) the(O) Royal(B-university) School(I-university) of(I-university) Mines(I-university) subsequently(O) merged(O) in(O) 1907(O) with(O) the(O) City(B-university) and(I-university) Guilds(I-university) Central(I-university) Technical(I-university) College(I-university) to(O) form(O) the(O) Imperial(B-university) College(I-university) of(I-university) Science(I-university) and(I-university) Technology(I-university),(O) each(O) continuing(O) as(O) a(O) Constituent(O) College(O) of(O) Imperial(B-university),(O) which(O) then(O) joined(O) the(O) University(B-university) of(I-university) London(I-university) in(O) 1929(O).(O)", "instance": {"id": "393", "words": ["The", "RCS", "and", "the", "Royal", "School", "of", "Mines", "subsequently", "merged", "in", "1907", "with", "the", "City", "and", "Guilds", "Central", "Technical", "College", "to", "form", "the", "Imperial", "College", "of", "Science", "and", "Technology", ",", "each", "continuing", "as", "a", "Constituent", "College", "of", "Imperial", ",", "which", "then", "joined", "the", "University", "of", "London", "in", "1929", "."], "labels": ["O", "B-university", "O", "O", "B-university", "I-university", "I-university", "I-university", "O", "O", "O", "O", "O", "O", "B-university", "I-university", "I-university", "I-university", "I-university", "I-university", "O", "O", "O", "B-university", "I-university", "I-university", "I-university", "I-university", "I-university", "O", "O", "O", "O", "O", "B-university", "I-university", "I-university", "I-university", "O", "O", "O", "O", "O", "B-university", "I-university", "I-university", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, award, country, theory, academic journal, scientist, person, astronomical object, chemical element, protein, discipline, organization, enzyme, university, location, chemical compound and O.\nSentence: The RCS and the Royal School of Mines subsequently merged in 1907 with the City and Guilds Central Technical College to form the Imperial College of Science and Technology , each continuing as a Constituent College of Imperial , which then joined the University of London in 1929 .", "prompt_labels": "The(O) RCS(B-university) and(O) the(O) Royal(B-university) School(I-university) of(I-university) Mines(I-university) subsequently(O) merged(O) in(O) 1907(O) with(O) the(O) City(B-university) and(I-university) Guilds(I-university) Central(I-university) Technical(I-university) College(I-university) to(O) form(O) the(O) Imperial(B-university) College(I-university) of(I-university) Science(I-university) and(I-university) Technology(I-university) ,(O) each(O) continuing(O) as(O) a(O) Constituent(B-university) College(I-university) of(I-university) Imperial(I-university) ,(O) which(O) then(O) joined(O) the(O) University(B-university) of(I-university) London(I-university) in(O) 1929(O) .(O)"}, "label_list": ["event", "award", "country", "theory", "academic journal", "scientist", "person", "astronomical object", "chemical element", "protein", "discipline", "organization", "enzyme", "university", "location", "chemical compound"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 10292, 11, 3224, 11, 10334, 11, 14584, 8486, 11, 28568, 11, 1732, 11, 87283, 1665, 11, 11742, 2449, 11, 13128, 11, 26434, 11, 7471, 11, 49242, 11, 12374, 11, 3813, 11, 11742, 24549, 323, 507, 627, 85664, 25, 578, 80256, 323, 279, 16591, 6150, 315, 66882, 28520, 27092, 304, 220, 7028, 22, 449, 279, 4409, 323, 33592, 82, 10913, 27766, 9304, 311, 1376, 279, 31013, 9304, 315, 10170, 323, 12053, 1174, 1855, 14691, 439, 264, 76704, 11942, 9304, 315, 31013, 1174, 902, 1243, 11096, 279, 3907, 315, 7295, 304, 220, 5926, 24, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "343", "dataset": "crossner_politics", "split": "dev", "prediction": "In(O) 1800(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election),(O) 1828(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election),(O) 1840(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) and(O) 1892(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election),(O) the(O) victorious(O) candidate(O) had(O) lost(O) to(O) the(O) same(O) opponent(O) in(O) the(O) previous(O) election(O).(O)", "instance": {"id": "343", "words": ["In", "1800", "United", "States", "presidential", "election", ",", "1828", "United", "States", "presidential", "election", ",", "1840", "United", "States", "presidential", "election", "and", "1892", "United", "States", "presidential", "election", ",", "the", "victorious", "candidate", "had", "lost", "to", "the", "same", "opponent", "in", "the", "previous", "election", "."], "labels": ["O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, country, politician, person, election, location, event, organization and O.\nSentence: In 1800 United States presidential election , 1828 United States presidential election , 1840 United States presidential election and 1892 United States presidential election , the victorious candidate had lost to the same opponent in the previous election .", "prompt_labels": "In(O) 1800(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ,(O) 1828(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ,(O) 1840(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) and(O) 1892(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ,(O) the(O) victorious(O) candidate(O) had(O) lost(O) to(O) the(O) same(O) opponent(O) in(O) the(O) previous(O) election(O) .(O)"}, "label_list": ["political party", "country", "politician", "person", "election", "location", "event", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5054, 4717, 11, 3224, 11, 37038, 11, 1732, 11, 6355, 11, 3813, 11, 1567, 11, 7471, 323, 507, 627, 85664, 25, 763, 220, 5245, 15, 3723, 4273, 13621, 6355, 1174, 220, 10828, 23, 3723, 4273, 13621, 6355, 1174, 220, 10336, 15, 3723, 4273, 13621, 6355, 323, 220, 9378, 17, 3723, 4273, 13621, 6355, 1174, 279, 74810, 9322, 1047, 5675, 311, 279, 1890, 15046, 304, 279, 3766, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "520", "dataset": "mit-restaurant", "split": "dev", "prediction": "how(O) far(O) to(O) the(O) nearest(B-Location) fast(B-Cuisine) food(I-Cuisine)", "instance": {"id": "520", "words": ["how", "far", "to", "the", "nearest", "fast", "food"], "labels": ["O", "O", "O", "O", "O", "B-Cuisine", "I-Cuisine"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Cuisine, Location, Rating, Hours, Price, Amenity, Restaurant Name and O.\nSentence: how far to the nearest fast food", "prompt_labels": "how(O) far(O) to(O) the(O) nearest(O) fast(B-Cuisine) food(I-Cuisine)"}, "label_list": ["Dish", "Cuisine", "Location", "Rating", "Hours", "Price", "Amenity", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 81961, 11, 10067, 11, 19767, 11, 30192, 11, 8650, 11, 3383, 56685, 11, 26568, 4076, 323, 507, 627, 85664, 25, 1268, 3117, 311, 279, 24379, 5043, 3691, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "667", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) want(O) to(O) get(O) some(O) chinese(B-Cuisine) food(O)", "instance": {"id": "667", "words": ["i", "want", "to", "get", "some", "chinese", "food"], "labels": ["O", "O", "O", "O", "O", "B-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Location, Rating, Dish, Cuisine, Restaurant Name, Amenity, Price and O.\nSentence: i want to get some chinese food", "prompt_labels": "i(O) want(O) to(O) get(O) some(O) chinese(B-Cuisine) food(O)"}, "label_list": ["Hours", "Location", "Rating", "Dish", "Cuisine", "Restaurant Name", "Amenity", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 10067, 11, 19767, 11, 49268, 11, 81961, 11, 26568, 4076, 11, 3383, 56685, 11, 8650, 323, 507, 627, 85664, 25, 602, 1390, 311, 636, 1063, 57487, 3691, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1805", "dataset": "mit-movie", "split": "dev", "prediction": "was(O) samuel(B-actor) l(I-actor) jackson(I-actor) in(O) any(O) crime(B-genre) movies(O) in(O) the(O) 1960(B-year) s(I-year) when(O) he(O) was(O) a(O) child(B-plot)", "instance": {"id": "1805", "words": ["was", "samuel", "l", "jackson", "in", "any", "crime", "movies", "in", "the", "1960", "s", "when", "he", "was", "a", "child"], "labels": ["O", "B-actor", "I-actor", "I-actor", "O", "O", "B-genre", "O", "O", "O", "B-year", "I-year", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, trailer, rating, average ratings, year, actor, plot, review, character, song, director, title and O.\nSentence: was samuel l jackson in any crime movies in the 1960 s when he was a child", "prompt_labels": "was(O) samuel(B-actor) l(I-actor) jackson(I-actor) in(O) any(O) crime(B-genre) movies(O) in(O) the(O) 1960(B-year) s(I-year) when(O) he(O) was(O) a(O) child(O)"}, "label_list": ["genre", "trailer", "rating", "average ratings", "year", "actor", "plot", "review", "character", "song", "director", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 19809, 11, 10959, 11, 5578, 18594, 11, 1060, 11, 12360, 11, 7234, 11, 3477, 11, 3752, 11, 5609, 11, 7690, 11, 2316, 323, 507, 627, 85664, 25, 574, 10167, 4088, 326, 503, 19950, 304, 904, 9977, 9698, 304, 279, 220, 5162, 15, 274, 994, 568, 574, 264, 1716, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "931", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) films(O) stars(O) both(O) nicole(B-actor) kidman(I-actor) and(O) will(B-actor) ferrell(I-actor)", "instance": {"id": "931", "words": ["what", "films", "stars", "both", "nicole", "kidman", "and", "will", "ferrell"], "labels": ["O", "O", "O", "O", "B-actor", "I-actor", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, character, average ratings, review, plot, song, rating, genre, director, title, year, actor and O.\nSentence: what films stars both nicole kidman and will ferrell", "prompt_labels": "what(O) films(O) stars(O) both(O) nicole(B-actor) kidman(I-actor) and(O) will(B-actor) ferrell(I-actor)"}, "label_list": ["trailer", "character", "average ratings", "review", "plot", "song", "rating", "genre", "director", "title", "year", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 3752, 11, 5578, 18594, 11, 3477, 11, 7234, 11, 5609, 11, 10959, 11, 17779, 11, 7690, 11, 2316, 11, 1060, 11, 12360, 323, 507, 627, 85664, 25, 1148, 12631, 9958, 2225, 17778, 1286, 10585, 1543, 323, 690, 18728, 16684, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "150", "dataset": "mit-restaurant", "split": "dev", "prediction": "can(O) you(O) find(O) east(B-Restaurant Name) dedham(I-Restaurant Name) pizzeria(I-Restaurant Name) that(O) have(O) a(O) dine(B-Amenity) at(I-Amenity) bar(I-Amenity) location(O)", "instance": {"id": "150", "words": ["can", "you", "find", "east", "dedham", "pizzeria", "that", "have", "a", "dine", "at", "bar", "location"], "labels": ["O", "O", "O", "B-Restaurant Name", "B-Location", "B-Cuisine", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Dish, Restaurant Name, Hours, Amenity, Price, Location, Cuisine and O.\nSentence: can you find east dedham pizzeria that have a dine at bar location", "prompt_labels": "can(O) you(O) find(O) east(B-Restaurant Name) dedham(B-Location) pizzeria(B-Cuisine) that(O) have(O) a(O) dine(O) at(O) bar(O) location(O)"}, "label_list": ["Rating", "Dish", "Restaurant Name", "Hours", "Amenity", "Price", "Location", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 49268, 11, 26568, 4076, 11, 30192, 11, 3383, 56685, 11, 8650, 11, 10067, 11, 81961, 323, 507, 627, 85664, 25, 649, 499, 1505, 11226, 7836, 5721, 281, 94429, 689, 430, 617, 264, 66207, 520, 3703, 3813, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "15", "dataset": "crossner_science", "split": "dev", "prediction": "For(O) example(O),(O) that(O) ancestor(O) had(O) at(O) least(O) 7(O) Pax(B-protein) genes(O) for(O) transcription(O) factor(O) s(O).(O)", "instance": {"id": "15", "words": ["For", "example", ",", "that", "ancestor", "had", "at", "least", "7", "Pax", "genes", "for", "transcription", "factor", "s", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, chemical compound, event, person, organization, chemical element, location, scientist, university, protein, academic journal, astronomical object, country, discipline, enzyme, theory and O.\nSentence: For example , that ancestor had at least 7 Pax genes for transcription factor s .", "prompt_labels": "For(O) example(O) ,(O) that(O) ancestor(O) had(O) at(O) least(O) 7(O) Pax(O) genes(O) for(O) transcription(O) factor(O) s(O) .(O)"}, "label_list": ["award", "chemical compound", "event", "person", "organization", "chemical element", "location", "scientist", "university", "protein", "academic journal", "astronomical object", "country", "discipline", "enzyme", "theory"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10292, 11, 11742, 24549, 11, 1567, 11, 1732, 11, 7471, 11, 11742, 2449, 11, 3813, 11, 28568, 11, 12374, 11, 13128, 11, 14584, 8486, 11, 87283, 1665, 11, 3224, 11, 26434, 11, 49242, 11, 10334, 323, 507, 627, 85664, 25, 1789, 3187, 1174, 430, 46831, 1047, 520, 3325, 220, 22, 71421, 21389, 369, 46940, 8331, 274, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1008", "dataset": "mit-restaurant", "split": "dev", "prediction": "name(O) the(O) local(B-Location) buffets(B-Amenity)", "instance": {"id": "1008", "words": ["name", "the", "local", "buffets"], "labels": ["O", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Rating, Restaurant Name, Price, Hours, Location, Dish, Amenity and O.\nSentence: name the local buffets", "prompt_labels": "name(O) the(O) local(B-Location) buffets(I-Location)"}, "label_list": ["Cuisine", "Rating", "Restaurant Name", "Price", "Hours", "Location", "Dish", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 19767, 11, 26568, 4076, 11, 8650, 11, 30192, 11, 10067, 11, 49268, 11, 3383, 56685, 323, 507, 627, 85664, 25, 836, 279, 2254, 11783, 1441, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2424", "dataset": "mit-movie", "split": "dev", "prediction": "pulp(B-title) fiction(I-title)", "instance": {"id": "2424", "words": ["pulp", "fiction"], "labels": ["B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, actor, title, song, character, average ratings, trailer, year, plot, review, genre, director and O.\nSentence: pulp fiction", "prompt_labels": "pulp(B-title) fiction(I-title)"}, "label_list": ["rating", "actor", "title", "song", "character", "average ratings", "trailer", "year", "plot", "review", "genre", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 12360, 11, 2316, 11, 5609, 11, 3752, 11, 5578, 18594, 11, 19809, 11, 1060, 11, 7234, 11, 3477, 11, 17779, 11, 7690, 323, 507, 627, 85664, 25, 64188, 17422, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "396", "dataset": "crossner_literature", "split": "dev", "prediction": "From(O) 1949(O) to(O) 1953(O),(O) Clement(B-writer)'s(O) first(O) three(O) novels(B-literary genre) were(O) two-part(O) Astounding(O) serials(O) under(O) Campbell(O) :(O) Needle(O) ((O) Doubleday(B-magazine),(O) 1950(O) )(O),(O) Iceworld(O) ((O) Gnome(B-magazine) Press(I-magazine),(O) 1953(O) )(O),(O) and(O) Mission(B-book) of(I-book) Gravity(I-book) ((O) 1954(O) )(O),(O) his(O) best-known(O) novel(B-literary genre),(O) published(O) by(O) Doubleday(B-magazine)'s(O) Science(B-organization) Fiction(I-organization) Book(I-organization) Club(I-organization) ((O) established(O) 1953(O) )(O).(O)", "instance": {"id": "396", "words": ["From", "1949", "to", "1953", ",", "Clement", "'s", "first", "three", "novels", "were", "two-", ",", "three-", ",", "and", "four-part", "Astounding", "serials", "under", "Campbell", ":", "Needle", "(", "Doubleday", ",", "1950", ")", ",", "Iceworld", "(", "Gnome", "Press", ",", "1953", ")", ",", "and", "Mission", "of", "Gravity", "(", "1954", ")", ",", "his", "best-known", "novel", ",", "published", "by", "Doubleday", "'s", "Science", "Fiction", "Book", "Club", "(", "established", "1953", ")", "."], "labels": ["O", "O", "O", "O", "O", "B-writer", "O", "O", "O", "B-literary genre", "O", "O", "O", "O", "O", "O", "O", "B-book", "O", "O", "B-writer", "O", "B-book", "O", "B-organization", "O", "O", "O", "O", "B-book", "O", "B-organization", "I-organization", "O", "O", "O", "O", "O", "B-book", "I-book", "I-book", "O", "O", "O", "O", "O", "O", "B-literary genre", "O", "O", "O", "B-organization", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: poem, writer, location, organization, event, award, literary genre, magazine, country, book, person and O.\nSentence: From 1949 to 1953 , Clement 's first three novels were two- , three- , and four-part Astounding serials under Campbell : Needle ( Doubleday , 1950 ) , Iceworld ( Gnome Press , 1953 ) , and Mission of Gravity ( 1954 ) , his best-known novel , published by Doubleday 's Science Fiction Book Club ( established 1953 ) .", "prompt_labels": "From(O) 1949(O) to(O) 1953(O) ,(O) Clement(B-writer) 's(O) first(O) three(O) novels(B-literary genre) were(O) two-(O) ,(O) three-(O) ,(O) and(O) four-part(O) Astounding(B-book) serials(O) under(O) Campbell(B-writer) :(O) Needle(B-book) ((O) Doubleday(B-organization) ,(O) 1950(O) )(O) ,(O) Iceworld(B-book) ((O) Gnome(B-organization) Press(I-organization) ,(O) 1953(O) )(O) ,(O) and(O) Mission(B-book) of(I-book) Gravity(I-book) ((O) 1954(O) )(O) ,(O) his(O) best-known(O) novel(B-literary genre) ,(O) published(O) by(O) Doubleday(B-organization) 's(O) Science(B-organization) Fiction(I-organization) Book(I-organization) Club(I-organization) ((O) established(O) 1953(O) )(O) .(O)"}, "label_list": ["poem", "writer", "location", "organization", "event", "award", "literary genre", "magazine", "country", "book", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 33894, 11, 7061, 11, 3813, 11, 7471, 11, 1567, 11, 10292, 11, 32465, 17779, 11, 14756, 11, 3224, 11, 2363, 11, 1732, 323, 507, 627, 85664, 25, 5659, 220, 6393, 24, 311, 220, 6280, 18, 1174, 53227, 364, 82, 1176, 2380, 32963, 1051, 1403, 12, 1174, 2380, 12, 1174, 323, 3116, 29137, 20717, 13900, 6275, 82, 1234, 30524, 551, 89900, 320, 55964, 839, 352, 1174, 220, 6280, 15, 883, 1174, 20534, 14957, 320, 480, 17518, 8612, 1174, 220, 6280, 18, 883, 1174, 323, 24098, 315, 48590, 320, 220, 6280, 19, 883, 1174, 813, 1888, 22015, 11775, 1174, 4756, 555, 55964, 839, 352, 364, 82, 10170, 43754, 6017, 10349, 320, 9749, 220, 6280, 18, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "692", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) would(O) like(O) to(O) find(O) a(O) french(B-Cuisine) restaurant(O) that(O) is(O) rated(O) at(O) least(O) 4(B-Rating) stars(I-Rating)", "instance": {"id": "692", "words": ["i", "would", "like", "to", "find", "a", "french", "restaurant", "that", "is", "rated", "at", "least", "4", "stars"], "labels": ["O", "O", "O", "O", "O", "O", "B-Cuisine", "O", "O", "O", "B-Rating", "I-Rating", "I-Rating", "I-Rating", "I-Rating"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Rating, Price, Hours, Location, Amenity, Cuisine, Restaurant Name and O.\nSentence: i would like to find a french restaurant that is rated at least 4 stars", "prompt_labels": "i(O) would(O) like(O) to(O) find(O) a(O) french(B-Cuisine) restaurant(O) that(O) is(O) rated(B-Rating) at(I-Rating) least(I-Rating) 4(I-Rating) stars(I-Rating)"}, "label_list": ["Dish", "Rating", "Price", "Hours", "Location", "Amenity", "Cuisine", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 19767, 11, 8650, 11, 30192, 11, 10067, 11, 3383, 56685, 11, 81961, 11, 26568, 4076, 323, 507, 627, 85664, 25, 602, 1053, 1093, 311, 1505, 264, 42293, 10960, 430, 374, 22359, 520, 3325, 220, 19, 9958, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "172", "dataset": "crossner_science", "split": "dev", "prediction": "Instead(O),(O) for(O) the(O) UEFA(B-event) Euro(I-event) 2008(I-event) articles(O) ((O) UEFA(B-event) Euro(I-event) 2008(I-event),(O) UEFA(B-event) Euro(I-event) 2008(I-event) Group(I-event) A(I-event),(O) UEFA(B-event) Euro(I-event) 2008(I-event) Group(I-event) B(I-event),(O) UEFA(B-event) Euro(I-event) 2008(I-event) Group(I-event) C(I-event),(O) UEFA(B-event) Euro(I-event) 2008(I-event) Group(I-event) D(I-event) and(O) UEFA(B-event) Euro(I-event) 2008(I-event) knockout(O) stage(O) )(O),(O) the(O) old(O) partial(O) URL(O) string(O) ones(O) :(O)", "instance": {"id": "172", "words": ["Instead", ",", "for", "the", "UEFA", "Euro", "2008", "articles", "(", "UEFA", "Euro", "2008", ",", "UEFA", "Euro", "2008", "Group", "A", ",", "UEFA", "Euro", "2008", "Group", "B", ",", "UEFA", "Euro", "2008", "Group", "C", ",", "UEFA", "Euro", "2008", "Group", "D", "and", "UEFA", "Euro", "2008", "knockout", "stage", ")", ",", "the", "old", "partial", "URL", "string", "ones", ":"], "labels": ["O", "O", "O", "O", "B-event", "I-event", "I-event", "O", "O", "B-event", "I-event", "I-event", "O", "B-event", "I-event", "I-event", "O", "O", "O", "B-event", "I-event", "I-event", "O", "O", "O", "B-event", "I-event", "I-event", "O", "O", "O", "B-event", "I-event", "I-event", "O", "O", "O", "B-event", "I-event", "I-event", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: astronomical object, location, enzyme, organization, country, person, discipline, university, protein, academic journal, chemical compound, scientist, award, chemical element, event, theory and O.\nSentence: Instead , for the UEFA Euro 2008 articles ( UEFA Euro 2008 , UEFA Euro 2008 Group A , UEFA Euro 2008 Group B , UEFA Euro 2008 Group C , UEFA Euro 2008 Group D and UEFA Euro 2008 knockout stage ) , the old partial URL string ones :", "prompt_labels": "Instead(O) ,(O) for(O) the(O) UEFA(B-event) Euro(I-event) 2008(I-event) articles(O) ((O) UEFA(B-event) Euro(I-event) 2008(I-event) ,(O) UEFA(B-event) Euro(I-event) 2008(I-event) Group(O) A(O) ,(O) UEFA(B-event) Euro(I-event) 2008(I-event) Group(O) B(O) ,(O) UEFA(B-event) Euro(I-event) 2008(I-event) Group(O) C(O) ,(O) UEFA(B-event) Euro(I-event) 2008(I-event) Group(O) D(O) and(O) UEFA(B-event) Euro(I-event) 2008(I-event) knockout(O) stage(O) )(O) ,(O) the(O) old(O) partial(O) URL(O) string(O) ones(O) :(O)"}, "label_list": ["astronomical object", "location", "enzyme", "organization", "country", "person", "discipline", "university", "protein", "academic journal", "chemical compound", "scientist", "award", "chemical element", "event", "theory"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 87283, 1665, 11, 3813, 11, 49242, 11, 7471, 11, 3224, 11, 1732, 11, 26434, 11, 12374, 11, 13128, 11, 14584, 8486, 11, 11742, 24549, 11, 28568, 11, 10292, 11, 11742, 2449, 11, 1567, 11, 10334, 323, 507, 627, 85664, 25, 12361, 1174, 369, 279, 79815, 20026, 220, 1049, 23, 9908, 320, 79815, 20026, 220, 1049, 23, 1174, 79815, 20026, 220, 1049, 23, 5856, 362, 1174, 79815, 20026, 220, 1049, 23, 5856, 426, 1174, 79815, 20026, 220, 1049, 23, 5856, 356, 1174, 79815, 20026, 220, 1049, 23, 5856, 423, 323, 79815, 20026, 220, 1049, 23, 77173, 6566, 883, 1174, 279, 2362, 7276, 5665, 925, 6305, 551, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "61", "dataset": "crossner_music", "split": "dev", "prediction": "Other(O) top-10(O) entries(O) from(O) 2015(B-year) like(O) Mark(B-musical artist) Ronson(I-musical artist) '(O) s(O) disco(O) groove-infused(O) Uptown(B-album) Funk(I-album),(O) Maroon(B-musical artist) 5(I-musical artist) '(O) s(O) Sugar(B-album),(O) the(B-musical artist) Weeknd(I-musical artist) '(O) s(O) Can(B-album) 't(I-album) Feel(I-album) My(I-album) Face(I-album) and(O) Jason(B-musical artist) Derulo(I-musical artist) '(O) s(O) Want(B-album) to(I-album) Want(I-album) Me(I-album) also(O) ascended(O) the(O) charts(O) and(O) have(O) a(O) strong(O) disco(O) influence(O).(O)", "instance": {"id": "61", "words": ["Other", "top-10", "entries", "from", "2015", "like", "Mark", "Ronson", "'", "s", "disco", "groove-infused", "Uptown", "Funk", ",", "Maroon", "5", "'", "s", "Sugar", ",", "the", "Weeknd", "'", "s", "Can", "'t", "Feel", "My", "Face", "and", "Jason", "Derulo", "'", "s", "Want", "to", "Want", "Me", "also", "ascended", "the", "charts", "and", "have", "a", "strong", "disco", "influence", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-musical artist", "I-musical artist", "O", "O", "B-song", "I-song", "B-song", "I-song", "O", "B-band", "I-band", "O", "O", "B-song", "O", "B-band", "I-band", "O", "O", "B-song", "I-song", "I-song", "I-song", "I-song", "O", "B-musical artist", "I-musical artist", "O", "O", "B-song", "I-song", "I-song", "I-song", "O", "O", "O", "O", "O", "O", "O", "O", "B-music genre", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, band, organization, musical artist, album, music genre, musical instrument, event, person, country, award, location and O.\nSentence: Other top-10 entries from 2015 like Mark Ronson ' s disco groove-infused Uptown Funk , Maroon 5 ' s Sugar , the Weeknd ' s Can 't Feel My Face and Jason Derulo ' s Want to Want Me also ascended the charts and have a strong disco influence .", "prompt_labels": "Other(O) top-10(O) entries(O) from(O) 2015(O) like(O) Mark(B-musical artist) Ronson(I-musical artist) '(O) s(O) disco(B-song) groove-infused(I-song) Uptown(B-song) Funk(I-song) ,(O) Maroon(B-band) 5(I-band) '(O) s(O) Sugar(B-song) ,(O) the(B-band) Weeknd(I-band) '(O) s(O) Can(B-song) 't(I-song) Feel(I-song) My(I-song) Face(I-song) and(O) Jason(B-musical artist) Derulo(I-musical artist) '(O) s(O) Want(B-song) to(I-song) Want(I-song) Me(I-song) also(O) ascended(O) the(O) charts(O) and(O) have(O) a(O) strong(O) disco(B-music genre) influence(O) .(O)"}, "label_list": ["song", "band", "organization", "musical artist", "album", "music genre", "musical instrument", "event", "person", "country", "award", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 7200, 11, 7471, 11, 18273, 10255, 11, 8176, 11, 4731, 17779, 11, 18273, 14473, 11, 1567, 11, 1732, 11, 3224, 11, 10292, 11, 3813, 323, 507, 627, 85664, 25, 7089, 1948, 12, 605, 10925, 505, 220, 679, 20, 1093, 4488, 14662, 942, 364, 274, 54969, 57506, 48336, 2656, 549, 418, 785, 40710, 1174, 2947, 9186, 220, 20, 364, 274, 32019, 1174, 279, 10563, 303, 364, 274, 3053, 364, 83, 32833, 3092, 19109, 323, 18984, 13031, 8938, 364, 274, 24133, 311, 24133, 2206, 1101, 14943, 2954, 279, 27223, 323, 617, 264, 3831, 54969, 10383, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1302", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) can(O) i(O) find(O) the(O) closest(B-Location) bakery(B-Cuisine)", "instance": {"id": "1302", "words": ["where", "can", "i", "find", "the", "closest", "bakery"], "labels": ["O", "O", "O", "O", "O", "B-Location", "B-Cuisine"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Cuisine, Restaurant Name, Hours, Price, Dish, Location, Rating and O.\nSentence: where can i find the closest bakery", "prompt_labels": "where(O) can(O) i(O) find(O) the(O) closest(B-Location) bakery(B-Cuisine)"}, "label_list": ["Amenity", "Cuisine", "Restaurant Name", "Hours", "Price", "Dish", "Location", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 81961, 11, 26568, 4076, 11, 30192, 11, 8650, 11, 49268, 11, 10067, 11, 19767, 323, 507, 627, 85664, 25, 1405, 649, 602, 1505, 279, 18585, 66244, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "433", "dataset": "crossner_politics", "split": "dev", "prediction": "He(O) is(O) also(O) the(O) Harry(B-politician) Chandler(I-politician) &(amp; amp;) ;(O) Norman(B-politician) Chandler(I-politician) Professor(O) of(O) Communication(O) at(O) Stanford(B-organization),(O) the(O) director(O) of(O) Stanford(B-organization)'s(O) Political(B-organization) Communication(I-organization) Lab(I-organization),(O) and(O) a(O) senior(O) fellow(O) at(O) the(O) Hoover(B-organization) Institution(I-organization).(O)", "instance": {"id": "433", "words": ["He", "is", "also", "the", "Harry", "Chandler", "&", "amp", ";", "Norman", "Chandler", "Professor", "of", "Communication", "at", "Stanford", ",", "the", "director", "of", "Stanford", "'s", "Political", "Communication", "Lab", ",", "and", "a", "senior", "fellow", "at", "the", "Hoover", "Institution", "."], "labels": ["O", "O", "O", "O", "B-person", "I-person", "O", "O", "O", "B-person", "I-person", "O", "O", "O", "O", "B-organization", "O", "O", "O", "O", "B-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, person, organization, country, location, event, election, politician and O.\nSentence: He is also the Harry Chandler & amp ; Norman Chandler Professor of Communication at Stanford , the director of Stanford 's Political Communication Lab , and a senior fellow at the Hoover Institution .", "prompt_labels": "He(O) is(O) also(O) the(O) Harry(B-person) Chandler(I-person) &(O) amp(O) ;(O) Norman(B-person) Chandler(I-person) Professor(O) of(O) Communication(O) at(O) Stanford(B-organization) ,(O) the(O) director(O) of(O) Stanford(B-organization) 's(O) Political(O) Communication(O) Lab(O) ,(O) and(O) a(O) senior(O) fellow(O) at(O) the(O) Hoover(B-organization) Institution(I-organization) .(O)"}, "label_list": ["political party", "person", "organization", "country", "location", "event", "election", "politician"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5054, 4717, 11, 1732, 11, 7471, 11, 3224, 11, 3813, 11, 1567, 11, 6355, 11, 37038, 323, 507, 627, 85664, 25, 1283, 374, 1101, 279, 14253, 61448, 612, 23598, 2652, 41168, 61448, 17054, 315, 31966, 520, 31788, 1174, 279, 7690, 315, 31788, 364, 82, 31597, 31966, 11868, 1174, 323, 264, 10195, 12637, 520, 279, 73409, 43964, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1055", "dataset": "mit-movie", "split": "dev", "prediction": "a(O) 1990(B-year) rated(O) g(B-rating) film(O) that(O) has(O) actor(O) marcus(B-director) testory(I-director) in(O) it(O) that(O) received(O) a(O) nine(B-average ratings) rating(O) that(O) is(O) film(B-genre) noir(I-genre)", "instance": {"id": "1055", "words": ["a", "1990", "rated", "g", "film", "that", "has", "actor", "marcus", "testory", "in", "it", "that", "received", "a", "nine", "rating", "that", "is", "film", "noir"], "labels": ["O", "B-year", "O", "B-rating", "O", "O", "O", "O", "B-actor", "I-actor", "O", "O", "O", "O", "O", "B-average ratings", "O", "O", "O", "B-genre", "I-genre"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, trailer, director, song, genre, rating, review, title, character, year, plot, actor and O.\nSentence: a 1990 rated g film that has actor marcus testory in it that received a nine rating that is film noir", "prompt_labels": "a(O) 1990(B-year) rated(O) g(B-rating) film(O) that(O) has(O) actor(O) marcus(B-actor) testory(I-actor) in(O) it(O) that(O) received(O) a(O) nine(B-average ratings) rating(O) that(O) is(O) film(B-genre) noir(I-genre)"}, "label_list": ["average ratings", "trailer", "director", "song", "genre", "rating", "review", "title", "character", "year", "plot", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 19809, 11, 7690, 11, 5609, 11, 17779, 11, 10959, 11, 3477, 11, 2316, 11, 3752, 11, 1060, 11, 7234, 11, 12360, 323, 507, 627, 85664, 25, 264, 220, 2550, 15, 22359, 342, 4632, 430, 706, 12360, 3678, 57440, 1296, 683, 304, 433, 430, 4036, 264, 11888, 10959, 430, 374, 4632, 56662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "555", "dataset": "mit-restaurant", "split": "dev", "prediction": "i(O) am(O) looking(O) for(O) sandwhiches(B-Dish)", "instance": {"id": "555", "words": ["i", "am", "looking", "for", "sandwhiches"], "labels": ["O", "O", "O", "O", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Location, Hours, Price, Restaurant Name, Rating, Dish, Cuisine and O.\nSentence: i am looking for sandwhiches", "prompt_labels": "i(O) am(O) looking(O) for(O) sandwhiches(B-Dish)"}, "label_list": ["Amenity", "Location", "Hours", "Price", "Restaurant Name", "Rating", "Dish", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 10067, 11, 30192, 11, 8650, 11, 26568, 4076, 11, 19767, 11, 49268, 11, 81961, 323, 507, 627, 85664, 25, 602, 1097, 3411, 369, 9462, 8370, 288, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "374", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) any(O) movies(O) directed(O) by(O) steven(B-director) spielberg(I-director)", "instance": {"id": "374", "words": ["list", "any", "movies", "directed", "by", "steven", "spielberg"], "labels": ["O", "O", "O", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, title, director, song, genre, rating, plot, trailer, year, actor, review, character and O.\nSentence: list any movies directed by steven spielberg", "prompt_labels": "list(O) any(O) movies(O) directed(O) by(O) steven(B-director) spielberg(I-director)"}, "label_list": ["average ratings", "title", "director", "song", "genre", "rating", "plot", "trailer", "year", "actor", "review", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 2316, 11, 7690, 11, 5609, 11, 17779, 11, 10959, 11, 7234, 11, 19809, 11, 1060, 11, 12360, 11, 3477, 11, 3752, 323, 507, 627, 85664, 25, 1160, 904, 9698, 15910, 555, 4179, 1055, 79252, 7881, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2349", "dataset": "mit-movie", "split": "dev", "prediction": "did(O) the(B-title) shining(I-title) scare(O) charlize(B-actor) theron(I-actor) when(O) she(O) was(O) a(O) kid(O)", "instance": {"id": "2349", "words": ["did", "the", "shining", "scare", "charlize", "theron", "when", "she", "was", "a", "kid"], "labels": ["O", "B-title", "I-title", "O", "B-actor", "I-actor", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, trailer, plot, title, director, character, average ratings, actor, review, genre, year, song and O.\nSentence: did the shining scare charlize theron when she was a kid", "prompt_labels": "did(O) the(B-title) shining(I-title) scare(O) charlize(B-actor) theron(I-actor) when(O) she(O) was(O) a(O) kid(O)"}, "label_list": ["rating", "trailer", "plot", "title", "director", "character", "average ratings", "actor", "review", "genre", "year", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 19809, 11, 7234, 11, 2316, 11, 7690, 11, 3752, 11, 5578, 18594, 11, 12360, 11, 3477, 11, 17779, 11, 1060, 11, 5609, 323, 507, 627, 85664, 25, 1550, 279, 49025, 44030, 1181, 75, 553, 9139, 263, 994, 1364, 574, 264, 10585, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1737", "dataset": "mit-movie", "split": "dev", "prediction": "name(O) all(O) the(O) r(B-rating) rated(O) dramas(B-genre) that(O) had(O) a(O) rating(O) of(O) four(B-average ratings) stars(I-average ratings) that(O) starred(O) alberta(B-actor) watson(I-actor)", "instance": {"id": "1737", "words": ["name", "all", "the", "r", "rated", "dramas", "that", "had", "a", "rating", "of", "four", "stars", "that", "starred", "alberta", "watson"], "labels": ["O", "O", "O", "B-rating", "O", "B-genre", "O", "O", "O", "O", "O", "B-average ratings", "I-average ratings", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, year, trailer, rating, director, character, song, title, actor, review, average ratings, genre and O.\nSentence: name all the r rated dramas that had a rating of four stars that starred alberta watson", "prompt_labels": "name(O) all(O) the(O) r(B-rating) rated(O) dramas(B-genre) that(O) had(O) a(O) rating(O) of(O) four(B-average ratings) stars(I-average ratings) that(O) starred(O) alberta(B-actor) watson(I-actor)"}, "label_list": ["plot", "year", "trailer", "rating", "director", "character", "song", "title", "actor", "review", "average ratings", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 1060, 11, 19809, 11, 10959, 11, 7690, 11, 3752, 11, 5609, 11, 2316, 11, 12360, 11, 3477, 11, 5578, 18594, 11, 17779, 323, 507, 627, 85664, 25, 836, 682, 279, 436, 22359, 88826, 430, 1047, 264, 10959, 315, 3116, 9958, 430, 59335, 453, 9339, 64, 30125, 942, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "381", "dataset": "crossner_literature", "split": "dev", "prediction": "Diaries(O) had(O) been(O) written(O) by(O) men(O) in(O) Chinese(O) for(O) some(O) time(O),(O) but(O) in(O) the(O) early(O) tenth(O) century(O) Ki(B-writer) no(I-writer) Tsurayuki(I-writer) chose(O) to(O) write(O) his(O) Tosa(B-book) Nikki(I-book) from(O) the(O) standpoint(O) of(O) a(O) woman(O),(O) in(O) kana(O).(O)", "instance": {"id": "381", "words": ["Diaries", "had", "been", "written", "by", "men", "in", "Chinese", "for", "some", "time", ",", "but", "in", "the", "early", "tenth", "century", "Ki", "no", "Tsurayuki", "chose", "to", "write", "his", "Tosa", "Nikki", "from", "the", "standpoint", "of", "a", "woman", ",", "in", "kana", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-writer", "I-writer", "I-writer", "O", "O", "O", "O", "B-poem", "I-poem", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, location, magazine, writer, literary genre, book, event, country, person, award, poem and O.\nSentence: Diaries had been written by men in Chinese for some time , but in the early tenth century Ki no Tsurayuki chose to write his Tosa Nikki from the standpoint of a woman , in kana .", "prompt_labels": "Diaries(O) had(O) been(O) written(O) by(O) men(O) in(O) Chinese(O) for(O) some(O) time(O) ,(O) but(O) in(O) the(O) early(O) tenth(O) century(O) Ki(B-writer) no(I-writer) Tsurayuki(I-writer) chose(O) to(O) write(O) his(O) Tosa(B-poem) Nikki(I-poem) from(O) the(O) standpoint(O) of(O) a(O) woman(O) ,(O) in(O) kana(O) .(O)"}, "label_list": ["organization", "location", "magazine", "writer", "literary genre", "book", "event", "country", "person", "award", "poem"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 3813, 11, 14756, 11, 7061, 11, 32465, 17779, 11, 2363, 11, 1567, 11, 3224, 11, 1732, 11, 10292, 11, 33894, 323, 507, 627, 85664, 25, 7923, 5548, 1047, 1027, 5439, 555, 3026, 304, 8620, 369, 1063, 892, 1174, 719, 304, 279, 4216, 56766, 9478, 30558, 912, 350, 20370, 352, 22227, 14896, 311, 3350, 813, 350, 12252, 70207, 505, 279, 51882, 315, 264, 5333, 1174, 304, 597, 3444, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "511", "dataset": "crossner_politics", "split": "dev", "prediction": "Brimming(O) with(O) confidence(O) after(O) their(O) victories(O) over(O) the(O) Russians(O) in(O) 1711(O) ((O) Pruth(B-event) River(I-event) Campaign(I-event) )(O) and(O) over(O) the(O) Venetians(O) in(O) 1715(O) ((O) Ottoman-Venetian(B-event) War(I-event) ((O) 1714-1718(O) )(O),(O) the(O) Ottomans(O) declared(O) war(O) on(O) the(O) Habsburg(B-country) Monarchy(I-country) in(O) 1716(O) and(O) marched(O) north(O) from(O) Belgrade(O) in(O) July(O) under(O) the(O) command(O) of(O) Grand(O) Vizier(O) Silahdar(O) Damat(O) Ali(O) Pasha(O).(O)", "instance": {"id": "511", "words": ["Brimming", "with", "confidence", "after", "their", "victories", "over", "the", "Russians", "in", "1711", "(", "Pruth", "River", "Campaign", ")", "and", "over", "the", "Venetians", "in", "1715", "(", "Ottoman-Venetian", "War", "(", "1714-1718", ")", ")", ",", "the", "Ottomans", "declared", "war", "on", "the", "Habsburg", "Monarchy", "in", "1716", "and", "marched", "north", "from", "Belgrade", "in", "July", "under", "the", "command", "of", "Grand", "Vizier", "Silahdar", "Damat", "Ali", "Pasha", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "O", "O", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "O", "O", "O", "O", "O", "O", "B-politician", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "O", "O", "O", "O", "O", "O", "O", "O", "B-politician", "I-politician", "I-politician", "I-politician", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, political party, organization, election, location, event, politician, country and O.\nSentence: Brimming with confidence after their victories over the Russians in 1711 ( Pruth River Campaign ) and over the Venetians in 1715 ( Ottoman-Venetian War ( 1714-1718 ) ) , the Ottomans declared war on the Habsburg Monarchy in 1716 and marched north from Belgrade in July under the command of Grand Vizier Silahdar Damat Ali Pasha .", "prompt_labels": "Brimming(O) with(O) confidence(O) after(O) their(O) victories(O) over(O) the(O) Russians(O) in(O) 1711(O) ((O) Pruth(B-event) River(I-event) Campaign(I-event) )(O) and(O) over(O) the(O) Venetians(O) in(O) 1715(O) ((O) Ottoman-Venetian(B-event) War(I-event) ((O) 1714-1718(O) )(O) )(O) ,(O) the(O) Ottomans(B-politician) declared(O) war(O) on(O) the(O) Habsburg(O) Monarchy(O) in(O) 1716(O) and(O) marched(O) north(O) from(O) Belgrade(B-location) in(O) July(O) under(O) the(O) command(O) of(O) Grand(O) Vizier(O) Silahdar(B-politician) Damat(I-politician) Ali(I-politician) Pasha(I-politician) .(O)"}, "label_list": ["person", "political party", "organization", "election", "location", "event", "politician", "country"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 5054, 4717, 11, 7471, 11, 6355, 11, 3813, 11, 1567, 11, 37038, 11, 3224, 323, 507, 627, 85664, 25, 3320, 41133, 449, 12410, 1306, 872, 46146, 927, 279, 35066, 304, 220, 11123, 16, 320, 2394, 952, 11188, 27643, 883, 323, 927, 279, 18732, 295, 5493, 304, 220, 11123, 20, 320, 70110, 20198, 70436, 1122, 5111, 320, 220, 11123, 19, 12, 11123, 23, 883, 883, 1174, 279, 24881, 316, 598, 14610, 4208, 389, 279, 473, 3518, 10481, 3206, 15630, 304, 220, 11123, 21, 323, 59761, 10411, 505, 7984, 7082, 304, 5887, 1234, 279, 3290, 315, 10517, 650, 450, 1291, 8211, 1494, 35223, 16758, 266, 14925, 393, 31543, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "925", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) more(O) than(O) one(O) fatty(B-Cuisine) fish(I-Cuisine) restaurant(O) on(O) long(B-Location) island(I-Location)", "instance": {"id": "925", "words": ["is", "there", "more", "than", "one", "fatty", "fish", "restaurant", "on", "long", "island"], "labels": ["O", "O", "O", "O", "O", "B-Restaurant Name", "I-Restaurant Name", "O", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Cuisine, Amenity, Rating, Location, Dish, Price, Restaurant Name and O.\nSentence: is there more than one fatty fish restaurant on long island", "prompt_labels": "is(O) there(O) more(O) than(O) one(O) fatty(B-Restaurant Name) fish(I-Restaurant Name) restaurant(O) on(O) long(B-Location) island(I-Location)"}, "label_list": ["Hours", "Cuisine", "Amenity", "Rating", "Location", "Dish", "Price", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 81961, 11, 3383, 56685, 11, 19767, 11, 10067, 11, 49268, 11, 8650, 11, 26568, 4076, 323, 507, 627, 85664, 25, 374, 1070, 810, 1109, 832, 40085, 7795, 10960, 389, 1317, 13218, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "242", "dataset": "mit-movie", "split": "dev", "prediction": "how(O) many(O) movies(O) has(O) clint(B-director) eastwood(I-director) directed(O) since(O) 1995(B-year)", "instance": {"id": "242", "words": ["how", "many", "movies", "has", "clint", "eastwood", "directed", "since", "1995"], "labels": ["O", "O", "O", "O", "B-director", "I-director", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, average ratings, title, rating, song, year, character, trailer, genre, review, plot, director and O.\nSentence: how many movies has clint eastwood directed since 1995", "prompt_labels": "how(O) many(O) movies(O) has(O) clint(B-director) eastwood(I-director) directed(O) since(B-year) 1995(I-year)"}, "label_list": ["actor", "average ratings", "title", "rating", "song", "year", "character", "trailer", "genre", "review", "plot", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 5578, 18594, 11, 2316, 11, 10959, 11, 5609, 11, 1060, 11, 3752, 11, 19809, 11, 17779, 11, 3477, 11, 7234, 11, 7690, 323, 507, 627, 85664, 25, 1268, 1690, 9698, 706, 1206, 396, 11226, 6798, 15910, 2533, 220, 2550, 20, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1021", "dataset": "mit-restaurant", "split": "dev", "prediction": "please(O) find(O) italian(B-Cuisine) restaurants(O) that(O) are(O) child(B-Amenity) friendly(I-Amenity)", "instance": {"id": "1021", "words": ["please", "find", "italian", "restaurants", "that", "are", "child", "friendly"], "labels": ["O", "O", "B-Cuisine", "O", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Cuisine, Price, Hours, Rating, Dish, Restaurant Name, Location and O.\nSentence: please find italian restaurants that are child friendly", "prompt_labels": "please(O) find(O) italian(B-Cuisine) restaurants(O) that(O) are(O) child(B-Amenity) friendly(I-Amenity)"}, "label_list": ["Amenity", "Cuisine", "Price", "Hours", "Rating", "Dish", "Restaurant Name", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 81961, 11, 8650, 11, 30192, 11, 19767, 11, 49268, 11, 26568, 4076, 11, 10067, 323, 507, 627, 85664, 25, 4587, 1505, 29048, 15926, 430, 527, 1716, 11919, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "218", "dataset": "mit-movie", "split": "dev", "prediction": "todd(B-title)", "instance": {"id": "218", "words": ["todd"], "labels": ["B-character"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, review, rating, director, plot, year, title, actor, song, genre, character, average ratings and O.\nSentence: todd", "prompt_labels": "todd(B-character)"}, "label_list": ["trailer", "review", "rating", "director", "plot", "year", "title", "actor", "song", "genre", "character", "average ratings"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 3477, 11, 10959, 11, 7690, 11, 7234, 11, 1060, 11, 2316, 11, 12360, 11, 5609, 11, 17779, 11, 3752, 11, 5578, 18594, 323, 507, 627, 85664, 25, 39034, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "38", "dataset": "crossner_literature", "split": "dev", "prediction": "Marsters(B-person) moved(O) to(O) Chicago(B-location),(O) where(O) his(O) first(O) professional(O) acting(O) role(O) was(O) Ferdinand(B-character) in(O) The(B-book) Tempest(I-book) at(O) the(O) Goodman(B-location) Theatre(I-location) in(O) 1987(O).(O)", "instance": {"id": "38", "words": ["Marsters", "moved", "to", "Chicago", ",", "where", "his", "first", "professional", "acting", "role", "was", "Ferdinand", "in", "The", "Tempest", "at", "the", "Goodman", "Theatre", "in", "1987", "."], "labels": ["B-person", "O", "O", "B-location", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-book", "I-book", "O", "O", "B-location", "I-location", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, location, book, writer, country, literary genre, award, poem, organization, magazine, person and O.\nSentence: Marsters moved to Chicago , where his first professional acting role was Ferdinand in The Tempest at the Goodman Theatre in 1987 .", "prompt_labels": "Marsters(B-person) moved(O) to(O) Chicago(B-location) ,(O) where(O) his(O) first(O) professional(O) acting(O) role(O) was(O) Ferdinand(O) in(O) The(B-book) Tempest(I-book) at(O) the(O) Goodman(B-location) Theatre(I-location) in(O) 1987(O) .(O)"}, "label_list": ["event", "location", "book", "writer", "country", "literary genre", "award", "poem", "organization", "magazine", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 3813, 11, 2363, 11, 7061, 11, 3224, 11, 32465, 17779, 11, 10292, 11, 33894, 11, 7471, 11, 14756, 11, 1732, 323, 507, 627, 85664, 25, 2947, 12855, 7882, 311, 10780, 1174, 1405, 813, 1176, 6721, 15718, 3560, 574, 93607, 304, 578, 8817, 30223, 520, 279, 71492, 27315, 304, 220, 3753, 22, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "210", "dataset": "crossner_politics", "split": "dev", "prediction": "He(O) unsuccessfully(O) ran(O) as(O) a(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) of(I-political party) Ontario(I-political party) candidate(O) in(O) the(O) 1981(B-election) Ontario(I-election) general(I-election) election(I-election) in(O) Hamilton(B-location) West(I-location),(O) losing(O) to(O) provincial(O) Ontario(B-political party) Liberal(I-political party) Party(I-political party) leader(O) Stuart(B-politician) Lyon(I-politician).(O)", "instance": {"id": "210", "words": ["He", "unsuccessfully", "ran", "as", "a", "Progressive", "Conservative", "Party", "of", "Ontario", "candidate", "in", "the", "1981", "Ontario", "general", "election", "in", "Hamilton", "West", ",", "losing", "to", "provincial", "Ontario", "Liberal", "Party", "leader", "Stuart", "Lyon", "Smith", "."], "labels": ["O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "I-political party", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "B-location", "I-location", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "O", "B-politician", "I-politician", "I-politician", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, event, person, location, country, politician, organization, election and O.\nSentence: He unsuccessfully ran as a Progressive Conservative Party of Ontario candidate in the 1981 Ontario general election in Hamilton West , losing to provincial Ontario Liberal Party leader Stuart Lyon Smith .", "prompt_labels": "He(O) unsuccessfully(O) ran(O) as(O) a(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) of(I-political party) Ontario(I-political party) candidate(O) in(O) the(O) 1981(B-election) Ontario(I-election) general(I-election) election(I-election) in(O) Hamilton(B-location) West(I-location) ,(O) losing(O) to(O) provincial(O) Ontario(B-political party) Liberal(I-political party) Party(I-political party) leader(O) Stuart(B-politician) Lyon(I-politician) Smith(I-politician) .(O)"}, "label_list": ["political party", "event", "person", "location", "country", "politician", "organization", "election"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5054, 4717, 11, 1567, 11, 1732, 11, 3813, 11, 3224, 11, 37038, 11, 7471, 11, 6355, 323, 507, 627, 85664, 25, 1283, 97725, 10837, 439, 264, 52870, 30071, 8722, 315, 21193, 9322, 304, 279, 220, 3753, 16, 21193, 4689, 6355, 304, 24051, 4410, 1174, 13490, 311, 36031, 21193, 31158, 8722, 7808, 44632, 56301, 9259, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "519", "dataset": "crossner_politics", "split": "dev", "prediction": "U.S.(B-country) President(O) George(B-politician) W.(I-politician) Bush(I-politician) also(O) set(O) his(O) hopes(O) on(O) leaders(O) of(O) the(O) summit(O) to(O) back(O) the(O) 2008(B-event) G-20(I-event) Washington(I-event) summit(I-event) and(O) declaration(O) to(O) the(O) financial(O) crisis(O) of(O) 2007-2008(O).(O)", "instance": {"id": "519", "words": ["U.S.", "President", "George", "W.", "Bush", "also", "set", "his", "hopes", "on", "leaders", "of", "the", "summit", "to", "back", "the", "2008", "G-20", "Washington", "summit", "and", "declaration", "to", "the", "financial", "crisis", "of", "2007-2008", "."], "labels": ["B-country", "O", "B-politician", "I-politician", "I-politician", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "I-event", "O", "O", "O", "O", "B-event", "I-event", "I-event", "I-event", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, political party, country, politician, election, person, location, organization and O.\nSentence: U.S. President George W. Bush also set his hopes on leaders of the summit to back the 2008 G-20 Washington summit and declaration to the financial crisis of 2007-2008 .", "prompt_labels": "U.S.(B-country) President(O) George(B-politician) W.(I-politician) Bush(I-politician) also(O) set(O) his(O) hopes(O) on(O) leaders(O) of(O) the(O) summit(O) to(O) back(O) the(O) 2008(B-event) G-20(I-event) Washington(I-event) summit(I-event) and(O) declaration(O) to(O) the(O) financial(B-event) crisis(I-event) of(I-event) 2007-2008(I-event) .(O)"}, "label_list": ["event", "political party", "country", "politician", "election", "person", "location", "organization"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 5054, 4717, 11, 3224, 11, 37038, 11, 6355, 11, 1732, 11, 3813, 11, 7471, 323, 507, 627, 85664, 25, 549, 815, 13, 4900, 10058, 468, 13, 14409, 1101, 743, 813, 16388, 389, 6164, 315, 279, 30048, 311, 1203, 279, 220, 1049, 23, 480, 12, 508, 6652, 30048, 323, 18489, 311, 279, 6020, 11501, 315, 220, 1049, 22, 12, 1049, 23, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "956", "dataset": "mit-movie", "split": "dev", "prediction": "looking(O) for(O) the(O) movie(O) with(O) a(O) black(B-title) man(I-title) as(I-title) an(I-title) alien(I-title) directed(O) by(O) john(B-director) sayles(I-director)", "instance": {"id": "956", "words": ["looking", "for", "the", "movie", "with", "a", "black", "man", "as", "an", "alien", "directed", "by", "john", "sayles"], "labels": ["O", "O", "O", "O", "O", "O", "B-plot", "I-plot", "I-plot", "I-plot", "I-plot", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, character, trailer, director, song, genre, rating, review, title, plot, average ratings, actor and O.\nSentence: looking for the movie with a black man as an alien directed by john sayles", "prompt_labels": "looking(O) for(O) the(O) movie(O) with(O) a(O) black(B-plot) man(I-plot) as(I-plot) an(I-plot) alien(I-plot) directed(O) by(O) john(B-director) sayles(I-director)"}, "label_list": ["year", "character", "trailer", "director", "song", "genre", "rating", "review", "title", "plot", "average ratings", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 3752, 11, 19809, 11, 7690, 11, 5609, 11, 17779, 11, 10959, 11, 3477, 11, 2316, 11, 7234, 11, 5578, 18594, 11, 12360, 323, 507, 627, 85664, 25, 3411, 369, 279, 5818, 449, 264, 3776, 893, 439, 459, 20167, 15910, 555, 40742, 2019, 645, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2196", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) unrated(B-rating) movie(O) came(O) out(O) in(O) 2000(B-year) and(O) stars(O) james(B-actor) van(I-actor) der(I-actor) beek(I-actor)", "instance": {"id": "2196", "words": ["what", "unrated", "movie", "came", "out", "in", "2000", "and", "stars", "james", "van", "der", "beek"], "labels": ["O", "B-rating", "O", "O", "O", "O", "B-year", "O", "O", "B-actor", "I-actor", "I-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, character, trailer, director, year, song, average ratings, genre, actor, plot, title, review and O.\nSentence: what unrated movie came out in 2000 and stars james van der beek", "prompt_labels": "what(O) unrated(B-rating) movie(O) came(O) out(O) in(O) 2000(B-year) and(O) stars(O) james(B-actor) van(I-actor) der(I-actor) beek(I-actor)"}, "label_list": ["rating", "character", "trailer", "director", "year", "song", "average ratings", "genre", "actor", "plot", "title", "review"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 3752, 11, 19809, 11, 7690, 11, 1060, 11, 5609, 11, 5578, 18594, 11, 17779, 11, 12360, 11, 7234, 11, 2316, 11, 3477, 323, 507, 627, 85664, 25, 1148, 41480, 660, 5818, 3782, 704, 304, 220, 1049, 15, 323, 9958, 86046, 5355, 2761, 387, 1247, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1658", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) all(O) fantasy(B-genre) movies(O) that(O) have(O) been(O) released(O) in(O) the(O) past(B-year) decade(I-year)", "instance": {"id": "1658", "words": ["list", "all", "fantasy", "movies", "that", "have", "been", "released", "in", "the", "past", "decade"], "labels": ["O", "O", "B-genre", "O", "O", "O", "O", "O", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, director, average ratings, song, year, actor, rating, review, genre, plot, title, trailer and O.\nSentence: list all fantasy movies that have been released in the past decade", "prompt_labels": "list(O) all(O) fantasy(B-genre) movies(O) that(O) have(O) been(O) released(O) in(O) the(O) past(B-year) decade(I-year)"}, "label_list": ["character", "director", "average ratings", "song", "year", "actor", "rating", "review", "genre", "plot", "title", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 7690, 11, 5578, 18594, 11, 5609, 11, 1060, 11, 12360, 11, 10959, 11, 3477, 11, 17779, 11, 7234, 11, 2316, 11, 19809, 323, 507, 627, 85664, 25, 1160, 682, 18884, 9698, 430, 617, 1027, 6004, 304, 279, 3347, 13515, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "737", "dataset": "mit-restaurant", "split": "dev", "prediction": "im(O) looking(O) for(O) a(O) pizza(B-Cuisine) restaurant(O) that(O) has(O) buffalo(B-Dish) chicken(I-Dish) where(O) i(O) can(O) eat(O) in(O) i(O) only(O) have(O) a(O) credit(B-Amenity) card(I-Amenity)", "instance": {"id": "737", "words": ["im", "looking", "for", "a", "pizza", "restaurant", "that", "has", "buffalo", "chicken", "where", "i", "can", "eat", "in", "i", "only", "have", "a", "credit", "card"], "labels": ["O", "O", "O", "O", "B-Cuisine", "O", "O", "O", "B-Dish", "I-Dish", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Price, Rating, Dish, Restaurant Name, Location, Amenity, Hours and O.\nSentence: im looking for a pizza restaurant that has buffalo chicken where i can eat in i only have a credit card", "prompt_labels": "im(O) looking(O) for(O) a(O) pizza(B-Cuisine) restaurant(O) that(O) has(O) buffalo(B-Dish) chicken(I-Dish) where(O) i(O) can(O) eat(O) in(O) i(O) only(O) have(O) a(O) credit(B-Amenity) card(I-Amenity)"}, "label_list": ["Cuisine", "Price", "Rating", "Dish", "Restaurant Name", "Location", "Amenity", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 8650, 11, 19767, 11, 49268, 11, 26568, 4076, 11, 10067, 11, 3383, 56685, 11, 30192, 323, 507, 627, 85664, 25, 737, 3411, 369, 264, 23317, 10960, 430, 706, 82455, 16553, 1405, 602, 649, 8343, 304, 602, 1193, 617, 264, 6807, 3786, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1422", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) is(O) the(O) closest(B-Location) sushi(B-Cuisine) bars(I-Cuisine) to(O) my(O) zip(B-Location) code(I-Location)", "instance": {"id": "1422", "words": ["where", "is", "the", "closest", "sushi", "bars", "to", "my", "zip", "code"], "labels": ["O", "O", "O", "B-Location", "B-Cuisine", "I-Cuisine", "O", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Dish, Cuisine, Hours, Location, Restaurant Name, Amenity, Rating and O.\nSentence: where is the closest sushi bars to my zip code", "prompt_labels": "where(O) is(O) the(O) closest(B-Location) sushi(B-Cuisine) bars(I-Cuisine) to(O) my(B-Location) zip(I-Location) code(I-Location)"}, "label_list": ["Price", "Dish", "Cuisine", "Hours", "Location", "Restaurant Name", "Amenity", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 49268, 11, 81961, 11, 30192, 11, 10067, 11, 26568, 4076, 11, 3383, 56685, 11, 19767, 323, 507, 627, 85664, 25, 1405, 374, 279, 18585, 67322, 16283, 311, 856, 10521, 2082, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "364", "dataset": "crossner_music", "split": "dev", "prediction": "Blue(B-band) \u00d6yster(I-band) Cult(I-band) '(O)'s(O) longest-lasting(O) and(O) most(O) commercially(O) successful(O) lineup(O) included(O) Buck(B-song) Dharma(I-song) ((O) lead(O) guitar(O),(O) Eric(B-song) Bloom(I-song) ((O) lead(O) vocals(O),(O) stun(O) guitar(O),(O) keyboards(O),(O) synthesizers(O) )(O),(O) Allen(B-song) Lanier(I-song) ((O) keyboards(O),(O) rhythm(O) guitar(O),(O) backing(O) vocals(O) )(O),(O) Joe(B-song) Bouchard(I-song) ((O) bass(O),(O) vocals(O) )(O),(O) and(O) Albert(B-song) Bouchard(I-song) ((O) drums(O),(O) percussion(O),(O) vocals(O) )(O).(O)", "instance": {"id": "364", "words": ["Blue", "\u00d6yster", "Cult", "'s", "longest-lasting", "and", "most", "commercially", "successful", "lineup", "included", "Buck", "Dharma", "(", "lead", "guitar", ",", "vocals", ")", ",", "Eric", "Bloom", "(", "lead", "vocals", ",", "stun", "guitar", ",", "keyboards", ",", "synthesizers", ")", ",", "Allen", "Lanier", "(", "keyboards", ",", "rhythm", "guitar", ",", "backing", "vocals", ")", ",", "Joe", "Bouchard", "(", "bass", ",", "vocals", ")", ",", "and", "Albert", "Bouchard", "(", "drums", ",", "percussion", ",", "vocals", ")", "."], "labels": ["B-band", "I-band", "I-band", "O", "O", "O", "O", "O", "O", "O", "O", "B-musical artist", "I-musical artist", "O", "O", "B-musical instrument", "O", "O", "O", "O", "B-musical artist", "I-musical artist", "O", "O", "O", "O", "B-musical instrument", "I-musical instrument", "O", "B-musical instrument", "O", "B-musical instrument", "O", "O", "B-musical artist", "I-musical artist", "O", "B-musical instrument", "O", "B-musical artist", "I-musical artist", "O", "O", "O", "O", "O", "B-musical artist", "I-musical artist", "O", "B-musical instrument", "O", "O", "O", "O", "O", "B-musical artist", "I-musical artist", "O", "B-musical instrument", "O", "B-musical instrument", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, musical instrument, person, award, album, music genre, event, band, country, organization, location, musical artist and O.\nSentence: Blue \u00d6yster Cult 's longest-lasting and most commercially successful lineup included Buck Dharma ( lead guitar , vocals ) , Eric Bloom ( lead vocals , stun guitar , keyboards , synthesizers ) , Allen Lanier ( keyboards , rhythm guitar , backing vocals ) , Joe Bouchard ( bass , vocals ) , and Albert Bouchard ( drums , percussion , vocals ) .", "prompt_labels": "Blue(B-band) \u00d6yster(I-band) Cult(I-band) 's(O) longest-lasting(O) and(O) most(O) commercially(O) successful(O) lineup(O) included(O) Buck(B-musical artist) Dharma(I-musical artist) ((O) lead(O) guitar(B-musical instrument) ,(O) vocals(O) )(O) ,(O) Eric(B-musical artist) Bloom(I-musical artist) ((O) lead(O) vocals(O) ,(O) stun(B-musical instrument) guitar(I-musical instrument) ,(O) keyboards(B-musical instrument) ,(O) synthesizers(B-musical instrument) )(O) ,(O) Allen(B-musical artist) Lanier(I-musical artist) ((O) keyboards(B-musical instrument) ,(O) rhythm(B-musical artist) guitar(I-musical artist) ,(O) backing(O) vocals(O) )(O) ,(O) Joe(B-musical artist) Bouchard(I-musical artist) ((O) bass(B-musical instrument) ,(O) vocals(O) )(O) ,(O) and(O) Albert(B-musical artist) Bouchard(I-musical artist) ((O) drums(B-musical instrument) ,(O) percussion(B-musical instrument) ,(O) vocals(O) )(O) .(O)"}, "label_list": ["song", "musical instrument", "person", "award", "album", "music genre", "event", "band", "country", "organization", "location", "musical artist"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 18273, 14473, 11, 1732, 11, 10292, 11, 8176, 11, 4731, 17779, 11, 1567, 11, 7200, 11, 3224, 11, 7471, 11, 3813, 11, 18273, 10255, 323, 507, 627, 85664, 25, 8868, 35137, 22604, 26676, 364, 82, 22807, 65265, 323, 1455, 54453, 6992, 28612, 5343, 27156, 423, 78338, 320, 3063, 17418, 1174, 47196, 883, 1174, 16645, 25517, 320, 3063, 47196, 1174, 66528, 17418, 1174, 71402, 1174, 52389, 12509, 883, 1174, 20661, 35882, 1291, 320, 71402, 1174, 37390, 17418, 1174, 25695, 47196, 883, 1174, 13142, 426, 3102, 569, 320, 22253, 1174, 47196, 883, 1174, 323, 17971, 426, 3102, 569, 320, 47389, 1174, 84849, 1174, 47196, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "357", "dataset": "mit-movie", "split": "dev", "prediction": "i(O) would(O) like(O) to(O) watch(O) a(O) romance(B-genre) about(O) soccer(B-plot)", "instance": {"id": "357", "words": ["i", "would", "like", "to", "watch", "a", "romance", "about", "soccer"], "labels": ["O", "O", "O", "O", "O", "O", "B-genre", "O", "B-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, trailer, plot, genre, character, review, average ratings, title, year, director, actor, song and O.\nSentence: i would like to watch a romance about soccer", "prompt_labels": "i(O) would(O) like(O) to(O) watch(O) a(O) romance(B-genre) about(O) soccer(B-plot)"}, "label_list": ["rating", "trailer", "plot", "genre", "character", "review", "average ratings", "title", "year", "director", "actor", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 19809, 11, 7234, 11, 17779, 11, 3752, 11, 3477, 11, 5578, 18594, 11, 2316, 11, 1060, 11, 7690, 11, 12360, 11, 5609, 323, 507, 627, 85664, 25, 602, 1053, 1093, 311, 3821, 264, 30363, 922, 22963, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1349", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) can(O) i(O) get(O) vegan(B-Cuisine) food(O)", "instance": {"id": "1349", "words": ["where", "can", "i", "get", "vegan", "food"], "labels": ["O", "O", "O", "O", "B-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Cuisine, Restaurant Name, Rating, Dish, Amenity, Location, Hours and O.\nSentence: where can i get vegan food", "prompt_labels": "where(O) can(O) i(O) get(O) vegan(B-Cuisine) food(O)"}, "label_list": ["Price", "Cuisine", "Restaurant Name", "Rating", "Dish", "Amenity", "Location", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 81961, 11, 26568, 4076, 11, 19767, 11, 49268, 11, 3383, 56685, 11, 10067, 11, 30192, 323, 507, 627, 85664, 25, 1405, 649, 602, 636, 30249, 3691, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "226", "dataset": "mit-restaurant", "split": "dev", "prediction": "diner(B-Cuisine)", "instance": {"id": "226", "words": ["diner"], "labels": ["B-Cuisine"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Location, Restaurant Name, Rating, Cuisine, Price, Dish, Hours and O.\nSentence: diner", "prompt_labels": "diner(B-Cuisine)"}, "label_list": ["Amenity", "Location", "Restaurant Name", "Rating", "Cuisine", "Price", "Dish", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 10067, 11, 26568, 4076, 11, 19767, 11, 81961, 11, 8650, 11, 49268, 11, 30192, 323, 507, 627, 85664, 25, 89206, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "533", "dataset": "mit-restaurant", "split": "dev", "prediction": "how(O) many(O) restaurants(O) that(O) accept(B-Amenity) reservations(I-Amenity) are(O) within(B-Location) 10(I-Location) miles(I-Location)", "instance": {"id": "533", "words": ["how", "many", "restaurants", "that", "accept", "reservations", "are", "within", "10", "miles"], "labels": ["O", "O", "O", "O", "B-Amenity", "I-Amenity", "O", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Price, Dish, Amenity, Restaurant Name, Hours, Cuisine, Location and O.\nSentence: how many restaurants that accept reservations are within 10 miles", "prompt_labels": "how(O) many(O) restaurants(O) that(O) accept(B-Amenity) reservations(I-Amenity) are(O) within(B-Location) 10(I-Location) miles(I-Location)"}, "label_list": ["Rating", "Price", "Dish", "Amenity", "Restaurant Name", "Hours", "Cuisine", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 8650, 11, 49268, 11, 3383, 56685, 11, 26568, 4076, 11, 30192, 11, 81961, 11, 10067, 323, 507, 627, 85664, 25, 1268, 1690, 15926, 430, 4287, 41162, 527, 2949, 220, 605, 8931, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1411", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) is(O) the(O) closest(B-Location) fine(B-Cuisine) dining(I-Cuisine) restaurant(O)", "instance": {"id": "1411", "words": ["where", "is", "the", "closest", "fine", "dining", "restaurant"], "labels": ["O", "O", "O", "B-Location", "B-Cuisine", "I-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Cuisine, Amenity, Location, Restaurant Name, Price, Dish, Rating and O.\nSentence: where is the closest fine dining restaurant", "prompt_labels": "where(O) is(O) the(O) closest(B-Location) fine(B-Cuisine) dining(I-Cuisine) restaurant(O)"}, "label_list": ["Hours", "Cuisine", "Amenity", "Location", "Restaurant Name", "Price", "Dish", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 81961, 11, 3383, 56685, 11, 10067, 11, 26568, 4076, 11, 8650, 11, 49268, 11, 19767, 323, 507, 627, 85664, 25, 1405, 374, 279, 18585, 7060, 18397, 10960, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "71", "dataset": "mit-movie", "split": "dev", "prediction": "favorite(O) quote(O) from(O) action(B-genre) movies(O)", "instance": {"id": "71", "words": ["favorite", "quote", "from", "action", "movies"], "labels": ["O", "O", "O", "B-genre", "I-genre"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, review, rating, trailer, character, average ratings, song, plot, actor, director, genre, title and O.\nSentence: favorite quote from action movies", "prompt_labels": "favorite(O) quote(O) from(O) action(B-genre) movies(I-genre)"}, "label_list": ["year", "review", "rating", "trailer", "character", "average ratings", "song", "plot", "actor", "director", "genre", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 3477, 11, 10959, 11, 19809, 11, 3752, 11, 5578, 18594, 11, 5609, 11, 7234, 11, 12360, 11, 7690, 11, 17779, 11, 2316, 323, 507, 627, 85664, 25, 7075, 12929, 505, 1957, 9698, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "163", "dataset": "crossner_science", "split": "dev", "prediction": "Within(O) the(O) Solar(O) System(O) there(O) are(O) five(O) candidates(O) for(O) Schumann(B-astronomical object) resonance(I-astronomical object) detection(O) besides(O) the(O) Earth(B-astronomical object) :(O) Venus(B-astronomical object),(O) Mars(B-astronomical object),(O) Jupiter(B-astronomical object),(O) Saturn(B-astronomical object),(O) and(O) Saturn(B-astronomical object)'s(O) biggest(O) moon(O) Titan(B-astronomical object).(O)", "instance": {"id": "163", "words": ["Within", "the", "Solar", "System", "there", "are", "five", "candidates", "for", "Schumann", "resonance", "detection", "besides", "the", "Earth", ":", "Venus", ",", "Mars", ",", "Jupiter", ",", "Saturn", ",", "and", "Saturn", "'s", "biggest", "moon", "Titan", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-astronomical object", "O", "B-astronomical object", "O", "B-astronomical object", "O", "B-astronomical object", "O", "B-astronomical object", "O", "O", "B-astronomical object", "O", "O", "O", "B-astronomical object", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: discipline, location, event, award, chemical element, university, enzyme, academic journal, theory, chemical compound, astronomical object, scientist, country, organization, person, protein and O.\nSentence: Within the Solar System there are five candidates for Schumann resonance detection besides the Earth : Venus , Mars , Jupiter , Saturn , and Saturn 's biggest moon Titan .", "prompt_labels": "Within(O) the(O) Solar(O) System(O) there(O) are(O) five(O) candidates(O) for(O) Schumann(O) resonance(O) detection(O) besides(O) the(O) Earth(B-astronomical object) :(O) Venus(B-astronomical object) ,(O) Mars(B-astronomical object) ,(O) Jupiter(B-astronomical object) ,(O) Saturn(B-astronomical object) ,(O) and(O) Saturn(B-astronomical object) 's(O) biggest(O) moon(O) Titan(B-astronomical object) .(O)"}, "label_list": ["discipline", "location", "event", "award", "chemical element", "university", "enzyme", "academic journal", "theory", "chemical compound", "astronomical object", "scientist", "country", "organization", "person", "protein"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26434, 11, 3813, 11, 1567, 11, 10292, 11, 11742, 2449, 11, 12374, 11, 49242, 11, 14584, 8486, 11, 10334, 11, 11742, 24549, 11, 87283, 1665, 11, 28568, 11, 3224, 11, 7471, 11, 1732, 11, 13128, 323, 507, 627, 85664, 25, 25218, 279, 25450, 744, 1070, 527, 4330, 11426, 369, 5124, 64607, 58081, 18468, 28858, 279, 9420, 551, 50076, 1174, 21725, 1174, 50789, 1174, 50253, 1174, 323, 50253, 364, 82, 8706, 18266, 28547, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "158", "dataset": "mit-restaurant", "split": "dev", "prediction": "can(O) you(O) find(O) me(O) a(O) nice(B-Rating) italian(B-Cuisine) restaurant(O) that(O) takes(O) reservations(B-Amenity)", "instance": {"id": "158", "words": ["can", "you", "find", "me", "a", "nice", "italian", "restaurant", "that", "takes", "reservations"], "labels": ["O", "O", "O", "O", "O", "B-Rating", "B-Cuisine", "O", "O", "O", "B-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Price, Location, Cuisine, Rating, Amenity, Restaurant Name, Dish and O.\nSentence: can you find me a nice italian restaurant that takes reservations", "prompt_labels": "can(O) you(O) find(O) me(O) a(O) nice(B-Rating) italian(B-Cuisine) restaurant(O) that(O) takes(O) reservations(B-Amenity)"}, "label_list": ["Hours", "Price", "Location", "Cuisine", "Rating", "Amenity", "Restaurant Name", "Dish"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 8650, 11, 10067, 11, 81961, 11, 19767, 11, 3383, 56685, 11, 26568, 4076, 11, 49268, 323, 507, 627, 85664, 25, 649, 499, 1505, 757, 264, 6555, 29048, 10960, 430, 5097, 41162, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1461", "dataset": "mit-restaurant", "split": "dev", "prediction": "where(O) should(O) we(O) go(O) to(O) get(O) some(O) great(B-Rating) food(O)", "instance": {"id": "1461", "words": ["where", "should", "we", "go", "to", "get", "some", "great", "food"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-Rating", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Price, Amenity, Dish, Location, Cuisine, Rating, Restaurant Name and O.\nSentence: where should we go to get some great food", "prompt_labels": "where(O) should(O) we(O) go(O) to(O) get(O) some(O) great(B-Rating) food(O)"}, "label_list": ["Hours", "Price", "Amenity", "Dish", "Location", "Cuisine", "Rating", "Restaurant Name"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 8650, 11, 3383, 56685, 11, 49268, 11, 10067, 11, 81961, 11, 19767, 11, 26568, 4076, 323, 507, 627, 85664, 25, 1405, 1288, 584, 733, 311, 636, 1063, 2294, 3691, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "219", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) was(O) the(O) film(O) about(O) brandon(B-character) teena(I-character)", "instance": {"id": "219", "words": ["what", "was", "the", "film", "about", "brandon", "teena"], "labels": ["O", "O", "O", "O", "O", "B-character", "I-character"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, plot, rating, title, trailer, director, actor, average ratings, song, year, genre, character and O.\nSentence: what was the film about brandon teena", "prompt_labels": "what(O) was(O) the(O) film(O) about(O) brandon(B-character) teena(I-character)"}, "label_list": ["review", "plot", "rating", "title", "trailer", "director", "actor", "average ratings", "song", "year", "genre", "character"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 7234, 11, 10959, 11, 2316, 11, 19809, 11, 7690, 11, 12360, 11, 5578, 18594, 11, 5609, 11, 1060, 11, 17779, 11, 3752, 323, 507, 627, 85664, 25, 1148, 574, 279, 4632, 922, 6883, 263, 1028, 7304, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "477", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) film(O) did(O) richard(B-actor) gere(I-actor) and(O) julia(B-actor) roberts(I-actor) star(O) together(O)", "instance": {"id": "477", "words": ["what", "film", "did", "richard", "gere", "and", "julia", "roberts", "star", "together"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O", "B-actor", "I-actor", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, year, director, song, trailer, actor, genre, review, rating, average ratings, plot, title and O.\nSentence: what film did richard gere and julia roberts star together", "prompt_labels": "what(O) film(O) did(O) richard(B-actor) gere(I-actor) and(O) julia(B-actor) roberts(I-actor) star(O) together(O)"}, "label_list": ["character", "year", "director", "song", "trailer", "actor", "genre", "review", "rating", "average ratings", "plot", "title"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 1060, 11, 7690, 11, 5609, 11, 19809, 11, 12360, 11, 17779, 11, 3477, 11, 10959, 11, 5578, 18594, 11, 7234, 11, 2316, 323, 507, 627, 85664, 25, 1148, 4632, 1550, 9257, 569, 67387, 323, 41638, 689, 89993, 82, 6917, 3871, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "72", "dataset": "mit-movie", "split": "dev", "prediction": "find(O) me(O) the(O) g(B-rating) rated(I-rating) movies(O) with(O) dogs(B-plot) that(O) were(O) released(O) in(O) the(O) 2000s(B-year)", "instance": {"id": "72", "words": ["find", "me", "the", "g", "rated", "movies", "with", "dogs", "that", "were", "released", "in", "the", "2000s"], "labels": ["O", "O", "O", "B-rating", "I-rating", "O", "O", "B-plot", "O", "O", "O", "O", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, average ratings, review, song, title, character, year, director, rating, genre, actor, plot and O.\nSentence: find me the g rated movies with dogs that were released in the 2000s", "prompt_labels": "find(O) me(O) the(O) g(B-rating) rated(I-rating) movies(O) with(O) dogs(B-plot) that(O) were(O) released(O) in(O) the(O) 2000s(B-year)"}, "label_list": ["trailer", "average ratings", "review", "song", "title", "character", "year", "director", "rating", "genre", "actor", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 5578, 18594, 11, 3477, 11, 5609, 11, 2316, 11, 3752, 11, 1060, 11, 7690, 11, 10959, 11, 17779, 11, 12360, 11, 7234, 323, 507, 627, 85664, 25, 1505, 757, 279, 342, 22359, 9698, 449, 12875, 430, 1051, 6004, 304, 279, 220, 1049, 15, 82, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "206", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) movies(O) directed(O) by(O) alexander(B-director) payne(I-director) from(O) the(O) 2000s(B-year)", "instance": {"id": "206", "words": ["show", "me", "movies", "directed", "by", "alexander", "payne", "from", "the", "2000s"], "labels": ["O", "O", "O", "O", "O", "B-director", "I-director", "O", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, song, genre, rating, review, plot, character, average ratings, trailer, actor, director, year and O.\nSentence: show me movies directed by alexander payne from the 2000s", "prompt_labels": "show(O) me(O) movies(O) directed(O) by(O) alexander(B-director) payne(I-director) from(O) the(O) 2000s(B-year)"}, "label_list": ["title", "song", "genre", "rating", "review", "plot", "character", "average ratings", "trailer", "actor", "director", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 5609, 11, 17779, 11, 10959, 11, 3477, 11, 7234, 11, 3752, 11, 5578, 18594, 11, 19809, 11, 12360, 11, 7690, 11, 1060, 323, 507, 627, 85664, 25, 1501, 757, 9698, 15910, 555, 57578, 8363, 2343, 818, 505, 279, 220, 1049, 15, 82, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "120", "dataset": "mit-restaurant", "split": "dev", "prediction": "can(O) i(O) find(O) any(O) restaurants(O) close(B-Location) by(I-Location) with(O) a(O) meal(B-Price) under(I-Price) 8(I-Price)", "instance": {"id": "120", "words": ["can", "i", "find", "any", "restaurants", "close", "by", "with", "a", "meal", "under", "8"], "labels": ["O", "O", "O", "O", "O", "B-Location", "I-Location", "O", "O", "B-Price", "I-Price", "I-Price"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Restaurant Name, Hours, Rating, Location, Cuisine, Dish, Price and O.\nSentence: can i find any restaurants close by with a meal under 8", "prompt_labels": "can(O) i(O) find(O) any(O) restaurants(O) close(B-Location) by(I-Location) with(O) a(O) meal(B-Price) under(I-Price) 8(I-Price)"}, "label_list": ["Amenity", "Restaurant Name", "Hours", "Rating", "Location", "Cuisine", "Dish", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 26568, 4076, 11, 30192, 11, 19767, 11, 10067, 11, 81961, 11, 49268, 11, 8650, 323, 507, 627, 85664, 25, 649, 602, 1505, 904, 15926, 3345, 555, 449, 264, 15496, 1234, 220, 23, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "479", "dataset": "mit-movie", "split": "dev", "prediction": "list(O) all(O) films(O) based(O) on(O) the(O) wizard(B-title) of(I-title) oz(I-title) books(I-title)", "instance": {"id": "479", "words": ["list", "all", "films", "based", "on", "the", "wizard", "of", "oz", "books"], "labels": ["O", "O", "O", "O", "O", "O", "B-title", "I-title", "I-title", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, review, character, actor, plot, title, rating, year, director, average ratings, genre, song and O.\nSentence: list all films based on the wizard of oz books", "prompt_labels": "list(O) all(O) films(O) based(O) on(O) the(O) wizard(B-title) of(I-title) oz(I-title) books(O)"}, "label_list": ["trailer", "review", "character", "actor", "plot", "title", "rating", "year", "director", "average ratings", "genre", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 3477, 11, 3752, 11, 12360, 11, 7234, 11, 2316, 11, 10959, 11, 1060, 11, 7690, 11, 5578, 18594, 11, 17779, 11, 5609, 323, 507, 627, 85664, 25, 1160, 682, 12631, 3196, 389, 279, 35068, 315, 25616, 6603, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1302", "dataset": "mit-movie", "split": "dev", "prediction": "how(O) is(O) the(O) movie(O) death(B-title) to(I-title) smoochy(I-title)", "instance": {"id": "1302", "words": ["how", "is", "the", "movie", "death", "to", "smoochy"], "labels": ["O", "O", "O", "O", "B-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, title, director, plot, rating, average ratings, genre, character, song, year, trailer, actor and O.\nSentence: how is the movie death to smoochy", "prompt_labels": "how(O) is(O) the(O) movie(O) death(B-title) to(I-title) smoochy(I-title)"}, "label_list": ["review", "title", "director", "plot", "rating", "average ratings", "genre", "character", "song", "year", "trailer", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 2316, 11, 7690, 11, 7234, 11, 10959, 11, 5578, 18594, 11, 17779, 11, 3752, 11, 5609, 11, 1060, 11, 19809, 11, 12360, 323, 507, 627, 85664, 25, 1268, 374, 279, 5818, 4648, 311, 1554, 2689, 59064, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "331", "dataset": "crossner_literature", "split": "dev", "prediction": "Georg(B-writer) Trakl(I-writer) ((O) 3(O) February(O) 1887(O) -(O) 3(O) November(O) 1914(O) )(O) was(O) an(O) Austria-Hungary(B-country) poet(O) and(O) brother(O) of(O) the(O) pianist(O) Grete(B-writer) Trakl(I-writer).(O)", "instance": {"id": "331", "words": ["Georg", "Trakl", "(", "3", "February", "1887", "-", "3", "November", "1914", ")", "was", "an", "Austria-Hungary", "poet", "and", "brother", "of", "the", "pianist", "Grete", "Trakl", "."], "labels": ["B-writer", "I-writer", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-country", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, country, writer, magazine, organization, award, location, book, event, literary genre, poem and O.\nSentence: Georg Trakl ( 3 February 1887 - 3 November 1914 ) was an Austria-Hungary poet and brother of the pianist Grete Trakl .", "prompt_labels": "Georg(B-writer) Trakl(I-writer) ((O) 3(O) February(O) 1887(O) -(O) 3(O) November(O) 1914(O) )(O) was(O) an(O) Austria-Hungary(B-country) poet(O) and(O) brother(O) of(O) the(O) pianist(O) Grete(B-person) Trakl(I-person) .(O)"}, "label_list": ["person", "country", "writer", "magazine", "organization", "award", "location", "book", "event", "literary genre", "poem"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 3224, 11, 7061, 11, 14756, 11, 7471, 11, 10292, 11, 3813, 11, 2363, 11, 1567, 11, 32465, 17779, 11, 33894, 323, 507, 627, 85664, 25, 13629, 1183, 587, 75, 320, 220, 18, 7552, 220, 9367, 22, 482, 220, 18, 6841, 220, 7529, 19, 883, 574, 459, 35998, 11529, 2234, 661, 40360, 323, 10868, 315, 279, 60166, 380, 13842, 668, 1183, 587, 75, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "176", "dataset": "crossner_science", "split": "dev", "prediction": "It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O),(O) by(O) Dutch(O) astronomer(O) couple(O) Ingrid(B-scientist) van(I-scientist) Houten-Groeneveld(I-scientist) and(O) Cornelis(B-scientist) van(I-scientist) Houten(I-scientist) in(O) collaboration(O) with(O) Dutch-American(O) astronomer(O) Tom(B-scientist) Gehrels(I-scientist) at(O) the(O) U.S.(B-location) Palomar(I-location) Observatory(I-location) in(O) California(B-location),(O) and(O) named(O) after(O) Dutch(O) astronomer(O) Gerard(B-scientist) Kuiper(I-scientist).(O)", "instance": {"id": "176", "words": ["It", "was", "discovered", "on", "24", "September", "1960", ",", "by", "Dutch", "astronomer", "couple", "Ingrid", "van", "Houten-Groeneveld", "and", "Cornelis", "van", "Houten", "in", "collaboration", "with", "Dutch-American", "astronomer", "Tom", "Gehrels", "at", "the", "U.S.", "Palomar", "Observatory", "in", "California", ",", "and", "named", "after", "Dutch", "astronomer", "Gerard", "Kuiper", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-scientist", "I-scientist", "I-scientist", "O", "B-scientist", "I-scientist", "I-scientist", "O", "O", "O", "O", "O", "B-scientist", "I-scientist", "O", "O", "B-location", "I-location", "I-location", "O", "B-location", "O", "O", "O", "O", "O", "O", "B-scientist", "I-scientist", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, university, country, enzyme, scientist, protein, chemical compound, chemical element, organization, theory, location, award, discipline, event, astronomical object, academic journal and O.\nSentence: It was discovered on 24 September 1960 , by Dutch astronomer couple Ingrid van Houten-Groeneveld and Cornelis van Houten in collaboration with Dutch-American astronomer Tom Gehrels at the U.S. Palomar Observatory in California , and named after Dutch astronomer Gerard Kuiper .", "prompt_labels": "It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O) ,(O) by(O) Dutch(O) astronomer(O) couple(O) Ingrid(B-scientist) van(I-scientist) Houten-Groeneveld(I-scientist) and(O) Cornelis(B-scientist) van(I-scientist) Houten(I-scientist) in(O) collaboration(O) with(O) Dutch-American(O) astronomer(O) Tom(B-scientist) Gehrels(I-scientist) at(O) the(O) U.S.(B-location) Palomar(I-location) Observatory(I-location) in(O) California(B-location) ,(O) and(O) named(O) after(O) Dutch(O) astronomer(O) Gerard(B-scientist) Kuiper(I-scientist) .(O)"}, "label_list": ["person", "university", "country", "enzyme", "scientist", "protein", "chemical compound", "chemical element", "organization", "theory", "location", "award", "discipline", "event", "astronomical object", "academic journal"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 12374, 11, 3224, 11, 49242, 11, 28568, 11, 13128, 11, 11742, 24549, 11, 11742, 2449, 11, 7471, 11, 10334, 11, 3813, 11, 10292, 11, 26434, 11, 1567, 11, 87283, 1665, 11, 14584, 8486, 323, 507, 627, 85664, 25, 1102, 574, 11352, 389, 220, 1187, 6250, 220, 5162, 15, 1174, 555, 24113, 46382, 261, 5743, 763, 4297, 5355, 473, 412, 268, 12279, 299, 1994, 85, 789, 323, 99045, 285, 5355, 473, 412, 268, 304, 20632, 449, 24113, 24145, 46382, 261, 8529, 74680, 54883, 520, 279, 549, 815, 13, 11165, 316, 277, 58974, 304, 7188, 1174, 323, 7086, 1306, 24113, 46382, 261, 82218, 33479, 13154, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "210", "dataset": "crossner_literature", "split": "dev", "prediction": "He(O) won(O) three(O) Tony(B-award) Award(I-award) s(I-award) and(O) three(O) Academy(B-award) Awards(I-award),(O) among(O) other(O) honors(O).(O)", "instance": {"id": "210", "words": ["He", "won", "three", "Tony", "Award", "s", "and", "three", "Academy", "Awards", ",", "among", "other", "honors", "."], "labels": ["O", "O", "O", "B-award", "I-award", "O", "O", "O", "B-award", "I-award", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, organization, country, literary genre, writer, award, event, book, location, poem, person and O.\nSentence: He won three Tony Award s and three Academy Awards , among other honors .", "prompt_labels": "He(O) won(O) three(O) Tony(B-award) Award(I-award) s(O) and(O) three(O) Academy(B-award) Awards(I-award) ,(O) among(O) other(O) honors(O) .(O)"}, "label_list": ["magazine", "organization", "country", "literary genre", "writer", "award", "event", "book", "location", "poem", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 14756, 11, 7471, 11, 3224, 11, 32465, 17779, 11, 7061, 11, 10292, 11, 1567, 11, 2363, 11, 3813, 11, 33894, 11, 1732, 323, 507, 627, 85664, 25, 1283, 2834, 2380, 19036, 17768, 274, 323, 2380, 16192, 23488, 1174, 4315, 1023, 49593, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "338", "dataset": "mit-restaurant", "split": "dev", "prediction": "find(O) a(O) classy(B-Amenity) expensive(B-Price) restaurant(O) with(O) excellent(B-Rating) reviews(I-Rating)", "instance": {"id": "338", "words": ["find", "a", "classy", "expensive", "restaurant", "with", "excellent", "reviews"], "labels": ["O", "O", "B-Amenity", "B-Price", "O", "O", "B-Rating", "I-Rating"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Restaurant Name, Dish, Rating, Hours, Price, Cuisine, Amenity and O.\nSentence: find a classy expensive restaurant with excellent reviews", "prompt_labels": "find(O) a(O) classy(B-Amenity) expensive(B-Price) restaurant(O) with(O) excellent(B-Rating) reviews(I-Rating)"}, "label_list": ["Location", "Restaurant Name", "Dish", "Rating", "Hours", "Price", "Cuisine", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 26568, 4076, 11, 49268, 11, 19767, 11, 30192, 11, 8650, 11, 81961, 11, 3383, 56685, 323, 507, 627, 85664, 25, 1505, 264, 71358, 11646, 10960, 449, 9250, 8544, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "460", "dataset": "crossner_politics", "split": "dev", "prediction": "The(O) review(O) also(O) regularly(O) features(O) forewords(O) from(O) the(O) chief(O) executives(O) of(O) industry-leading(O) trade(O) bodies(O),(O) such(O) as(O) TechUK(B-organization),(O) the(O) British(B-organization) Retail(I-organization) Consortium(I-organization),(O) the(O) Federation(B-organization) of(I-organization) Master(I-organization) Builders(I-organization),(O) EEF(B-organization) and(O) the(O) British(B-organization) Property(I-organization) Federation(I-organization).(O)", "instance": {"id": "460", "words": ["The", "review", "also", "regularly", "features", "forewords", "from", "the", "chief", "executives", "of", "industry-leading", "trade", "bodies", ",", "such", "as", "TechUK", ",", "the", "British", "Retail", "Consortium", ",", "the", "Federation", "of", "Master", "Builders", ",", "EEF", "and", "the", "British", "Property", "Federation", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "O", "O", "B-organization", "I-organization", "I-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, country, event, person, election, organization, political party, location and O.\nSentence: The review also regularly features forewords from the chief executives of industry-leading trade bodies , such as TechUK , the British Retail Consortium , the Federation of Master Builders , EEF and the British Property Federation .", "prompt_labels": "The(O) review(O) also(O) regularly(O) features(O) forewords(O) from(O) the(O) chief(O) executives(O) of(O) industry-leading(O) trade(O) bodies(O) ,(O) such(O) as(O) TechUK(B-organization) ,(O) the(O) British(B-organization) Retail(I-organization) Consortium(I-organization) ,(O) the(O) Federation(B-organization) of(I-organization) Master(I-organization) Builders(I-organization) ,(O) EEF(B-organization) and(O) the(O) British(B-organization) Property(I-organization) Federation(I-organization) .(O)"}, "label_list": ["politician", "country", "event", "person", "election", "organization", "political party", "location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 37038, 11, 3224, 11, 1567, 11, 1732, 11, 6355, 11, 7471, 11, 5054, 4717, 11, 3813, 323, 507, 627, 85664, 25, 578, 3477, 1101, 15870, 4519, 2291, 5880, 505, 279, 10388, 29509, 315, 5064, 69475, 6696, 13162, 1174, 1778, 439, 17829, 25554, 1174, 279, 8013, 35139, 73547, 1174, 279, 28331, 315, 11060, 76848, 1174, 469, 15229, 323, 279, 8013, 8825, 28331, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "2102", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) is(O) the(O) name(O) of(O) the(O) psychological(B-genre) movie(O) about(O) a(O) lawyer(B-plot) starring(O) david(B-actor) mccallum(I-actor)", "instance": {"id": "2102", "words": ["what", "is", "the", "name", "of", "the", "psychological", "movie", "about", "a", "lawyer", "starring", "david", "mccallum"], "labels": ["O", "O", "O", "O", "O", "O", "B-genre", "O", "O", "O", "B-plot", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, rating, actor, song, director, character, plot, year, title, genre, average ratings, trailer and O.\nSentence: what is the name of the psychological movie about a lawyer starring david mccallum", "prompt_labels": "what(O) is(O) the(O) name(O) of(O) the(O) psychological(B-genre) movie(O) about(O) a(O) lawyer(B-plot) starring(O) david(B-actor) mccallum(I-actor)"}, "label_list": ["review", "rating", "actor", "song", "director", "character", "plot", "year", "title", "genre", "average ratings", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 10959, 11, 12360, 11, 5609, 11, 7690, 11, 3752, 11, 7234, 11, 1060, 11, 2316, 11, 17779, 11, 5578, 18594, 11, 19809, 323, 507, 627, 85664, 25, 1148, 374, 279, 836, 315, 279, 24064, 5818, 922, 264, 15779, 40500, 55046, 74947, 543, 372, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1746", "dataset": "mit-movie", "split": "dev", "prediction": "please(O) list(O) a(O) 1940(B-year) s(I-year) short(B-genre) movie(O) rated(O) pg(B-rating) 13(I-rating) starring(O) jon(B-actor) stewart(I-actor)", "instance": {"id": "1746", "words": ["please", "list", "a", "1940", "s", "short", "movie", "rated", "pg", "13", "starring", "jon", "stewart"], "labels": ["O", "O", "O", "B-year", "I-year", "B-genre", "O", "O", "B-rating", "I-rating", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, genre, title, director, average ratings, rating, character, trailer, song, year, plot, actor and O.\nSentence: please list a 1940 s short movie rated pg 13 starring jon stewart", "prompt_labels": "please(O) list(O) a(O) 1940(B-year) s(I-year) short(B-genre) movie(O) rated(O) pg(B-rating) 13(I-rating) starring(O) jon(B-actor) stewart(I-actor)"}, "label_list": ["review", "genre", "title", "director", "average ratings", "rating", "character", "trailer", "song", "year", "plot", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 17779, 11, 2316, 11, 7690, 11, 5578, 18594, 11, 10959, 11, 3752, 11, 19809, 11, 5609, 11, 1060, 11, 7234, 11, 12360, 323, 507, 627, 85664, 25, 4587, 1160, 264, 220, 6393, 15, 274, 2875, 5818, 22359, 17953, 220, 1032, 40500, 89604, 357, 27595, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1022", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) played(O) both(O) boys(O) in(O) the(O) errol(B-title) flynn(I-title) movie(O) the(B-title) prince(I-title) and(I-title) the(I-title) pauper(I-title)", "instance": {"id": "1022", "words": ["who", "played", "both", "boys", "in", "the", "errol", "flynn", "movie", "the", "prince", "and", "the", "pauper"], "labels": ["O", "O", "O", "O", "O", "O", "B-actor", "I-actor", "O", "B-title", "I-title", "I-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, character, rating, plot, review, average ratings, year, song, title, trailer, actor, director and O.\nSentence: who played both boys in the errol flynn movie the prince and the pauper", "prompt_labels": "who(O) played(O) both(O) boys(O) in(O) the(O) errol(B-actor) flynn(I-actor) movie(O) the(B-title) prince(I-title) and(I-title) the(I-title) pauper(I-title)"}, "label_list": ["genre", "character", "rating", "plot", "review", "average ratings", "year", "song", "title", "trailer", "actor", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 3752, 11, 10959, 11, 7234, 11, 3477, 11, 5578, 18594, 11, 1060, 11, 5609, 11, 2316, 11, 19809, 11, 12360, 11, 7690, 323, 507, 627, 85664, 25, 889, 6476, 2225, 13305, 304, 279, 2781, 1098, 11722, 7521, 5818, 279, 42826, 323, 279, 7251, 3550, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "908", "dataset": "mit-movie", "split": "dev", "prediction": "what(O) year(O) was(O) psycho(B-title) released(O)", "instance": {"id": "908", "words": ["what", "year", "was", "psycho", "released"], "labels": ["O", "O", "O", "B-title", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, director, genre, actor, review, title, average ratings, plot, character, rating, trailer, year and O.\nSentence: what year was psycho released", "prompt_labels": "what(O) year(O) was(O) psycho(B-title) released(O)"}, "label_list": ["song", "director", "genre", "actor", "review", "title", "average ratings", "plot", "character", "rating", "trailer", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 7690, 11, 17779, 11, 12360, 11, 3477, 11, 2316, 11, 5578, 18594, 11, 7234, 11, 3752, 11, 10959, 11, 19809, 11, 1060, 323, 507, 627, 85664, 25, 1148, 1060, 574, 42111, 6004, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "36", "dataset": "crossner_literature", "split": "dev", "prediction": "In(O) 1973(O),(O) Sakharov(B-writer) was(O) nominated(O) for(O) the(O) Nobel(B-award) Peace(I-award) Prize(I-award) and(O) in(O) 1974(O) was(O) awarded(O) the(O) Prix(B-award) mondial(I-award) Cino(I-award) Del(I-award) Duca(I-award).(O)", "instance": {"id": "36", "words": ["In", "1973", ",", "Sakharov", "was", "nominated", "for", "the", "Nobel", "Peace", "Prize", "and", "in", "1974", "was", "awarded", "the", "Prix", "mondial", "Cino", "Del", "Duca", "."], "labels": ["O", "O", "O", "B-person", "O", "O", "O", "O", "B-award", "I-award", "I-award", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, magazine, location, country, award, writer, book, literary genre, organization, event, poem and O.\nSentence: In 1973 , Sakharov was nominated for the Nobel Peace Prize and in 1974 was awarded the Prix mondial Cino Del Duca .", "prompt_labels": "In(O) 1973(O) ,(O) Sakharov(B-person) was(O) nominated(O) for(O) the(O) Nobel(B-award) Peace(I-award) Prize(I-award) and(O) in(O) 1974(O) was(O) awarded(O) the(O) Prix(B-award) mondial(I-award) Cino(I-award) Del(I-award) Duca(I-award) .(O)"}, "label_list": ["person", "magazine", "location", "country", "award", "writer", "book", "literary genre", "organization", "event", "poem"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 14756, 11, 3813, 11, 3224, 11, 10292, 11, 7061, 11, 2363, 11, 32465, 17779, 11, 7471, 11, 1567, 11, 33894, 323, 507, 627, 85664, 25, 763, 220, 4468, 18, 1174, 39867, 13279, 869, 574, 39048, 369, 279, 48078, 26888, 32293, 323, 304, 220, 4468, 19, 574, 22034, 279, 44394, 62940, 532, 356, 3394, 7462, 16062, 936, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "493", "dataset": "mit-movie", "split": "dev", "prediction": "who(O) starred(O) in(O) avatar(B-title)", "instance": {"id": "493", "words": ["who", "starred", "in", "avatar"], "labels": ["O", "O", "O", "B-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, title, genre, song, review, trailer, actor, year, character, average ratings, plot, director and O.\nSentence: who starred in avatar", "prompt_labels": "who(O) starred(O) in(O) avatar(B-title)"}, "label_list": ["rating", "title", "genre", "song", "review", "trailer", "actor", "year", "character", "average ratings", "plot", "director"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 2316, 11, 17779, 11, 5609, 11, 3477, 11, 19809, 11, 12360, 11, 1060, 11, 3752, 11, 5578, 18594, 11, 7234, 11, 7690, 323, 507, 627, 85664, 25, 889, 59335, 304, 21359, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "115", "dataset": "crossner_ai", "split": "dev", "prediction": "In(O) 1978(O),(O) the(O) PUMA(B-product) ((O) Programmable(B-product) Universal(I-product) Machine(I-product) for(I-product) Assembly(I-product) )(O) robot(O) was(O) developed(O) by(O) Unimation(B-organization) from(O) Vicarm(B-organization) ((O) Victor(B-researcher) Scheinman(I-researcher) )(O) and(O) with(O) support(O) from(O) General(B-organization) Motors(I-organization).(O)", "instance": {"id": "115", "words": ["In", "1978", ",", "the", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "robot", "was", "developed", "by", "Unimation", "from", "Vicarm", "(", "Victor", "Scheinman", ")", "and", "with", "support", "from", "General", "Motors", "."], "labels": ["O", "O", "O", "O", "B-product", "O", "B-product", "I-product", "I-product", "I-product", "I-product", "O", "O", "O", "O", "O", "B-organization", "O", "B-organization", "O", "B-researcher", "I-researcher", "O", "O", "O", "O", "O", "B-organization", "I-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, person, programming language, metric, location, product, researcher, organization, field, country, algorithm, conference, task and O.\nSentence: In 1978 , the PUMA ( Programmable Universal Machine for Assembly ) robot was developed by Unimation from Vicarm ( Victor Scheinman ) and with support from General Motors .", "prompt_labels": "In(O) 1978(O) ,(O) the(O) PUMA(B-product) ((O) Programmable(B-product) Universal(I-product) Machine(I-product) for(I-product) Assembly(I-product) )(O) robot(O) was(O) developed(O) by(O) Unimation(B-organization) from(O) Vicarm(B-organization) ((O) Victor(B-researcher) Scheinman(I-researcher) )(O) and(O) with(O) support(O) from(O) General(B-organization) Motors(I-organization) .(O)"}, "label_list": ["university", "person", "programming language", "metric", "location", "product", "researcher", "organization", "field", "country", "algorithm", "conference", "task"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12374, 11, 1732, 11, 15840, 4221, 11, 18767, 11, 3813, 11, 2027, 11, 32185, 11, 7471, 11, 2115, 11, 3224, 11, 12384, 11, 10017, 11, 3465, 323, 507, 627, 85664, 25, 763, 220, 4468, 23, 1174, 279, 393, 2864, 32, 320, 75010, 481, 26581, 13257, 369, 12000, 883, 12585, 574, 8040, 555, 1252, 5582, 505, 44847, 2227, 320, 33412, 54772, 258, 1543, 883, 323, 449, 1862, 505, 3331, 37792, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1481", "dataset": "mit-movie", "split": "dev", "prediction": "is(O) there(O) a(O) gold(B-plot) strike(I-plot) starring(O) danny(B-actor) glover(I-actor) in(O) the(O) last(B-year) decade(I-year)", "instance": {"id": "1481", "words": ["is", "there", "a", "gold", "strike", "starring", "danny", "glover", "in", "the", "last", "decade"], "labels": ["O", "O", "O", "B-plot", "I-plot", "O", "B-actor", "I-actor", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, rating, plot, song, review, actor, title, trailer, average ratings, character, genre, year and O.\nSentence: is there a gold strike starring danny glover in the last decade", "prompt_labels": "is(O) there(O) a(O) gold(B-plot) strike(I-plot) starring(O) danny(B-actor) glover(I-actor) in(O) the(O) last(B-year) decade(I-year)"}, "label_list": ["director", "rating", "plot", "song", "review", "actor", "title", "trailer", "average ratings", "character", "genre", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 10959, 11, 7234, 11, 5609, 11, 3477, 11, 12360, 11, 2316, 11, 19809, 11, 5578, 18594, 11, 3752, 11, 17779, 11, 1060, 323, 507, 627, 85664, 25, 374, 1070, 264, 6761, 13471, 40500, 294, 13184, 14015, 424, 304, 279, 1566, 13515, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1198", "dataset": "mit-restaurant", "split": "dev", "prediction": "what(O) restaurants(O) stay(B-Hours) open(I-Hours) after(I-Hours) 2(I-Hours) am(I-Hours) within(B-Location) 5(I-Location) miles(I-Location)", "instance": {"id": "1198", "words": ["what", "restaurants", "stay", "open", "after", "2", "am", "within", "5", "miles"], "labels": ["O", "O", "O", "B-Hours", "I-Hours", "I-Hours", "I-Hours", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Restaurant Name, Cuisine, Rating, Price, Amenity, Dish, Hours and O.\nSentence: what restaurants stay open after 2 am within 5 miles", "prompt_labels": "what(O) restaurants(O) stay(O) open(B-Hours) after(I-Hours) 2(I-Hours) am(I-Hours) within(B-Location) 5(I-Location) miles(I-Location)"}, "label_list": ["Location", "Restaurant Name", "Cuisine", "Rating", "Price", "Amenity", "Dish", "Hours"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 26568, 4076, 11, 81961, 11, 19767, 11, 8650, 11, 3383, 56685, 11, 49268, 11, 30192, 323, 507, 627, 85664, 25, 1148, 15926, 4822, 1825, 1306, 220, 17, 1097, 2949, 220, 20, 8931, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "230", "dataset": "crossner_politics", "split": "dev", "prediction": "In(O) March(O) 1987(O),(O) Western(B-organization) Goals(I-organization) UK(I-organization) had(O) filed(O) a(O) complaint(O) with(O) the(O) Charity(B-organization) Commission(I-organization) for(I-organization) England(I-organization) and(I-organization) Wales(I-organization) against(O) three(O) major(O) British(O) charities(O),(O) Oxfam(B-organization),(O) War(B-organization) on(I-organization) Want(I-organization),(O) and(O) Christian(B-organization) Aid(I-organization) claiming(O) that(O) they(O) were(O) involved(O) in(O) political(O) campaigning(O) work(O) ((O) which(O) was(O) then(O) contrary(O) to(O) UK(O) charity(O) law(O) )(O) in(O) support(O) of(O) left-wing(O) organizations(O) due(O) to(O) their(O) campaigns(O) against(O) apartheid(O) in(O) South(B-country) Africa(I-country).(O)", "instance": {"id": "230", "words": ["In", "March", "1987", ",", "Western", "Goals", "UK", "had", "filed", "a", "complaint", "with", "the", "Charity", "Commission", "for", "England", "and", "Wales", "against", "three", "major", "British", "charities", ",", "Oxfam", ",", "War", "on", "Want", ",", "and", "Christian", "Aid", "claiming", "that", "they", "were", "involved", "in", "political", "campaigning", "work", "(", "which", "was", "then", "contrary", "to", "UK", "charity", "law", ")", "in", "support", "of", "left-wing", "organizations", "due", "to", "their", "campaigns", "against", "apartheid", "in", "South", "Africa", "."], "labels": ["O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "B-organization", "O", "B-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-country", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "O", "B-country", "I-country", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, event, person, organization, location, politician, election, political party and O.\nSentence: In March 1987 , Western Goals UK had filed a complaint with the Charity Commission for England and Wales against three major British charities , Oxfam , War on Want , and Christian Aid claiming that they were involved in political campaigning work ( which was then contrary to UK charity law ) in support of left-wing organizations due to their campaigns against apartheid in South Africa .", "prompt_labels": "In(O) March(O) 1987(O) ,(O) Western(B-organization) Goals(I-organization) UK(I-organization) had(O) filed(O) a(O) complaint(O) with(O) the(O) Charity(B-organization) Commission(I-organization) for(I-organization) England(I-organization) and(I-organization) Wales(I-organization) against(O) three(O) major(O) British(O) charities(O) ,(O) Oxfam(B-organization) ,(O) War(B-organization) on(I-organization) Want(I-organization) ,(O) and(O) Christian(B-organization) Aid(I-organization) claiming(O) that(O) they(O) were(O) involved(O) in(O) political(O) campaigning(O) work(O) ((O) which(O) was(O) then(O) contrary(O) to(O) UK(B-country) charity(O) law(O) )(O) in(O) support(O) of(O) left-wing(O) organizations(O) due(O) to(O) their(O) campaigns(O) against(O) apartheid(B-organization) in(O) South(B-country) Africa(I-country) .(O)"}, "label_list": ["country", "event", "person", "organization", "location", "politician", "election", "political party"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 1567, 11, 1732, 11, 7471, 11, 3813, 11, 37038, 11, 6355, 11, 5054, 4717, 323, 507, 627, 85664, 25, 763, 5587, 220, 3753, 22, 1174, 11104, 55293, 6560, 1047, 13019, 264, 12458, 449, 279, 67031, 9849, 369, 9635, 323, 23782, 2403, 2380, 3682, 8013, 51371, 1174, 507, 5972, 309, 1174, 5111, 389, 24133, 1174, 323, 9052, 38505, 21039, 430, 814, 1051, 6532, 304, 5054, 55927, 990, 320, 902, 574, 1243, 26102, 311, 6560, 23693, 2383, 883, 304, 1862, 315, 2163, 29480, 11351, 4245, 311, 872, 21343, 2403, 93059, 304, 4987, 10384, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "861", "dataset": "mit-movie", "split": "dev", "prediction": "find(O) meg(B-actor) ryan(I-actor) films(O) from(O) the(O) 1990s(B-year) with(O) angels(B-plot)", "instance": {"id": "861", "words": ["find", "meg", "ryan", "films", "from", "the", "1990s", "with", "angels"], "labels": ["O", "O", "O", "O", "O", "O", "B-year", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, year, trailer, review, average ratings, rating, actor, title, director, plot, song, genre and O.\nSentence: find meg ryan films from the 1990s with angels", "prompt_labels": "find(O) meg(O) ryan(O) films(O) from(O) the(O) 1990s(B-year) with(O) angels(O)"}, "label_list": ["character", "year", "trailer", "review", "average ratings", "rating", "actor", "title", "director", "plot", "song", "genre"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 1060, 11, 19809, 11, 3477, 11, 5578, 18594, 11, 10959, 11, 12360, 11, 2316, 11, 7690, 11, 7234, 11, 5609, 11, 17779, 323, 507, 627, 85664, 25, 1505, 19262, 436, 8503, 12631, 505, 279, 220, 2550, 15, 82, 449, 46968, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1055", "dataset": "mit-restaurant", "split": "dev", "prediction": "show(O) me(O) all(O) of(O) the(O) local(B-Location) restaurants(O) with(O) a(O) smoking(B-Amenity) area(I-Amenity)", "instance": {"id": "1055", "words": ["show", "me", "all", "of", "the", "local", "restaurants", "with", "a", "smoking", "area"], "labels": ["O", "O", "O", "O", "O", "B-Location", "O", "O", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Dish, Restaurant Name, Rating, Price, Hours, Location, Amenity and O.\nSentence: show me all of the local restaurants with a smoking area", "prompt_labels": "show(O) me(O) all(O) of(O) the(O) local(B-Location) restaurants(O) with(O) a(O) smoking(B-Amenity) area(I-Amenity)"}, "label_list": ["Cuisine", "Dish", "Restaurant Name", "Rating", "Price", "Hours", "Location", "Amenity"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 49268, 11, 26568, 4076, 11, 19767, 11, 8650, 11, 30192, 11, 10067, 11, 3383, 56685, 323, 507, 627, 85664, 25, 1501, 757, 682, 315, 279, 2254, 15926, 449, 264, 20149, 3158, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1425", "dataset": "mit-movie", "split": "dev", "prediction": "in(O) the(O) past(B-year) seven(I-year) decades(I-year) was(O) mimi(B-actor) rogers(I-actor) an(O) many(O) adventure(B-genre) films(O)", "instance": {"id": "1425", "words": ["in", "the", "past", "seven", "decades", "was", "mimi", "rogers", "an", "many", "adventure", "films"], "labels": ["O", "O", "B-year", "I-year", "I-year", "O", "B-actor", "I-actor", "O", "O", "B-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, rating, review, director, title, trailer, genre, character, average ratings, song, plot, actor and O.\nSentence: in the past seven decades was mimi rogers an many adventure films", "prompt_labels": "in(O) the(O) past(B-year) seven(I-year) decades(I-year) was(O) mimi(B-actor) rogers(I-actor) an(O) many(O) adventure(B-genre) films(O)"}, "label_list": ["year", "rating", "review", "director", "title", "trailer", "genre", "character", "average ratings", "song", "plot", "actor"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 10959, 11, 3477, 11, 7690, 11, 2316, 11, 19809, 11, 17779, 11, 3752, 11, 5578, 18594, 11, 5609, 11, 7234, 11, 12360, 323, 507, 627, 85664, 25, 304, 279, 3347, 8254, 11026, 574, 296, 25877, 938, 10863, 459, 1690, 18427, 12631, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "290", "dataset": "mit-restaurant", "split": "dev", "prediction": "does(O) midys(B-Restaurant Name) have(O) takeout(B-Amenity)", "instance": {"id": "290", "words": ["does", "midys", "have", "takeout"], "labels": ["O", "B-Restaurant Name", "O", "B-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Rating, Hours, Price, Amenity, Restaurant Name, Dish, Location and O.\nSentence: does midys have takeout", "prompt_labels": "does(O) midys(B-Restaurant Name) have(O) takeout(B-Amenity)"}, "label_list": ["Cuisine", "Rating", "Hours", "Price", "Amenity", "Restaurant Name", "Dish", "Location"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 19767, 11, 30192, 11, 8650, 11, 3383, 56685, 11, 26568, 4076, 11, 49268, 11, 10067, 323, 507, 627, 85664, 25, 1587, 5209, 1065, 617, 1935, 412, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "247", "dataset": "mit-restaurant", "split": "dev", "prediction": "do(O) they(O) have(O) any(O) restaurants(O) in(B-Location) the(I-Location) mall(I-Location)", "instance": {"id": "247", "words": ["do", "they", "have", "any", "restaurants", "in", "the", "mall"], "labels": ["O", "O", "O", "O", "O", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Cuisine, Price, Amenity, Hours, Restaurant Name, Location, Rating and O.\nSentence: do they have any restaurants in the mall", "prompt_labels": "do(O) they(O) have(O) any(O) restaurants(O) in(B-Location) the(I-Location) mall(I-Location)"}, "label_list": ["Dish", "Cuisine", "Price", "Amenity", "Hours", "Restaurant Name", "Location", "Rating"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 81961, 11, 8650, 11, 3383, 56685, 11, 30192, 11, 26568, 4076, 11, 10067, 11, 19767, 323, 507, 627, 85664, 25, 656, 814, 617, 904, 15926, 304, 279, 34353, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "353", "dataset": "crossner_politics", "split": "dev", "prediction": "Campbell(B-politician)'s(O) Progressive(B-political party) Conservatives(I-political party) and(O) McLaughlin(B-politician)'s(O) New(B-political party) Democratic(I-political party) Party(I-political party) were(O) decimated(O) in(O) 1993(O),(O) both(O) failing(O) to(O) reach(O) official(O) party(O) status(O),(O) and(O) Lyn(B-politician) McLeod(I-politician) '(O) s(O) Ontario(B-political party) Liberal(I-political party) Party(I-political party) lost(O) the(O) 1995(B-election) Ontario(I-election) general(I-election) election(I-election) despite(O) having(O) more(O) than(O) a(O) 10(O) per(O) cent(O) lead(O) in(O) the(O) polls(O) when(O) the(O) election(O) was(O) called(O).(O)", "instance": {"id": "353", "words": ["Campbell", "'s", "Progressive", "Conservatives", "and", "McLaughlin", "'s", "New", "Democratic", "Party", "were", "decimated", "in", "1993", ",", "both", "failing", "to", "reach", "official", "party", "status", ",", "and", "Lyn", "McLeod", "'", "s", "Ontario", "Liberal", "Party", "lost", "the", "1995", "Ontario", "general", "election", "despite", "having", "more", "than", "a", "10", "per", "cent", "lead", "in", "the", "polls", "when", "the", "election", "was", "called", "."], "labels": ["B-politician", "O", "B-political party", "I-political party", "O", "B-politician", "O", "B-political party", "I-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-politician", "I-politician", "O", "O", "B-political party", "I-political party", "I-political party", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, country, politician, event, political party, location, election, person and O.\nSentence: Campbell 's Progressive Conservatives and McLaughlin 's New Democratic Party were decimated in 1993 , both failing to reach official party status , and Lyn McLeod ' s Ontario Liberal Party lost the 1995 Ontario general election despite having more than a 10 per cent lead in the polls when the election was called .", "prompt_labels": "Campbell(B-politician) 's(O) Progressive(B-political party) Conservatives(I-political party) and(O) McLaughlin(B-politician) 's(O) New(B-political party) Democratic(I-political party) Party(I-political party) were(O) decimated(O) in(O) 1993(O) ,(O) both(O) failing(O) to(O) reach(O) official(O) party(O) status(O) ,(O) and(O) Lyn(B-politician) McLeod(I-politician) '(O) s(O) Ontario(B-political party) Liberal(I-political party) Party(I-political party) lost(O) the(O) 1995(B-election) Ontario(I-election) general(I-election) election(I-election) despite(O) having(O) more(O) than(O) a(O) 10(O) per(O) cent(O) lead(O) in(O) the(O) polls(O) when(O) the(O) election(O) was(O) called(O) .(O)"}, "label_list": ["organization", "country", "politician", "event", "political party", "location", "election", "person"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 3224, 11, 37038, 11, 1567, 11, 5054, 4717, 11, 3813, 11, 6355, 11, 1732, 323, 507, 627, 85664, 25, 30524, 364, 82, 52870, 49344, 323, 4584, 84967, 3817, 364, 82, 1561, 11650, 8722, 1051, 1654, 7292, 304, 220, 2550, 18, 1174, 2225, 22109, 311, 5662, 4033, 4717, 2704, 1174, 323, 21820, 4584, 95590, 364, 274, 21193, 31158, 8722, 5675, 279, 220, 2550, 20, 21193, 4689, 6355, 8994, 3515, 810, 1109, 264, 220, 605, 824, 2960, 3063, 304, 279, 23925, 994, 279, 6355, 574, 2663, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1783", "dataset": "mit-movie", "split": "dev", "prediction": "tim(B-actor) abell(I-actor) was(O) featured(O) in(O) what(O) g(B-rating) rated(O) 1970(B-year) s(I-year) italian(B-plot) american(I-plot) film(O) with(O) an(O) average(O) rating(O) of(O) four(B-average ratings)", "instance": {"id": "1783", "words": ["tim", "abell", "was", "featured", "in", "what", "g", "rated", "1970", "s", "italian", "american", "film", "with", "an", "average", "rating", "of", "four"], "labels": ["B-actor", "I-actor", "O", "O", "O", "O", "B-rating", "O", "B-year", "O", "B-plot", "I-plot", "O", "O", "O", "O", "O", "O", "B-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, review, average ratings, director, rating, title, song, actor, year, plot, character, trailer and O.\nSentence: tim abell was featured in what g rated 1970 s italian american film with an average rating of four", "prompt_labels": "tim(B-actor) abell(I-actor) was(O) featured(O) in(O) what(O) g(B-rating) rated(O) 1970(B-year) s(O) italian(B-plot) american(I-plot) film(O) with(O) an(O) average(O) rating(O) of(O) four(B-average ratings)"}, "label_list": ["genre", "review", "average ratings", "director", "rating", "title", "song", "actor", "year", "plot", "character", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 3477, 11, 5578, 18594, 11, 7690, 11, 10959, 11, 2316, 11, 5609, 11, 12360, 11, 1060, 11, 7234, 11, 3752, 11, 19809, 323, 507, 627, 85664, 25, 6935, 671, 616, 574, 15109, 304, 1148, 342, 22359, 220, 4468, 15, 274, 29048, 39542, 4632, 449, 459, 5578, 10959, 315, 3116, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "199", "dataset": "crossner_politics", "split": "dev", "prediction": "1885(O) boundaries(O) were(O) also(O) used(O) in(O) the(O) 1886(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) the(O) 1892(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) the(O) 1895(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) the(O) 1900(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) the(O) 1906(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election),(O) the(O) January(B-election) 1910(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) the(O) December(B-election) 1910(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election).(O)", "instance": {"id": "199", "words": ["1885", "boundaries", "were", "also", "used", "in", "the", "1886", "United", "Kingdom", "general", "election", ",", "the", "1892", "United", "Kingdom", "general", "election", ",", "the", "1895", "United", "Kingdom", "general", "election", ",", "the", "1900", "United", "Kingdom", "general", "election", ",", "the", "1906", "United", "Kingdom", "general", "election", ",", "the", "January", "1910", "United", "Kingdom", "general", "election", "and", "the", "December", "1910", "United", "Kingdom", "general", "election", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "I-election", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, person, event, politician, organization, country, election, political party and O.\nSentence: 1885 boundaries were also used in the 1886 United Kingdom general election , the 1892 United Kingdom general election , the 1895 United Kingdom general election , the 1900 United Kingdom general election , the 1906 United Kingdom general election , the January 1910 United Kingdom general election and the December 1910 United Kingdom general election .", "prompt_labels": "1885(O) boundaries(O) were(O) also(O) used(O) in(O) the(O) 1886(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1892(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1895(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1900(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1906(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) January(B-election) 1910(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) the(O) December(B-election) 1910(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)"}, "label_list": ["location", "person", "event", "politician", "organization", "country", "election", "political party"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 1732, 11, 1567, 11, 37038, 11, 7471, 11, 3224, 11, 6355, 11, 5054, 4717, 323, 507, 627, 85664, 25, 220, 9367, 20, 23546, 1051, 1101, 1511, 304, 279, 220, 9367, 21, 3723, 15422, 4689, 6355, 1174, 279, 220, 9378, 17, 3723, 15422, 4689, 6355, 1174, 279, 220, 9378, 20, 3723, 15422, 4689, 6355, 1174, 279, 220, 7028, 15, 3723, 15422, 4689, 6355, 1174, 279, 220, 7028, 21, 3723, 15422, 4689, 6355, 1174, 279, 6186, 220, 7529, 15, 3723, 15422, 4689, 6355, 323, 279, 6790, 220, 7529, 15, 3723, 15422, 4689, 6355, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "57", "dataset": "mit-movie", "split": "dev", "prediction": "find(O) me(O) comedy(B-genre) movies(I-genre) with(O) liam(B-actor) hemsworth(I-actor)", "instance": {"id": "57", "words": ["find", "me", "comedy", "movies", "with", "liam", "hemsworth"], "labels": ["O", "O", "B-genre", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, rating, review, title, actor, year, plot, genre, trailer, character, director, song and O.\nSentence: find me comedy movies with liam hemsworth", "prompt_labels": "find(O) me(O) comedy(B-genre) movies(O) with(O) liam(B-actor) hemsworth(I-actor)"}, "label_list": ["average ratings", "rating", "review", "title", "actor", "year", "plot", "genre", "trailer", "character", "director", "song"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 10959, 11, 3477, 11, 2316, 11, 12360, 11, 1060, 11, 7234, 11, 17779, 11, 19809, 11, 3752, 11, 7690, 11, 5609, 323, 507, 627, 85664, 25, 1505, 757, 23160, 9698, 449, 908, 309, 17728, 61831, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "214", "dataset": "crossner_music", "split": "dev", "prediction": "British psychedelic(B-music genre) /(O) progressive(B-music genre) rock(I-music genre) band(O) Knifeworld(B-band) features(O) the(O) bassoon(O) playing(O) of(O) Chloe(B-musical artist) Herrington(I-musical artist),(O) who(O) also(O) plays(O) for(O) experimental(O) Baroque(B-music genre) pop(I-music genre) orchestra(O) Chrome(B-band) Hoof(I-band).(O)", "instance": {"id": "214", "words": ["British", "psychedelic", "/", "progressive", "rock", "band", "Knifeworld", "features", "the", "bassoon", "playing", "of", "Chloe", "Herrington", ",", "who", "also", "plays", "for", "experimental", "Baroque", "pop", "orchestra", "Chrome", "Hoof", "."], "labels": ["B-music genre", "I-music genre", "O", "B-music genre", "I-music genre", "O", "B-band", "O", "O", "B-musical instrument", "O", "O", "B-musical artist", "I-musical artist", "O", "O", "O", "O", "O", "O", "B-music genre", "I-music genre", "O", "B-band", "I-band", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, location, song, person, musical instrument, musical artist, award, event, music genre, organization, country, band and O.\nSentence: British psychedelic / progressive rock band Knifeworld features the bassoon playing of Chloe Herrington , who also plays for experimental Baroque pop orchestra Chrome Hoof .", "prompt_labels": "British(B-music genre) psychedelic(I-music genre) /(O) progressive(B-music genre) rock(I-music genre) band(O) Knifeworld(B-band) features(O) the(O) bassoon(B-musical instrument) playing(O) of(O) Chloe(B-musical artist) Herrington(I-musical artist) ,(O) who(O) also(O) plays(O) for(O) experimental(O) Baroque(B-music genre) pop(I-music genre) orchestra(O) Chrome(B-band) Hoof(I-band) .(O)"}, "label_list": ["album", "location", "song", "person", "musical instrument", "musical artist", "award", "event", "music genre", "organization", "country", "band"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8176, 11, 3813, 11, 5609, 11, 1732, 11, 18273, 14473, 11, 18273, 10255, 11, 10292, 11, 1567, 11, 4731, 17779, 11, 7471, 11, 3224, 11, 7200, 323, 507, 627, 85664, 25, 8013, 82082, 611, 23053, 7091, 7200, 13934, 333, 96872, 4519, 279, 22253, 9186, 5737, 315, 60470, 43350, 4910, 1174, 889, 1101, 11335, 369, 22772, 4821, 61652, 2477, 69155, 17669, 17723, 1073, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "283", "dataset": "mit-movie", "split": "dev", "prediction": "i(O) am(O) looking(O) for(O) a(O) movie(O) starring(O) elvis(B-actor) with(O) scenes(B-plot) at(I-plot) a(I-plot) beach(I-plot)", "instance": {"id": "283", "words": ["i", "am", "looking", "for", "a", "movie", "starring", "elvis", "with", "scenes", "at", "a", "beach"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-actor", "O", "O", "O", "O", "B-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, song, review, genre, actor, plot, year, average ratings, character, director, title, trailer and O.\nSentence: i am looking for a movie starring elvis with scenes at a beach", "prompt_labels": "i(O) am(O) looking(O) for(O) a(O) movie(O) starring(O) elvis(B-actor) with(O) scenes(O) at(O) a(O) beach(B-plot)"}, "label_list": ["rating", "song", "review", "genre", "actor", "plot", "year", "average ratings", "character", "director", "title", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 5609, 11, 3477, 11, 17779, 11, 12360, 11, 7234, 11, 1060, 11, 5578, 18594, 11, 3752, 11, 7690, 11, 2316, 11, 19809, 323, 507, 627, 85664, 25, 602, 1097, 3411, 369, 264, 5818, 40500, 658, 2749, 449, 16451, 520, 264, 11573, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "808", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) a(O) chinese(B-Cuisine) restaurant(O) in(B-Location) the(I-Location) midvale(I-Location) mall(I-Location)", "instance": {"id": "808", "words": ["is", "there", "a", "chinese", "restaurant", "in", "the", "midvale", "mall"], "labels": ["O", "O", "O", "B-Cuisine", "O", "O", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Amenity, Location, Restaurant Name, Dish, Rating, Cuisine, Price and O.\nSentence: is there a chinese restaurant in the midvale mall", "prompt_labels": "is(O) there(O) a(O) chinese(B-Cuisine) restaurant(O) in(O) the(O) midvale(B-Location) mall(I-Location)"}, "label_list": ["Hours", "Amenity", "Location", "Restaurant Name", "Dish", "Rating", "Cuisine", "Price"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 3383, 56685, 11, 10067, 11, 26568, 4076, 11, 49268, 11, 19767, 11, 81961, 11, 8650, 323, 507, 627, 85664, 25, 374, 1070, 264, 57487, 10960, 304, 279, 5209, 78829, 34353, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "276", "dataset": "mit-movie", "split": "dev", "prediction": "show(O) me(O) listing(O) that(O) have(O) micheal(B-actor) in(O) them(O)", "instance": {"id": "276", "words": ["show", "me", "listing", "that", "have", "micheal", "in", "them"], "labels": ["O", "O", "O", "O", "O", "B-actor", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, actor, trailer, plot, character, average ratings, title, rating, review, director, song, year and O.\nSentence: show me listing that have micheal in them", "prompt_labels": "show(O) me(O) listing(O) that(O) have(O) micheal(B-actor) in(O) them(O)"}, "label_list": ["genre", "actor", "trailer", "plot", "character", "average ratings", "title", "rating", "review", "director", "song", "year"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 12360, 11, 19809, 11, 7234, 11, 3752, 11, 5578, 18594, 11, 2316, 11, 10959, 11, 3477, 11, 7690, 11, 5609, 11, 1060, 323, 507, 627, 85664, 25, 1501, 757, 15182, 430, 617, 296, 12333, 278, 304, 1124, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "859", "dataset": "mit-restaurant", "split": "dev", "prediction": "is(O) there(O) a(O) restaurant(O) close(B-Location) by(I-Location) that(O) has(O) dancing(B-Amenity) and(O) serves(O) scallops(B-Dish)", "instance": {"id": "859", "words": ["is", "there", "a", "restaurant", "close", "by", "that", "has", "dancing", "and", "serves", "scallops"], "labels": ["O", "O", "O", "O", "B-Location", "I-Location", "O", "O", "B-Amenity", "O", "O", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Dish, Rating, Restaurant Name, Hours, Amenity, Price, Cuisine and O.\nSentence: is there a restaurant close by that has dancing and serves scallops", "prompt_labels": "is(O) there(O) a(O) restaurant(O) close(B-Location) by(I-Location) that(O) has(O) dancing(B-Amenity) and(O) serves(O) scallops(B-Dish)"}, "label_list": ["Location", "Dish", "Rating", "Restaurant Name", "Hours", "Amenity", "Price", "Cuisine"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 49268, 11, 19767, 11, 26568, 4076, 11, 30192, 11, 3383, 56685, 11, 8650, 11, 81961, 323, 507, 627, 85664, 25, 374, 1070, 264, 10960, 3345, 555, 430, 706, 29066, 323, 17482, 24964, 54789, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "600", "dataset": "mit-movie", "split": "dev", "prediction": "name(O) a(O) film(O) with(O) brian(B-actor) entwhistle(I-actor) in(O) it(O)", "instance": {"id": "600", "words": ["name", "a", "film", "with", "brian", "entwhistle", "in", "it"], "labels": ["O", "O", "O", "O", "B-actor", "I-actor", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, year, song, plot, title, genre, character, rating, director, average ratings, review, trailer and O.\nSentence: name a film with brian entwhistle in it", "prompt_labels": "name(O) a(O) film(O) with(O) brian(B-actor) entwhistle(I-actor) in(O) it(O)"}, "label_list": ["actor", "year", "song", "plot", "title", "genre", "character", "rating", "director", "average ratings", "review", "trailer"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 1060, 11, 5609, 11, 7234, 11, 2316, 11, 17779, 11, 3752, 11, 10959, 11, 7690, 11, 5578, 18594, 11, 3477, 11, 19809, 323, 507, 627, 85664, 25, 836, 264, 4632, 449, 293, 7414, 1218, 1336, 29400, 304, 433, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
{"id": "1306", "dataset": "mit-movie", "split": "dev", "prediction": "how(O) many(O) films(O) featured(O) stacey(B-actor) dash(I-actor) in(O) 1950(B-year)", "instance": {"id": "1306", "words": ["how", "many", "films", "featured", "stacey", "dash", "in", "1950"], "labels": ["O", "O", "O", "O", "B-actor", "I-actor", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, title, genre, actor, song, year, trailer, character, average ratings, review, rating, plot and O.\nSentence: how many films featured stacey dash in 1950", "prompt_labels": "how(O) many(O) films(O) featured(O) stacey(B-actor) dash(I-actor) in(O) 1950(B-year)"}, "label_list": ["director", "title", "genre", "actor", "song", "year", "trailer", "character", "average ratings", "review", "rating", "plot"], "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 2316, 11, 17779, 11, 12360, 11, 5609, 11, 1060, 11, 19809, 11, 3752, 11, 5578, 18594, 11, 3477, 11, 10959, 11, 7234, 323, 507, 627, 85664, 25, 1268, 1690, 12631, 15109, 357, 57020, 24858, 304, 220, 6280, 15, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
