[01.30 00:42:59] ┇ INFO    ┇             DeepKNLP ┇ Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: True
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ =========================================================================================================================================
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ [INIT] python task2-nerG-trainer2.py --local_rank=0 --trainer_deepspeed configs/deepspeed/ds1_llama.json
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ =========================================================================================================================================
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ -----------------------------------------------------------------------------------------------------------------------------------------
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇   #	TrainingArgumentsForAccelerator              	value
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ -----------------------------------------------------------------------------------------------------------------------------------------
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇   1	env.hostname                                 	ptlm3
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇   2	env.hostaddr                                 	129.254.121.74
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇   3	env.global_rank                              	-1
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇   4	env.local_rank                               	0
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇   5	env.node_rank                                	-1
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇   6	env.world_size                               	4
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇   7	env.time_stamp                               	0130.004254
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇   8	env.python_path                              	/home/chrisjihee/miniforge3/envs/DeepKNLP/bin/python
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇   9	env.current_dir                              	/home/chrisjihee/proj/DeepKNLP
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  10	env.current_file                             	task2-nerG-trainer2.py
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  11	env.command_args                             	['--local_rank=0', '--trainer_deepspeed', 'configs/deepspeed/ds1_llama.json']
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  12	env.output_home                              	output
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  13	env.output_name                              	GNER
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  14	env.run_version                              	EAGLE-1B-debug
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  15	env.output_file                              	train-metrics-0130.004254.csv
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  16	env.logging_file                             	train-loggings-0130.004254.out
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  17	env.logging_level                            	30
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  18	env.logging_format                           	%(asctime)s ┇ %(levelname)-7s ┇ %(name)20s ┇ %(message)s
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  19	env.datetime_format                          	[%m.%d %H:%M:%S]
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  20	env.argument_file                            	train-arguments-0130.004254.json
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  21	env.random_seed                              	7
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  22	env.max_workers                              	4
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  23	env.debugging                                	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  24	env.output_dir                               	output/GNER/EAGLE-1B-debug
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  25	time.t1                                      	2025-01-30 00:43:00.240701
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  26	time.t2                                      	2025-01-30 00:42:54.619016
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  27	time.started                                 	[01.30 00:43:00]
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  28	time.settled
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  29	time.elapsed
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  30	data.pretrained                              	etri-lirs/egpt-1.3b-preview
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  31	data.train_file                              	data/gner/zero-shot-train.jsonl
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  32	data.study_file
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  33	data.eval_file                               	data/gner/zero-shot-dev-100.jsonl
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  34	data.pred_file                               	data/gner/zero-shot-test-100.jsonl
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  35	data.max_train_samples                       	-1
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  36	data.max_study_samples                       	-1
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  37	data.max_eval_samples                        	-1
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  38	data.max_pred_samples                        	-1
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  39	data.max_source_length                       	640
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  40	data.max_target_length                       	640
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  41	data.use_cache_data                          	True
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  42	data.ignore_pad_token_for_loss               	True
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  43	train.output_dir                             	output/GNER/EAGLE-1B-debug
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  44	train.overwrite_output_dir                   	True
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  45	train.do_train                               	True
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  46	train.do_eval                                	True
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  47	train.do_predict                             	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  48	train.eval_strategy                          	IntervalStrategy.NO
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  49	train.prediction_loss_only                   	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  50	train.per_device_train_batch_size            	8
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  51	train.per_device_eval_batch_size             	8
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  52	train.per_gpu_train_batch_size
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  53	train.per_gpu_eval_batch_size
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  54	train.gradient_accumulation_steps            	4
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  55	train.eval_accumulation_steps                	4
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  56	train.eval_delay                             	0
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  57	train.torch_empty_cache_steps
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  58	train.learning_rate                          	2e-05
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  59	train.weight_decay                           	0.0
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  60	train.adam_beta1                             	0.9
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  61	train.adam_beta2                             	0.999
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  62	train.adam_epsilon                           	1e-08
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  63	train.max_grad_norm                          	1.0
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  64	train.num_train_epochs                       	1.0
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  65	train.max_steps                              	-1
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  66	train.lr_scheduler_type                      	SchedulerType.COSINE
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  67	train.lr_scheduler_kwargs                    	{}
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  68	train.warmup_ratio                           	0.04
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  69	train.warmup_steps                           	0
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  70	train.log_level                              	warning
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  71	train.log_level_replica                      	error
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  72	train.log_on_each_node                       	True
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  73	train.logging_dir                            	output/GNER/EAGLE-1B-debug/runs/Jan30_00-42-58_ptlm3
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  74	train.logging_strategy                       	IntervalStrategy.NO
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  75	train.logging_first_step                     	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  76	train.logging_steps                          	0.1
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  77	train.logging_nan_inf_filter                 	True
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  78	train.save_strategy                          	SaveStrategy.NO
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  79	train.save_steps                             	9223372036854775807
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  80	train.save_total_limit
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  81	train.save_safetensors                       	True
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  82	train.save_on_each_node                      	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  83	train.save_only_model                        	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  84	train.restore_callback_states_from_checkpoint	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  85	train.no_cuda                                	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  86	train.use_cpu                                	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  87	train.use_mps_device                         	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  88	train.seed                                   	7
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  89	train.data_seed
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  90	train.jit_mode_eval                          	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  91	train.use_ipex                               	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  92	train.bf16                                   	True
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  93	train.fp16                                   	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  94	train.fp16_opt_level                         	O1
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  95	train.half_precision_backend                 	auto
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  96	train.bf16_full_eval                         	True
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  97	train.fp16_full_eval                         	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  98	train.tf32                                   	True
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇  99	train.local_rank                             	0
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 100	train.ddp_backend
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 101	train.tpu_num_cores
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 102	train.tpu_metrics_debug                      	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 103	train.debug                                  	[]
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 104	train.dataloader_drop_last                   	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 105	train.eval_steps                             	0.3333333333333333
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 106	train.dataloader_num_workers                 	0
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 107	train.dataloader_prefetch_factor
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 108	train.past_index                             	-1
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 109	train.run_name                               	output/GNER/EAGLE-1B-debug
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 110	train.disable_tqdm                           	True
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 111	train.remove_unused_columns                  	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 112	train.label_names
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 113	train.load_best_model_at_end                 	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 114	train.metric_for_best_model
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 115	train.greater_is_better
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 116	train.ignore_data_skip                       	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 117	train.fsdp                                   	[]
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 118	train.fsdp_min_num_params                    	0
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 119	train.fsdp_config                            	{'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 120	train.fsdp_transformer_layer_cls_to_wrap
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 121	train.accelerator_config                     	{'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False}
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 122	train.deepspeed                              	configs/deepspeed/ds1_llama.json
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 123	train.label_smoothing_factor                 	0.0
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 124	train.optim                                  	OptimizerNames.ADAMW_TORCH
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 125	train.optim_args
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 126	train.adafactor                              	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 127	train.group_by_length                        	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 128	train.length_column_name                     	length
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 129	train.report_to                              	[]
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 130	train.ddp_find_unused_parameters
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 131	train.ddp_bucket_cap_mb
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 132	train.ddp_broadcast_buffers
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 133	train.dataloader_pin_memory                  	True
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 134	train.dataloader_persistent_workers          	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 135	train.skip_memory_metrics                    	True
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 136	train.use_legacy_prediction_loop             	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 137	train.push_to_hub                            	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 138	train.resume_from_checkpoint
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 139	train.hub_model_id
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 140	train.hub_strategy                           	HubStrategy.EVERY_SAVE
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 141	train.hub_token
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 142	train.hub_private_repo
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 143	train.hub_always_push                        	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 144	train.gradient_checkpointing                 	True
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 145	train.gradient_checkpointing_kwargs
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 146	train.include_inputs_for_metrics             	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 147	train.include_for_metrics                    	[]
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 148	train.eval_do_concat_batches                 	True
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 149	train.fp16_backend                           	auto
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 150	train.evaluation_strategy
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 151	train.push_to_hub_model_id
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 152	train.push_to_hub_organization
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 153	train.push_to_hub_token
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 154	train._n_gpu                                 	1
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 155	train.mp_parameters
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 156	train.auto_find_batch_size                   	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 157	train.full_determinism                       	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 158	train.torchdynamo
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 159	train.ray_scope                              	last
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 160	train.ddp_timeout                            	1800
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 161	train.torch_compile                          	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 162	train.torch_compile_backend
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 163	train.torch_compile_mode
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 164	train.dispatch_batches
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 165	train.split_batches
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 166	train.include_tokens_per_second              	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 167	train.include_num_input_tokens_seen          	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 168	train.neftune_noise_alpha
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 169	train.optim_target_modules
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 170	train.batch_eval_metrics                     	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 171	train.eval_on_start                          	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 172	train.use_liger_kernel                       	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 173	train.eval_use_gather_object                 	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 174	train.average_tokens_across_devices          	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 175	train.sortish_sampler                        	False
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 176	train.predict_with_generate                  	True
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 177	train.generation_max_length                  	640
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 178	train.generation_num_beams
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ 179	train.generation_config
[01.30 00:43:00] ┇ INFO    ┇       chrisbase.data ┇ -----------------------------------------------------------------------------------------------------------------------------------------
[01.30 00:43:06] ┇ INFO    ┇             DeepKNLP ┇ type(model)=<class 'transformers.models.gpt_neox.modeling_gpt_neox.GPTNeoXForCausalLM'>
[01.30 00:43:06] ┇ INFO    ┇             DeepKNLP ┇ model.generation_config.pad_token_id=0
[01.30 00:43:06] ┇ INFO    ┇             DeepKNLP ┇ Loaded raw train_dataset (#=18135): data/gner/zero-shot-train.jsonl
[01.30 00:43:06] ┇ INFO    ┇             DeepKNLP ┇ Completed preprocessing for train_dataset at [01.29 17:08:17]
[01.30 00:43:07] ┇ INFO    ┇             DeepKNLP ┇ Loaded raw eval_dataset (#=700): data/gner/zero-shot-dev-100.jsonl
[01.30 00:43:07] ┇ INFO    ┇             DeepKNLP ┇ Completed preprocessing for eval_dataset at [01.29 17:08:21]
[01.30 00:43:07] ┇ INFO    ┇ transformers.trainer ┇ Using auto half precision backend
[01.30 00:43:07] ┇ INFO    ┇             DeepKNLP ┇ Using deepspeed configuration:
{
  "fp16": {
    "enabled": false
  },
  "bf16": {
    "enabled": true
  },
  "optimizer": {
    "type": "AdamW",
    "params": {
      "lr": 2e-05,
      "betas": [
        0.9,
        0.999
      ],
      "eps": 1e-08,
      "weight_decay": 0.0
    }
  },
  "scheduler": {
    "type": "WarmupDecayLR",
    "params": {
      "warmup_min_lr": 0,
      "warmup_max_lr": 2e-05,
      "warmup_num_steps": "auto",
      "total_num_steps": "auto"
    }
  },
  "zero_optimization": {
    "stage": 1,
    "allgather_partitions": true,
    "allgather_bucket_size": 200000000.0,
    "overlap_comm": true,
    "reduce_scatter": true,
    "reduce_bucket_size": 200000000.0,
    "contiguous_gradients": true
  },
  "gradient_accumulation_steps": 4,
  "gradient_clipping": 1.0,
  "train_batch_size": 128,
  "train_micro_batch_size_per_gpu": 8,
  "steps_per_print": Infinity
}
[01.30 00:43:16] ┇ WARNING ┇            DeepSpeed ┇ Attempting to get learning rate from scheduler before it has started
[01.30 00:43:16] ┇ INFO    ┇ transformers.trainer ┇ ***** Running training *****
[01.30 00:43:16] ┇ INFO    ┇ transformers.trainer ┇   Num examples = 18,135
[01.30 00:43:16] ┇ INFO    ┇ transformers.trainer ┇   Num Epochs = 1
[01.30 00:43:16] ┇ INFO    ┇ transformers.trainer ┇   Instantaneous batch size per device = 8
[01.30 00:43:16] ┇ INFO    ┇ transformers.trainer ┇   Total train batch size (w. parallel, distributed & accumulation) = 128
[01.30 00:43:16] ┇ INFO    ┇ transformers.trainer ┇   Gradient Accumulation steps = 4
[01.30 00:43:16] ┇ INFO    ┇ transformers.trainer ┇   Total optimization steps = 141
[01.30 00:43:16] ┇ INFO    ┇ transformers.trainer ┇   Number of trainable parameters = 1,341,247,488
[01.30 00:43:20] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]   1%|▏                   |   1/141 [0:00:03<0:08:35, 0.27Hz] | (Ep 0.007)
[01.30 00:43:23] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]   1%|▎                   |   2/141 [0:00:06<0:07:13, 0.32Hz] | (Ep 0.014)
[01.30 00:43:27] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]   3%|▌                   |   4/141 [0:00:10<0:05:54, 0.39Hz] | (Ep 0.028)
[01.30 00:43:29] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]   4%|▋                   |   5/141 [0:00:12<0:05:43, 0.40Hz] | (Ep 0.035)
[01.30 00:43:31] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]   4%|▊                   |   6/141 [0:00:14<0:05:37, 0.40Hz] | (Ep 0.043)
[01.30 00:43:35] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]   6%|█▏                  |   8/141 [0:00:19<0:05:16, 0.42Hz] | (Ep 0.057)
[01.30 00:43:38] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]   6%|█▎                  |   9/141 [0:00:21<0:05:11, 0.42Hz] | (Ep 0.064)
[01.30 00:43:40] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]   7%|█▍                  |  10/141 [0:00:23<0:05:05, 0.43Hz] | (Ep 0.071)
[01.30 00:43:43] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]   9%|█▋                  |  12/141 [0:00:26<0:04:49, 0.45Hz] | (Ep 0.085)
[01.30 00:43:47] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  10%|█▉                  |  14/141 [0:00:31<0:04:41, 0.45Hz] | (Ep 0.099)
[01.30 00:43:47] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    loss    grad_norm    learning_rate
[01.30 00:43:47] ┇ INFO    ┇             DeepKNLP ┇ >>     14    0.099  0.7257     0.636308       1.8963e-05
[01.30 00:43:51] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  11%|██▎                 |  16/141 [0:00:34<0:04:32, 0.46Hz] | (Ep 0.113)
[01.30 00:43:55] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  13%|██▌                 |  18/141 [0:00:38<0:04:23, 0.47Hz] | (Ep 0.128)
[01.30 00:43:57] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  13%|██▋                 |  19/141 [0:00:40<0:04:21, 0.47Hz] | (Ep 0.135)
[01.30 00:44:01] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  15%|██▉                 |  21/141 [0:00:44<0:04:16, 0.47Hz] | (Ep 0.149)
[01.30 00:44:05] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  16%|███▎                |  23/141 [0:00:48<0:04:10, 0.47Hz] | (Ep 0.163)
[01.30 00:44:09] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  18%|███▌                |  25/141 [0:00:52<0:04:04, 0.47Hz] | (Ep 0.177)
[01.30 00:44:11] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  18%|███▋                |  26/141 [0:00:54<0:04:02, 0.47Hz] | (Ep 0.184)
[01.30 00:44:13] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  19%|███▊                |  27/141 [0:00:56<0:04:00, 0.47Hz] | (Ep 0.191)
[01.30 00:44:15] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  20%|███▉                |  28/141 [0:00:59<0:03:58, 0.47Hz] | (Ep 0.199)
[01.30 00:44:15] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    loss    grad_norm    learning_rate
[01.30 00:44:15] ┇ INFO    ┇             DeepKNLP ┇ >>     28    0.199  0.0809     0.167124      1.68889e-05
[01.30 00:44:18] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  21%|████                |  29/141 [0:01:01<0:03:57, 0.47Hz] | (Ep 0.206)
[01.30 00:44:20] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  21%|████▎               |  30/141 [0:01:03<0:03:55, 0.47Hz] | (Ep 0.213)
[01.30 00:44:22] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  22%|████▍               |  31/141 [0:01:05<0:03:53, 0.47Hz] | (Ep 0.220)
[01.30 00:44:26] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  23%|████▋               |  33/141 [0:01:09<0:03:47, 0.47Hz] | (Ep 0.234)
[01.30 00:44:30] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  25%|████▉               |  35/141 [0:01:13<0:03:42, 0.48Hz] | (Ep 0.248)
[01.30 00:44:34] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  26%|█████▏              |  37/141 [0:01:17<0:03:37, 0.48Hz] | (Ep 0.262)
[01.30 00:44:36] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  27%|█████▍              |  38/141 [0:01:19<0:03:35, 0.48Hz] | (Ep 0.270)
[01.30 00:44:40] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  28%|█████▋              |  40/141 [0:01:23<0:03:30, 0.48Hz] | (Ep 0.284)
[01.30 00:44:44] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  30%|█████▉              |  42/141 [0:01:27<0:03:27, 0.48Hz] | (Ep 0.298)
[01.30 00:44:44] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    loss    grad_norm    learning_rate
[01.30 00:44:44] ┇ INFO    ┇             DeepKNLP ┇ >>     42    0.298   0.052     0.182025      1.48148e-05
[01.30 00:44:47] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  30%|██████              |  43/141 [0:01:30<0:03:25, 0.48Hz] | (Ep 0.305)
[01.30 00:44:49] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  31%|██████▏             |  44/141 [0:01:32<0:03:23, 0.48Hz] | (Ep 0.312)
[01.30 00:44:52] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  33%|██████▌             |  46/141 [0:01:35<0:03:18, 0.48Hz] | (Ep 0.326)
[01.30 00:44:55] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  33%|██████▋             |  47/141 [0:01:38<0:03:16, 0.48Hz] | (Ep 0.333)
[01.30 00:44:55] ┇ INFO    ┇ transformers.trainer ┇ ***** Running Evaluation *****
[01.30 00:44:55] ┇ INFO    ┇ transformers.trainer ┇   Num examples = 700
[01.30 00:44:55] ┇ INFO    ┇ transformers.trainer ┇   Batch size = 8
[01.30 00:45:01] ┇ INFO    ┇             DeepKNLP ┇ [METERING]   5%|▉                   |  1/22 [0:00:00<0:00:00, 96720.43Hz]
[01.30 00:45:07] ┇ INFO    ┇             DeepKNLP ┇ [METERING]   9%|█▊                  |  2/22 [0:00:05<0:00:59, 0.34Hz]
[01.30 00:45:12] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  14%|██▋                 |  3/22 [0:00:11<0:01:12, 0.26Hz]
[01.30 00:45:18] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  18%|███▋                |  4/22 [0:00:17<0:01:17, 0.23Hz]
[01.30 00:45:24] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  23%|████▌               |  5/22 [0:00:23<0:01:18, 0.22Hz]
[01.30 00:45:29] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  27%|█████▍              |  6/22 [0:00:28<0:01:16, 0.21Hz]
[01.30 00:45:35] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  32%|██████▎             |  7/22 [0:00:34<0:01:14, 0.20Hz]
[01.30 00:45:41] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  36%|███████▎            |  8/22 [0:00:40<0:01:11, 0.20Hz]
[01.30 00:45:47] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  41%|████████▏           |  9/22 [0:00:46<0:01:07, 0.19Hz]
[01.30 00:45:53] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  45%|█████████           | 10/22 [0:00:52<0:01:03, 0.19Hz]
[01.30 00:45:59] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  50%|██████████          | 11/22 [0:00:58<0:00:58, 0.19Hz]
[01.30 00:46:06] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  55%|██████████▉         | 12/22 [0:01:04<0:00:53, 0.19Hz]
[01.30 00:46:12] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  59%|███████████▊        | 13/22 [0:01:10<0:00:49, 0.18Hz]
[01.30 00:46:18] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  64%|████████████▋       | 14/22 [0:01:17<0:00:44, 0.18Hz]
[01.30 00:46:24] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  68%|█████████████▋      | 15/22 [0:01:23<0:00:38, 0.18Hz]
[01.30 00:46:30] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  73%|██████████████▌     | 16/22 [0:01:29<0:00:33, 0.18Hz]
[01.30 00:46:33] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  82%|████████████████▎   | 18/22 [0:01:32<0:00:20, 0.19Hz]
[01.30 00:46:37] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  91%|██████████████████▏ | 20/22 [0:01:35<0:00:09, 0.21Hz]
[01.30 00:46:39] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  95%|███████████████████ | 21/22 [0:01:37<0:00:04, 0.21Hz]
[01.30 00:46:44] ┇ INFO    ┇             DeepKNLP ┇ [METERING] 100%|████████████████████| 22/22 [0:01:42<0:00:00, 0.21Hz]
[01.30 00:46:45] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    eval_crossner_ai    eval_crossner_literature    eval_crossner_music    eval_crossner_politics    eval_crossner_science    eval_mit-movie    eval_mit-restaurant    eval_AVERAGE    eval_runtime    eval_samples_per_second    eval_steps_per_second
[01.30 00:46:45] ┇ INFO    ┇             DeepKNLP ┇ >>     47    0.333            0.262295                    0.428571                0.34981                  0.432738                 0.416766          0.828431               0.683417        0.486004         109.891                       6.37                      0.2
[01.30 00:46:47] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  34%|██████▊             |  48/141 [0:03:30<0:06:47, 0.23Hz] | (Ep 0.340)
[01.30 00:46:49] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  35%|██████▉             |  49/141 [0:03:32<0:06:39, 0.23Hz] | (Ep 0.348)
[01.30 00:46:52] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  35%|███████             |  50/141 [0:03:35<0:06:31, 0.23Hz] | (Ep 0.355)
[01.30 00:46:55] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  37%|███████▍            |  52/141 [0:03:39<0:06:15, 0.24Hz] | (Ep 0.369)
[01.30 00:46:58] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  38%|███████▌            |  53/141 [0:03:41<0:06:07, 0.24Hz] | (Ep 0.376)
[01.30 00:47:00] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  38%|███████▋            |  54/141 [0:03:43<0:05:59, 0.24Hz] | (Ep 0.383)
[01.30 00:47:04] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  40%|███████▉            |  56/141 [0:03:47<0:05:45, 0.25Hz] | (Ep 0.397)
[01.30 00:47:04] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    loss    grad_norm    learning_rate
[01.30 00:47:04] ┇ INFO    ┇             DeepKNLP ┇ >>     56    0.397  0.0411     0.136252      1.27407e-05
[01.30 00:47:08] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  41%|████████▏           |  58/141 [0:03:51<0:05:31, 0.25Hz] | (Ep 0.411)
[01.30 00:47:10] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  42%|████████▎           |  59/141 [0:03:54<0:05:25, 0.25Hz] | (Ep 0.418)
[01.30 00:47:13] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  43%|████████▌           |  60/141 [0:03:56<0:05:18, 0.25Hz] | (Ep 0.426)
[01.30 00:47:16] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  44%|████████▊           |  62/141 [0:04:00<0:05:05, 0.26Hz] | (Ep 0.440)
[01.30 00:47:18] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  45%|████████▉           |  63/141 [0:04:02<0:04:59, 0.26Hz] | (Ep 0.447)
[01.30 00:47:21] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  45%|█████████           |  64/141 [0:04:04<0:04:54, 0.26Hz] | (Ep 0.454)
[01.30 00:47:24] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  47%|█████████▎          |  66/141 [0:04:08<0:04:45, 0.26Hz] | (Ep 0.468)
[01.30 00:47:27] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  48%|█████████▌          |  67/141 [0:04:10<0:04:41, 0.26Hz] | (Ep 0.475)
[01.30 00:47:29] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  48%|█████████▋          |  68/141 [0:04:12<0:04:37, 0.26Hz] | (Ep 0.482)
[01.30 00:47:32] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  50%|█████████▉          |  70/141 [0:04:16<0:04:29, 0.26Hz] | (Ep 0.496)
[01.30 00:47:32] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    loss    grad_norm    learning_rate
[01.30 00:47:32] ┇ INFO    ┇             DeepKNLP ┇ >>     70    0.496  0.0368     0.159781      1.06667e-05
[01.30 00:47:34] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  50%|██████████          |  71/141 [0:04:18<0:04:25, 0.26Hz] | (Ep 0.504)
[01.30 00:47:38] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  52%|██████████▎         |  73/141 [0:04:21<0:04:17, 0.26Hz] | (Ep 0.518)
[01.30 00:47:40] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  52%|██████████▍         |  74/141 [0:04:24<0:04:13, 0.26Hz] | (Ep 0.525)
[01.30 00:47:43] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  53%|██████████▋         |  75/141 [0:04:26<0:04:10, 0.26Hz] | (Ep 0.532)
[01.30 00:47:46] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  55%|██████████▉         |  77/141 [0:04:29<0:04:02, 0.26Hz] | (Ep 0.546)
[01.30 00:47:48] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  55%|███████████         |  78/141 [0:04:31<0:03:58, 0.26Hz] | (Ep 0.553)
[01.30 00:47:50] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  56%|███████████▏        |  79/141 [0:04:33<0:03:55, 0.26Hz] | (Ep 0.560)
[01.30 00:47:55] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  57%|███████████▍        |  81/141 [0:04:38<0:03:48, 0.26Hz] | (Ep 0.574)
[01.30 00:47:57] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  58%|███████████▋        |  82/141 [0:04:40<0:03:44, 0.26Hz] | (Ep 0.582)
[01.30 00:47:59] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  59%|███████████▊        |  83/141 [0:04:42<0:03:40, 0.26Hz] | (Ep 0.589)
[01.30 00:48:01] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  60%|███████████▉        |  84/141 [0:04:44<0:03:37, 0.26Hz] | (Ep 0.596)
[01.30 00:48:03] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  60%|████████████        |  85/141 [0:04:46<0:03:33, 0.26Hz] | (Ep 0.603)
[01.30 00:48:03] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    loss    grad_norm    learning_rate
[01.30 00:48:03] ┇ INFO    ┇             DeepKNLP ┇ >>     85    0.603   0.035      0.10525      8.44444e-06
[01.30 00:48:05] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  61%|████████████▏       |  86/141 [0:04:49<0:03:29, 0.26Hz] | (Ep 0.610)
[01.30 00:48:09] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  62%|████████████▍       |  88/141 [0:04:53<0:03:22, 0.26Hz] | (Ep 0.624)
[01.30 00:48:12] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  63%|████████████▌       |  89/141 [0:04:55<0:03:18, 0.26Hz] | (Ep 0.631)
[01.30 00:48:14] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  64%|████████████▊       |  90/141 [0:04:57<0:03:15, 0.26Hz] | (Ep 0.638)
[01.30 00:48:17] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  65%|████████████▉       |  91/141 [0:05:00<0:03:11, 0.26Hz] | (Ep 0.645)
[01.30 00:48:19] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  65%|█████████████       |  92/141 [0:05:02<0:03:07, 0.26Hz] | (Ep 0.652)
[01.30 00:48:21] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  66%|█████████████▏      |  93/141 [0:05:05<0:03:04, 0.26Hz] | (Ep 0.660)
[01.30 00:48:24] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  67%|█████████████▎      |  94/141 [0:05:07<0:03:00, 0.26Hz] | (Ep 0.667)
[01.30 00:48:24] ┇ INFO    ┇ transformers.trainer ┇ ***** Running Evaluation *****
[01.30 00:48:24] ┇ INFO    ┇ transformers.trainer ┇   Num examples = 700
[01.30 00:48:24] ┇ INFO    ┇ transformers.trainer ┇   Batch size = 8
[01.30 00:48:30] ┇ INFO    ┇             DeepKNLP ┇ [METERING]   5%|▉                   |  1/22 [0:00:00<0:00:00, 104297.41Hz]
[01.30 00:48:36] ┇ INFO    ┇             DeepKNLP ┇ [METERING]   9%|█▊                  |  2/22 [0:00:06<0:01:06, 0.30Hz]
[01.30 00:48:42] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  14%|██▋                 |  3/22 [0:00:12<0:01:16, 0.25Hz]
[01.30 00:48:48] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  18%|███▋                |  4/22 [0:00:17<0:01:19, 0.23Hz]
[01.30 00:48:54] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  23%|████▌               |  5/22 [0:00:23<0:01:21, 0.21Hz]
[01.30 00:48:59] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  27%|█████▍              |  6/22 [0:00:29<0:01:18, 0.20Hz]
[01.30 00:49:06] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  32%|██████▎             |  7/22 [0:00:35<0:01:16, 0.20Hz]
[01.30 00:49:12] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  36%|███████▎            |  8/22 [0:00:41<0:01:13, 0.19Hz]
[01.30 00:49:18] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  41%|████████▏           |  9/22 [0:00:48<0:01:09, 0.19Hz]
[01.30 00:49:24] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  45%|█████████           | 10/22 [0:00:54<0:01:05, 0.18Hz]
[01.30 00:49:30] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  50%|██████████          | 11/22 [0:01:00<0:01:00, 0.18Hz]
[01.30 00:49:37] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  55%|██████████▉         | 12/22 [0:01:06<0:00:55, 0.18Hz]
[01.30 00:49:43] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  59%|███████████▊        | 13/22 [0:01:13<0:00:50, 0.18Hz]
[01.30 00:49:49] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  64%|████████████▋       | 14/22 [0:01:18<0:00:45, 0.18Hz]
[01.30 00:49:54] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  68%|█████████████▋      | 15/22 [0:01:24<0:00:39, 0.18Hz]
[01.30 00:50:00] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  73%|██████████████▌     | 16/22 [0:01:30<0:00:33, 0.18Hz]
[01.30 00:50:03] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  82%|████████████████▎   | 18/22 [0:01:33<0:00:20, 0.19Hz]
[01.30 00:50:07] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  91%|██████████████████▏ | 20/22 [0:01:36<0:00:09, 0.21Hz]
[01.30 00:50:09] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  95%|███████████████████ | 21/22 [0:01:38<0:00:04, 0.21Hz]
[01.30 00:50:14] ┇ INFO    ┇             DeepKNLP ┇ [METERING] 100%|████████████████████| 22/22 [0:01:43<0:00:00, 0.21Hz]
[01.30 00:50:15] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    eval_crossner_ai    eval_crossner_literature    eval_crossner_music    eval_crossner_politics    eval_crossner_science    eval_mit-movie    eval_mit-restaurant    eval_AVERAGE    eval_runtime    eval_samples_per_second    eval_steps_per_second
[01.30 00:50:15] ┇ INFO    ┇             DeepKNLP ┇ >>     94    0.667            0.434109                    0.508046                0.53918                  0.545455                 0.549327           0.86618               0.763285        0.600797         111.343                      6.287                    0.198
[01.30 00:50:17] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  67%|█████████████▍      |  95/141 [0:07:00<0:04:18, 0.18Hz] | (Ep 0.674)
[01.30 00:50:19] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  68%|█████████████▌      |  96/141 [0:07:03<0:04:12, 0.18Hz] | (Ep 0.681)
[01.30 00:50:22] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  69%|█████████████▊      |  97/141 [0:07:05<0:04:07, 0.18Hz] | (Ep 0.688)
[01.30 00:50:24] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  70%|█████████████▉      |  98/141 [0:07:07<0:04:01, 0.18Hz] | (Ep 0.695)
[01.30 00:50:26] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  70%|██████████████      |  99/141 [0:07:09<0:03:56, 0.18Hz] | (Ep 0.702)
[01.30 00:50:26] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    loss    grad_norm    learning_rate
[01.30 00:50:26] ┇ INFO    ┇             DeepKNLP ┇ >>     99    0.702  0.0334     0.091726      6.37037e-06
[01.30 00:50:28] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  71%|██████████████▏     | 100/141 [0:07:11<0:03:50, 0.18Hz] | (Ep 0.709)
[01.30 00:50:30] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  72%|██████████████▎     | 101/141 [0:07:13<0:03:44, 0.18Hz] | (Ep 0.716)
[01.30 00:50:33] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  72%|██████████████▍     | 102/141 [0:07:16<0:03:39, 0.18Hz] | (Ep 0.723)
[01.30 00:50:37] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  74%|██████████████▊     | 104/141 [0:07:20<0:03:28, 0.18Hz] | (Ep 0.738)
[01.30 00:50:42] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  75%|███████████████     | 106/141 [0:07:25<0:03:17, 0.18Hz] | (Ep 0.752)
[01.30 00:50:44] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  76%|███████████████▏    | 107/141 [0:07:27<0:03:11, 0.18Hz] | (Ep 0.759)
[01.30 00:50:46] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  77%|███████████████▎    | 108/141 [0:07:29<0:03:06, 0.18Hz] | (Ep 0.766)
[01.30 00:50:49] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  77%|███████████████▍    | 109/141 [0:07:32<0:03:00, 0.18Hz] | (Ep 0.773)
[01.30 00:50:53] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  79%|███████████████▋    | 111/141 [0:07:36<0:01:57, 0.26Hz] | (Ep 0.787)
[01.30 00:50:55] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  79%|███████████████▉    | 112/141 [0:07:38<0:01:53, 0.26Hz] | (Ep 0.794)
[01.30 00:50:57] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    loss    grad_norm    learning_rate
[01.30 00:50:57] ┇ INFO    ┇             DeepKNLP ┇ >>    113    0.801  0.0316    0.0676008       4.2963e-06
[01.30 00:50:59] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  81%|████████████████▏   | 114/141 [0:07:42<0:01:45, 0.26Hz] | (Ep 0.809)
[01.30 00:51:01] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  82%|████████████████▎   | 115/141 [0:07:44<0:01:41, 0.26Hz] | (Ep 0.816)
[01.30 00:51:03] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  82%|████████████████▍   | 116/141 [0:07:47<0:01:37, 0.26Hz] | (Ep 0.823)
[01.30 00:51:06] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  83%|████████████████▌   | 117/141 [0:07:49<0:01:33, 0.26Hz] | (Ep 0.830)
[01.30 00:51:08] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  84%|████████████████▋   | 118/141 [0:07:51<0:01:29, 0.26Hz] | (Ep 0.837)
[01.30 00:51:10] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  84%|████████████████▉   | 119/141 [0:07:53<0:01:25, 0.26Hz] | (Ep 0.844)
[01.30 00:51:12] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  85%|█████████████████   | 120/141 [0:07:55<0:01:22, 0.26Hz] | (Ep 0.851)
[01.30 00:51:15] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  86%|█████████████████▏  | 121/141 [0:07:58<0:01:18, 0.26Hz] | (Ep 0.858)
[01.30 00:51:17] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  87%|█████████████████▎  | 122/141 [0:08:00<0:01:14, 0.26Hz] | (Ep 0.865)
[01.30 00:51:19] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  87%|█████████████████▍  | 123/141 [0:08:03<0:01:10, 0.26Hz] | (Ep 0.872)
[01.30 00:51:21] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  88%|█████████████████▌  | 124/141 [0:08:05<0:01:06, 0.26Hz] | (Ep 0.879)
[01.30 00:51:23] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  89%|█████████████████▋  | 125/141 [0:08:07<0:01:02, 0.26Hz] | (Ep 0.887)
[01.30 00:51:26] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  89%|█████████████████▊  | 126/141 [0:08:09<0:00:58, 0.25Hz] | (Ep 0.894)
[01.30 00:51:28] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  90%|██████████████████  | 127/141 [0:08:11<0:00:54, 0.25Hz] | (Ep 0.901)
[01.30 00:51:28] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    loss    grad_norm    learning_rate
[01.30 00:51:28] ┇ INFO    ┇             DeepKNLP ┇ >>    127    0.901  0.0331    0.0810025      2.22222e-06
[01.30 00:51:30] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  91%|██████████████████▏ | 128/141 [0:08:13<0:00:51, 0.25Hz] | (Ep 0.908)
[01.30 00:51:32] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  91%|██████████████████▎ | 129/141 [0:08:15<0:00:47, 0.25Hz] | (Ep 0.915)
[01.30 00:51:34] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  92%|██████████████████▍ | 130/141 [0:08:17<0:00:43, 0.25Hz] | (Ep 0.922)
[01.30 00:51:37] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  93%|██████████████████▌ | 131/141 [0:08:20<0:00:39, 0.25Hz] | (Ep 0.929)
[01.30 00:51:39] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  94%|██████████████████▋ | 132/141 [0:08:22<0:00:35, 0.25Hz] | (Ep 0.936)
[01.30 00:51:43] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  95%|███████████████████ | 134/141 [0:08:26<0:00:27, 0.25Hz] | (Ep 0.950)
[01.30 00:51:45] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  96%|███████████████████▏| 135/141 [0:08:28<0:00:23, 0.25Hz] | (Ep 0.957)
[01.30 00:51:47] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  96%|███████████████████▎| 136/141 [0:08:31<0:00:19, 0.25Hz] | (Ep 0.965)
[01.30 00:51:49] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  97%|███████████████████▍| 137/141 [0:08:33<0:00:15, 0.25Hz] | (Ep 0.972)
[01.30 00:51:52] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  98%|███████████████████▌| 138/141 [0:08:35<0:00:11, 0.25Hz] | (Ep 0.979)
[01.30 00:51:54] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  99%|███████████████████▋| 139/141 [0:08:37<0:00:07, 0.25Hz] | (Ep 0.986)
[01.30 00:51:56] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  99%|███████████████████▊| 140/141 [0:08:39<0:00:03, 0.25Hz] | (Ep 0.993)
[01.30 00:51:58] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    loss    grad_norm    learning_rate
[01.30 00:51:58] ┇ INFO    ┇             DeepKNLP ┇ >>    141        1  0.0308    0.0841451      1.48148e-07
[01.30 00:51:58] ┇ INFO    ┇ transformers.trainer ┇ ***** Running Evaluation *****
[01.30 00:51:58] ┇ INFO    ┇ transformers.trainer ┇   Num examples = 700
[01.30 00:51:58] ┇ INFO    ┇ transformers.trainer ┇   Batch size = 8
[01.30 00:52:04] ┇ INFO    ┇             DeepKNLP ┇ [METERING]   5%|▉                   |  1/22 [0:00:00<0:00:00, 100109.95Hz]
[01.30 00:52:10] ┇ INFO    ┇             DeepKNLP ┇ [METERING]   9%|█▊                  |  2/22 [0:00:06<0:01:04, 0.31Hz]
[01.30 00:52:16] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  14%|██▋                 |  3/22 [0:00:12<0:01:16, 0.25Hz]
[01.30 00:52:22] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  18%|███▋                |  4/22 [0:00:17<0:01:20, 0.22Hz]
[01.30 00:52:28] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  23%|████▌               |  5/22 [0:00:23<0:01:20, 0.21Hz]
[01.30 00:52:33] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  27%|█████▍              |  6/22 [0:00:29<0:01:17, 0.21Hz]
[01.30 00:52:39] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  32%|██████▎             |  7/22 [0:00:35<0:01:16, 0.20Hz]
[01.30 00:52:46] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  36%|███████▎            |  8/22 [0:00:41<0:01:12, 0.19Hz]
[01.30 00:52:52] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  41%|████████▏           |  9/22 [0:00:48<0:01:09, 0.19Hz]
[01.30 00:52:58] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  45%|█████████           | 10/22 [0:00:54<0:01:05, 0.18Hz]
[01.30 00:53:04] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  50%|██████████          | 11/22 [0:01:00<0:01:00, 0.18Hz]
[01.30 00:53:10] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  55%|██████████▉         | 12/22 [0:01:06<0:00:55, 0.18Hz]
[01.30 00:53:17] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  59%|███████████▊        | 13/22 [0:01:12<0:00:50, 0.18Hz]
[01.30 00:53:23] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  64%|████████████▋       | 14/22 [0:01:19<0:00:45, 0.18Hz]
[01.30 00:53:29] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  68%|█████████████▋      | 15/22 [0:01:25<0:00:39, 0.18Hz]
[01.30 00:53:36] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  73%|██████████████▌     | 16/22 [0:01:31<0:00:34, 0.17Hz]
[01.30 00:53:39] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  82%|████████████████▎   | 18/22 [0:01:34<0:00:21, 0.19Hz]
[01.30 00:53:42] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  91%|██████████████████▏ | 20/22 [0:01:38<0:00:09, 0.20Hz]
[01.30 00:53:44] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  95%|███████████████████ | 21/22 [0:01:40<0:00:04, 0.21Hz]
[01.30 00:53:49] ┇ INFO    ┇             DeepKNLP ┇ [METERING] 100%|████████████████████| 22/22 [0:01:44<0:00:00, 0.21Hz]
[01.30 00:53:50] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    eval_crossner_ai    eval_crossner_literature    eval_crossner_music    eval_crossner_politics    eval_crossner_science    eval_mit-movie    eval_mit-restaurant    eval_AVERAGE    eval_runtime    eval_samples_per_second    eval_steps_per_second
[01.30 00:53:50] ┇ INFO    ┇             DeepKNLP ┇ >>    141        1            0.468413                    0.542759               0.613523                  0.575678                  0.60791          0.882927               0.795238        0.640921         111.933                      6.254                    0.197
[01.30 00:53:50] ┇ INFO    ┇ transformers.trainer ┇ 

Training completed. Do not forget to share your model on huggingface.co/models =)


[01.30 00:53:50] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    train_runtime    train_samples_per_second    train_steps_per_second    total_flos    train_loss
[01.30 00:53:50] ┇ INFO    ┇             DeepKNLP ┇ >>    141        1          633.629                      28.621                     0.223   4.48307e+16      0.109496
[01.30 00:53:50] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING] 100%|████████████████████| 141/141 [0:08:41<0:00:00, 0.25Hz] | (Ep 1.000)
[01.30 00:53:50] ┇ INFO    ┇             DeepKNLP ┇ Train result: TrainOutput(global_step=141, training_loss=0.10949630602031735, metrics={'train_runtime': 633.6287, 'train_samples_per_second': 28.621, 'train_steps_per_second': 0.223, 'total_flos': 4.48307099902935e+16, 'train_loss': 0.10949630602031735, 'epoch': 1.0})
[01.30 00:53:50] ┇ INFO    ┇       chrisbase.data ┇ =========================================================================================================================================
[01.30 00:53:50] ┇ INFO    ┇       chrisbase.data ┇ [EXIT] python task2-nerG-trainer2.py --local_rank=0 --trainer_deepspeed configs/deepspeed/ds1_llama.json ($=00:10:50.268)
[01.30 00:53:50] ┇ INFO    ┇       chrisbase.data ┇ =========================================================================================================================================
