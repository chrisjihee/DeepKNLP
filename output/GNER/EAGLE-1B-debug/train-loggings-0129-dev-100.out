[01.29 16:45:31] ┇ WARNING ┇             DeepKNLP ┇ accelerator.is_main_process=False
[01.29 16:45:31] ┇ WARNING ┇             DeepKNLP ┇ accelerator.is_main_process=False
[01.29 16:45:31] ┇ WARNING ┇             DeepKNLP ┇ accelerator.is_main_process=True
[01.29 16:45:31] ┇ WARNING ┇             DeepKNLP ┇ accelerator.is_main_process=False
[01.29 16:45:32] ┇ INFO    ┇             DeepKNLP ┇ Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: True
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ =========================================================================================================================================
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ [INIT] python task2-nerG-trainer2.py --local_rank=0 --trainer_deepspeed configs/deepspeed/ds1_llama.json
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ =========================================================================================================================================
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ -----------------------------------------------------------------------------------------------------------------------------------------
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇   #	TrainingArgumentsForAccelerator              	value
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ -----------------------------------------------------------------------------------------------------------------------------------------
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇   1	env.hostname                                 	ptlm3
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇   2	env.hostaddr                                 	129.254.121.74
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇   3	env.global_rank                              	-1
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇   4	env.local_rank                               	0
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇   5	env.node_rank                                	-1
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇   6	env.world_size                               	4
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇   7	env.time_stamp                               	0129.164527
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇   8	env.python_path                              	/home/chrisjihee/miniforge3/envs/DeepKNLP/bin/python
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇   9	env.current_dir                              	/home/chrisjihee/proj/DeepKNLP
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  10	env.current_file                             	task2-nerG-trainer2.py
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  11	env.command_args                             	['--local_rank=0', '--trainer_deepspeed', 'configs/deepspeed/ds1_llama.json']
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  12	env.output_home                              	output
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  13	env.output_name                              	GNER
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  14	env.run_version                              	EAGLE-1B-debug
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  15	env.output_file                              	train-metrics-0129.164527.csv
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  16	env.logging_file                             	train-loggings-0129.164527.out
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  17	env.logging_level                            	30
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  18	env.logging_format                           	%(asctime)s ┇ %(levelname)-7s ┇ %(name)20s ┇ %(message)s
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  19	env.datetime_format                          	[%m.%d %H:%M:%S]
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  20	env.argument_file                            	train-arguments-0129.164527.json
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  21	env.random_seed                              	7
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  22	env.max_workers                              	4
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  23	env.debugging                                	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  24	env.output_dir                               	output/GNER/EAGLE-1B-debug
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  25	time.t1                                      	2025-01-29 16:45:33.318197
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  26	time.t2                                      	2025-01-29 16:45:27.582179
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  27	time.started                                 	[01.29 16:45:33]
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  28	time.settled
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  29	time.elapsed
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  30	data.pretrained                              	etri-lirs/egpt-1.3b-preview
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  31	data.train_file                              	data/gner/zero-shot-train.jsonl
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  32	data.study_file
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  33	data.eval_file                               	data/gner/zero-shot-dev-100.jsonl
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  34	data.pred_file                               	data/gner/zero-shot-test.jsonl
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  35	data.max_train_samples                       	-1
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  36	data.max_study_samples                       	-1
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  37	data.max_eval_samples                        	-1
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  38	data.max_pred_samples                        	-1
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  39	data.max_source_length                       	640
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  40	data.max_target_length                       	640
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  41	data.use_cache_data                          	True
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  42	data.ignore_pad_token_for_loss               	True
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  43	train.output_dir                             	output/GNER/EAGLE-1B-debug
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  44	train.overwrite_output_dir                   	True
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  45	train.do_train                               	True
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  46	train.do_eval                                	True
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  47	train.do_predict                             	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  48	train.eval_strategy                          	IntervalStrategy.EPOCH
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  49	train.prediction_loss_only                   	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  50	train.per_device_train_batch_size            	8
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  51	train.per_device_eval_batch_size             	8
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  52	train.per_gpu_train_batch_size
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  53	train.per_gpu_eval_batch_size
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  54	train.gradient_accumulation_steps            	4
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  55	train.eval_accumulation_steps                	4
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  56	train.eval_delay                             	0
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  57	train.torch_empty_cache_steps
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  58	train.learning_rate                          	2e-05
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  59	train.weight_decay                           	0.0
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  60	train.adam_beta1                             	0.9
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  61	train.adam_beta2                             	0.999
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  62	train.adam_epsilon                           	1e-08
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  63	train.max_grad_norm                          	1.0
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  64	train.num_train_epochs                       	1.0
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  65	train.max_steps                              	-1
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  66	train.lr_scheduler_type                      	SchedulerType.COSINE
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  67	train.lr_scheduler_kwargs                    	{}
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  68	train.warmup_ratio                           	0.04
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  69	train.warmup_steps                           	0
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  70	train.log_level                              	warning
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  71	train.log_level_replica                      	error
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  72	train.log_on_each_node                       	True
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  73	train.logging_dir                            	output/GNER/EAGLE-1B-debug/runs/Jan29_16-45-31_ptlm3
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  74	train.logging_strategy                       	IntervalStrategy.STEPS
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  75	train.logging_first_step                     	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  76	train.logging_steps                          	10
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  77	train.logging_nan_inf_filter                 	True
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  78	train.save_strategy                          	SaveStrategy.NO
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  79	train.save_steps                             	9223372036854775807
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  80	train.save_total_limit
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  81	train.save_safetensors                       	True
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  82	train.save_on_each_node                      	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  83	train.save_only_model                        	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  84	train.restore_callback_states_from_checkpoint	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  85	train.no_cuda                                	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  86	train.use_cpu                                	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  87	train.use_mps_device                         	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  88	train.seed                                   	7
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  89	train.data_seed
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  90	train.jit_mode_eval                          	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  91	train.use_ipex                               	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  92	train.bf16                                   	True
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  93	train.fp16                                   	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  94	train.fp16_opt_level                         	O1
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  95	train.half_precision_backend                 	auto
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  96	train.bf16_full_eval                         	True
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  97	train.fp16_full_eval                         	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  98	train.tf32                                   	True
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇  99	train.local_rank                             	0
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 100	train.ddp_backend
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 101	train.tpu_num_cores
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 102	train.tpu_metrics_debug                      	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 103	train.debug                                  	[]
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 104	train.dataloader_drop_last                   	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 105	train.eval_steps                             	0
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 106	train.dataloader_num_workers                 	0
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 107	train.dataloader_prefetch_factor
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 108	train.past_index                             	-1
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 109	train.run_name                               	output/GNER/EAGLE-1B-debug
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 110	train.disable_tqdm                           	True
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 111	train.remove_unused_columns                  	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 112	train.label_names
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 113	train.load_best_model_at_end                 	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 114	train.metric_for_best_model
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 115	train.greater_is_better
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 116	train.ignore_data_skip                       	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 117	train.fsdp                                   	[]
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 118	train.fsdp_min_num_params                    	0
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 119	train.fsdp_config                            	{'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 120	train.fsdp_transformer_layer_cls_to_wrap
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 121	train.accelerator_config                     	{'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False}
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 122	train.deepspeed                              	configs/deepspeed/ds1_llama.json
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 123	train.label_smoothing_factor                 	0.0
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 124	train.optim                                  	OptimizerNames.ADAMW_TORCH
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 125	train.optim_args
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 126	train.adafactor                              	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 127	train.group_by_length                        	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 128	train.length_column_name                     	length
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 129	train.report_to                              	[]
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 130	train.ddp_find_unused_parameters
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 131	train.ddp_bucket_cap_mb
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 132	train.ddp_broadcast_buffers
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 133	train.dataloader_pin_memory                  	True
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 134	train.dataloader_persistent_workers          	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 135	train.skip_memory_metrics                    	True
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 136	train.use_legacy_prediction_loop             	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 137	train.push_to_hub                            	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 138	train.resume_from_checkpoint
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 139	train.hub_model_id
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 140	train.hub_strategy                           	HubStrategy.EVERY_SAVE
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 141	train.hub_token
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 142	train.hub_private_repo
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 143	train.hub_always_push                        	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 144	train.gradient_checkpointing                 	True
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 145	train.gradient_checkpointing_kwargs
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 146	train.include_inputs_for_metrics             	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 147	train.include_for_metrics                    	[]
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 148	train.eval_do_concat_batches                 	True
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 149	train.fp16_backend                           	auto
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 150	train.evaluation_strategy
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 151	train.push_to_hub_model_id
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 152	train.push_to_hub_organization
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 153	train.push_to_hub_token
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 154	train._n_gpu                                 	1
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 155	train.mp_parameters
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 156	train.auto_find_batch_size                   	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 157	train.full_determinism                       	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 158	train.torchdynamo
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 159	train.ray_scope                              	last
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 160	train.ddp_timeout                            	1800
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 161	train.torch_compile                          	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 162	train.torch_compile_backend
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 163	train.torch_compile_mode
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 164	train.dispatch_batches
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 165	train.split_batches
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 166	train.include_tokens_per_second              	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 167	train.include_num_input_tokens_seen          	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 168	train.neftune_noise_alpha
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 169	train.optim_target_modules
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 170	train.batch_eval_metrics                     	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 171	train.eval_on_start                          	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 172	train.use_liger_kernel                       	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 173	train.eval_use_gather_object                 	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 174	train.average_tokens_across_devices          	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 175	train.sortish_sampler                        	False
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 176	train.predict_with_generate                  	True
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 177	train.generation_max_length                  	640
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 178	train.generation_num_beams
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ 179	train.generation_config
[01.29 16:45:33] ┇ INFO    ┇       chrisbase.data ┇ -----------------------------------------------------------------------------------------------------------------------------------------
[01.29 16:45:37] ┇ INFO    ┇             DeepKNLP ┇ type(model)=<class 'transformers.models.gpt_neox.modeling_gpt_neox.GPTNeoXForCausalLM'>
[01.29 16:45:37] ┇ INFO    ┇             DeepKNLP ┇ model.generation_config.pad_token_id=0
[01.29 16:45:37] ┇ INFO    ┇             DeepKNLP ┇ Loaded raw train_dataset (#=18135): data/gner/zero-shot-train.jsonl
[01.29 16:45:38] ┇ INFO    ┇             DeepKNLP ┇ Preprocess train_dataset:   0%|                    |     4/18135 [0:00:00<0:40:00, 7.55Hz]
[01.29 16:45:40] ┇ INFO    ┇             DeepKNLP ┇ Preprocess train_dataset:  34%|██████▊             |  6156/18135 [0:00:02<0:00:02, 4585.97Hz]
[01.29 16:45:42] ┇ INFO    ┇             DeepKNLP ┇ Preprocess train_dataset:  78%|███████████████▌    | 14100/18135 [0:00:04<0:00:06, 618.24Hz]
[01.29 16:45:43] ┇ INFO    ┇             DeepKNLP ┇ Preprocess train_dataset: 100%|████████████████████| 18135/18135 [0:00:05<0:00:00, 4173.10Hz]
[01.29 16:45:44] ┇ INFO    ┇             DeepKNLP ┇ Completed preprocessing for train_dataset at [01.29 16:45:43]
[01.29 16:45:46] ┇ INFO    ┇             DeepKNLP ┇ Loaded raw eval_dataset (#=700): data/gner/zero-shot-dev-100.jsonl
[01.29 16:45:46] ┇ INFO    ┇             DeepKNLP ┇ Preprocess eval_dataset:   1%|                    |   4/700 [0:00:00<0:01:42, 6.76Hz]
[01.29 16:45:46] ┇ INFO    ┇             DeepKNLP ┇ Preprocess eval_dataset: 100%|████████████████████| 700/700 [0:00:00<0:00:00, 6239.81Hz]
[01.29 16:45:47] ┇ INFO    ┇             DeepKNLP ┇ Completed preprocessing for eval_dataset at [01.29 16:45:47]
[01.29 16:45:47] ┇ INFO    ┇ transformers.trainer ┇ Using auto half precision backend
[01.29 16:45:47] ┇ WARNING ┇             DeepKNLP ┇ trainer.accelerator=<accelerate.accelerator.Accelerator object at 0x7f2122b18ad0> / trainer.accelerator.state=Distributed environment: DistributedType.DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'optimizer': {'type': 'AdamW', 'params': {'lr': 2e-05, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.0}}, 'scheduler': {'type': 'WarmupDecayLR', 'params': {'warmup_min_lr': 0, 'warmup_max_lr': 2e-05, 'warmup_num_steps': 'auto', 'total_num_steps': 'auto'}}, 'zero_optimization': {'stage': 1, 'allgather_partitions': True, 'allgather_bucket_size': 200000000.0, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 200000000.0, 'contiguous_gradients': True}, 'gradient_accumulation_steps': 4, 'gradient_clipping': 1.0, 'train_batch_size': 128, 'train_micro_batch_size_per_gpu': 8, 'steps_per_print': inf, 'fp16': {'enabled': False}}

[01.29 16:45:55] ┇ WARNING ┇            DeepSpeed ┇ Attempting to get learning rate from scheduler before it has started
[01.29 16:45:55] ┇ INFO    ┇ transformers.trainer ┇ ***** Running training *****
[01.29 16:45:55] ┇ INFO    ┇ transformers.trainer ┇   Num examples = 18,135
[01.29 16:45:55] ┇ INFO    ┇ transformers.trainer ┇   Num Epochs = 1
[01.29 16:45:55] ┇ INFO    ┇ transformers.trainer ┇   Instantaneous batch size per device = 8
[01.29 16:45:55] ┇ INFO    ┇ transformers.trainer ┇   Total train batch size (w. parallel, distributed & accumulation) = 128
[01.29 16:45:55] ┇ INFO    ┇ transformers.trainer ┇   Gradient Accumulation steps = 4
[01.29 16:45:55] ┇ INFO    ┇ transformers.trainer ┇   Total optimization steps = 141
[01.29 16:45:55] ┇ INFO    ┇ transformers.trainer ┇   Number of trainable parameters = 1,341,247,488
[01.29 16:45:58] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]   1%|▏                   |   1/141 [0:00:03<0:08:01, 0.29Hz] | (Ep 0.00)
[01.29 16:46:01] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]   1%|▎                   |   2/141 [0:00:06<0:07:40, 0.30Hz] | (Ep 0.01)
[01.29 16:46:06] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]   3%|▌                   |   4/141 [0:00:10<0:06:08, 0.37Hz] | (Ep 0.02)
[01.29 16:46:08] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]   4%|▋                   |   5/141 [0:00:13<0:05:54, 0.38Hz] | (Ep 0.03)
[01.29 16:46:10] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]   4%|▊                   |   6/141 [0:00:15<0:05:46, 0.39Hz] | (Ep 0.04)
[01.29 16:46:14] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]   6%|█▏                  |   8/141 [0:00:19<0:05:23, 0.41Hz] | (Ep 0.05)
[01.29 16:46:16] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]   6%|█▎                  |   9/141 [0:00:21<0:05:17, 0.42Hz] | (Ep 0.06)
[01.29 16:46:18] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]   7%|█▍                  |  10/141 [0:00:23<0:05:10, 0.42Hz] | (Ep 0.06)
[01.29 16:46:18] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    loss    grad_norm    learning_rate
[01.29 16:46:18] ┇ INFO    ┇             DeepKNLP ┇ >>     10     0.07  0.9522     0.941048      1.95556e-05
[01.29 16:46:22] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]   9%|█▋                  |  12/141 [0:00:27<0:04:54, 0.44Hz] | (Ep 0.08)
[01.29 16:46:26] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  10%|█▉                  |  14/141 [0:00:31<0:04:45, 0.45Hz] | (Ep 0.09)
[01.29 16:46:30] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  11%|██▎                 |  16/141 [0:00:35<0:04:35, 0.45Hz] | (Ep 0.11)
[01.29 16:46:34] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  13%|██▌                 |  18/141 [0:00:39<0:04:26, 0.46Hz] | (Ep 0.12)
[01.29 16:46:36] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  13%|██▋                 |  19/141 [0:00:41<0:04:24, 0.46Hz] | (Ep 0.13)
[01.29 16:46:38] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    loss    grad_norm    learning_rate
[01.29 16:46:38] ┇ INFO    ┇             DeepKNLP ┇ >>     20     0.14  0.1217     0.261576      1.80741e-05
[01.29 16:46:40] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  15%|██▉                 |  21/141 [0:00:45<0:04:18, 0.46Hz] | (Ep 0.14)
[01.29 16:46:44] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  16%|███▎                |  23/141 [0:00:49<0:04:12, 0.47Hz] | (Ep 0.16)
[01.29 16:46:48] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  18%|███▌                |  25/141 [0:00:53<0:04:06, 0.47Hz] | (Ep 0.17)
[01.29 16:46:50] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  18%|███▋                |  26/141 [0:00:55<0:04:04, 0.47Hz] | (Ep 0.18)
[01.29 16:46:52] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  19%|███▊                |  27/141 [0:00:57<0:04:02, 0.47Hz] | (Ep 0.18)
[01.29 16:46:54] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  20%|███▉                |  28/141 [0:00:59<0:03:59, 0.47Hz] | (Ep 0.19)
[01.29 16:46:57] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  21%|████                |  29/141 [0:01:01<0:03:58, 0.47Hz] | (Ep 0.20)
[01.29 16:46:59] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  21%|████▎               |  30/141 [0:01:04<0:03:56, 0.47Hz] | (Ep 0.20)
[01.29 16:46:59] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    loss    grad_norm    learning_rate
[01.29 16:46:59] ┇ INFO    ┇             DeepKNLP ┇ >>     30     0.21  0.0679     0.162845      1.65926e-05
[01.29 16:47:01] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  22%|████▍               |  31/141 [0:01:06<0:03:54, 0.47Hz] | (Ep 0.21)
[01.29 16:47:05] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  23%|████▋               |  33/141 [0:01:09<0:03:49, 0.47Hz] | (Ep 0.23)
[01.29 16:47:09] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  25%|████▉               |  35/141 [0:01:13<0:03:43, 0.47Hz] | (Ep 0.24)
[01.29 16:47:13] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  26%|█████▏              |  37/141 [0:01:17<0:03:39, 0.47Hz] | (Ep 0.25)
[01.29 16:47:15] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  27%|█████▍              |  38/141 [0:01:20<0:03:36, 0.47Hz] | (Ep 0.26)
[01.29 16:47:19] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  28%|█████▋              |  40/141 [0:01:23<0:03:31, 0.48Hz] | (Ep 0.28)
[01.29 16:47:19] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    loss    grad_norm    learning_rate
[01.29 16:47:19] ┇ INFO    ┇             DeepKNLP ┇ >>     40     0.28  0.0504     0.106956      1.51111e-05
[01.29 16:47:23] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  30%|█████▉              |  42/141 [0:01:28<0:03:28, 0.48Hz] | (Ep 0.29)
[01.29 16:47:25] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  30%|██████              |  43/141 [0:01:30<0:03:26, 0.47Hz] | (Ep 0.30)
[01.29 16:47:28] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  31%|██████▏             |  44/141 [0:01:32<0:03:24, 0.47Hz] | (Ep 0.30)
[01.29 16:47:31] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  33%|██████▌             |  46/141 [0:01:36<0:03:19, 0.48Hz] | (Ep 0.32)
[01.29 16:47:34] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  33%|██████▋             |  47/141 [0:01:38<0:03:17, 0.48Hz] | (Ep 0.32)
[01.29 16:47:36] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  34%|██████▊             |  48/141 [0:01:41<0:03:15, 0.47Hz] | (Ep 0.33)
[01.29 16:47:38] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  35%|██████▉             |  49/141 [0:01:43<0:03:13, 0.47Hz] | (Ep 0.34)
[01.29 16:47:40] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  35%|███████             |  50/141 [0:01:45<0:03:12, 0.47Hz] | (Ep 0.35)
[01.29 16:47:40] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    loss    grad_norm    learning_rate
[01.29 16:47:40] ┇ INFO    ┇             DeepKNLP ┇ >>     50     0.35  0.0447     0.147279      1.36296e-05
[01.29 16:47:44] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  37%|███████▍            |  52/141 [0:01:49<0:03:07, 0.47Hz] | (Ep 0.36)
[01.29 16:47:47] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  38%|███████▌            |  53/141 [0:01:51<0:03:05, 0.47Hz] | (Ep 0.37)
[01.29 16:47:49] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  38%|███████▋            |  54/141 [0:01:53<0:03:03, 0.47Hz] | (Ep 0.37)
[01.29 16:47:53] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  40%|███████▉            |  56/141 [0:01:58<0:02:59, 0.47Hz] | (Ep 0.39)
[01.29 16:47:57] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  41%|████████▏           |  58/141 [0:02:02<0:02:54, 0.48Hz] | (Ep 0.40)
[01.29 16:47:59] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  42%|████████▎           |  59/141 [0:02:04<0:02:53, 0.47Hz] | (Ep 0.41)
[01.29 16:48:02] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  43%|████████▌           |  60/141 [0:02:06<0:02:51, 0.47Hz] | (Ep 0.42)
[01.29 16:48:02] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    loss    grad_norm    learning_rate
[01.29 16:48:02] ┇ INFO    ┇             DeepKNLP ┇ >>     60     0.42  0.0371     0.113942      1.21481e-05
[01.29 16:48:05] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  44%|████████▊           |  62/141 [0:02:10<0:02:46, 0.47Hz] | (Ep 0.43)
[01.29 16:48:07] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  45%|████████▉           |  63/141 [0:02:12<0:02:44, 0.47Hz] | (Ep 0.44)
[01.29 16:48:10] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  45%|█████████           |  64/141 [0:02:14<0:02:40, 0.48Hz] | (Ep 0.44)
[01.29 16:48:13] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  47%|█████████▎          |  66/141 [0:02:18<0:02:34, 0.48Hz] | (Ep 0.46)
[01.29 16:48:16] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  48%|█████████▌          |  67/141 [0:02:20<0:02:32, 0.48Hz] | (Ep 0.47)
[01.29 16:48:18] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  48%|█████████▋          |  68/141 [0:02:22<0:02:30, 0.49Hz] | (Ep 0.47)
[01.29 16:48:21] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  50%|█████████▉          |  70/141 [0:02:26<0:02:25, 0.49Hz] | (Ep 0.49)
[01.29 16:48:21] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    loss    grad_norm    learning_rate
[01.29 16:48:21] ┇ INFO    ┇             DeepKNLP ┇ >>     70     0.49   0.037     0.159781      1.06667e-05
[01.29 16:48:23] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  50%|██████████          |  71/141 [0:02:28<0:02:23, 0.49Hz] | (Ep 0.49)
[01.29 16:48:27] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  52%|██████████▎         |  73/141 [0:02:32<0:02:18, 0.49Hz] | (Ep 0.51)
[01.29 16:48:29] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  52%|██████████▍         |  74/141 [0:02:34<0:02:17, 0.49Hz] | (Ep 0.51)
[01.29 16:48:32] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  53%|██████████▋         |  75/141 [0:02:36<0:02:15, 0.49Hz] | (Ep 0.52)
[01.29 16:48:35] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  55%|██████████▉         |  77/141 [0:02:40<0:02:10, 0.49Hz] | (Ep 0.54)
[01.29 16:48:37] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  55%|███████████         |  78/141 [0:02:42<0:02:09, 0.49Hz] | (Ep 0.54)
[01.29 16:48:39] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  56%|███████████▏        |  79/141 [0:02:44<0:02:07, 0.49Hz] | (Ep 0.55)
[01.29 16:48:41] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    loss    grad_norm    learning_rate
[01.29 16:48:41] ┇ INFO    ┇             DeepKNLP ┇ >>     80     0.56  0.0353    0.0996763      9.18519e-06
[01.29 16:48:44] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  57%|███████████▍        |  81/141 [0:02:48<0:02:03, 0.48Hz] | (Ep 0.56)
[01.29 16:48:46] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  58%|███████████▋        |  82/141 [0:02:50<0:02:01, 0.49Hz] | (Ep 0.57)
[01.29 16:48:48] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  59%|███████████▊        |  83/141 [0:02:53<0:01:59, 0.48Hz] | (Ep 0.58)
[01.29 16:48:50] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  60%|███████████▉        |  84/141 [0:02:55<0:01:57, 0.48Hz] | (Ep 0.59)
[01.29 16:48:52] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  60%|████████████        |  85/141 [0:02:57<0:01:56, 0.48Hz] | (Ep 0.59)
[01.29 16:48:54] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  61%|████████████▏       |  86/141 [0:02:59<0:01:53, 0.48Hz] | (Ep 0.60)
[01.29 16:48:59] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  62%|████████████▍       |  88/141 [0:03:03<0:01:49, 0.48Hz] | (Ep 0.61)
[01.29 16:49:01] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  63%|████████████▌       |  89/141 [0:03:06<0:01:48, 0.48Hz] | (Ep 0.62)
[01.29 16:49:03] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  64%|████████████▊       |  90/141 [0:03:08<0:01:46, 0.48Hz] | (Ep 0.63)
[01.29 16:49:03] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    loss    grad_norm    learning_rate
[01.29 16:49:03] ┇ INFO    ┇             DeepKNLP ┇ >>     90     0.63  0.0335    0.0901678       7.7037e-06
[01.29 16:49:06] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  65%|████████████▉       |  91/141 [0:03:10<0:01:44, 0.48Hz] | (Ep 0.63)
[01.29 16:49:08] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  65%|█████████████       |  92/141 [0:03:13<0:01:42, 0.48Hz] | (Ep 0.64)
[01.29 16:49:11] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  66%|█████████████▏      |  93/141 [0:03:15<0:01:40, 0.48Hz] | (Ep 0.65)
[01.29 16:49:13] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  67%|█████████████▎      |  94/141 [0:03:17<0:01:38, 0.48Hz] | (Ep 0.66)
[01.29 16:49:15] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  67%|█████████████▍      |  95/141 [0:03:20<0:01:36, 0.48Hz] | (Ep 0.66)
[01.29 16:49:17] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  68%|█████████████▌      |  96/141 [0:03:22<0:01:34, 0.48Hz] | (Ep 0.67)
[01.29 16:49:19] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  69%|█████████████▊      |  97/141 [0:03:24<0:01:32, 0.48Hz] | (Ep 0.68)
[01.29 16:49:21] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  70%|█████████████▉      |  98/141 [0:03:26<0:01:30, 0.47Hz] | (Ep 0.68)
[01.29 16:49:24] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  70%|██████████████      |  99/141 [0:03:28<0:01:28, 0.47Hz] | (Ep 0.69)
[01.29 16:49:26] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  71%|██████████████▏     | 100/141 [0:03:30<0:01:26, 0.47Hz] | (Ep 0.70)
[01.29 16:49:26] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    loss    grad_norm    learning_rate
[01.29 16:49:26] ┇ INFO    ┇             DeepKNLP ┇ >>    100     0.71  0.0338    0.0872761      6.22222e-06
[01.29 16:49:28] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  72%|██████████████▎     | 101/141 [0:03:33<0:01:24, 0.47Hz] | (Ep 0.71)
[01.29 16:49:31] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  72%|██████████████▍     | 102/141 [0:03:35<0:01:22, 0.47Hz] | (Ep 0.71)
[01.29 16:49:35] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  74%|██████████████▊     | 104/141 [0:03:40<0:01:18, 0.47Hz] | (Ep 0.73)
[01.29 16:49:40] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  75%|███████████████     | 106/141 [0:03:44<0:01:14, 0.47Hz] | (Ep 0.74)
[01.29 16:49:42] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  76%|███████████████▏    | 107/141 [0:03:46<0:01:12, 0.47Hz] | (Ep 0.75)
[01.29 16:49:44] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  77%|███████████████▎    | 108/141 [0:03:49<0:01:10, 0.47Hz] | (Ep 0.75)
[01.29 16:49:46] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  77%|███████████████▍    | 109/141 [0:03:51<0:01:08, 0.47Hz] | (Ep 0.76)
[01.29 16:49:48] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    loss    grad_norm    learning_rate
[01.29 16:49:48] ┇ INFO    ┇             DeepKNLP ┇ >>    110     0.78  0.0324     0.113684      4.74074e-06
[01.29 16:49:51] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  79%|███████████████▋    | 111/141 [0:03:55<0:01:04, 0.47Hz] | (Ep 0.78)
[01.29 16:49:53] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  79%|███████████████▉    | 112/141 [0:03:57<0:01:01, 0.47Hz] | (Ep 0.78)
[01.29 16:49:57] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  81%|████████████████▏   | 114/141 [0:04:02<0:00:57, 0.47Hz] | (Ep 0.80)
[01.29 16:49:59] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  82%|████████████████▎   | 115/141 [0:04:04<0:00:55, 0.47Hz] | (Ep 0.80)
[01.29 16:50:01] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  82%|████████████████▍   | 116/141 [0:04:06<0:00:53, 0.47Hz] | (Ep 0.81)
[01.29 16:50:03] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  83%|████████████████▌   | 117/141 [0:04:08<0:00:51, 0.47Hz] | (Ep 0.82)
[01.29 16:50:06] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  84%|████████████████▋   | 118/141 [0:04:10<0:00:49, 0.47Hz] | (Ep 0.83)
[01.29 16:50:08] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  84%|████████████████▉   | 119/141 [0:04:13<0:00:47, 0.47Hz] | (Ep 0.83)
[01.29 16:50:10] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  85%|█████████████████   | 120/141 [0:04:15<0:00:45, 0.47Hz] | (Ep 0.84)
[01.29 16:50:10] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    loss    grad_norm    learning_rate
[01.29 16:50:10] ┇ INFO    ┇             DeepKNLP ┇ >>    120     0.85  0.0313     0.089712      3.25926e-06
[01.29 16:50:12] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  86%|█████████████████▏  | 121/141 [0:04:17<0:00:43, 0.46Hz] | (Ep 0.85)
[01.29 16:50:15] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  87%|█████████████████▎  | 122/141 [0:04:20<0:00:40, 0.46Hz] | (Ep 0.85)
[01.29 16:50:17] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  87%|█████████████████▍  | 123/141 [0:04:22<0:00:38, 0.46Hz] | (Ep 0.86)
[01.29 16:50:19] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  88%|█████████████████▌  | 124/141 [0:04:24<0:00:36, 0.46Hz] | (Ep 0.87)
[01.29 16:50:21] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  89%|█████████████████▋  | 125/141 [0:04:26<0:00:34, 0.46Hz] | (Ep 0.87)
[01.29 16:50:23] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  89%|█████████████████▊  | 126/141 [0:04:28<0:00:32, 0.46Hz] | (Ep 0.88)
[01.29 16:50:26] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  90%|██████████████████  | 127/141 [0:04:30<0:00:30, 0.46Hz] | (Ep 0.89)
[01.29 16:50:28] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  91%|██████████████████▏ | 128/141 [0:04:32<0:00:28, 0.46Hz] | (Ep 0.90)
[01.29 16:50:30] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  91%|██████████████████▎ | 129/141 [0:04:34<0:00:25, 0.46Hz] | (Ep 0.90)
[01.29 16:50:32] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  92%|██████████████████▍ | 130/141 [0:04:37<0:00:23, 0.46Hz] | (Ep 0.91)
[01.29 16:50:32] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    loss    grad_norm    learning_rate
[01.29 16:50:32] ┇ INFO    ┇             DeepKNLP ┇ >>    130     0.92  0.0329      0.10102      1.77778e-06
[01.29 16:50:34] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  93%|██████████████████▌ | 131/141 [0:04:39<0:00:21, 0.46Hz] | (Ep 0.92)
[01.29 16:50:37] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  94%|██████████████████▋ | 132/141 [0:04:41<0:00:19, 0.46Hz] | (Ep 0.92)
[01.29 16:50:41] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  95%|███████████████████ | 134/141 [0:04:45<0:00:15, 0.46Hz] | (Ep 0.94)
[01.29 16:50:43] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  96%|███████████████████▏| 135/141 [0:04:48<0:00:13, 0.46Hz] | (Ep 0.95)
[01.29 16:50:45] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  96%|███████████████████▎| 136/141 [0:04:50<0:00:10, 0.46Hz] | (Ep 0.95)
[01.29 16:50:47] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  97%|███████████████████▍| 137/141 [0:04:52<0:00:08, 0.46Hz] | (Ep 0.96)
[01.29 16:50:49] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  98%|███████████████████▌| 138/141 [0:04:54<0:00:06, 0.46Hz] | (Ep 0.97)
[01.29 16:50:52] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  99%|███████████████████▋| 139/141 [0:04:56<0:00:04, 0.46Hz] | (Ep 0.97)
[01.29 16:50:54] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING]  99%|███████████████████▊| 140/141 [0:04:59<0:00:02, 0.45Hz] | (Ep 0.98)
[01.29 16:50:54] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    loss    grad_norm    learning_rate
[01.29 16:50:54] ┇ INFO    ┇             DeepKNLP ┇ >>    140     0.99  0.0303     0.138408      2.96296e-07
[01.29 16:50:56] ┇ INFO    ┇ transformers.trainer ┇ ***** Running Evaluation *****
[01.29 16:50:56] ┇ INFO    ┇ transformers.trainer ┇   Num examples = 700
[01.29 16:50:56] ┇ INFO    ┇ transformers.trainer ┇   Batch size = 8
[01.29 16:51:02] ┇ INFO    ┇             DeepKNLP ┇ [METERING]   5%|▉                   |  1/22 [0:00:00<0:00:00, 94606.97Hz]
[01.29 16:51:08] ┇ INFO    ┇             DeepKNLP ┇ [METERING]   9%|█▊                  |  2/22 [0:00:06<0:01:05, 0.30Hz]
[01.29 16:51:14] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  14%|██▋                 |  3/22 [0:00:12<0:01:16, 0.25Hz]
[01.29 16:51:20] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  18%|███▋                |  4/22 [0:00:18<0:01:21, 0.22Hz]
[01.29 16:51:26] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  23%|████▌               |  5/22 [0:00:23<0:01:21, 0.21Hz]
[01.29 16:51:31] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  27%|█████▍              |  6/22 [0:00:29<0:01:18, 0.20Hz]
[01.29 16:51:37] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  32%|██████▎             |  7/22 [0:00:35<0:01:16, 0.20Hz]
[01.29 16:51:44] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  36%|███████▎            |  8/22 [0:00:41<0:01:13, 0.19Hz]
[01.29 16:51:50] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  41%|████████▏           |  9/22 [0:00:48<0:01:09, 0.19Hz]
[01.29 16:51:56] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  45%|█████████           | 10/22 [0:00:54<0:01:05, 0.18Hz]
[01.29 16:52:02] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  50%|██████████          | 11/22 [0:01:00<0:01:00, 0.18Hz]
[01.29 16:52:09] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  55%|██████████▉         | 12/22 [0:01:06<0:00:55, 0.18Hz]
[01.29 16:52:15] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  59%|███████████▊        | 13/22 [0:01:13<0:00:50, 0.18Hz]
[01.29 16:52:21] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  64%|████████████▋       | 14/22 [0:01:19<0:00:45, 0.18Hz]
[01.29 16:52:28] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  68%|█████████████▋      | 15/22 [0:01:25<0:00:40, 0.17Hz]
[01.29 16:52:34] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  73%|██████████████▌     | 16/22 [0:01:31<0:00:34, 0.17Hz]
[01.29 16:52:37] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  82%|████████████████▎   | 18/22 [0:01:35<0:00:21, 0.19Hz]
[01.29 16:52:40] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  91%|██████████████████▏ | 20/22 [0:01:38<0:00:09, 0.20Hz]
[01.29 16:52:42] ┇ INFO    ┇             DeepKNLP ┇ [METERING]  95%|███████████████████ | 21/22 [0:01:40<0:00:04, 0.21Hz]
[01.29 16:52:46] ┇ INFO    ┇             DeepKNLP ┇ [METERING] 100%|████████████████████| 22/22 [0:01:44<0:00:00, 0.21Hz]
[01.29 16:52:48] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    eval_crossner_ai    eval_crossner_literature    eval_crossner_music    eval_crossner_politics    eval_crossner_science    eval_mit-movie    eval_mit-restaurant    eval_AVERAGE    eval_runtime    eval_samples_per_second    eval_steps_per_second
[01.29 16:52:48] ┇ INFO    ┇             DeepKNLP ┇ >>    141     0.99            0.468413                    0.542759               0.613523                  0.575678                  0.60791          0.882927               0.795238        0.640921          111.64                       6.27                    0.197
[01.29 16:52:48] ┇ INFO    ┇ transformers.trainer ┇ 

Training completed. Do not forget to share your model on huggingface.co/models =)


[01.29 16:52:48] ┇ INFO    ┇             DeepKNLP ┇ >>   step    epoch    train_runtime    train_samples_per_second    train_steps_per_second    total_flos    train_loss
[01.29 16:52:48] ┇ INFO    ┇             DeepKNLP ┇ >>    141     0.99           412.77                      43.935                     0.342   4.48307e+16       0.10958
[01.29 16:52:48] ┇ INFO    ┇             DeepKNLP ┇ [TRAINING] 100%|████████████████████| 141/141 [0:05:01<0:00:00, 0.45Hz] | (Ep 0.99)
[01.29 16:52:48] ┇ INFO    ┇             DeepKNLP ┇ Train result: TrainOutput(global_step=141, training_loss=0.10957955299539769, metrics={'train_runtime': 412.7698, 'train_samples_per_second': 43.935, 'train_steps_per_second': 0.342, 'total_flos': 4.483070918498714e+16, 'train_loss': 0.10957955299539769, 'epoch': 0.9947089947089947})
[01.29 16:52:48] ┇ INFO    ┇       chrisbase.data ┇ =========================================================================================================================================
[01.29 16:52:48] ┇ INFO    ┇       chrisbase.data ┇ [EXIT] python task2-nerG-trainer2.py --local_rank=0 --trainer_deepspeed configs/deepspeed/ds1_llama.json ($=00:07:14.732)
[01.29 16:52:48] ┇ INFO    ┇       chrisbase.data ┇ =========================================================================================================================================
